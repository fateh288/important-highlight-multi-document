{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "import scipy.cluster.hierarchy as hcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# topics = [\"ml1\", \"ml2\", \"ml3\", \"ml4\", \"ml5\", \"ml6\", \"ml7\", \"ml8\", \"ml9\", \"ml10\", \"ml11\", \"ml12\", \"ml13\", \"ml14\", \"ml15\", \"ml16\", \"ml17\", \"ml18\", \"ml19\"]\n",
    "# print \"The titles are \", topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./books/segnet1.txt\n",
      "./books/segnet2.txt\n",
      "./books/segnet3.txt\n",
      "114802\n",
      "114802\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "filePath = './books'\n",
    "fileCounter = len(glob.glob(filePath + \"*.txt\"))\n",
    "\n",
    "paragraphs = []\n",
    "topics = []\n",
    "for index, filename in enumerate(glob.glob(filePath + '/*.txt')):\n",
    "    print(filename)\n",
    "    file = open(filename, 'r')\n",
    "    content=file.readlines()\n",
    "    for lines in content :\n",
    "        flag= True\n",
    "        for character in lines :\n",
    "            if not (character.isalnum() or character == ' ' or character == '.' or character == ',' or character == '\\n') :\n",
    "                flag = False\n",
    "                break\n",
    "            if flag:\n",
    "                txt.append(lines.replace('\\n', ''))\n",
    "    txt = filter(None,txt)\n",
    "    txt=''.join(txt)\n",
    "    txt = txt.replace('\\n', '').split('.')\n",
    "    txt = filter(None, txt)\n",
    "    for i in np.arange(0, len(txt)):\n",
    "        topics.append('book:%d sentence:%d' % (index, i))\n",
    "        paragraphs.append(txt[i])\n",
    "\n",
    "print len(topics)\n",
    "print len(paragraphs)\n",
    "#print topics\n",
    "#print paragraphs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# paragraphs=[]\n",
    "# paragraphs.append(\"Machine learning is a type of artificial intelligence (AI) that provides computers with the ability to learn without being explicitly programmed.\")\n",
    "# paragraphs.append(\"Machine learning focuses on the development of computer programs that can change when exposed to new data.\")\n",
    "# paragraphs.append(\" The process of machine learning is similar to that of data mining. Both systems search through data to look for patterns.\")\n",
    "# paragraphs.append(\" However, instead of extracting data for human comprehension -- as is the case in data mining applications -- machine learning uses that data to detect patterns in data and adjust program actions accordingly.\")\n",
    "# paragraphs.append(\"  Machine learning algorithms are often categorized as being supervised or unsupervized. Supervised algorithms can apply what has been learned in the past to new data.\")\n",
    "# paragraphs.append(\"Unsupervised algorithms can draw inferences from datasets.\")\n",
    "# \n",
    "# paragraphs.append(\"Machine learning is the subfield of computer science that gives computers the ability to learn without being explicitly programmed. \")\n",
    "# paragraphs.append(\"Evolved from the study of pattern recognition and computational learning theory in artificial intelligence,[1] machine learning explores the study and construction of algorithms that can learn from and make predictions on data[2] â€“ such algorithms overcome following strictly static program instructions by making data driven predictions or decisions,[3]:2 through building a model from sample inputs.\")\n",
    "# paragraphs.append(\"Machine learning tasks are typically classified into three broad categories, depending on the nature of the learning signal or feedback available to a learning system.\")\n",
    "# paragraphs.append(\" These are[13]Supervised learning: The computer is presented with example inputs and their desired outputs, given by a teacher, and the goal is to learn a general rule that maps inputs to outputs.\")\n",
    "# paragraphs.append(\"Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input.\")\n",
    "# paragraphs.append(\" Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\")\n",
    "# \n",
    "# paragraphs.append(\"Machine learning studies computer algorithms for learning to do stuff. \")\n",
    "# paragraphs.append(\"We might, forinstance, be interested in learning to complete a task, or to make accurate predictions,or to behave intelligently.\")\n",
    "# paragraphs.append(\" The learning that is being done is always based on some sortof observations or data, such as examples (the most common case in this course), directexperience, or instruction.\")\n",
    "# paragraphs.append(\" So in general, machine learning is about learning to do better inthe future based on what was experienced in the past.\")\n",
    "# \n",
    "# paragraphs.append(\"Machine learning is an artificial intelligence (AI) discipline geared toward the technological development of human knowledge. \")\n",
    "# paragraphs.append(\"Machine learning allows computers to handle new situations via analysis, self-training, observation and experience.\") \n",
    "# paragraphs.append(\"Machine learning facilitates the continuous advancement of computing through exposure to new scenarios, testing and adaptation, while employing pattern and trend detection for improved decisions in subsequent (though not identical) situations.\")\n",
    "# \n",
    "# print \"The paragraphs are \", paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now we want to break a word into its root using a stemmer.\n",
    "#We use the snowball.\n",
    "#snowball is better than porter stemmer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#First the parageraph is tokenized by sentence then by word\n",
    "def tokenize(paragraph) :\n",
    "    tokenList = [word for sentence in nltk.sent_tokenize(paragraph) for word in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    filteredTokens = []\n",
    "    \n",
    "    for token in tokenList:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filteredTokens.append(token)\n",
    "    return filteredTokens\n",
    "\n",
    "#Next step would be to remove the useless tokens. Useless tokens are raw puntuation, numeric tokens, etc.\n",
    "def stem(filteredTokens) :\n",
    "    stemList = [stemmer.stem(tok) for tok in filteredTokens]\n",
    "    return stemList\n",
    "\n",
    "def tokenizeAndStem(paragraph) :\n",
    "    tokens = [word for sentence in nltk.sent_tokenize(paragraph) for word in nltk.word_tokenize(sentence)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):  #normal regex search\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 4: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-17ad7aed4d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtokenizedParagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizedParagraphList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizedParagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstemmedParagraphList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizedParagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtokenizedParagraphList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mstemmedParagraphList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-c9206afba622>\u001b[0m in \u001b[0;36mstem\u001b[0;34m(filteredTokens)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Next step would be to remove the useless tokens. Useless tokens are raw puntuation, numeric tokens, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilteredTokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mstemList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilteredTokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstemList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/stem/snowball.pyc\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# Map the different apostrophe characters to a single consistent one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         word = (word.replace(\"\\u2019\", \"\\x27\")\n\u001b[0m\u001b[1;32m    693\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\u2018\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\x27\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                     .replace(\"\\u201B\", \"\\x27\"))\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 4: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "tokenizedParagraphList = []\n",
    "stemmedParagraphList = []\n",
    "for i in paragraphs :\n",
    "    tokenizedParagraph = tokenize(i)\n",
    "    tokenizedParagraphList.extend(tokenizedParagraph)\n",
    "    stemmedParagraphList.extend(stem(tokenizedParagraph))\n",
    "print tokenizedParagraphList\n",
    "print stemmedParagraphList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a pandas DataFrame with the stemmed vocabulary as the index and the tokenized words as the column.\n",
    "#The benefit of this is it provides an efficient way to look up a stem and return a full token. \n",
    "#The downside here is that stems to tokens are one to many: the stem 'run' could be associated with 'ran', 'runs', 'running', etc.\n",
    "\n",
    "\n",
    "vocabFrame = pd.DataFrame({'words': tokenizedParagraphList}, index = stemmedParagraphList)\n",
    "print 'there are ' + str(vocabFrame.shape[0]) + ' items in vocab_frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 452 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n",
      "  (0, 16920)\t0.000165765559816\n",
      "  (0, 1355)\t0.000156156795383\n",
      "  (0, 29272)\t0.000156156795383\n",
      "  (0, 29290)\t0.000156156795383\n",
      "  (0, 29291)\t0.000156156795383\n",
      "  (0, 22271)\t0.000156156795383\n",
      "  (0, 10623)\t0.000156156795383\n",
      "  (0, 18346)\t0.000156156795383\n",
      "  (0, 22277)\t0.00643066369993\n",
      "  (0, 10625)\t0.00643066369993\n",
      "  (0, 18347)\t0.00843246695066\n",
      "  (0, 9690)\t0.0069569550735\n",
      "  (0, 33046)\t0.00622327899488\n",
      "  (0, 26740)\t0.00622327899488\n",
      "  (0, 32910)\t0.00653671661191\n",
      "  (0, 1092)\t0.000153063464154\n",
      "  (0, 22236)\t0.000156156795383\n",
      "  (0, 10617)\t0.000156156795383\n",
      "  (0, 7857)\t0.00640242861069\n",
      "  (0, 22250)\t0.00640242861069\n",
      "  (0, 10620)\t0.00640242861069\n",
      "  (0, 20211)\t0.00655858540607\n",
      "  (0, 1299)\t0.000156156795383\n",
      "  (0, 29268)\t0.000156156795383\n",
      "  (0, 22261)\t0.000156156795383\n",
      "  :\t:\n",
      "  (114796, 14365)\t0.588611135188\n",
      "  (114796, 14364)\t0.588611135188\n",
      "  (114796, 22205)\t0.554142457375\n",
      "  (114797, 31516)\t1.0\n",
      "  (114798, 12595)\t0.283042238213\n",
      "  (114798, 7396)\t0.283042238213\n",
      "  (114798, 7395)\t0.283042238213\n",
      "  (114798, 24762)\t0.275059478462\n",
      "  (114798, 12594)\t0.275059478462\n",
      "  (114798, 24761)\t0.275059478462\n",
      "  (114798, 12593)\t0.275059478462\n",
      "  (114798, 25112)\t0.270124145298\n",
      "  (114798, 25111)\t0.270124145298\n",
      "  (114798, 20522)\t0.225745500416\n",
      "  (114798, 7392)\t0.263617511895\n",
      "  (114798, 25110)\t0.26458955087\n",
      "  (114798, 20516)\t0.217540023216\n",
      "  (114798, 24756)\t0.222472232563\n",
      "  (114798, 20114)\t0.154323976493\n",
      "  (114799, 3821)\t0.447041967279\n",
      "  (114799, 24090)\t0.446589748886\n",
      "  (114799, 3865)\t0.446589748886\n",
      "  (114799, 3813)\t0.371491056677\n",
      "  (114799, 24078)\t0.365403306948\n",
      "  (114799, 3812)\t0.360199236466\n",
      "[u'//arxiv', u'//arxivorg/pdf/150504366pdf', u'//arxivorg/pdf/150504366pdf 2015http', u'//arxivorg/pdf/150504366pdf 2015http //arxivorg/pdf/150504366pdf', u'//arxivorg/pdf/150504366pdf see2', u'//arxivorg/pdf/150504366pdf see2 see2', u'//arxivorg/pdf/160506211v1pdf', u'//arxivorg/pdf/160506211v1pdf 2016imag', u'//arxivorg/pdf/160506211v1pdf 2016imag boundari', u'//arxivorg/pdf/160506211v1pdf 2016semant', u'//arxivorg/pdf/160506211v1pdf 2016semant segment', u'//david', u'//davidgrangierinfo/scen', u'//davidgrangierinfo/scen parsing/encod', u'//davidgrangierinfo/scen parsing/encod follow', u'//davidgrangierinfo/scen parsing/http', u'//davidgrangierinfo/scen parsing/http //davidgrangierinfo/scen', u'//develop', u'//developernvidia3', u'//developernvidia3 speedup', u'//developernvidia3 speedup gain', u'//developernvidiacom/cudnncom/cudnncom/cudnncomput', u'//developernvidiacom/cudnncom/cudnncom/cudnncomput layer', u'//developernvidiacom/cudnncom/cudnncom/cudnncomput layer usingcomput', u'//host', u'//mi', u'//miengcamacfig', u'//miengcamacfig segnet', u'//miengcamacfig segnet predict', u'//miengcamacuk/projects/segnet/', u'//miengcamacuk/projects/segnet/ segnet', u'//miengcamacuk/projects/segnet/ segnet code', u'//miengcamacuk/projects/segnet/convolut', u'//miengcamacuk/projects/segnet/convolut layer', u'//miengcamacuk/projects/segnet/convolut layer model', u'//miengcamacuk/projects/segnet/http', u'//miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/convolut', u'//miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/convolut layer', u'//miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/http', u'//miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/convolut', u'//miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/http', u'//miengcamacuk/projects/segnet/index', u'//miengcamacuk/projects/segnet/index terms\\u2014deep', u'//miengcamacuk/projects/segnet/index terms\\u2014deep convolut', u'//miengcamacuk/projects/segnet/to', u'//miengcamacuk/projects/segnet/to architectur', u'//miengcamacuk/projects/segnet/to architectur provid', u'//miengcamacuk/projects/segnet/tutorialhtml', u'//miengcamacuk/projects/segnet/tutorialhtml examplecaff', u'//miengcamacuk/projects/segnet/tutorialhtml examplecaff prototxt', u'//miengcamacuk/projects/segnet/tutorialhtml examplehttp', u'//miengcamacuk/projects/segnet/tutorialhtml examplehttp //miengcamacuk/projects/segnet/tutorialhtml', u'//miengcamacuk/projects/segnet/tutorialhtmlfor', u'//miengcamacuk/projects/segnet/tutorialhtmlfor code', u'//miengcamacuk/projects/segnet/tutorialhtmlfor code evalu', u'//miengcamacuk/projects/segnet/tutorialhtmlstatist', u'//miengcamacuk/projects/segnet/tutorialhtmlstatist http', u'//miengcamacuk/projects/segnet/tutorialhtmlstatist http //miengcamacuk/projects/segnet/tutorialhtmlfor', u'//miengcamacuk/projects/segnet/tutorialhtmlstatist http //miengcamacuk/projects/segnet/tutorialhtmlstatist', u'//miengcamacuk/projects/segnet/uk/projects/segnet/advantag', u'//miengcamacuk/projects/segnet/uk/projects/segnet/advantag improv', u'//miengcamacuk/projects/segnet/uk/projects/segnet/advantag improv boundari', u'00561v3', u'00561v3 cs', u'02680v2', u'02680v2 cs', u'06211v1', u'07293v1', u'07293v1 cs', u'0bayesian', u'0bayesian segnet', u'0bayesian segnet work', u'0mioumioumioumioumiou88', u'0rgb-drgb-drgb-dgupta', u'0rgb-drgb-drgb-dgupta et', u'0rgb-drgb-drgb-dgupta et al', u'0segnet', u'0segnet segnet', u'0segnet segnet segnet', u'0segnet sm', u'0segnet sm segnet', u'0tabl', u'0tabl nyu', u'0tabl nyu v2', u'100epoch', u'100epoch dataset', u'100epoch dataset perform', u'100of', u'100of optim', u'100of optim perform', u'1024featur', u'1024featur size', u'1024featur size fulli', u'1024so', u'1024so enabl', u'1024so enabl train', u'1090\\u2013hierarchi', u'1090\\u2013hierarchi visual', u'1090\\u2013hierarchi visual recognit', u'10epoch', u'10epoch layer', u'10epoch layer empir', u'10the', u'10the optim', u'10the optim run', u'11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn', u'11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn learnt', u'11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn learnt deconv', u'119735973597359735973518061806180618061806539539539539deconvnet', u'119735973597359735973518061806180618061806539539539539deconvnet deconvnet', u'119735973597359735973518061806180618061806539539539539deconvnet deconvnet deconvnet', u'11mb', u'11mb smaller', u'11mb smaller use', u'11semant', u'11semant class', u'11semant class road', u'11springer', u'11springer new', u'11springer new york', u'11the', u'11the camvid', u'11the camvid kitti', u'129\\u2013and', u'129\\u2013and natur', u'129\\u2013and natur languag', u'12m', u'12m paramet', u'12m paramet compar', u'134m', u'134m 147m', u'134m 147m compar', u'13convolut', u'13convolut layer', u'13convolut layer vgg16', u'13of', u'13of convolut', u'13of convolut layer', u'140k', u'140k buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t', u'140k buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t 2tabl', u'140k segnet', u'140k segnet 35k', u'140k85', u'140k8595', u'140k8595 140k8595', u'140k8595 140k8595 140k8595', u'140k8595 140k8595 140kdeeplab-largefov-densecrf', u'140k8595 140kdeeplab-largefov-densecrf', u'140k8595 140kdeeplab-largefov-densecrf deeplab-largefov-densecrf', u'140k88', u'140k8881', u'140k8881 140k8881', u'140k8881 140k8881 140k8881', u'140k8881 140k8881 140kdeeplab-largefov', u'140k8881 140kdeeplab-largefov', u'140k8881 140kdeeplab-largefov deeplab-largefov', u'140k89', u'140k8971', u'140k8971 140k8971', u'140k8971 140k8971 140k8971', u'140k8971 140k8971 140kfcnfcnfcnfcn8197', u'140k8971 140kfcnfcnfcnfcn8197', u'140k8971 140kfcnfcnfcnfcn8197 200k8197', u'140kdeeplab-largefov', u'140kdeeplab-largefov deeplab-largefov', u'140kdeeplab-largefov deeplab-largefov deeplab-largefov', u'140kdeeplab-largefov-densecrf', u'140kdeeplab-largefov-densecrf deeplab-largefov-densecrf', u'140kdeeplab-largefov-densecrf deeplab-largefov-densecrf deeplab-largefov-densecrf', u'140kfcnfcnfcnfcn81', u'140kfcnfcnfcnfcn8197', u'140kfcnfcnfcnfcn8197 200k8197', u'140kfcnfcnfcnfcn8197 200k8197 200k8197', u'1468a', u'1468a similar', u'1468a similar architectur', u'147m', u'147m compar', u'147m compar othernetwork', u'147m compar otherrec', u'14mad', u'14mad hoc', u'14mad hoc featur', u'14mparamet', u'14mparamet method', u'14mparamet method use', u'150epoch', u'150epoch observ', u'150epoch observ accuraci', u'150we', u'150we report', u'150we report maximum', u'159731973197319731973118721872187218721872877877877877tabl', u'159731973197319731973118721872187218721872877877877877tabl 6tabl', u'159731973197319731973118721872187218721872877877877877tabl 6tabl 6tabl', u'160k83', u'160k8321', u'160k8321 160k8321', u'160k8321 160k8321 160k8321', u'160k8321 160k8321 160kdeconvnet', u'160k8321 160kdeconvnet', u'160k8321 160kdeconvnet deconvnet', u'160kdeconvnet', u'160kdeconvnet deconvnet', u'160kdeconvnet deconvnet deconvnet', u'17mb', u'17mb store', u'17mb store use', u'180k', u'180k metric', u'180k metrics3208', u'180k metrics3208 180k', u'180k metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi', u'180k metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi clear', u'1915\\u20131929,201320132013201320132013n', u'1915\\u20131929,201320132013201320132013n hft', u'1915\\u20131929,201320132013201320132013n hft h', u'19mb', u'19mb storagereduct', u'19mb storagereduct featur', u'19mb storagesegnet', u'19mb storagesegnet hand', u'1abs/1409', u'1abs/14091556', u'1abs/14091556 1abs/14091556', u'1abs/14091556 1abs/14091556 1scene', u'1abs/14091556 1scene', u'1abs/14091556 1scene understand', u'1are', u'1are shown', u'1are shown fig', u'1arxiv:1301', u'1bayesian', u'1bayesian segnet', u'1bayesian segnet work', u'1booksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgesegnet', u'1booksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgesegnet segnet', u'1booksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgesegnet segnet segnet', u'1boost', u'1boost boost', u'1boost boost boost', u'1column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecarcarcarcar89', u'1comparison', u'1comparison decod', u'1comparison decod variant', u'1decod', u'1decod variantsdecod', u'1decod variantsdecod variantsdecod', u'1dropout', u'1dropout classifierdropout', u'1dropout classifierdropout classifierdropout', u'1fcn-8', u'1fcn-8 fcn-8', u'1fcn-8 fcn-8 fcn-8', u'1i', u'1i goodfellow', u'1i goodfellow r', u'1local', u'1local label', u'1local label descriptor', u'1note', u'1note comput', u'1note comput scienc', u'1pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianskyskyskysky61', u'1probabl', u'1probabl distribut', u'1road', u'1road scene', u'1road scene segmentationroad', u'1scene', u'1scene understand', u'1scene understand bmvc', u'1structur', u'1structur random', u'1structur random forest', u'1tabl', u'1tabl 1comparison', u'1tabl 1comparison decod', u'1tabl 1tabl', u'1tabl 1tabl 1comparison', u'1tabl 1tabl 1tabl', u'1tabl quantit', u'1tabl quantit result', u'1the', u'1the remaind', u'1the remaind paper', u'1wallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoordoordoordoordoorwindowwindowwindowwindowwindowwindowwindowbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfpicturepicturepicturepicturepicturepicturepicturepicturecountercountercountercountercountercountercountercounterblindsblindsblindsblindsblindsblindsblindsdeskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor', u'1wallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoordoordoordoordoorwindowwindowwindowwindowwindowwindowwindowbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfpicturepicturepicturepicturepicturepicturepicturepicturecountercountercountercountercountercountercountercounterblindsblindsblindsblindsblindsblindsblindsdeskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor matfloor', u'1wallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoordoordoordoordoorwindowwindowwindowwindowwindowwindowwindowbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfbookshelfpicturepicturepicturepicturepicturepicturepicturepicturecountercountercountercountercountercountercountercounterblindsblindsblindsblindsblindsblindsblindsdeskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor matfloor matfloor', u'1what', u'1what best', u'1what best multi-stag', u'2,88and', u'2,88and lopezand', u'2,88and lopezand lopezand', u'2000a', u'2000a reader', u'2000a reader inform', u'2000he', u'2000he becam', u'2000he becam fellow', u'2004and', u'2004and semant', u'2004and semant consist', u'2004pp', u'2004pp 2004and', u'2004pp 2004and semant', u'2004pp 2004pp', u'2004pp 2004pp 2004and', u'2004pp 2004pp 2004pp', u'2007recognit', u'2007recognit cvpr', u'2007recognit cvpr 2007recognit', u'2007recognit cvpr 2007segment', u'2007segment', u'2007segment wild', u'2007segment wild comput', u'2008imag', u'2008imag categor', u'2008imag categor segment', u'2008in', u'2008in bmvc', u'2008in bmvc 2009in', u'2008no', u'2008no pp', u'2008no pp 2008no', u'2008no pp 2008u', u'2008u', u'2008u frank', u'2008u frank s', u'2008use', u'2008use structur', u'2008use structur motion', u'2009a', u'2009a databas', u'2009a databas web-bas', u'2009and', u'2009and semant', u'2009and semant consist', u'2009for', u'2009for scene', u'2009for scene pars', u'2009in', u'2009in bmvc', u'2009in bmvc 2009in', u'2009in bmvc 2009where', u'2009semant', u'2009semant feedback', u'2009semant feedback convolut', u'2009surpass', u'2009surpass human-level', u'2009surpass human-level perform', u'2009understand', u'2009understand benchmark', u'2009understand benchmark suit', u'2009where', u'2009where mani', u'2009where mani combin', u'200k67', u'200k6731', u'200k6731 200k6731', u'200k6731 200k6731 200k6731', u'200k6731 200k6731 200kdeconvnet', u'200k6731 200kdeconvnet', u'200k6731 200kdeconvnet deconvnet', u'200k81', u'200k8197', u'200k8197 200k8197', u'200k8197 200k8197 200k8197', u'200k8197 200k8197 200kfcn', u'200k8197 200kfcn', u'200k8197 200kfcn learnt', u'200kdeconvnet', u'200kdeconvnet deconvnet', u'200kdeconvnet deconvnet deconvnet', u'200kfcn', u'200kfcn learnt', u'200kfcn learnt deconv', u'2010and', u'2010and y', u'2010and y lecun', u'2010class-label', u'2010class-label random', u'2010class-label random forest', u'2010network', u'2010network cvpr', u'2010network cvpr pp', u'2010network imag', u'2010network imag super-resolut', u'2010pp', u'2010pp 2010class-label', u'2010pp 2010class-label random', u'2010pp 2010pp', u'2010pp 2010pp 2010class-label', u'2010pp 2010pp 2010pp', u'2010recognit', u'2010recognit nip', u'2010recognit nip pp', u'2010scene', u'2010scene use', u'2010scene use dens', u'201111springer', u'201111springer new', u'201111springer new york', u'2011imag', u'2011imag label', u'2011imag label cvpr', u'2011multimod', u'2011multimod deep', u'2011multimod deep learn', u'2011potenti', u'2011potenti nip', u'2011potenti nip 2011imag', u'2011potenti nip 2011potenti', u'2011pp', u'2011pp ieee', u'2011pp ieee 2011pp', u'2011pp ieee 2011scene', u'2011s', u'2011s zheng', u'2011s zheng s', u'2011scene', u'2011scene use', u'2011scene use dens', u'2012algorithm', u'2012algorithm cvpr', u'2012algorithm cvpr pp', u'2012drive', u'2012drive kitti', u'2012drive kitti vision', u'2012indoor', u'2012indoor scene', u'2012indoor scene rgb-d', u'2012pp', u'2012pp springer', u'2012pp springer 2012pp', u'2012pp springer 2012segment', u'2012segment', u'2012segment deep', u'2012segment deep pars', u'2012springer', u'2012springer 2012drive', u'2012springer 2012drive kitti', u'2012springer 2012springer', u'2012springer 2012springer 2012drive', u'2012springer 2012springer 2012springer', u'2013algorithm', u'2013algorithm cvpr', u'2013algorithm cvpr pp', u'2013evalu', u'2013evalu measur', u'2013evalu measur semant', u'2013ieee', u'2013ieee 2013ieee', u'2013ieee 2013ieee 2013ieee', u'2013ieee 2013ieee 2013multiscal', u'2013ieee 2013multiscal', u'2013ieee 2013multiscal featur', u'2013multiscal', u'2013multiscal featur', u'2013multiscal featur learn', u'2013semant', u'2013semant segment', u'2013semant segment https', u'2014a', u'2014a karpathi', u'2014a karpathi khosla', u'2014and', u'2014and support', u'2014and support infer', u'2014c', u'2014c farabet', u'2014c farabet c', u'2014confer', u'2014confer multimedia', u'2014confer multimedia pp', u'2014context', u'2014context comput', u'2014context comput vision\\u2013eccv', u'2014deep', u'2014deep structur', u'2014deep structur model', u'2014edg', u'2014edg comput', u'2014edg comput vision\\u2013eccv', u'2014evalu', u'2014evalu measur', u'2014evalu measur semant', u'2014for', u'2014for scene', u'2014for scene label', u'2014imag', u'2014imag label', u'2014imag label cvpr', u'2014imag use', u'2014imag use multi-scal', u'2014in', u'2014in cvpr', u'2014in cvpr 2016in', u'2014indoor', u'2014indoor scene', u'2014indoor scene rgb-d', u'2014j', u'2014j long', u'2014j long e', u'2014label', u'2014label descriptor', u'2014label descriptor exampl', u'2014large-scal', u'2014large-scal imag', u'2014large-scal imag recognit', u'2014network', u'2014network train', u'2014network train reduc', u'2014on', u'2014on deep', u'2014on deep vision', u'2014preprint', u'2014preprint arxiv:14114734', u'2014preprint arxiv:14114734 2014in', u'2014preprint arxiv:14114734 2014preprint', u'2014publish', u'2014publish 2014publish', u'2014publish 2014publish 2014publish', u'2014publish 2014publish 2014r', u'2014publish 2014r', u'2014publish 2014r socher', u'2014r', u'2014r socher', u'2014r socher c', u'2014recognit', u'2014recognit indoor', u'2014recognit indoor scene', u'2015arxiv', u'2015arxiv preprint', u'2015arxiv preprint arxiv:150202734', u'2015arxiv:150401013', u'2015arxiv:150401013 2015arxiv:150401013', u'2015arxiv:150401013 2015arxiv:150401013 2015arxiv:150401013', u'2015arxiv:150401013 2015arxiv:150401013 2015object', u'2015arxiv:150401013 2015object', u'2015arxiv:150401013 2015object segment', u'2015arxiv:1505', u'2015arxiv:150507293v1', u'2015arxiv:150507293v1 cscv', u'2015arxiv:150507293v1 cscv 2015arxiv:150507293v1', u'2015arxiv:150507293v1 cscv 2015vijay', u'2015best', u'2015best multi-stag', u'2015best multi-stag architectur', u'2015better', u'2015better corr', u'2015better corr vol', u'2015c', u'2015c liang-chieh', u'2015c liang-chieh g', u'2015c szegedi', u'2015c szegedi w', u'2015comput', u'2015comput vision', u'2015comput vision pp', u'2015confer', u'2015confer comput', u'2015confer comput vision', u'2015connect', u'2015connect crfs', u'2015connect crfs iclr', u'2015cvpr', u'2015cvpr pp', u'2015cvpr pp 2015cvpr', u'2015cvpr pp 2015k', u'2015d', u'2015d eigen', u'2015d eigen r', u'2015edg', u'2015edg comput', u'2015edg comput vision\\u2013eccv', u'2015for', u'2015for biomed', u'2015for biomed imag', u'2015h', u'2015h noh', u'2015h noh s', u'2015http', u'2015http //arxivorg/pdf/150504366pdf', u'2015http //arxivorg/pdf/150504366pdf 2015http', u'2015http //arxivorg/pdf/150504366pdf see2', u'2015iccv', u'2015iccv pp', u'2015iccv pp 2015iccv', u'2015iccv pp 2015s', u'2015insight', u'2015insight applic', u'2015insight applic deep', u'2015intern', u'2015intern confer', u'2015intern confer comput', u'2015journal', u'2015journal comput', u'2015journal comput vision', u'2015k', u'2015k simonyan', u'2015k simonyan zisserman', u'2015label', u'2015label common', u'2015label common multi-scal', u'2015label corr', u'2015label corr vol', u'2015object', u'2015object segment', u'2015object segment fine-grain', u'2015on', u'2015on comput', u'2015on comput vision', u'2015p', u'2015p dolla\\u0301r', u'2015p dolla\\u0301r c', u'2015pp', u'2015pp 2015pp', u'2015pp 2015pp 2015pp', u'2015pp 2015pp 2015semi-supervis', u'2015pp 2015semi-supervis', u'2015pp 2015semi-supervis learn', u'2015s', u'2015s guadarrama', u'2015s guadarrama t', u'2015semant', u'2015semant segment', u'2015semant segment corr', u'2015semant segment cvpr', u'2015semant segment iccv', u'2015semi-supervis', u'2015semi-supervis learn', u'2015semi-supervis learn dcnn', u'2015uncertainti', u'2015uncertainti deep', u'2015uncertainti deep convolut', u'2015understand', u'2015understand arxiv', u'2015understand arxiv preprint', u'2015v', u'2015v badrinarayanan', u'2015v badrinarayanan handa', u'2015vijay', u'2015vijay badrinarayanan', u'2015vijay badrinarayanan ankur', u'2015vijay badrinarayanan obtain', u'2015vol', u'2015vol abs/150203167', u'2015vol abs/150203167 2015semant', u'2015vol abs/150203167 2015vol', u'2015w', u'2015w liu', u'2015w liu rabinovich', u'2016agk34', u'2016agk34 vb292', u'2016agk34 vb292 rc10001', u'2016arxiv:1511', u'2016arxiv:151100561v3', u'2016arxiv:151100561v3 cscv', u'2016arxiv:151100561v3 cscv oct', u'2016imag', u'2016imag boundari', u'2016imag boundari use', u'2016in', u'2016in cvpr', u'2016in cvpr 2016in', u'2016in cvpr 2016insight', u'2016insight', u'2016insight applic', u'2016insight applic deep', u'2016potenti', u'2016potenti nip', u'2016potenti nip 2011potenti', u'2016semant', u'2016semant segment', u'2016semant segment https', u'2016urban', u'2016urban scene', u'2016urban scene understand', u'2016vijay', u'2016vijay badrinarayanan', u'2016vijay badrinarayanan alex', u'2146\\u2013best', u'2146\\u2013best multi-stag', u'2146\\u2013best multi-stag architectur', u'224x224', u'224x224 pixel', u'224x224pixel', u'224x224the', u'224x224the hardest', u'224x224the hardest segment', u'2273towel', u'2273towel shower', u'2273towel shower curtaintowel', u'22l', u'22l iteratur', u'22l iteratur r', u'22nd', u'22nd acm', u'22nd acm internationalconfer', u'22nd acm internationalfast', u'2348\\u2013advanc', u'2348\\u2013advanc neural', u'2348\\u2013advanc neural inform', u'240k66', u'240k6696', u'240k6696 240k6696', u'240k6696 240k6696 240k6696', u'240k6696 240k6696 240kfcn', u'240k6696 240kfcn', u'240k6696 240kfcn learnt', u'240k70', u'240k7070', u'240k7070 240k7070', u'240k7070 240k7070 240k7070', u'240k7070 240k7070 240kdeeplab-largefov-densecrf', u'240k7070 240kdeeplab-largefov-densecrf', u'240k7070 240kdeeplab-largefov-densecrf deeplab-largefov-densecrf', u'240k7073', u'240k7073 240k7073', u'240k7073 240k7073 240k7073', u'240k7073 240k7073 240kdeeplab-largefov', u'240k7073 240kdeeplab-largefov', u'240k7073 240kdeeplab-largefov deeplab-largefov', u'240kdeeplab-largefov', u'240kdeeplab-largefov deeplab-largefov', u'240kdeeplab-largefov deeplab-largefov deeplab-largefov', u'240kdeeplab-largefov-densecrf', u'240kdeeplab-largefov-densecrf deeplab-largefov-densecrf', u'240kdeeplab-largefov-densecrf deeplab-largefov-densecrf deeplab-largefov-densecrf', u'240kfcn', u'240kfcn learnt', u'240kfcn learnt deconv', u'260k85', u'260k8526', u'260k8526 260k8526', u'260k8526 260k8526 260k8526', u'260k8526 260k8526 260ktabl', u'260k8526 260ktabl', u'260k8526 260ktabl 3tabl', u'260ktabl', u'260ktabl 3tabl', u'260ktabl 3tabl 3tabl', u'29deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor', u'29deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor mat', u'29deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor mat cloth', u'2a', u'2acm', u'2advanc', u'2advanc neural', u'2advanc neural inform', u'2arxiv:1301', u'2arxiv:1411', u'2class-label', u'2class-label random', u'2class-label random forest', u'2column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole89', u'2dropout', u'2dropout central', u'2dropout central enc-dec', u'2eccv', u'2eccv page', u'2featur', u'2featur map', u'2featur map valu', u'2for', u'2for camera', u'2for camera reloc', u'2for pool', u'2for pool indic', u'2i', u'2i 2featur', u'2i 2featur map', u'2i 2i', u'2i 2i 2featur', u'2i 2i 2i', u'2ieee', u'2imag', u'2imag understand', u'2imag understand multi-class', u'2inform', u'2inform process', u'2inform process page', u'2journal', u'2journal comput', u'2journal comput vision', u'2m', u'2m paramet', u'2m paramet compar', u'2n/an/an/abayesian', u'2n/an/an/abayesian segnet', u'2n/an/an/abayesian segnet model', u'2nd', u'2nd edit', u'2nd edit 4network', u'2nd edit 4springer', u'2network', u'2network train', u'2network train reduc', u'2pool', u'2pool window', u'2pool window creat', u'2quantit', u'2quantit comparison', u'2quantit comparison segnet', u'2secs/fram', u'2secs/fram bulk', u'2secs/fram bulk comput', u'2segnet', u'2segnet layer', u'2segnet layer 4segnet', u'2semant', u'2semant segment', u'2statist', u'2statist model', u'2sun', u'2sun rgb-d', u'2sun rgb-d indoor', u'2tabl', u'2tabl 2quantit', u'2tabl 2quantit comparison', u'2tabl 2tabl', u'2tabl 2tabl 2quantit', u'2tabl 2tabl 2tabl', u'2trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw', u'2trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw use', u'2trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw use camvid', u'2where', u'2where mani', u'2where mani combin', u'31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet', u'31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet deconvnet', u'31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet deconvnet deconvnet', u'32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw', u'32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw use', u'32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw use camvid', u'3354\\u20133361,201220122012201220122012imag', u'3354\\u20133361,201220122012201220122012imag categor', u'3354\\u20133361,201220122012201220122012imag categor segment', u'3376\\u20133385,201520152015201520152015network', u'3376\\u20133385,201520152015201520152015network cvpr', u'3376\\u20133385,201520152015201520152015network cvpr pp', u'33a', u'33a rchitecturea', u'33a rchitecturea rchitecturea', u'33analysi', u'33analysi sec', u'33analysi sec 33analysi', u'33analysi sec 33surpris', u'33surpris', u'33surpris deeplab-largefov', u'33surpris deeplab-largefov train', u'35k', u'35k dataset', u'35k dataset train', u'35k imag', u'35k imag particular', u'35ms', u'35ms frameand', u'35ms frameand bayesian', u'35ms framefor', u'35ms framefor sampl', u'360x480', u'360x480 pixel', u'360x480 pixel train', u'360\\xd7480been', u'360\\xd7480been hand-label', u'360\\xd7480been hand-label class', u'360\\xd7480to', u'360\\xd7480to make', u'360\\xd7480to make compat', u'367camvid', u'367camvid road', u'367camvid road scene', u'367train', u'367train imag', u'367train imag test', u'380k59', u'380k5962', u'380k5962 380k5962', u'380k5962 380k5962 380k5962', u'380k5962 380k5962 380ktabl', u'380k5962 380ktabl', u'380k5962 380ktabl 4tabl', u'380ktabl', u'380ktabl 4tabl', u'380ktabl 4tabl 4tabl', u'3analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto', u'3analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto compar', u'3analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto compar quantit', u'3and', u'3and algorithm', u'3and algorithm cvpr', u'3arxiv', u'3arxiv preprint', u'3arxiv preprint arxiv:1411', u'3boost', u'3boost pairwis', u'3boost pairwis crf', u'3comput', u'3comput vision\\u2013eccv', u'3comput vision\\u2013eccv page', u'3cvpr', u'3cvpr page', u'3cvpr page 6cvpr', u'3cvpr page ieee', u'3d', u'3d semant', u'3d semant map', u'3fcn-32s', u'3fcn-32s rgb-d', u'3fcn-32s rgb-d fcn-32s', u'3from', u'3from singl', u'3from singl imag', u'3global', u'3global avg', u'3in', u'3in cvpr', u'3in cvpr workshop', u'3learn', u'3learn 3cvpr', u'3learn 3cvpr page', u'3learn 3learn', u'3learn 3learn 3cvpr', u'3learn 3learn 3learn', u'3m', u'3m mathieu', u'3m mathieu y', u'3multimod', u'3multimod deep', u'3multimod deep learn', u'3n/an/argbrgbrgbrgbliu', u'3n/an/argbrgbrgbrgbliu et', u'3n/an/argbrgbrgbrgbliu et al', u'3network', u'3network scene', u'3network scene label', u'3page', u'3page springer', u'3page springer 3from', u'3page springer 3page', u'3pars', u'3pars multiscal', u'3pars multiscal featur', u'3pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar46', u'3practic', u'3practic applic', u'3practic applic random', u'3preprint', u'3preprint arxiv:1406', u'3preprint arxiv:14062283', u'3preprint arxiv:14062283 3pars', u'3preprint arxiv:14062283 3preprint', u'3probabl', u'3probabl distribut', u'3quantit', u'3quantit comparison', u'3quantit comparison deep', u'3repres', u'3repres model', u'3repres model uncertainti', u'3roadroadroadroadroadskyskyskyskyboost', u'3roadroadroadroadroadskyskyskyskyboost pairwis', u'3roadroadroadroadroadskyskyskyskyboost pairwis crf', u'3roadroadroadroadroadtreetreetreetreetree46', u'3segnet', u'3segnet layersegnet', u'3segnet layersegnet layersegnet', u'3segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition1', u'3tabl', u'3tabl 3quantit', u'3tabl 3quantit comparison', u'3tabl 3tabl', u'3tabl 3tabl 3quantit', u'3tabl 3tabl 3tabl', u'3tabl architectur', u'3tabl architectur variant', u'3to', u'3to highest', u'3to highest miou', u'3top', u'3top n', u'3top n featur', u'3understand', u'3understand benchmark', u'3understand benchmark suit', u'3use', u'3use divis', u'3use divis normal', u'3we', u'3we observ', u'3we observ predict', u'3what', u'3what best', u'3what best multi-stag', u'4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor', u'4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor mat', u'4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor mat cloth', u'40k', u'40k 80k', u'40k 80k 80k', u'40n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u221760', u'43d', u'43d seman', u'43d seman map', u'441414141road', u'441414141road scene', u'441414141road scene segmentationroad', u'447\\u2013object', u'447\\u2013object segment', u'447\\u2013object segment fine-grain', u'44the', u'44the best', u'44the best perform', u'4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob', u'4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob avgglob', u'4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob avgglob avgglob', u'47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl', u'47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl 6tabl', u'47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl 6tabl 6tabl', u'480imag', u'480imag task', u'480imag task 480imag', u'480imag task 480we', u'480we', u'480we benchmark', u'480we benchmark segnet', u'4as', u'4as compar', u'4as compar segnet', u'4cci/u42', u'4comput', u'4comput vision', u'4crf', u'4crf base', u'4crf base approachescrf', u'4d', u'4deconvnet', u'4deconvnet later', u'4deconvnet later paper', u'4dens', u'4dens depth', u'4dens depth map', u'4dropout', u'4dropout encoderdropout', u'4dropout encoderdropout encoderdropout', u'4each', u'4each layer', u'4each layer dure', u'4epoch', u'4epoch layer', u'4epoch layer empir', u'4epoch margin', u'4epoch margin note', u'4fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol61', u'4forest', u'4forest imag', u'4forest imag categor', u'4fr/', u'4fr/ mschmidt/software/minfunc', u'4fr/ mschmidt/software/minfunc html', u'4gaussian', u'4gaussian edg', u'4gaussian edg potenti', u'4icml', u'4icml page', u'4icml page 4icml', u'4icml page 4use', u'4mad', u'4mad hoc', u'4mad hoc featur', u'4model', u'4model predict', u'4model predict shown', u'4mparamet', u'4n/a98', u'4network', u'4network arxiv', u'4network arxiv preprint', u'4network scene', u'4network scene label', u'4nip', u'4nip page', u'4nip page 4nip', u'4nip page 4torr', u'4of', u'4of non-zero', u'4of non-zero featur', u'4of urban', u'4of urban scene', u'4quantit', u'4quantit comparison', u'4quantit comparison deep', u'4segment', u'4segment support', u'4segment support infer', u'4segment tasksegment', u'4segment tasksegment tasksegment', u'4segnet', u'4segnet layer', u'4segnet layer 4segnet', u'4segnet layer 505tabl', u'4segnet segnet', u'4segnet segnet segnet', u'4springer', u'4springer new', u'4springer new york', u'4tabl', u'4tabl 4quantit', u'4tabl 4quantit comparison', u'4tabl 4tabl', u'4tabl 4tabl 4quantit', u'4tabl 4tabl 4tabl', u'4tabl bayesian', u'4tabl bayesian segnet', u'4th', u'4th layer', u'4th layer segnet', u'4this', u'4this increas', u'4this increas consequ', u'4thlayer', u'4thlayer featur', u'4thlayer featur predict', u'4torr', u'4torr mani', u'4torr mani combin', u'4use', u'4use divis', u'4use divis normal', u'4we', u'4we use', u'4we use mini-batch', u'5050tabl', u'5050tabl sun', u'5050tabl sun indoor', u'5050test', u'5050test imag', u'5050test imag indoor', u'505tabl', u'505tabl quantit', u'505tabl quantit result', u'507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238', u'507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238 576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448', u'507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238 576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448 848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439', u'5243d', u'5243d seman', u'5243d seman map', u'528learn', u'528learn upsampl', u'528learn upsampl bilinear', u'542segnet', u'542segnet layer', u'542segnet layer 4segnet', u'55d', u'55d iscuss', u'55d iscuss futur', u'576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448', u'576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448 848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439', u'576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448 848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439 678tabl', u'579797900comput', u'579797900comput parallel', u'579797900comput parallel gpu', u'585858500mont', u'585858500mont carlo', u'585858500mont carlo dropout', u'587tabl', u'587tabl quantit', u'587tabl quantit result', u'599upsampl', u'599upsampl use', u'599upsampl use max-pool', u'5arxiv:1502', u'5class', u'5class averag', u'5class averag accuraci', u'5comput', u'5comput vision', u'5comput vision\\u2013eccv', u'5comput vision\\u2013eccv page', u'5convolut', u'5convolut encoder-decod', u'5convolut encoder-decod architectur', u'5eigen', u'5eigen et', u'5eigen et al', u'5fast', u'5fast featur', u'5fast featur embed', u'5for', u'5for camera', u'5for camera reloc', u'5fr/', u'5fr/ mschmidt/software/minfunc', u'5fr/ mschmidt/software/minfunc html', u'5in', u'5in comput', u'5in comput vision\\u2013eccv', u'5inform', u'5inform process', u'5inform process page', u'5k', u'5k dataset', u'5k dataset train', u'5k imag', u'5label', u'5labelm', u'5labelm databas', u'5labelm databas web-bas', u'5local', u'5local label', u'5local label descriptor', u'5mont', u'5mont carlo', u'5mont carlo dropout', u'5n/an/a16', u'5n/an/a61', u'5network', u'5network scene', u'5network scene pars', u'5neural', u'5neural decis', u'5neural decis forest', u'5p', u'5page', u'5page ieee', u'5page ieee 5network', u'5page ieee 5page', u'5s', u'5show', u'5show mean', u'5show mean iou', u'5show result', u'5show result compar', u'5side-walkside-walkside-walkside-walk68', u'5side-walkside-walkside-walkside-walksign-symbolsign-symbolsign-symbolsign-symbol68', u'5springer', u'5tabl', u'5tabl 5class', u'5tabl 5class averag', u'5tabl 5tabl', u'5tabl 5tabl 5class', u'5tabl 5tabl 5tabl', u'5tabl pascal', u'5tabl pascal voc12', u'5their', u'5their train', u'5their train open', u'5where', u'5where mani', u'5where mani combin', u'5with', u'5with score', u'5with score comput', u'5yuill', u'611segnet', u'611segnet deep', u'611segnet deep convolutionalsegnet', u'622l', u'622l iteratur', u'622l iteratur r', u'63d', u'63d seman', u'63d seman map', u'65n/a23', u'66c', u'66c onclusionc', u'66c onclusionc onclusionc', u'678tabl', u'678tabl 1tabl', u'678tabl 1tabl 1tabl', u'689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331', u'689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331 528learn', u'689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331 528learn upsampl', u'691boost', u'691boost boost', u'691boost boost boost', u'6a', u'6a comparison', u'6a comparison comput', u'6and', u'6and recognit', u'6and recognit use', u'6arxiv', u'6arxiv preprint', u'6arxiv preprint arxiv:1411', u'6class', u'6class avg', u'6classif', u'6classif deep', u'6classif deep convolut', u'6comput', u'6comput vision\\u2013eccv', u'6comput vision\\u2013eccv page', u'6convolut', u'6convolut network', u'6convolut network eccv', u'6convolut network imag', u'6cvpr', u'6cvpr page', u'6cvpr page 6cvpr', u'6cvpr page 6into', u'6eccv', u'6eccv marseill', u'6eccv marseill 6eccv', u'6eccv marseill 6semant', u'6eccv page', u'6fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction1', u'6for', u'6for large-scal', u'6for large-scal imag', u'6for object', u'6for object segment', u'6for semant', u'6for semant segment', u'6gaussian', u'6gaussian edg', u'6gaussian edg potenti', u'6h', u'6h jiang', u'6h jiang local', u'6imag', u'6imag categor', u'6imag categor segment', u'6imag label', u'6imag label eccv', u'6into', u'6into geometr', u'6into geometr semant', u'6journal', u'6journal comput', u'6journal comput vision', u'6label', u'6label iccv', u'6label iccv page', u'6mean', u'6mean i/umean', u'6mean i/umean i/umean', u'6pointer', u'6pointer futur', u'6pointer futur work', u'6prl', u'6prl 6and', u'6prl 6and recognit', u'6prl 6prl', u'6prl 6prl 6and', u'6prl 6prl 6prl', u'6rgb-hhargb-hhargb-hhafcn-16', u'6rgb-hhargb-hhargb-hhafcn-16 rgb-hha', u'6rgb-hhargb-hhargb-hhafcn-16 rgb-hha fcn-16s', u'6segnet', u'6segnet deep', u'6segnet deep convolut', u'6segnet r', u'6segnet r segnet', u'6semant', u'6semant imag', u'6semant imag label', u'6space-tim', u'6space-tim crf', u'6structur', u'6structur class-label', u'6structur class-label random', u'6super', u'6super pars', u'6super pars super', u'6tabl', u'6tabl 6a', u'6tabl 6a comparison', u'6tabl 6tabl', u'6tabl 6tabl 6a', u'6tabl 6tabl 6tabl', u'716803680368036803680310521052105210521052117117117117deeplab-largefov', u'716803680368036803680310521052105210521052117117117117deeplab-largefov deeplab-largefov', u'716803680368036803680310521052105210521052117117117117deeplab-largefov deeplab-largefov deeplab-largefov', u'725neural', u'725neural decis', u'725neural decis forest', u'733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530', u'733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530 689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331', u'733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530 689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331 528learn', u'735618561856185618561819931993199319931993838383fcn', u'735618561856185618561819931993199319931993838383fcn learnt', u'735618561856185618561819931993199319931993838383fcn learnt deconv', u'736super', u'736super pars', u'736super pars super', u'73towel', u'73towel shower', u'73towel shower curtaintowel', u'764dens', u'764dens depth', u'764dens depth map', u'76tabl', u'76tabl 5tabl', u'76tabl 5tabl 5tabl', u'798boosting+high', u'798boosting+high order', u'798boosting+high order boosting+high', u'7a', u'7a y', u'7a y ng', u'7d', u'7d anguelov', u'7d anguelov d', u'7dropout', u'7dropout centerdropout', u'7dropout centerdropout centerdropout', u'7dropout central', u'7dropout central enc-dec', u'7fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition0', u'7m', u'7m compar', u'7m compar othernetwork', u'7m compar otherrec', u'7n/an/a10', u'7n/an/an/an/an/an/an/an/a46', u'7scene', u'7scene understand', u'7scene understand bmvc', u'7segnet', u'7segnet l4', u'7segnet l4 segnet', u'7tabl', u'7torr', u'7torr mani', u'7torr mani combin', u'80k', u'80k 80k', u'80k 80k iter', u'80k iter', u'80k iter whichbenchmark', u'80k iter whichgiven', u'821local', u'821local label', u'821local label descriptor', u'821structur', u'821structur random', u'821structur random forest', u'830segnet', u'830segnet sm', u'830segnet sm segnet', u'833segnet', u'833segnet layersegnet', u'833segnet layersegnet layersegnet', u'838boosting+detectors+crf', u'838boosting+detectors+crf boosting+detectors+crf', u'838boosting+detectors+crf boosting+detectors+crf boosting+detectors+crf', u'838tabl', u'838tabl quantit', u'838tabl quantit result', u'843boost', u'843boost pairwis', u'843boost pairwis crf', u'848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439', u'848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439 678tabl', u'848fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction16251625162516251625162500439 678tabl 1tabl', u'856segnet', u'856segnet r', u'856segnet r segnet', u'856space-tim', u'856space-tim crf', u'856space-tim crf 856segnet', u'856space-tim crf 856space-tim', u'863d', u'863d seman', u'863d seman map', u'880m', u'880m gtxgeforce780', u'880m gtxgeforce780 gpus', u'88\\u2013video', u'88\\u2013video high-definit', u'88\\u2013video high-definit ground', u'897segnet', u'897segnet l4', u'897segnet l4 segnet', u'8abs/1409', u'8abs/14091556', u'8abs/14091556 1abs/14091556', u'8abs/14091556 1abs/14091556 1abs/14091556', u'8advanc', u'8advanc artifici', u'8advanc artifici intellig', u'8algorithm', u'8bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist42', u'8boosting+detectors+crf', u'8boosting+detectors+crf boosting+detectors+crf', u'8boosting+detectors+crf boosting+detectors+crf boosting+detectors+crf', u'8boosting+high', u'8boosting+high order', u'8boosting+high order boosting+high', u'8class', u'8class avg', u'8comput', u'8comput vision\\u2013eccv', u'8comput vision\\u2013eccv page', u'8cvpr', u'8cvpr page', u'8cvpr page ieee', u'8dens', u'8dens correspond', u'8dens correspond differ', u'8dilat', u'8dilat network', u'8dropout', u'8dropout decoderdropout', u'8dropout decoderdropout decoderdropout', u'8eccv', u'8eccv page', u'8eccv page springer', u'8fcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreductionfcn-basic-noaddition-nodimreduction1', u'8global', u'8global avg', u'8labelm', u'8labelm databas', u'8labelm databas web-bas', u'8learn', u'8learn upsampl', u'8learn upsampl bilinear', u'8letter', u'8map', u'8map indoor', u'8map indoor scene', u'8n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70', u'8network', u'8paradigm', u'8paradigm autonom', u'8paradigm autonom drive', u'8pars', u'8pars multiscal', u'8pars multiscal featur', u'8statist', u'8statist model', u'8tabl', u'8tabl 1tabl', u'8tabl 1tabl 1tabl', u'8top-down', u'8top-down semant', u'8top-down semant feedback', u'8trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingfitfitfitfitggc', u'8trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingfitfitfitfitggc i/uc', u'8trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingfitfitfitfitggc i/uc i/uc', u'90msand', u'90msand bayesian', u'90msand bayesian segnet', u'90msper', u'90msper frame', u'90msper frame titan', u'90th', u'90th percentil', u'90th percentil confid', u'90thof', u'90thof accuraci', u'90thof accuraci valu', u'90thpercentil', u'90thpercentil dataset', u'939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost', u'939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost pairwis', u'939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost pairwis crf', u'964crf', u'964crf base', u'964crf base approachescrf', u'98\\u2013136pp', u'98\\u2013136pp 98\\u2013136pp', u'98\\u2013136pp 98\\u2013136pp 98\\u2013136pp', u'98\\u2013136pp 98\\u2013136pp 98\\u2013136video', u'98\\u2013136pp 98\\u2013136video', u'98\\u2013136pp 98\\u2013136video high-definit', u'98\\u2013136video', u'98\\u2013136video high-definit', u'98\\u2013136video high-definit ground', u'9arxiv', u'9arxiv preprint', u'9arxiv preprint arxiv:1511', u'9bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist42', u'9fencefencefencefencefencefencebayesian', u'9fencefencefencefencefencefencebayesian segnet-basicbayesian', u'9fencefencefencefencefencefencebayesian segnet-basicbayesian segnet-basicbayesian', u'9journal', u'9journal comput', u'9journal comput vision', u'9mb', u'9mb storag', u'9mont', u'9mont carlomont', u'9mont carlomont carlomont', u'9n/a27', u'9r', u'9segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder0', u'9upsampl', u'9upsampl use', u'9upsampl use max-pool', u'9video', u'9video high-definit', u'9video high-definit ground', u'9with', u'9with bernoulli', u'9with bernoulli approxim', u'a1', u'a1 onlin', u'a1 onlin demo', u'a3433', u'a3433 imag', u'a3433 imag train', u'aacross', u'aacross dataset', u'aacross dataset use', u'aand', u'aand slight', u'aand slight lower', u'abil', u'abil deep', u'abil deep architectur', u'abil delin', u'abil delin boundari', u'abil delineateobject', u'abil delineateobject base', u'abil delineatesegment', u'abil delineatesegment engin', u'abil model', u'abil model appear', u'abil propos', u'abil propos architectur', u'abil segnet', u'abil segnet segment', u'abil toa', u'abil toa highlight', u'abil toproduc', u'abil toproduc smooth', u'abil train', u'abil train end-to-endcomput', u'abil train end-to-endin', u'abl', u'abl accur', u'abl accur segment', u'abl benchmark', u'abl benchmark approach', u'abl predict', u'abl predict pixelwis', u'abl toa', u'abl toa camvid', u'abl tocop', u'abl tocop addit', u'abl tolearn', u'abl tolearn spatial', u'abl topredict', u'abl topredict reason', u'ablat', u'ablat studi', u'ablat studi choos', u'ablat studi gain', u'ablat studi layer', u'ablat studi topatch', u'ablat studi tounderstand', u'ablefig', u'ablefig clear', u'ablefig clear superior', u'ableto', u'ableto segment', u'ableto segment small', u'about90', u'about90 paramet', u'about90 paramet entir', u'aboutnetwork', u'aboutnetwork howev', u'aboutnetwork howev encod', u'abov', u'abov 90thof', u'abov 90thof accuraci', u'abov 90thpercentil', u'abov 90thpercentil dataset', u'abov analysi', u'abov analysi followinggener', u'abov analysi followingw', u'abov boost', u'abov boost d', u'abov pascal', u'abov pascal voc', u'abov variant', u'abov variant studi', u'abov variant variant', u'abs/1409', u'abs/14091556', u'abs/14091556 2014c', u'abs/14091556 2014c farabet', u'abs/14091556 2014large-scal', u'abs/14091556 2014large-scal imag', u'abs/14094842', u'abs/14094842 deeper', u'abs/14094842 deeper convolut', u'abs/14094842,2014', u'abs/14094842,2014 1i', u'abs/14094842,2014 1i goodfellow', u'abs/1502', u'abs/150203167', u'abs/150203167 2015semant', u'abs/150203167 2015semant segment', u'abs/150203167 2015vol', u'abs/150203167 2015vol abs/150203167', u'abs/1505', u'abs/150504366', u'abs/150504366 2015best', u'abs/150504366 2015best multi-stag', u'abs/150504366 2015semant', u'abs/150504366 2015semant segment', u'abs/150507293', u'abs/150507293 2015d', u'abs/150507293 2015d eigen', u'abs/150507293 2015label', u'abs/150507293 2015label corr', u'abs/1506', u'abs/150604579', u'abs/150604579 2015better', u'abs/150604579 2015better corr', u'abs/150604579 2015v', u'abs/150604579 2015v badrinarayanan', u'absolut', u'absolut model', u'absolut model uncertainti', u'abstract\\u2014w', u'abstract\\u2014w present', u'abstract\\u2014w present novel', u'ac', u'academi', u'academi engin', u'academi engin freng', u'acceler', u'acceler resultsfor', u'acceler resultsfor test', u'acceler resultsnot', u'acceler resultsnot optimis', u'acceleration480', u'acceleration480 input', u'acceleration480 input nvidia', u'accelerationw', u'accelerationw note', u'accelerationw note upsampl', u'acceptful', u'acceptful imag', u'acceptful imag size', u'acceptpatch', u'acceptpatch extend', u'acceptpatch extend kavukcuoglu', u'access', u'access predict', u'access predict older', u'accur', u'accur boundari', u'accur boundari local', u'accur boundari localizationour', u'accur boundari localizationwhich', u'accur class', u'accur class good', u'accur complex', u'accur pixel-wis', u'accur pixel-wis classif', u'accur pixel-wis classificationobtain', u'accur pixel-wis classificationth', u'accur segment', u'accur segment class', u'accur variant', u'accur variant particular', u'accuraci', u'accuraci achiev', u'accuraci achiev use', u'accuraci addit', u'accuraci addit unabl', u'accuraci appli', u'accuraci appli segnet', u'accuraci architectur', u'accuraci architectur whichtrain', u'accuraci architectur whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor', u'accuraci bayesian', u'accuraci bayesian segnet', u'accuraci beaccuraci', u'accuraci beaccuraci smaller', u'accuraci beimprov', u'accuraci beimprov larger', u'accuraci buti', u'accuraci buti suitabl', u'accuraci butthi', u'accuraci butthi lower', u'accuraci c', u'accuraci c intersect', u'accuraci c iscorrect', u'accuraci c isth', u'accuraci class', u'accuraci class meanintersect', u'accuraci class meanth', u'accuraci clear', u'accuraci clear experi', u'accuraci come', u'accuraci come ad', u'accuraci compar', u'accuraci compar exceed', u'accuraci compar larger', u'accuraci correspond', u'accuraci correspond good', u'accuraci dataset', u'accuraci dataset makesit', u'accuraci dataset makesrecip', u'accuraci domin', u'accuraci domin class', u'accuraci fcn-basic', u'accuraci fcn-basic forand', u'accuraci fcn-basic forth', u'accuraci fcn-basic-noadditioni', u'accuraci fcn-basic-noadditioni lower', u'accuraci fcn-basic-noadditionto', u'accuraci fcn-basic-noadditionto larger', u'accuraci fig', u'accuraci follow', u'accuraci follow byand', u'accuraci follow bysegment', u'accuraci foraddit', u'accuraci foraddit tabl', u'accuraci forvari', u'accuraci forvari level', u'accuraci function', u'accuraci function confidencefor', u'accuraci function confidencet', u'accuraci g', u'accuraci g class', u'accuraci g measur', u'accuraci global', u'accuraci global accuraci', u'accuraci highest', u'accuraci highest weightingmetr', u'accuraci highest weightingsinc', u'accuraci iii', u'accuraci iii easypixel', u'accuraci iii easyto', u'accuraci improv', u'accuraci improv orepoch', u'accuraci improv orwhen', u'accuraci increas', u'accuraci increas note', u'accuraci indic', u'accuraci indic perceptu', u'accuraci inter-class', u'accuraci inter-class boundari', u'accuraci lower', u'accuraci lower thesam', u'accuraci lower thesegnet-bas', u'accuraci method', u'accuraci method eitheral', u'accuraci method eitherus', u'accuraci mioumetr', u'accuraci mioumetr global', u'accuraci miouth', u'accuraci miouth variant', u'accuraci model', u'accuraci model uncertainti', u'accuraci number', u'accuraci number offigur', u'accuraci number ofmont', u'accuraci out-perform', u'accuraci out-perform previous', u'accuraci point', u'accuraci point allud', u'accuraci poorer', u'accuraci poorer share', u'accuraci recent', u'accuraci recent approach', u'accuraci recent perform', u'accuraci remain', u'accuraci remain class', u'accuraci segment', u'accuraci segment architectur', u'accuraci segment architecturesmemori', u'accuraci segment architecturesth', u'accuraci segnet', u'accuraci segnet predict', u'accuraci segnetboth', u'accuraci segnetboth qualit', u'accuraci segnetfor', u'accuraci segnetfor outdoor', u'accuraci segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax', u'accuraci segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax itermax', u'accuraci segnetse', u'accuraci segnetse tabl', u'accuraci shown', u'accuraci shown percentag', u'accuraci sinc', u'accuraci sinc penal', u'accuraci smaller/thinn', u'accuraci smaller/thinn class', u'accuraci strong', u'accuraci strong correl', u'accuraci structuredbuild', u'accuraci structuredbuild littl', u'accuraci structuredbut', u'accuraci structuredbut equal', u'accuraci tabl', u'accuraci tabl 3practic', u'accuraci tabl 3to', u'accuraci tabl 4model', u'accuraci tabl 4segment', u'accuraci tempor', u'accuraci tempor super-pixel', u'accuraci term', u'accuraci term ofmiou', u'accuraci term ofmodel', u'accuraci toresult', u'accuraci toresult overal', u'accuraci toth', u'accuraci toth variant', u'accuraci trade-off', u'accuraci trade-off involv', u'accuraci train', u'accuraci train alarg', u'accuraci train apredict', u'accuraci use', u'accuraci use conjunct', u'accuraci valu', u'accuraci valu model', u'accuraci versus', u'accuraci versus infer', u'accuraciesa', u'accuraciesa small', u'accuraciesa small imag', u'accuraciesreport', u'accuraciesreport tabl', u'accuraciesreport tabl clear', u'accuracybut', u'accuracybut segnet', u'accuracybut segnet effici', u'accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun', u'accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun rgbdsun', u'accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun rgbdsun rgbdsun', u'accuracyclass', u'accuracyclass resembl', u'accuracyclass resembl build', u'accuracyglob', u'accuracyglob avgglob', u'accuracyglob avgglob avgglob', u'accuracyi', u'accuracyi highest', u'accuracyi highest evalu', u'accuracymodel', u'accuracymodel deconvnet', u'accuracymodel deconvnet higher', u'accuracyon', u'accuracyon class', u'accuracyon class method', u'accuracypixel-wis', u'accuracypixel-wis classif', u'accuracypixel-wis classif accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun', u'accuracypixel-wis classif accuracypixel-wis', u'accuracyth', u'accuracyth camvid', u'accuracyth camvid kitti', u'accuracytrain', u'accuracytrain set', u'accuracytrain set select', u'accurateand', u'accurateand smooth', u'accurateand smooth class', u'accuratemeaning', u'accuratemeaning featur', u'accuratemeaning featur input', u'achiev', u'achiev acompetit', u'achiev acompetit accuraci', u'achiev addit', u'achiev addit parameteris', u'achiev aevalu', u'achiev aevalu server', u'achiev better', u'achiev better accuraci', u'achiev better accuracyglob', u'achiev better accuracyon', u'achiev better perform', u'achiev better performancelack', u'achiev better performanceth', u'achiev encod', u'achiev encod featuremap', u'achiev encod featureth', u'achiev good', u'achiev good perform', u'achiev good segment', u'achiev high', u'achiev high global', u'achiev high score', u'achiev higher', u'achiev higher train', u'achiev improv', u'achiev improv segmenationaccuraci', u'achiev improv segmenationbroad', u'achiev increas', u'achiev increas success', u'achiev particularof', u'achiev particularof model', u'achiev particularresult', u'achiev particularresult main', u'achiev sampl', u'achiev sampl network', u'achiev translat', u'achiev translat invari', u'achiev translat invariancea', u'achiev translat invarianceov', u'achiev use', u'achiev use deep', u'achiev use depth', u'achieveshigh', u'achieveshigh metric', u'achieveshigh metric far', u'achievesoppos', u'achievesoppos fix', u'achievesoppos fix bi-linear', u'achievesstate-of-the-art', u'achievesstate-of-the-art perform', u'achievesstate-of-the-art perform use', u'achievesth', u'achievesth nyu', u'achievesth nyu dataset', u'acknowledg', u'acknowledg shortcom', u'acknowledg shortcom hope', u'acm', u'acm 2014confer', u'acm 2014confer multimedia', u'acm 2014evalu', u'acm 2014evalu measur', u'acm internationalconfer', u'acm internationalconfer multimedia', u'acm internationalfast', u'acm internationalfast featur', u'acombin', u'acombin popular', u'acombin popular hand', u'acomparison', u'acomparison decod', u'acomparison decod variant', u'acompetit', u'acompetit accuraci', u'acompetit accuraci method', u'aconst', u'aconst kernel', u'aconst kernel size', u'acontext', u'acontext window', u'acontext window input', u'acontrol', u'acontrol benchmark', u'acontrol benchmark use', u'acorrespond', u'acorrespond decod', u'acorrespond decod stack', u'acrossth', u'acrossth distribut', u'acrossth distribut model', u'acrossthi', u'acrossthi becaus', u'acrossthi becaus low', u'activ', u'activ 4each', u'activ 4each layer', u'activ 4of', u'activ 4of non-zero', u'activ base', u'activ base label', u'activ car', u'activ car zero', u'activ consid', u'activ consid activ', u'activ deeper', u'activ deeper layer', u'activ encod', u'activ encod use', u'activ featur', u'activ featur n', u'activ fewer', u'activ fewer featur', u'activ layer', u'activ layer astudi', u'activ layer atrain', u'activ layer pixel', u'activ layer3', u'activ layer3 speedup', u'activ layerfeatur', u'activ layerfeatur activ', u'activ mappedback', u'activ mappedback imag', u'activ mappedtrain', u'activ mappedtrain network', u'activ miss', u'activ miss categori', u'activ s', u'activ s pixel', u'activ semant', u'activ semant pixel-wis', u'activ therefor', u'activ therefor focus', u'activ topic', u'activ topic research', u'activ tune', u'activ tune larg', u'activ use', u'activ use remain', u'activ use visual', u'activated100', u'activated100 activated100', u'activated100 activated100 activated100', u'activated100 activated100 activated48', u'activated100 activated100 activated484', u'activated100 activated100 activated54', u'activated100 activated100 activated546', u'activated100 activated100 activated57', u'activated100 activated100 activated578', u'activated100 activated100 activated62', u'activated100 activated100 activated625', u'activated100 activated48', u'activated100 activated484', u'activated100 activated484 activated484', u'activated100 activated54', u'activated100 activated546', u'activated100 activated546 activated546', u'activated100 activated57', u'activated100 activated578', u'activated100 activated578 activated578', u'activated100 activated62', u'activated100 activated625', u'activated100 activated625 activated625', u'activated11train', u'activated11train sampletrain', u'activated11train sampletrain sampletrain', u'activated17', u'activated1719', u'activated1719 activated11train', u'activated1719 activated11train sampletrain', u'activated1719 activated1719', u'activated1719 activated1719 activated11train', u'activated1719 activated1719 activated1719', u'activated18', u'activated1875', u'activated1875 activated100', u'activated1875 activated100 activated100', u'activated1875 activated1875', u'activated1875 activated1875 activated100', u'activated1875 activated1875 activated1875', u'activated40', u'activated4062', u'activated4062 activated1719', u'activated4062 activated1719 activated1719', u'activated4062 activated4062', u'activated4062 activated4062 activated1719', u'activated4062 activated4062 activated4062', u'activated42', u'activated4219', u'activated4219 activated1875', u'activated4219 activated1875 activated1875', u'activated4219 activated4219', u'activated4219 activated4219 activated1875', u'activated4219 activated4219 activated4219', u'activated43', u'activated4375', u'activated4375 activated4375', u'activated4375 activated4375 activated4375', u'activated4375 activated4375 activated625', u'activated4375 activated625', u'activated4375 activated625 activated625', u'activated46', u'activated468', u'activated468 activated1875', u'activated468 activated1875 activated1875', u'activated468 activated468', u'activated468 activated468 activated1875', u'activated468 activated468 activated468', u'activated48', u'activated484', u'activated484 activated4062', u'activated484 activated4062 activated4062', u'activated484 activated484', u'activated484 activated484 activated4062', u'activated484 activated484 activated484', u'activated54', u'activated546', u'activated546 activated4375', u'activated546 activated4375 activated4375', u'activated546 activated546', u'activated546 activated546 activated4375', u'activated546 activated546 activated546', u'activated57', u'activated578', u'activated578 activated4219', u'activated578 activated4219 activated4219', u'activated578 activated578', u'activated578 activated578 activated4219', u'activated578 activated578 activated578', u'activated6', u'activated62', u'activated625', u'activated625 activated100', u'activated625 activated100 activated100', u'activated625 activated468', u'activated625 activated468 activated468', u'activated625 activated625', u'activated625 activated625 activated100', u'activated625 activated625 activated468', u'activated625 activated625 activated625', u'activatedlayerlayerlayerlayerlayerlayeral', u'activatedlayerlayerlayerlayerlayerlayeral featuresal', u'activatedlayerlayerlayerlayerlayerlayeral featuresal featuresal', u'activatedon', u'activatedon featur', u'activatedon featur activatedlayerlayerlayerlayerlayerlayeral', u'activatedon featur activatedon', u'activations/mapsfor', u'activations/mapsfor given', u'activations/mapsfor given layer', u'activations/mapsfor sampl', u'activations/mapsfor sampl train', u'activationsfin', u'activationsfin tune', u'activationsfin tune activationsfin', u'activationsfin tune activationsfor', u'activationsfor', u'activationsfor given', u'activationsfor given layer', u'ad', u'ad demonstr', u'ad demonstr high', u'ad element-wis', u'ad element-wis correspond', u'ad element-wis tomap', u'ad element-wis toth', u'ad end', u'ad end deeper3', u'ad end deeperwa', u'ad hoc', u'ad hoc method', u'ad hoc techniqu', u'ad new', u'ad new featuresin', u'ad new featuresor', u'ad post', u'ad post process', u'ad result', u'ad result theafter', u'ad result thetop', u'adapt', u'adapt appropri', u'adapt appropri learn', u'adapt employ', u'adapt employ pattern', u'add', u'add architectur', u'add architectur deconvnet', u'add correspond', u'add correspond encod', u'add deeper', u'add deeper encoder-decod', u'add dropout', u'add dropout central', u'add effort', u'add effort perform', u'add encod', u'add encod featur', u'adddataset', u'adddataset analys', u'adddataset analys effect', u'addedbatch', u'addedbatch normal', u'addedbatch normal layer', u'addedon', u'addedon dataset', u'addedon dataset enabl', u'addground', u'addground truthground', u'addground truthground truthground', u'addit', u'addit abov', u'addit abov variant', u'addit aid', u'addit aid sucha', u'addit aid suchof', u'addit benchmark', u'addit benchmark a3433', u'addit benchmark aweb', u'addit benefit', u'addit benefit sinc', u'addit compar', u'addit compar promin', u'addit cost', u'addit cost infer', u'addit cue', u'addit cue ground', u'addit degre', u'addit degre freedom', u'addit infer', u'addit infer aid', u'addit infer time', u'addit model', u'addit model paramet', u'addit model uncertainti', u'addit ofeach', u'addit ofeach deeper', u'addit ofpervis', u'addit ofpervis manner', u'addit overal', u'addit overal smoothqual', u'addit overal smoothsegnet-bas', u'addit parameteris', u'addit parametris', u'addit perform', u'addit perform boost', u'addit perform improvementbeyond', u'addit perform improvementw', u'addit pre-train', u'addit pre-train train', u'addit result', u'addit result avail', u'addit resultscan', u'addit resultscan view', u'addit resultsnyu', u'addit resultsnyu dataset', u'addit step', u'addit step andmodel', u'addit step andon', u'addit tabl', u'addit tabl segment', u'addit train', u'addit train dataand', u'addit train datafor', u'addit train time', u'addit unabl', u'addit unabl toin', u'addit unabl toprovid', u'addit uncertainti', u'addit uncertainti smaller', u'additional/deep', u'additional/deep encoder-decod', u'additional/deep encoder-decod pair', u'additional/deep encoder-decod pairfor', u'additional/deep encoder-decod pairin', u'additionalcu', u'additionalcu depth', u'additionalcu depth video', u'additionalstate-of-the-art', u'additionalstate-of-the-art perform', u'additionalstate-of-the-art perform use', u'address', u'address imbal', u'address imbal label', u'address import', u'address import drawback', u'adecod', u'adecod featur', u'adecod featur map', u'adopt', u'adopt deep', u'adopt deep architectur', u'adopt fcn', u'adopt fcn convolv', u'adopt fcn known', u'adopt network', u'adopt network design', u'adopteddeep', u'adopteddeep architectur', u'adopteddeep architectur segment', u'adoptedw', u'adoptedw benchmark', u'adoptedw benchmark segnet', u'adphil', u'adphil comput', u'adphil comput vision', u'advanc', u'advanc comput', u'advanc comput exposur', u'advanc neural', u'advanc neural inform', u'advanc state-of-the-art', u'advanc state-of-the-art bydesign', u'advanc state-of-the-art bylearn', u'advancesin', u'advancesin artifici', u'advancesin artifici intellig', u'advancesscen', u'advancesscen gpu-acceler', u'advancesscen gpu-acceler deep', u'advantag', u'advantag comput', u'advantag comput cost', u'advantag crf-rnn', u'advantag crf-rnn revealedtrain', u'advantag crf-rnn revealedwhen', u'advantag crf-rnnquestion', u'advantag crf-rnnquestion perceiv', u'advantag crf-rnnwould', u'advantag crf-rnnwould reduc', u'advantag deeper', u'advantag deeper layer', u'advantag drawback', u'advantag drawback approach', u'advantag fcn-basic', u'advantag fcn-basic infer', u'advantag improv', u'advantag improv boundari', u'advantag retain', u'advantag retain class', u'advantag step', u'advantag step mani', u'advantag trainingstack', u'advantag trainingstack train', u'advantag trainingth', u'advantag trainingth soft-max', u'advoc', u'advoc use', u'advoc use l-bfgs', u'aevalu', u'aevalu server', u'afirst', u'afirst class', u'afirst class boundari', u'afor', u'afor domest', u'afor domest robot', u'aforest', u'aforest anoth', u'aforest anoth approach', u'afresh', u'afresh random', u'afresh random initi', u'afteraround', u'afteraround sampl', u'afteraround sampl signific', u'afterconvolut', u'afterconvolut use', u'afterconvolut use trainabl', u'aftersampl', u'aftersampl outperform', u'aftersampl outperform weight', u'afterupsampl', u'afterupsampl densifi', u'afterupsampl densifi featur', u'agk34', u'agk34 cipolla', u'agk34 cipolla eng', u'agk34 cipolla engcamacukpedestrian', u'agre', u'agre analysi', u'agre analysi sec', u'agre class', u'agre class predict', u'agre earlieranalysi', u'agre earlieranalysi sec', u'agre earlierhigh', u'agre earlierhigh metric', u'agreement', u'agreement earlier', u'agreement earlier work', u'agreescontour', u'agreescontour accuraci', u'agreescontour accuraci use', u'agreesmor', u'agreesmor human', u'agreesmor human rank', u'ah781', u'ah781 cipolla', u'ah781 cipolla eng', u'ah781 cipolla engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl', u'ah781 cipolla engcamacukvb292', u'ahand', u'ahand fcn-basic', u'ahand fcn-basic store', u'ahigh', u'ahigh level', u'ahigh level uncertainti', u'ai', u'ai disciplin', u'ai disciplin gear', u'aid', u'aid asarchitectur', u'aid asarchitectur fcn', u'aid ascan', u'aid ascan boost', u'aid asregion', u'aid asregion propos', u'aid object', u'aid object propos', u'aid report', u'aid report perform', u'aid sucha', u'aid sucha use', u'aid suchof', u'aid suchof network', u'aim', u'aim tobi', u'aim tobi use', u'aim toproduc', u'aim toproduc high', u'ain', u'ain deepest', u'ain deepest layer', u'al', u'al acceptful', u'al acceptful imag', u'al acceptpatch', u'al acceptpatch extend', u'al advoc', u'al advoc use', u'al key', u'al key learningarchitectur', u'al key learningmodul', u'al keylearn', u'al keylearn modul', u'al keyour', u'al keyour work', u'al multi-scalebeen', u'al multi-scalebeen use', u'al multi-scaledeep', u'al multi-scaledeep learn', u'al notecommon', u'al notecommon use', u'al notethat', u'al notethat metric', u'al ren', u'al ren et', u'al segnet', u'al segnet featur', u'al simpli', u'al simpli extend', u'al studi', u'al studi effect', u'al tabl', u'al tabl sun', u'al train', u'al train variant', u'al use', u'al use test', u'alarg', u'alarg dataset', u'alarg dataset 35k', u'alex', u'alex kendal', u'alex kendal graduat', u'alex kendal roberto', u'algorithm', u'algorithm cvpr', u'algorithm cvpr page', u'algorithm cvpr pp', u'algorithm numer', u'algorithm numer demonstr', u'algorithm particular', u'algorithm particular deep', u'algorithm unari', u'algorithm unari unaries+crf', u'alland', u'alland perform', u'alland perform poor', u'allobserv', u'allobserv weight', u'allobserv weight result', u'allow', u'allow comput', u'allow comput handl', u'allow explor', u'allow explor mani', u'allow learn', u'allow learn distribut', u'allow tomont', u'allow tomont carlo', u'allow tounderstand', u'allow tounderstand model', u'allth', u'allth variant', u'allth variant particular', u'allth variant variant', u'allud', u'allud recent', u'allud recent theauthor', u'allud recent theevalu', u'almain', u'almain focus', u'almain focus layer-wis', u'alnetwork', u'alnetwork classif', u'alnetwork classif architectur', u'alon', u'alon experi', u'alon experi train', u'alreadi', u'alreadi present', u'alreadi present improv', u'alreadi signific', u'alreadi signific parameter', u'alreadi store', u'alreadi store pool', u'alreadyselect', u'alreadyselect state-of-the-art', u'alreadyselect state-of-the-art method', u'alreadytrain', u'alreadytrain respect', u'alreadytrain respect author', u'alsobeen', u'alsobeen popular', u'alsobeen popular factor', u'alsodeconvnet', u'alsodeconvnet compar', u'alsodeconvnet compar compet', u'alsodemonstr', u'alsodemonstr use', u'alsodemonstr use pre-train', u'alsofilt', u'alsofilt pair', u'alsofilt pair encod', u'alsogain', u'alsogain popular', u'alsogain popular sinc', u'alsoher', u'alsoher note', u'alsoher note author', u'alsoindoor', u'alsoindoor rgbd', u'alsoindoor rgbd pixel-wis', u'alsointerest', u'alsointerest estim', u'alsointerest estim model', u'alsomak', u'alsomak difficult', u'alsomak difficult evalu', u'alsomor', u'alsomor effici', u'alsomor effici architectur', u'alsoperform', u'alsoperform boost', u'alsoperform boost post-process', u'alsoreport', u'alsoreport littl', u'alsoreport littl loss', u'alsose', u'alsose tabl', u'alsose tabl individu', u'alsosinc', u'alsosinc input', u'alsosinc input modal', u'alsotim', u'alsotim signific', u'alsotim signific benchmark', u'alsounti', u'alsounti provid', u'alsounti provid addit', u'alsous', u'alsous segment', u'alsous segment thinner', u'alsowithout', u'alsowithout use', u'alsowithout use ani', u'althoughit', u'althoughit encod', u'althoughit encod input', u'althoughth', u'althoughth input', u'althoughth input imag', u'alway', u'alway correspond', u'alway correspond human', u'alwaysfrom', u'alwaysfrom vehicl', u'alwaysfrom vehicl camera', u'alwaysparallel', u'alwaysparallel road', u'alwaysparallel road surfac', u'ambigu', u'ambigu model', u'ambigu object', u'ambigu object cyclist', u'ambigu surround', u'ambigu surround definit', u'amongfrom', u'amongfrom scene', u'amongfrom scene understand', u'amongobject', u'amongobject autonom', u'amongobject autonom drive', u'amountcop', u'amountcop addit', u'amountcop addit uncertainti', u'amountof', u'amountof data', u'analys', u'analys effect', u'analys effect supervis', u'analys result', u'analys result class', u'analys segnet', u'analys segnet compar', u'analysednecessari', u'analysednecessari achiev', u'analysednecessari achiev good', u'analysedth', u'analysedth decod', u'analysedth decod process', u'analysi', u'analysi complement', u'analysi complement benchmark', u'analysi dataset', u'analysi dataset tomeasur', u'analysi dataset toof', u'analysi designmor', u'analysi designmor effici', u'analysi designsegment', u'analysi designsegment architectur', u'analysi followinggener', u'analysi followinggener point', u'analysi followinggener pointsgener', u'analysi followingw', u'analysi followingw summar', u'analysi indoor', u'analysi indoor rgbd', u'analysi machin', u'analysi machin intellig', u'analysi quantit', u'analysi quantit experi', u'analysi sec', u'analysi sec sec', u'analysi sec usingand', u'analysi sec usingth', u'analysi self-train', u'analysi self-train observ', u'analysi shown', u'analysi shown tabl', u'analysi sinc', u'analysi sinc conceptu', u'analysi use', u'analysi use smaller', u'analysi variant', u'analysi variant hold', u'analysi which1', u'analysi which1 segnet-bas', u'analysi whichfcn-bas', u'analysi whichfcn-bas compar', u'analysis4', u'analysis4 experi', u'analysis4 experi analysis4', u'analysis4 experi analysisa', u'analysisa', u'analysisa number', u'analysisa number outdoor', u'analysisin', u'analysisin sec', u'analysisin sec fact', u'analysisin tabl', u'analysisin tabl report', u'analysisnetwork', u'analysisnetwork train', u'analysisnetwork train veri', u'analysisof', u'analysisof segnet', u'analysisof segnet decod', u'analysison', u'analysison main', u'analysison main contribut', u'analysisw', u'analysisw size', u'analysisw size trainabl', u'and/or', u'and/or crf', u'and/or crf contemporari', u'and/or crf major', u'and4', u'and4 decod', u'and4 decod experi', u'and654', u'and654 test', u'and654 test imag', u'anda', u'anda larger', u'anda larger number', u'anda relu', u'anda relu non-linear', u'andand', u'andand visual', u'andand visual ambigu', u'andarchitectur', u'andarchitectur learn', u'andarchitectur learn upsampl', u'andavoid', u'andavoid gpu-cpu', u'andavoid gpu-cpu memori', u'andbatch', u'andbatch use', u'andbatch use maxim', u'andbuild', u'andbuild pixel', u'andbuild pixel apart', u'andbut', u'andbut believ', u'andbut believ indoor', u'andchalleng', u'andchalleng onli', u'andchalleng onli use', u'andclass', u'andclass balanc', u'andclass balanc use', u'andcombin', u'andcombin correspond', u'andcombin correspond encod', u'andcomput', u'andcomput time', u'andcomput time dure', u'andcontextu', u'andcontextu relationship', u'andcontextu relationship effect', u'andconvolut', u'andconvolut trainabl', u'andconvolut trainabl decod', u'anddataset', u'anddataset contain', u'anddataset contain train', u'anddecod', u'anddecod strong', u'anddecod strong regularis', u'anddil', u'anddil network', u'anddil network addit', u'anddusk', u'anddusk poor', u'anddusk poor light', u'andfergus', u'andfix', u'andfix total', u'andfix total use', u'andfor', u'andfor network', u'andfor network effici', u'andghahramani', u'andghahramani link', u'andghahramani link techniqu', u'andha', u'andha current', u'andha current practic', u'andhenc', u'andhenc come', u'andhenc come various', u'andher', u'andher larg', u'andher larg perform', u'andi', u'andi effici', u'andi effici store', u'andi largest', u'andi largest benchmark', u'andin', u'andin featur', u'andin featur map', u'andindoor', u'andindoor scene', u'andindoor scene segment', u'andiniti', u'andiniti paramet', u'andiniti paramet camvid', u'andmiou', u'andmiou metric', u'andmiou metric obtain', u'andmodel', u'andmodel discard', u'andmodel discard encod', u'andof', u'andof indoor', u'andof indoor scene', u'andof state', u'andof state art', u'andon', u'andon learn', u'andon learn upsampl', u'andor', u'andor convolut', u'andor convolut layer', u'andoth', u'andoth deep', u'andoth deep architectur', u'andpass', u'andpass decod', u'andpass decod decod', u'andpedestrian', u'andpedestrian class', u'andpercentag', u'andrev', u'andrev practic', u'andrev practic trade-off', u'andsampl', u'andsampl posterior', u'andsampl posterior distribut', u'andsegnet', u'andsegnet primarili', u'andsegnet primarili motiv', u'andshallow', u'andshallow architectur', u'andshallow architectur use', u'andsimpli', u'andsimpli upsampl', u'andsimpli upsampl replic', u'andsinc', u'andsinc major', u'andsinc major scene', u'andsometim', u'andsometim valid', u'andsometim valid set', u'andsub-sampl', u'andsub-sampl achiev', u'andsub-sampl achiev translat', u'andtest', u'andtest use', u'andtest use depth', u'andth', u'andth max', u'andth max locat', u'andth soft-max', u'andth soft-max weight', u'andthi', u'andthi control', u'andthi control analysi', u'andthi use', u'andthi use bit', u'andtrain', u'andtrain onli', u'andtrain onli 4th', u'andtrain separ', u'andtrain separ recip', u'andu-net', u'andu-net share', u'andu-net share similar', u'andw', u'andw add', u'andw add architectur', u'andw use', u'andw use mini-batch', u'andwith', u'andwith determinist', u'andwith determinist weight', u'anencod', u'anencod follow', u'anencod follow correspond', u'anencod use', u'anencod use convolution-relu-max', u'anencoder-decod', u'anencoder-decod stack', u'anencoder-decod stack train', u'anexampl', u'anexampl cyclist', u'anexampl cyclist camvid', u'angen', u'angen model', u'angen model unsupervis', u'anguelov', u'anguelov d', u'anguelov d erhan', u'ani', u'ani addit', u'ani addit model', u'ani arbitrari', u'ani arbitrari multichannel', u'ani case', u'ani case crf-rnn', u'ani crf', u'ani crf post-process', u'ani deep', u'ani deep architectur', u'ani deep segment', u'ani depth', u'ani depthsegnet', u'ani depthsegnet compos', u'ani depthto', u'ani depthto visualis', u'ani encoder-decoderarchitectur', u'ani encoder-decoderarchitectur onli', u'ani encoder-decoderform', u'ani encoder-decoderform upsampl', u'ani label', u'ani label imbalancesin', u'ani label imbalancesweight', u'ani learn', u'ani learn perform', u'ani learn rate', u'ani predictivesystem', u'ani predictivesystem output', u'ani predictiveuncertainti', u'ani predictiveuncertainti natur', u'ani test', u'ani test imag', u'animag', u'animag pixel', u'animag pixel level', u'ankur', u'ankur handa', u'ankur handa roberto', u'annot', u'annot ijcv', u'annot ijcv 5fr/', u'annot ijcv 5labelm', u'annot ijcv vol', u'anoth', u'anoth 4epoch', u'anoth 4epoch layer', u'anoth 4epoch margin', u'anoth approach', u'anoth approach argu', u'anoth approach use', u'anoth approachand', u'anoth approachand support', u'anoth approachargu', u'anoth approachargu use', u'anoth approachfocuss', u'anoth approachfocuss real-tim', u'anoth approachfor', u'anoth approachfor classif', u'anoth commonfeatur', u'anoth commonfeatur trainabl', u'anoth commonof', u'anoth commonof decod', u'anoth comparison', u'anoth comparison fcn-basicnoaddit', u'anoth difficulti', u'anoth difficulti caus', u'anoth memori', u'anoth memori intens', u'anoth perspect', u'anoth perspect decod', u'anoth perspect faster', u'anoth reason', u'anoth reason choos', u'anoth reason isedg', u'anoth reason isthat', u'anoth reason poor', u'anoth reason thatresult', u'anoth reason thatth', u'anoth recent', u'anoth recent independ', u'anoth recent method', u'anotherapproach', u'anotherapproach focus', u'anotherapproach focus real-tim', u'anotherus', u'anotherus combin', u'anotherus combin rgb', u'anrgb', u'anrgb imag', u'anrgb imag input', u'ansemant', u'ansemant segment', u'ansemant segment requir', u'anth', u'anth object', u'anth object appear', u'anunderstand', u'anunderstand benchmark', u'anunderstand benchmark sun', u'anyactiv', u'anyactiv featur', u'anyactiv featur layer', u'anyand', u'anyand decod', u'anyand decod pixel-wis', u'anyclass', u'anyclass blanc', u'anyclass blanc train', u'anycompar', u'anycompar experi', u'anycompar experi tabl', u'apart', u'apart infer', u'apart infer compar', u'apartfrom', u'apartfrom train', u'apartfrom train relat', u'apartmap', u'apartmap certain', u'apartmap certain lead', u'apixel', u'apixel deepest', u'apixel deepest layer', u'appear', u'appear blocky2', u'appear blocky2 exact', u'appear dataset', u'appear explor', u'appear explor foror', u'appear explor forth', u'appear infrequ', u'appear infrequ accuraciesa', u'appear infrequ accuraciesreport', u'appear probabl', u'appear probabl center', u'appear road', u'appear road build', u'appear sfm', u'appear sfm appear', u'appear textur', u'appear textur shape', u'appear uncertain', u'appear uncertain model', u'appear visual', u'appear visual ambigu', u'appearanceforest', u'appearanceforest boost', u'appearanceforest boost predict', u'appearanceth', u'appearanceth camvid', u'appearanceth camvid test', u'append', u'append crf', u'append crf multi-scal', u'append fcn', u'append fcn recurr', u'append network', u'append network pre-trainedarchitectur', u'append network pre-trainedto', u'appendedmad', u'appendedmad better', u'appendedmad better ani', u'appendedto', u'appendedto ani', u'appendedto ani deep', u'appli', u'appli bayesian', u'appli bayesian weight', u'appli deep', u'appli deep learn', u'appli follow', u'appli follow batch', u'appli follow max-pool', u'appli imag', u'appli imag video', u'appli map', u'appli mapsa', u'appli mapsa batch', u'appli mapsnot', u'appli mapsnot decod', u'appli network', u'appli network design', u'appli networksa', u'appli networksa segment', u'appli networksdesign', u'appli networksdesign object', u'appli pixel-wis', u'appli pixel-wis semant', u'appli segnet', u'appli segnet fcn', u'applic', u'applic alsointerest', u'applic alsointerest estim', u'applic alsomor', u'applic alsomor effici', u'applic ar', u'applic ar robot', u'applic ar roboticsha', u'applic ar roboticsto', u'applic autonom', u'applic autonom drive', u'applic deep', u'applic deep learn', u'applic forautonom', u'applic forautonom drive', u'applic forroad', u'applic forroad scene', u'applic general', u'applic henc', u'applic henc design', u'applic input', u'applic input rgbimag', u'applic input rgbto', u'applic method', u'applic method appli', u'applic method demonstr', u'applic number', u'applic number state', u'applic objectlearn', u'applic objectlearn invari', u'applic objectrecognit', u'applic objectrecognit cvpr', u'applic pixel', u'applic pixel wise', u'applic random', u'applic random test', u'applic rangingfrom', u'applic rangingfrom scene', u'applic rangingsemant', u'applic rangingsemant segment', u'applic requiremotiv', u'applic requiremotiv road', u'applic requireth', u'applic requireth abil', u'applic road', u'applic road scene', u'applic robot', u'applic robot interact', u'applicability5', u'applicabilityto', u'applicabilityto demonstr', u'applicabilityto demonstr general', u'applicationsfrom', u'applicationsfrom overal', u'applicationsfrom overal effici', u'applicationsi', u'applicationsi suitabl', u'applicationsi suitabl practic', u'applicationson', u'applicationson specialis', u'applicationson specialis embed', u'applicationsth', u'applicationsth appropri', u'applicationsth appropri decod', u'approach', u'approach aim', u'approach aim tobi', u'approach aim toproduc', u'approach argu', u'approach argu use', u'approach decod', u'approach decod process', u'approach entir', u'approach entir disentangl', u'approach howev', u'approach howev didhierarch', u'approach howev didnot', u'approach includ', u'approach includ comput', u'approach islearn', u'approach islearn feed-forward', u'approach iswith', u'approach iswith deeper', u'approach note', u'approach note learn', u'approach object', u'approach object use', u'approach reconstruct', u'approach reconstruct thecross-entropi', u'approach reconstruct theinput', u'approach reveal', u'approach reveal pros', u'approach scene', u'approach scene pars', u'approach scene understand', u'approach tri', u'approach tri direct', u'approach use', u'approach use featur', u'approach use featuresdataset', u'approach use featuressuch', u'approach use hand', u'approach use recurr', u'approach use recurrentclassif', u'approach use recurrentneur', u'approach usear', u'approach usear abl', u'approach usemot', u'approach usemot structur', u'approach useof', u'approach useof hand', u'approach useth', u'approach useth common', u'approach whichhav', u'approach whichhav adopt', u'approach whichinput', u'approach whichinput imag', u'approach withi', u'approach withi follow', u'approach withpoint', u'approach withpoint futur', u'approach withsemant', u'approach withsemant pixel', u'approach withtextonboost', u'approach withtextonboost textonforest', u'approachand', u'approachand support', u'approachand support relationship', u'approachargu', u'approachargu use', u'approachargu use combin', u'approaches74', u'approaches744', u'approaches744 939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost', u'approaches744 939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost pairwis', u'approachescrf', u'approachescrf base', u'approachescrf base approaches74', u'approachescrf base approaches744', u'approachescrf base approachescrf', u'approachfocuss', u'approachfocuss real-tim', u'approachfocuss real-tim joint', u'approachfor', u'approachfor classif', u'approachfor classif use', u'appropri', u'appropri decod', u'appropri decod decod', u'appropri decod e', u'appropri decod segnet', u'appropri learn', u'appropri learn rate', u'appropri magnitud', u'appropri magnitud adapt', u'appropri magnitud deep', u'approxim', u'approxim 12m', u'approxim 12m paramet', u'approxim bayesian', u'approxim bayesian infer', u'approxim crop', u'approxim crop centr', u'approxim distribut', u'approxim distribut posterior', u'approxim distribut thesein', u'approxim distribut theseweight', u'approxim effect', u'approxim effect averag', u'approxim everi', u'approxim everi epoch', u'approxim infer', u'approxim infer bayesian', u'approxim model', u'approxim model posterior', u'approxim posterior', u'approxim posterior distribut', u'approxim relat', u'approxim relat probabl', u'approxim sampl', u'approxim timesmor', u'approxim timesmor pedestrian', u'approxim timesroad', u'approxim timesroad sky', u'approxim variat', u'approxim variat distribut', u'approxim variat infer', u'approxim \\u201cinfluences\\u201d', u'approxim \\u201cinfluences\\u201d optim', u'approximateand', u'approximateand variat', u'approximateand variat paramet', u'approximatelycorrespond', u'approximatelycorrespond epoch', u'approximatelycorrespond epoch test', u'approximatelygiven', u'approximatelygiven mini-batch', u'approximatelygiven mini-batch size', u'approximatemodel', u'approximatemodel gaussian', u'approximatemodel gaussian process', u'apredict', u'apredict accur', u'apredict accur class', u'april', u'april 2015journal', u'april 2015journal comput', u'april 2015p', u'april 2015p dolla\\u0301r', u'ar', u'ar applic', u'ar applic input', u'ar applicationsfrom', u'ar applicationsfrom overal', u'ar applicationson', u'ar applicationson specialis', u'ar robot', u'ar roboticsha', u'ar roboticsha current', u'ar roboticsto', u'ar roboticsto encourag', u'ar task', u'ar tasksdecor', u'ar tasksdecor object', u'ar taskshowev', u'ar taskshowev compar', u'arbitrari', u'arbitrari multichannel', u'arbitrari multichannel imag', u'architectur', u'architectur 66c', u'architectur 66c onclusionc', u'architectur abil', u'architectur abil toa', u'architectur abil toproduc', u'architectur achiev', u'architectur achiev improv', u'architectur ad', u'architectur ad post', u'architectur architectur', u'architectur architectur architectur', u'architectur architectur predict', u'architectur arxivlabel', u'architectur arxivlabel common', u'architectur arxivpreprint', u'architectur arxivpreprint arxiv:1411', u'architectur arxivpreprint arxiv:14114734', u'architectur base', u'architectur base onli', u'architectur base onth', u'architectur bayesian', u'architectur bayesian convolut', u'architectur caff', u'architectur caff time', u'architectur common', u'architectur common ideai', u'architectur common idealay', u'architectur comparison', u'architectur comparison reveal', u'architectur consistsconvolut', u'architectur consistsconvolut encod', u'architectur consistsof', u'architectur consistsof sequenc', u'architectur construct', u'architectur construct train', u'architectur controlleddataset', u'architectur controlleddataset need', u'architectur controlledfor', u'architectur controlledfor poor', u'architectur core', u'architectur core segment', u'architectur deconvnet', u'architectur deconvnet andu-net', u'architectur deconvnet andw', u'architectur deep', u'architectur deep encoder-decod', u'architectur deep segment', u'architectur design', u'architectur design categori', u'architectur design unsupervis', u'architectur differ', u'architectur differ approach', u'architectur difficultsharp', u'architectur difficultsharp class', u'architectur difficultto', u'architectur difficultto train', u'architectur dropout', u'architectur dropout use', u'architectur encod', u'architectur encod network', u'architectur extractcrf', u'architectur extractcrf abil', u'architectur extractmeaning', u'architectur extractmeaning featur', u'architectur fcn8', u'architectur fcn8 fact', u'architectur forfast', u'architectur forfast featur', u'architectur fulli', u'architectur fulli connect', u'architectur gather', u'architectur gather analysi', u'architectur guadarrama', u'architectur guadarrama t', u'architectur havemann', u'architectur havemann train', u'architectur haveus', u'architectur haveus host', u'architectur iccv', u'architectur iccv label', u'architectur iccv pp', u'architectur imag', u'architectur imag segment', u'architectur imageencoder-decod', u'architectur imageencoder-decod architectur', u'architectur imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:1511', u'architectur imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3', u'architectur imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3 cscv', u'architectur includ', u'architectur includ segnet', u'architectur includ segnetmulti-scal', u'architectur includ segnetto', u'architectur includingclass', u'architectur includingclass blanc', u'architectur includingsegnet', u'architectur includingsegnet becaus', u'architectur independ', u'architectur independ segnet', u'architectur isth', u'architectur isth vgg16', u'architectur isthes', u'architectur isthes low', u'architectur key', u'architectur key compon', u'architectur larg', u'architectur larg sun', u'architectur larg variabl', u'architectur learn', u'architectur learn scheme3', u'architectur learn schemea', u'architectur learn upsampl', u'architectur leav', u'architectur leav particular', u'architectur methodsin', u'architectur methodsin comput', u'architectur methodsth', u'architectur methodsth hardest', u'architectur number', u'architectur number featur', u'architectur object', u'architectur object recognit', u'architectur onli', u'architectur onli littl', u'architectur particularlydesign', u'architectur particularlydesign segment', u'architectur particularlynew', u'architectur particularlynew deep', u'architectur perform', u'architectur perform poor', u'architectur performa', u'architectur performa car', u'architectur performrobust', u'architectur performrobust hope', u'architectur pixel', u'architectur pixel wise', u'architectur pixel-wis', u'architectur pixel-wis semant', u'architectur potenti', u'architectur potenti deploy', u'architectur predict', u'architectur predict perform', u'architectur probabilist', u'architectur probabilist auto-encod', u'architectur propos', u'architectur propos ranzato', u'architectur propos train', u'architectur proposeda', u'architectur proposeda similar', u'architectur proposedhttp', u'architectur proposedhttp //arxiv', u'architectur proposedhttp //arxivorg/pdf/150504366pdf', u'architectur provid', u'architectur provid caff', u'architectur pursu', u'architectur pursu multi-scal', u'architectur pursu scale', u'architectur ranzato', u'architectur ranzato et', u'architectur ranzato main', u'architectur real-tim', u'architectur real-tim applic', u'architectur recent', u'architectur recent deep', u'architectur road', u'architectur road indoorscen', u'architectur road indoorwa', u'architectur road scene', u'architectur robust', u'architectur robust semant', u'architectur robustsegnet', u'architectur robustsegnet deep', u'architectur robustsemant', u'architectur robustsemant pixel-wis', u'architectur sceneuncertainti', u'architectur sceneuncertainti deep', u'architectur sceneunderstand', u'architectur sceneunderstand arxiv', u'architectur sec', u'architectur sec sec', u'architectur sec withit', u'architectur seen', u'architectur seen fig', u'architectur segment', u'architectur segment asadopt', u'architectur segment ascompar', u'architectur segment fcn', u'architectur segment feed-forward', u'architectur segment haveident', u'architectur segment haveth', u'architectur segment particularlyinvolv', u'architectur segment particularlysegnet', u'architectur segment particularlytrain', u'architectur segment particularlywhen', u'architectur segment smallerclass', u'architectur segment smallershow', u'architectur segnet', u'architectur segnet design', u'architectur segnet fcn', u'architectur segnet hand', u'architectur segnet max-pool', u'architectur segnet semant', u'architectur segnet somediffer', u'architectur semant', u'architectur semant pixel-wis', u'architectur share', u'architectur share sameencod', u'architectur share samemani', u'architectur sunrgb-d', u'architectur sunrgb-d dataset', u'architectur tabl', u'architectur tabl encod', u'architectur thedecod', u'architectur thedecod learn', u'architectur theexampl', u'architectur theexampl featur', u'architectur train', u'architectur train end-to-endon', u'architectur train end-to-endth', u'architectur trainedw', u'architectur trainedw appli', u'architectur trainedwith', u'architectur trainedwith dropout', u'architectur use', u'architectur use experimentsa', u'architectur use experimentsi', u'architectur use forbank', u'architectur use forunsupervis', u'architectur use motion', u'architectur use paper', u'architectur use unsupervis', u'architectur vari', u'architectur vari parameter', u'architectur variant', u'architectur variant iter', u'architectur variant segnet-bas', u'architectur wasbenchmark', u'architectur wasbenchmark control', u'architectur wastrain', u'architectur wastrain separ', u'architectur wemodifi', u'architectur wemodifi produc', u'architectur wew', u'architectur wew briefli', u'architectur whichen', u'architectur whichen compar', u'architectur whichha', u'architectur whichha larg', u'architectur whichproduc', u'architectur whichproduc input', u'architectur whichtrain', u'architectur whichtrain time', u'architectur whichus', u'architectur whichus motion', u'architectur whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor', u'architectur whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor window', u'architectur wide', u'architectur wide adopt', u'architecturalmodif', u'architecturalmodif care', u'architecturalmodif care post-process', u'architecturalmodifications/redesign', u'architecturalmodifications/redesign qualiti', u'architecturalmodifications/redesign qualiti depth', u'architecturaltest', u'architecturaltest use', u'architecturaltest use depth', u'architecturalus', u'architecturalus depth', u'architecturalus depth modal', u'architecture3', u'architecturediscard', u'architecturediscard fulli', u'architecturediscard fulli connect', u'architecturefor', u'architecturefor joint', u'architecturefor joint featur', u'architecturefor semant', u'architecturefor semant segment', u'architecturein', u'architecturein sec', u'architecturein sec fact', u'architecturemak', u'architecturemak difficult', u'architecturemak difficult evalu', u'architecturesmemori', u'architecturesmemori accuraci', u'architecturesmemori accuraci segment', u'architecturesth', u'architecturesth column', u'architecturesth column tabl', u'architectureth', u'architectureth impact', u'architectureth impact dens', u'architecturew', u'architecturew briefli', u'architecturew briefli review', u'architecturew present', u'architecturew present segnet', u'archiv', u'archiv version', u'archiv version paper1', u'archiv version papershar', u'arcurr', u'arcurr applic', u'arcurr applic autonom', u'area', u'area fcn-basic-nodimreduct', u'area fcn-basic-nodimreduct segnet-encoderaddit', u'arealreadi', u'arealreadi improv', u'arealreadi improv hand', u'arean', u'arean integr', u'arean integr network', u'areboth', u'areboth accur', u'areboth accur variant', u'areground', u'areground truth', u'areground truth row', u'areinclud', u'areinclud shallow', u'areinclud shallow method', u'arejoint', u'arejoint supervis', u'arejoint supervis learn', u'arelarg', u'arelarg correct', u'arelarg correct edg', u'arelarg correct lack', u'arelarg differ', u'arelarg differ view', u'aremad', u'aremad use', u'aremad use deep', u'arenot', u'arenot optimis', u'arenot optimis use', u'areobtain', u'areobtain reason', u'areobtain reason predict', u'areoften', u'areoften use', u'areoften use variat', u'areoth', u'areoth applic', u'areoth applic pixel', u'areoth dataset', u'areoth dataset balanc', u'areperform', u'areperform infer', u'areperform infer bayesian', u'aresimpli', u'aresimpli upsampl', u'aresimpli upsampl replic', u'arestil', u'arestil imag', u'arestil imag dataset', u'areth', u'areth qualit', u'areth qualit result', u'areth signific', u'areth signific improv', u'arethen', u'arethen batch', u'arethen batch normal', u'areto', u'areto creat', u'areto creat input', u'arew', u'arew note', u'arew note upsampl', u'arew tri', u'arew tri generic', u'arewith', u'arewith filter', u'arewith filter bank', u'argb', u'argb dataset', u'argb dataset object', u'argu', u'argu use', u'argu use acombin', u'argu use aforest', u'arisesfeatur', u'arisesfeatur map', u'arisesfeatur map resolut', u'arisesfrom', u'arisesfrom need', u'arisesfrom need map', u'aros', u'aros need', u'aros need match', u'aroundobject', u'aroundobject boundari', u'aroundpredict', u'aroundpredict smooth', u'aroundpredict smooth sharp', u'arrang', u'arrang capturedclass', u'arrang capturedclass spatial', u'arrang capturedfrom', u'arrang capturedfrom vehicl', u'arrang observ', u'arrang observ scene', u'array', u'array applic', u'array applic rangingfrom', u'array applic rangingsemant', u'array indic', u'array indic upsampl', u'array of1', u'array of1 version', u'array ofsemant', u'array ofsemant segment', u'arreal-tim', u'arreal-tim applic', u'arreal-tim applic road', u'arriv', u'arriv deep', u'arriv deep network', u'arriv high', u'arriv high accuraci', u'art', u'art architectur', u'art architectur achiev', u'art architectur segnet', u'arth', u'arth metric', u'arth metric chose', u'arthi', u'arthi primari', u'arthi primari motiv', u'artifici', u'artifici intellig', u'artifici intellig ai', u'artifici intellig c', u'artifici intellig research', u'artifici intellig volum', u'arxiv', u'arxiv preprint', u'arxiv preprint arxiv:1312', u'arxiv preprint arxiv:13126199', u'arxiv preprint arxiv:1408', u'arxiv preprint arxiv:1409', u'arxiv preprint arxiv:14091556', u'arxiv preprint arxiv:1411', u'arxiv preprint arxiv:1412', u'arxiv preprint arxiv:1502', u'arxiv preprint arxiv:1505', u'arxiv preprint arxiv:1509', u'arxiv preprint arxiv:1511', u'arxiv preprint arxiv:151102680', u'arxiv preprint arxiv:1604', u'arxiv preprint arxiv:160401685', u'arxiv preprintarxiv:1411', u'arxiv preprintarxiv:1502', u'arxiv preprintarxiv:1504', u'arxiv preprintarxiv:150401013', u'arxiv preprintarxiv:150401013 2015arxiv:150401013', u'arxiv preprintdeep', u'arxiv preprintdeep structur', u'arxiv preprintfor', u'arxiv preprintfor object', u'arxiv preprintnetwork', u'arxiv preprintnetwork train', u'arxiv:1312', u'arxiv:13126199', u'arxiv:13126199 4network', u'arxiv:13126199 4network arxiv', u'arxiv:13126199 6h', u'arxiv:13126199 6h jiang', u'arxiv:1406', u'arxiv:14062283', u'arxiv:14062283 3pars', u'arxiv:14062283 3pars multiscal', u'arxiv:14062283 3preprint', u'arxiv:14062283 3preprint arxiv:14062283', u'arxiv:1408', u'arxiv:1409', u'arxiv:14091556', u'arxiv:14091556 2014j', u'arxiv:14091556 2014j long', u'arxiv:14091556 2014large-scal', u'arxiv:14091556 2014large-scal imag', u'arxiv:1411', u'arxiv:14114734', u'arxiv:14114734 2014in', u'arxiv:14114734 2014in cvpr', u'arxiv:14114734 2014preprint', u'arxiv:14114734 2014preprint arxiv:14114734', u'arxiv:1412', u'arxiv:1502', u'arxiv:150202734', u'arxiv:150202734 2015arxiv', u'arxiv:150202734 2015arxiv preprint', u'arxiv:150202734 2015for', u'arxiv:150202734 2015for biomed', u'arxiv:1504', u'arxiv:1505', u'arxiv:1506', u'arxiv:1509', u'arxiv:1511', u'arxiv:151102680', u'arxiv:151102680 2015understand', u'arxiv:151102680 2015understand arxiv', u'arxiv:151102680 2015vijay', u'arxiv:151102680 2015vijay badrinarayanan', u'arxiv:1604', u'arxiv:160401685', u'arxiv:160401685 2016potenti', u'arxiv:160401685 2016potenti nip', u'arxiv:160401685 2016urban', u'arxiv:160401685 2016urban scene', u'arxivfrom', u'arxivfrom singl', u'arxivfrom singl imag', u'arxivlabel', u'arxivlabel common', u'arxivlabel common multi-scal', u'arxivpreprint', u'arxivpreprint arxiv:1406', u'arxivpreprint arxiv:14062283', u'arxivpreprint arxiv:14062283 3preprint', u'arxivpreprint arxiv:1411', u'arxivpreprint arxiv:14114734', u'arxivpreprint arxiv:14114734 2014preprint', u'asa', u'asa measur', u'asa measur uncertainti', u'asadopt', u'asadopt fulli', u'asadopt fulli convolut', u'asarchitectur', u'asarchitectur fcn', u'asarchitectur fcn use', u'asaverag', u'asaverag mont', u'asaverag mont carlo', u'asbayesian', u'asbayesian neural', u'asbayesian neural network', u'ascan', u'ascan boost', u'ascan boost use', u'ascompar', u'ascompar experi', u'ascompar experi tabl', u'ascompar larger', u'ascompar larger model', u'asdeconvolut', u'asdeconvolut note', u'asdeconvolut note comparison', u'asegnet', u'asegnet compos', u'asegnet compos stack', u'asemant', u'asemant contour', u'asemant contour measur', u'asfig', u'asfig result', u'asfig result camvid', u'asfor', u'asfor fcn', u'asfor fcn model', u'asinput', u'asinput decod', u'asinput decod filter', u'askernel', u'askernel size', u'askernel size manner', u'asmal', u'asmal comput', u'asmal comput budget', u'asmal size', u'asmal size preserv', u'asneur', u'asneur network', u'asneur network model', u'asoppos', u'asoppos fix', u'asoppos fix bi-linear', u'aspercentag', u'asregion', u'asregion propos', u'asregion propos infer', u'asregion propos therefor', u'asroad', u'asroad build', u'asroad build car', u'asscen', u'assess', u'assess segnet', u'assess segnet predict', u'assessmentsand', u'assessmentsand architectur', u'assessmentsand architectur road', u'assessmentsshow', u'assessmentsshow segnet', u'assessmentsshow segnet provid', u'asshow', u'asshow mean', u'asshow mean iou', u'assign', u'assign class', u'assign class loss', u'assign map', u'assign map singl', u'associ', u'associ machin', u'associ machin intellig', u'astand', u'astand alon', u'astand alon experi', u'asth', u'asth number', u'asth number upsampl', u'astudi', u'astudi effect', u'astudi effect featur', u'asvari', u'asvari measur', u'asvari measur overal', u'at3', u'at3 web', u'at3 web demo', u'at360', u'at360 resolut', u'at360 resolut challeng', u'at367', u'at367 train', u'at367 train test', u'atask', u'atask practic', u'atask practic applic', u'atfergus', u'atfigur', u'atfigur segnet', u'atfigur segnet featur', u'atfrom', u'atfrom number', u'atfrom number network', u'ath', u'ath univers', u'ath univers pennsylvania', u'athttp', u'athttp //mi', u'athttp //miengcamacuk/projects/segnet/http', u'athttp //miengcamacuk/projects/segnet/http //miengcamacuk/projects/segnet/http', u'atim', u'atim memori', u'atim memori constraint', u'atleast', u'atleast 150epoch', u'atleast 150epoch observ', u'atleast 150we', u'atleast 150we report', u'atmodel', u'atmodel uncertainti', u'atmodel uncertainti class', u'atrain', u'atrain network', u'atrain network featur', u'attain', u'attain rank', u'attain rank use', u'attempt', u'attempt appli', u'attempt appli networksa', u'attempt appli networksdesign', u'attempt use', u'attempt use deep', u'attemptsha', u'attemptsha onli', u'attemptsha onli just', u'attemptsto', u'attemptsto appli', u'attemptsto appli network', u'attent', u'attent challeng', u'attent challeng indoor', u'attent hasbeen', u'attent hasbeen paid', u'attent hasfrom', u'attent hasfrom overal', u'attent paid', u'attent paid import', u'attest', u'attest time', u'attest time standard', u'attract', u'attract properti', u'attract properti onli', u'attribut', u'attribut approach', u'attribut approach useof', u'attribut approach useth', u'atvari', u'atvari depth', u'atvari depth onli', u'atwhich', u'atwhich class', u'atwhich class label', u'auckland', u'auckland new', u'auckland new zealand', u'augment', u'augment inferencei', u'augment inferencei expens', u'augment inferenceprocess', u'augment inferenceprocess employ', u'augment realiti', u'augment realiti ar', u'author', u'author book', u'author book edit', u'author compar', u'author compar fcn', u'author deeplab-largefov', u'author deeplab-largefov alsoher', u'author deeplab-largefov alsoreport', u'author discuss', u'author discuss need', u'author map', u'author map predict', u'author ofnon-linear', u'author ofnon-linear upsampl', u'author ofthes', u'author ofthes architectur', u'author use', u'author use dropout', u'author use stage-wis', u'auto-encod', u'auto-encod l-bfgs', u'auto-encod l-bfgs faster', u'auto-encod use', u'auto-encod use buildgen', u'auto-encod use buildw', u'autonom', u'autonom drive', u'autonom drive earli', u'autonom drive ismain', u'autonom drive isth', u'autonom drive link', u'autonom drive relat', u'autonom drive robot', u'autonom drive wacv', u'autonomousappl', u'autonomousappl rang', u'autonomousappl rang estim', u'autonomousdecis', u'autonomousdecis make', u'autonomousvehicl', u'autonomousvehicl drive', u'autonomousvehicl drive earli', u'autonomousvehicl segment', u'autonomousvehicl segment object', u'avail', u'avail evalu', u'avail evalu at3', u'avail evalu athttp', u'avail fora', u'avail fora number', u'avail forsemant', u'avail forsemant pars', u'avail leaderboardhost', u'avail leaderboardth', u'avail leaderboardth bayesian', u'avail massiv', u'avail massiv dataset', u'avail public', u'avail public soon', u'avail roadscen', u'avail roadscen dataset', u'avail roadth', u'avail roadth kitti', u'avail semant', u'avail semant parsinga', u'avail semant parsingus', u'avail sensor', u'avail sensor seen', u'avail test', u'avail test imag', u'available51', u'available514', u'available514 725neural', u'available514 725neural decis', u'available56', u'available561', u'available561 821local', u'available561 821local label', u'availablein', u'availablein tabl', u'availablein tabl compar', u'availablenot', u'availablenot available56', u'availablenot available561', u'availablenot available561 821local', u'availablenot availablenot', u'availablenot availablenot available56', u'availablenot availablenot available561', u'availablenot availablenot availablenot', u'availablestructur', u'availablestructur random', u'availablestructur random forest', u'availablewhen', u'availablewhen suffici', u'availablewhen suffici train', u'averag', u'averag accuraci', u'averag accuraci c', u'averag accuraci mioumetr', u'averag accuraci miouth', u'averag accuraci segnet', u'averag accuraci sinc', u'averag accuraci strong', u'averag accuraci train', u'averag andher', u'averag andher larg', u'averag andmiou', u'averag andmiou metric', u'averag approxim', u'averag approxim sampl', u'averag c', u'averag c mean', u'averag class', u'averag class row', u'averag correl', u'averag correl miou', u'averag denot', u'averag denot boundari', u'averag diminsh', u'averag diminsh howev', u'averag global', u'averag global averag', u'averag highest', u'averag highest evenclass', u'averag highest evenwhen', u'averag highest oftencorrespond', u'averag highest oftennumer', u'averag imag', u'averag imag f1', u'averag iter', u'averag iter mini', u'averag mean', u'averag mean intersect', u'averag measur', u'averag measur use', u'averag mont', u'averag mont carlo4', u'averag mont carlodropout', u'averag predict', u'averag predict thinn', u'averag produc', u'averag produc imag', u'averag producedbett', u'averag producedbett result', u'averag producedfound', u'averag producedfound comput', u'averag propos', u'averag propos remov', u'averag techniqu', u'averag techniqu approxim', u'averag techniqu produc', u'averag techniqu propos', u'averag techniqu use', u'averag time', u'averag time forward', u'averag trial', u'averag trial standard', u'averagedacross', u'averagedacross class', u'averagedacross class row', u'averagedtruth', u'averagedtruth shown', u'averagedtruth shown second', u'averaging101010202020303030404040numb', u'averaging101010202020303030404040numb samplesnumb', u'averaging101010202020303030404040numb samplesnumb samplesnumb', u'averagingweight', u'averagingweight averaging101010202020303030404040numb', u'averagingweight averaging101010202020303030404040numb samplesnumb', u'averagingweight averagingweight', u'averagingweight averagingweight averaging101010202020303030404040numb', u'averagingweight averagingweight averagingweight', u'avg', u'avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class', u'avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class avgclass', u'avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class avgclass avgclass', u'avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627', u'avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627 964crf', u'avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627 964crf base', u'avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear sfm+appear', u'avgclass', u'avgclass avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627', u'avgclass avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627 964crf', u'avgclass avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'avgclass avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'avgclass avgclass', u'avgclass avgclass avg807807807807807870870870870870896896896896896895895895895895929929929929929985985985985985n/an/a164164164164164n/a980980980980980627', u'avgclass avgclass avgbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'avgclass avgclass avgclass', u'avgclass avgclass avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim', u'avgclass avgclass avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass', u'avgclass avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim', u'avgclass avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim crf', u'avgclass avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass', u'avgclass avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass car', u'avgglob', u'avgglob avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class', u'avgglob avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class avgclass', u'avgglob avgclass', u'avgglob avgclass avgclass', u'avgglob avgglob', u'avgglob avgglob avg615615615615615671671671671671834834834834834536536536536536495495495495495238238238238238class', u'avgglob avgglob avgclass', u'avgglob avgglob avgglob', u'avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim', u'avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim crf', u'avgsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodspace-tim crf 856space-tim', u'avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass', u'avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass car', u'avgtvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass car pedestrian', u'avoid', u'avoid gpu-cpu', u'avoid gpu-cpu memori', u'avoid highlight', u'avoid highlight pseudo', u'avoid paramet', u'avoid paramet explos', u'avoid upsampl', u'avoid upsampl reduc', u'award', u'award woolf', u'award woolf fisher', u'awareimprov', u'awareimprov larger', u'awareimprov larger size', u'awaretrain', u'awaretrain techniqu', u'awaretrain techniqu anoth', u'aweb', u'aweb demo', u'aweb demo footnot', u'b', u'b c', u'b c d', u'b enchmarkingb', u'b enchmarkingb enchmarkingb', u'b han', u'b han \\u201clearn', u'b romera-pared', u'b romera-pared v', u'b schiel', u'b schiel \\u201cthe', u'ba', u'ba engin', u'ba engin degre', u'bachelor', u'bachelor engin', u'bachelor engin class', u'back-propag', u'back-propag imperfect', u'back-propag imperfect theinvolv', u'back-propag imperfect theoptim', u'background', u'background class', u'background implicitlyclass', u'background implicitlyclass surround', u'background implicitlyfavour', u'background implicitlyfavour techniqu', u'backpropag', u'backpropag path', u'backpropag path fft', u'backpropag visual', u'backpropag visual segnet32', u'backward', u'backward pass', u'backward pass ms', u'badrinarayanan', u'badrinarayanan alex', u'badrinarayanan alex kendal', u'badrinarayanan ankur', u'badrinarayanan ankur handa', u'badrinarayanan handa', u'badrinarayanan handa r', u'badrinarayanan kendal', u'badrinarayanan kendal r', u'badrinarayanan obtain', u'badrinarayanan obtain ph', u'badrinarayanan obtain phd', u'badrinarayananunivers', u'badrinarayananunivers cambridgeunivers', u'badrinarayananunivers cambridgeunivers cambridgeunivers', u'badrinarayananvijay', u'badrinarayananvijay badrinarayananunivers', u'badrinarayananvijay badrinarayananunivers cambridgeunivers', u'badrinarayananvijay badrinarayananvijay', u'badrinarayananvijay badrinarayananvijay badrinarayananunivers', u'badrinarayananvijay badrinarayananvijay badrinarayananvijay', u'balanc', u'balanc cross-entropi', u'balanc cross-entropi loss', u'balanc cross-entropi lossth', u'balanc cross-entropi lossthrough', u'balanc end-to-end', u'balanc end-to-end train', u'balanc label', u'balanc label frequenc', u'balanc metric', u'balanc metric higher', u'balanc obtain', u'balanc obtain 180k', u'balanc obtain segnet', u'balanc orequival', u'balanc orequival use', u'balanc orwith', u'balanc orwith train', u'balanc thebalanc', u'balanc thebalanc use', u'balanc theweight', u'balanc theweight assign', u'balanc trainingcamvid', u'balanc trainingcamvid test', u'balanc trainingsegnet-bas', u'balanc trainingsegnet-bas segnet', u'balanc trainingth', u'balanc trainingth variant', u'balanc trainingthat', u'balanc trainingthat use', u'balanc use', u'balanc use formula', u'balanc use natur', u'balanc webenchmark', u'balanc webenchmark perform', u'balanc wemodel', u'balanc wemodel deconvnet', u'balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto', u'balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto compar', u'balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto compar quantit', u'balancinganalys', u'balancinganalys result', u'balancinganalys result class', u'balancingequival', u'balancingequival use', u'balancingequival use natur', u'balancingfrom', u'balancingfrom tabl', u'balancingfrom tabl bilinear', u'balancingiter', u'balancingiter result', u'balancingiter result tabul', u'balancingmedian', u'balancingmedian frequenc', u'balancingmedian frequenc balancingmedian', u'balancingmedian frequenc balancingnatur', u'balancingnatur', u'balancingnatur frequenc', u'balancingnatur frequenc balancingnatur', u'balancingnatur frequenc balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam', u'balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam', u'balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam m', u'balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam m multipli', u'bank', u'bank convolut', u'bank convolut tanh', u'bank element-wis', u'bank element-wis tanh', u'bank fcn', u'bank fcn upsampl', u'bank produc', u'bank produc dens', u'bank produc set', u'bank reconstructswitch', u'bank reconstructswitch learn', u'bank reconstructth', u'bank reconstructth input', u'bank reludecod', u'bank reludecod upsampl', u'bank relunon-linear', u'bank relunon-linear use', u'bankfactor', u'bankfactor consid', u'bankfactor consid choos', u'bankinput', u'bankinput use', u'bankinput use transfer', u'bankit', u'bankit perform', u'bankit perform convolut', u'bankof', u'bankof model', u'bankof model train', u'bankpervis', u'bankpervis manner', u'bankpervis manner pixel-wis', u'bankto', u'bankto densifi', u'bankto densifi featur', u'bar', u'bar mont', u'bar mont carlo', u'bar shown', u'bar shown camvid', u'base', u'base appear', u'base appear probabl', u'base appear sfm', u'base appearanceforest', u'base appearanceforest boost', u'base appearanceth', u'base appearanceth camvid', u'base approach', u'base approach note', u'base approaches74', u'base approaches744', u'base approaches744 939bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclist429429429429429585585585585585465465465465465side-walkside-walkside-walkside-walk686686686686686711711711711711692692692692692column-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-pole897897897897897911911911911911954954954954954fencefencefencefencefencefencesign-symbolsign-symbolsign-symbolsign-symbol619619619619619673673673673673573573573573573pedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestriancarcarcarcar462462462462462619619619619619853853853853853roadroadroadroadroadskyskyskyskyboost', u'base approachescrf', u'base approachescrf base', u'base berkeley', u'base berkeley contourmatch', u'base berkeley contourmetr', u'base challeng', u'base challeng whichar', u'base challeng whichthi', u'base classifi', u'base classifi deep', u'base classifi second', u'base compar', u'base compar studi', u'base convolut', u'base convolut dure', u'base convolut layer', u'base cue', u'base cue anoth', u'base cue anotherapproach', u'base cue anotherus', u'base fact', u'base fact smallestmodel', u'base fact smallestthi', u'base label', u'base label layer', u'base method', u'base method boost', u'base method segnetoth', u'base method segnetpredict', u'base method user', u'base methodstrain', u'base methodstrain dataset', u'base methodsvalu', u'base methodsvalu increas', u'base model', u'base onal', u'base onal measur', u'base onli', u'base onli inabl', u'base onli size', u'base onth', u'base onth vgg', u'base onupsampl', u'base onupsampl ani', u'base optim', u'base optim hyperparamet', u'base percept', u'base percept problem', u'base percept problemsalex', u'base percept problemsgraph', u'base result', u'base result smooth', u'base semant', u'base semant imag', u'base semantich', u'base semantich jiang', u'base semanticimag', u'base semanticimag label', u'base shape', u'base shape despit', u'base techniqu', u'base techniquesth', u'base techniquesth result', u'base techniquesto', u'base techniquesto classic', u'base true', u'base true class', u'base unari', u'base unari improv', u'base unari structur', u'basedfrom', u'basedfrom tabl', u'basedfrom tabl bilinear', u'basedpixel', u'basedpixel improv', u'basedpixel improv result', u'basedpredict', u'basedpredict high', u'basedpredict high global', u'basedtest', u'basedtest imag', u'basedtest imag indoor', u'basedunari', u'basedunari structur', u'basedunari structur class', u'basedupsampl', u'basedupsampl ani', u'basedupsampl ani learn', u'basic', u'basic featur', u'basic featur extract', u'batch', u'batch normal', u'batch normal element-wis', u'batch normal step', u'batch normal tocontrol', u'batch normal toenabl', u'batch normal usedaft', u'batch normal usedth', u'batch normalis', u'batch normalis anda', u'batch normalis andor', u'batch normalis layer', u'batch normalis reluconv', u'batch normalis reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur', u'batch normalis relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig', u'batch normalis statist', u'batch size', u'batch size imag', u'batch size model', u'batch size modelsher', u'batch size modelsso', u'batchcommand', u'batchcommand comput', u'batchcommand comput memori', u'batchsiz', u'batchsiz model', u'batchsiz model size', u'bathroom', u'bathroom shown', u'bathroom shown fig', u'bayesian', u'bayesian approach', u'bayesian convolut', u'bayesian convolut neural', u'bayesian framework', u'bayesian framework methodleverag', u'bayesian framework methodobtain', u'bayesian infer', u'bayesian infer network', u'bayesian network', u'bayesian network train', u'bayesian neural', u'bayesian neural network', u'bayesian segnet', u'bayesian segnet accuraci', u'bayesian segnet architectur', u'bayesian segnet confid', u'bayesian segnet consider', u'bayesian segnet end-to-end', u'bayesian segnet higher', u'bayesian segnet indoor', u'bayesian segnet maintain', u'bayesian segnet make', u'bayesian segnet model', u'bayesian segnet mont', u'bayesian segnet obtainsand', u'bayesian segnet obtainsth', u'bayesian segnet onand', u'bayesian segnet oncamvid', u'bayesian segnet onthre', u'bayesian segnet onw', u'bayesian segnet outperform', u'bayesian segnet outperformsmodel', u'bayesian segnet outperformsshallow', u'bayesian segnet perform', u'bayesian segnet popular', u'bayesian segnet posterior', u'bayesian segnet predict', u'bayesian segnet probabilist', u'bayesian segnet produc', u'bayesian segnet result', u'bayesian segnet segment', u'bayesian segnet setsin', u'bayesian segnet setsth', u'bayesian segnet topperform', u'bayesian segnet topwhich', u'bayesian segnet use', u'bayesian segnet work', u'bayesian segnet4', u'bayesian segnetbayesian', u'bayesian segnetbayesian segnetbayesian', u'bayesian segnetth', u'bayesian segnetth techniqu', u'bayesian variant', u'bayesian variant thearchitectur', u'bayesian variant thecamvid', u'bayesian weight', u'bayesian weight layer', u'bayesianof', u'bayesianof variant', u'bayesianof variant differ', u'bayesianor', u'bayesianor determinist', u'bayesianor determinist encod', u'bayesianpixel-wis', u'bayesianpixel-wis semant', u'bayesianpixel-wis semant segment', u'bayesiansegnet', u'bayesiansegnet add', u'bayesiansegnet add dropout', u'bayesianth', u'bayesianth central', u'bayesianth central enc-dec', u'beaccuraci', u'beaccuraci smaller', u'beaccuraci smaller class', u'becam', u'becam fellow', u'becam fellow royal', u'becamea', u'becamea reader', u'becamea reader inform', u'becamejapan', u'becamejapan join', u'becamejapan join depart', u'becaus', u'becaus better', u'becaus better modelledth', u'becaus better modelledwith', u'becaus difficult', u'becaus difficult train', u'becaus illumin', u'becaus illumin relat', u'becaus low', u'becaus low level', u'becaus max', u'becaus max pool', u'becaus object', u'becaus object classeschair', u'becaus object classescom', u'becaus thergb', u'becaus thergb modal', u'becaus thesmal', u'becaus thesmal size', u'becauselarg', u'becauselarg correct', u'becauselarg correct edg', u'becauseof', u'becauseof low', u'becauseof low input', u'becom', u'becom import', u'becom import considerationof', u'becom import considerationparticular', u'bedroom', u'bedroom live', u'bedroom live room', u'beennetwork', u'beennetwork fcn', u'beennetwork fcn dilat', u'beenpropos', u'beenpropos refer', u'beenpropos refer core', u'befor', u'befor classifi', u'befor epoch', u'befor epoch train', u'befor pass', u'befor pass decodernetwork', u'befor pass decodernot', u'befor perform', u'befor perform categori', u'beforefuel', u'beforefuel challeng', u'beforefuel challeng dataset', u'beforeth', u'beforeth arriv', u'beforeth arriv deep', u'begun', u'begun attemptsha', u'begun attemptsha onli', u'begun attemptsto', u'begun attemptsto appli', u'behnk', u'behnk \\u201cfast', u'behnk \\u201cfast semant', u'beimprov', u'beimprov larger', u'beimprov larger size', u'believ', u'believ indoor', u'believ indoor scene', u'believ iscan', u'believ iscan wide', u'believ isth', u'believ isth hardest', u'believ theaid', u'believ theaid region', u'believ theperceiv', u'believ theperceiv perform', u'believeour', u'believeour control', u'believeour control benchmark', u'believeresult', u'believeresult appli', u'believeresult appli bayesian', u'believesometim', u'believesometim valid', u'believesometim valid set', u'believethi', u'believethi becaus', u'believethi becaus low', u'believeto', u'believeto robust', u'believeto robust extract', u'believeus', u'believeus depth', u'believeus depth segment', u'belong', u'belong larg', u'belong larg class', u'benchmark', u'benchmark a3433', u'benchmark a3433 imag', u'benchmark andrev', u'benchmark andrev practic', u'benchmark andthi', u'benchmark andthi control', u'benchmark approach', u'benchmark approach usear', u'benchmark approach usemot', u'benchmark aweb', u'benchmark aweb demo', u'benchmark bayesian', u'benchmark bayesian segnet', u'benchmark challeng', u'benchmark challeng segment', u'benchmark class', u'benchmark compar', u'benchmark compar segnet', u'benchmark dataset', u'benchmark dataset contain', u'benchmark dataset describ', u'benchmark dataset nyuv2', u'benchmark dataset performanceclass', u'benchmark dataset performancecorrel', u'benchmark describ', u'benchmark describ earlier', u'benchmark experi', u'benchmark experi divertedin', u'benchmark experi divertedtoward', u'benchmark farabet', u'benchmark farabet et', u'benchmark howev', u'benchmark howev csurka', u'benchmark includ', u'benchmark includ use', u'benchmark onin', u'benchmark onin particular', u'benchmark onmani', u'benchmark onmani popular', u'benchmark outdoor', u'benchmark outdoor scene', u'benchmark perform', u'benchmark perform decod', u'benchmark point', u'benchmark point view', u'benchmark promin', u'benchmark promin scene', u'benchmark segnet', u'benchmark segnet sever', u'benchmark segnetand', u'benchmark segnetand architectur', u'benchmark segnetarchitectur', u'benchmark segnetarchitectur train', u'benchmark set', u'benchmark set overal', u'benchmark set segnet', u'benchmark suit', u'benchmark suit cvpr', u'benchmark suit proceed', u'benchmark sun', u'benchmark sun left', u'benchmark train', u'benchmark train bayesian', u'benchmark unfortun', u'benchmark unfortun difficult', u'benchmark use', u'benchmark use batch', u'benchmark use caff', u'benchmark use complement', u'benchmark use samein', u'benchmark use samesgd', u'benchmark various', u'benchmark various deep', u'benchmarkdeep', u'benchmarkdeep learn', u'benchmarkdeep learn approach', u'benchmarki', u'benchmarki therefor', u'benchmarki therefor use', u'benchmarkingan', u'benchmarkingan import', u'benchmarkingan import choic', u'benchmarkingdiffer', u'benchmarkingdiffer deep', u'benchmarkingdiffer deep architectur', u'benchmarknot', u'benchmarknot anoth', u'benchmarknot anoth recent', u'benchmarkon', u'benchmarkon road', u'benchmarkon road scene', u'benefici', u'benefici segment', u'benefici segment whereboundari', u'benefici segment whereimag', u'benefici train', u'benefici train deepest', u'benefit', u'benefit reduc', u'benefit reduc number', u'benefit sinc', u'benefit sinc easilydesc', u'benefit sinc easilyrepeat', u'berg', u'berg l', u'berg l fei-fei', u'berg \\u201cparsenet', u'berg \\u201cparsenet look', u'berkeley', u'berkeley contourmatch', u'berkeley contourmatch score', u'berkeley contourmetr', u'berkeley contourmetr boundari', u'bernoulli', u'bernoulli approxim', u'bernoulli approxim variat', u'bernoulli distribut', u'bernoulli distribut convolut', u\"bernoulli distribut network'sallow\", u\"bernoulli distribut network'sweight\", u'bernoulli distribut random', u'bernoulli pi', u'bernoulli pi j', u'bernoullidistribut', u'bernoullidistribut network', u'bernoullidistribut network weight', u'bernoulliin', u'bernoulliin bayesian', u'bernoulliin bayesian convolut', u'bernstein', u'bernstein c', u'bernstein c berg', u'best', u'best accuraci', u'best accuraci term', u'best butconsum', u'best butconsum memori', u'best butstor', u'best butstor encod', u'best case', u'best case bothcost', u'best case bothmemori', u'best configur', u'best configur drop', u'best effici', u'best effici term', u'best knowledgefor', u'best knowledgefor pixel-wis', u'best knowledgethi', u'best knowledgethi deep', u'best multi-stag', u'best multi-stag architectur', u'best perform', u'best perform achiev', u'best perform benchmark', u'best perform method', u'best perform techniqu', u'best sever', u'best sever challengingglob', u'best sever challengingt', u'better', u'better accuraci', u'better accuracyclass', u'better accuracyclass resembl', u'better accuracyglob', u'better accuracyglob avgglob', u'better accuracyon', u'better accuracyon class', u'better accuracyth', u'better accuracyth camvid', u'better ani', u'better ani case', u'better butsmal', u'better butsmal class', u'better butwith', u'better butwith addit', u'better class', u'better class bayesian', u'better class contour', u'better corr', u'better corr vol', u'better deconvnet', u'better deconvnet thelargest', u'better deconvnet thepost-process', u'better emphas', u'better emphas need', u'better fcn', u'better fcn cost', u'better fix', u'better fix bilinear', u'better g', u'better g c', u'better global', u'better global compar', u'better method', u'better method produc', u'better modelledth', u'better modelledth distribut', u'better modelledwith', u'better modelledwith determinist', u'better multi-scal', u'better multi-scal convnet', u'better object', u'better object class', u'better particular', u'better particular fine', u'better perform', u'better perform lend', u'better perform particular', u'better performancelack', u'better performancelack cue', u'better performanceth', u'better performanceth qualit', u'better pixel-wis', u'better pixel-wis classif', u'better predictionsshallow', u'better predictionsshallow layer', u'better predictionsto', u'better predictionsto top-1', u'better result', u'better shorter', u'better shorter time', u'better sky', u'better sky road', u'better thebalanc', u'better thebalanc includ', u'better thelarg', u'better thelarg fcn-basic-noaddition-nodimreduct', u'better variant', u'better variantsless', u'better variantsless effici', u'better variantsw', u'better variantsw summar', u'better weight', u'better weight averag', u'betweenbench', u'betweenbench tabl', u'betweenbetween', u'betweenbetween uncertainti', u'betweenbetween uncertainti accuraci', u'betweencat', u'betweencat dog', u'betweencat dog train', u'betweenmemori', u'betweenmemori accuraci', u'betweenmemori accuraci segment', u'betweenscor', u'betweenscor onc', u'betweenscor onc emphas', u'betweenuncertainti', u'betweenuncertainti frequenc', u'betweenuncertainti frequenc class', u'beunion', u'beunion score', u'beunion score signific', u'beview', u'beview fig', u'bf', u'bf averag', u'bf averag imag', u'bf clear', u'bf clearlycontour', u'bf clearlycontour delin', u'bf clearlywhen', u'bf clearlywhen memori', u'bf g', u'bf g c', u'bf measur', u'bf measur herecontour', u'bf measur hereit', u'bf measur segnetbas', u'bf metric', u'bf metricsand', u'bf metricsand slight', u'bf metricscould', u'bf metricscould access', u'bf metricsdeconvnet', u'bf metricsdeconvnet fulli', u'bf metricssegnet', u'bf metricssegnet outperform', u'bf score', u'bf score achieveshigh', u'bf score achievesoppos', u'bf score higher', u'bf score indic', u'bf score measur', u'bf score metric', u'bf score note', u'bf test', u'bf test set', u'bf test train', u'bf toarchitectur', u'bf toarchitectur like', u'bf tocompl', u'bf tocompl exist', u'bfbest', u'bfbest perform', u'bfbest perform fcn-basic', u'bfc', u'bfc miou', u'bfc miou bfc', u'bfc miou bfggc', u'bfc miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet70', u'bfc miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073', u'bfc miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet88', u'bfc miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881', u'bfggc', u'bfggc miou', u'bfggc miou bfc', u'bfscore', u'bfscore onc', u'bfscore onc emphas', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet70', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073 240k7073', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073 240k7073 240k7073', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet88', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881 140k8881', u'bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881 140k8881 140k8881', u'bi', u'bi bi', u'bi bi vector', u'bi j', u'bi j bernoulli', u'bi vector', u'bi vector bernoulli', u'bi wi', u'bi wi mi', u'bi-linear', u'bi-linear interpol', u'bi-linear interpol weight', u'bias', u'bias term', u'bias term classifi', u'bias towardscompl', u'bias towardscompl exist', u'bias towardsregion', u'bias towardsregion accuraci', u'bias use', u'bias use convolut', u'bicyclist', u'bicyclist bayesian', u'bicyclist bayesian segnet', u'bicyclist class', u'bicyclist class produc', u'bicyclist column', u'bicyclist column far', u'bicyclist difficult', u'bicyclist difficult class', u'bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'bicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistbicyclistsidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkcolumn-polecolumn-polecolumn-polecolumn-polecolumn-polecolumn-polefencefencefencefencefencefencepedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianpedestrianroadroadroadroadroadsign-symbolsign-symbolsign-symbolsign-symbolcarcarcarcarskyskyskyskytreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear sfm+appear', u'bicyclistsin', u'bicyclistsin dataset', u'bicyclistsin dataset make', u'bicyclistsmor', u'bicyclistsmor pedestrian', u'bicyclistsmor pedestrian pole', u'bigger', u'bigger butlarg', u'bigger butlarg fcn-basic-noaddition-nodimreduct', u'bigger butless', u'bigger butless effici', u'bilinear', u'bilinear initialis', u'bilinear initialis fcn-basicfcn-basicfcn-basic0', u'bilinear initialis fcn-basicfcn-basicfcn-basic065065065065065111111242', u'bilinear initialis learn', u'bilinear interpol', u'bilinear interpol basedfrom', u'bilinear interpol basedupsampl', u'bilinear interpol weight', u'bilinear upsampl', u'bilinear upsampl deconvnet', u'bilinear-interpol', u'bilinear-interpol otherextrem', u'bilinear-interpol otherextrem add', u'bilinear-interpol otherlearn', u'bilinear-interpol otherlearn upsampl', u'bin', u'bin featur', u'bin featur wereactiv', u'bin featur werenon-zero', u'binari', u'binari measur', u'binari measur ofmodel', u'binari measur ofthi', u'biomed', u'biomed imag', u'biomed imag segment', u'bit', u'bit 2for', u'bit 2for pool', u'bit 2pool', u'bit 2pool window', u'bit float', u'bit float point', u'bit pool', u'bit pool window', u'black', u'black colour', u'black colour mask', u'blacken', u'blackenedfigur', u'blackenedfigur row', u'blackenedfigur row indoor', u'blackenedon', u'blackenedon soft-max', u'blackenedon soft-max classifi', u'blake', u'blake m', u'blanc', u'blanc train', u'blanc train ani', u'blinds83', u'blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766', u'blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766 4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor', u'blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766 4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor mat', u'blindsdoor', u'blindsdoor window', u'blindsdoor window bookshelf', u'block', u'block match', u'block match imag', u'block matchbi', u'block matchbi replic', u'block matchimag', u'block matchimag dimens', u'block ourexampl', u'block ourexampl featur', u'block ourwithin', u'block ourwithin block', u'block pixel', u'block pixel block', u'block u-net', u'block u-net vgg', u'blocki', u'blocki anoth', u'blocki anoth approach', u'blocky2', u'blocky2 exact', u'blocky2 exact improv', u'bmvc', u'bmvc 2009in', u'bmvc 2009in bmvc', u'bmvc 2009where', u'bmvc 2009where mani', u'bmvc 2013evalu', u'bmvc 2013evalu measur', u'bmvc 2013semant', u'bmvc 2013semant segment', u'bmvc 7d', u'bmvc 7d anguelov', u'bmvc 7scene', u'bmvc 7scene understand', u'board', u'board http', u'board http //host', u'bodi', u'bodi work', u'bodi work whichi', u'bodi work whichus', u'bollard', u'bollard extendedto', u'bollard extendedto pole', u'bollard extendedtre', u'bollard extendedtre build', u'book', u'book edit', u'book edit volum', u'bookshelf', u'bookshelf pictur', u'bookshelf pictur counter', u'boost', u'boost 764dens', u'boost 764dens depth', u'boost boost', u'boost boost 764dens', u'boost boost boost', u'boost boost dens', u'boost boost structur', u'boost combin', u'boost combin crf', u'boost d', u'boost d abov', u'boost dens', u'boost dens depth', u'boost pairwis', u'boost pairwis crf', u'boost post-process', u'boost post-process techniqu', u'boost predict', u'boost predict class', u'boost predict classforest', u'boost predict classprob', u'boost structur', u'boost structur random', u'boost use', u'boost use addit', u'boosting+detectors+crf', u'boosting+detectors+crf 838tabl', u'boosting+detectors+crf 838tabl quantit', u'boosting+detectors+crf boosting+detectors+crf', u'boosting+detectors+crf boosting+detectors+crf 838tabl', u'boosting+detectors+crf boosting+detectors+crf boosting+detectors+crf', u'boosting+detectors+crf boosting+detectors+crf segnet-bas', u'boosting+detectors+crf boosting+detectors+crf treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear', u'boosting+detectors+crf segnet-bas', u'boosting+detectors+crf segnet-bas layer-wis', u'boosting+detectors+crf treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear', u'boosting+detectors+crf treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'boosting+high', u'boosting+high order', u'boosting+high order 838boosting+detectors+crf', u'boosting+high order boosting+detectors+crf', u'boosting+high order boosting+high', u'bootstrap', u'bootstrap core', u'bootstrap core segment', u'border', u'border segmentationsand', u'border segmentationsand visual', u'border segmentationsthat', u'border segmentationsthat uncertain', u'bothaccuraci', u'bothaccuraci follow', u'bothaccuraci follow crf', u'bothclass', u'bothclass segment', u'bothclass segment support', u'bothcost', u'bothcost accuraci', u'bothcost accuraci versus', u'bothi', u'bothi use', u'bothi use featur', u'bothloc', u'bothloc global', u'bothloc global context', u'bothmemori', u'bothmemori infer', u'bothmemori infer time', u'boundari', u'boundari accuraci', u'boundari accuraci point', u'boundari accuraci poorer', u'boundari architectur', u'boundari architectur difficultsharp', u'boundari architectur difficultto', u'boundari ascompar', u'boundari ascompar larger', u'boundari asfig', u'boundari asfig result', u'boundari delin', u'boundari delin accuracybut', u'boundari delin accuracymodel', u'boundari delin capabl', u'boundari delin ii', u'boundari delin signific', u'boundari difficult', u'boundari difficult visual', u'boundari f1-measur', u'boundari f1-measur bf', u'boundari featur', u'boundari featur map', u'boundari imag', u'boundari imag represent', u'boundari inform', u'boundari inform encod', u'boundari inform extract', u'boundari local', u'boundari localizationour', u'boundari localizationour architectur', u'boundari localizationwhich', u'boundari localizationwhich use', u'boundari measur', u'boundari measur base', u'boundari metric', u'boundari metric globaland', u'boundari metric globalarchitectur', u'boundari model', u'boundari model display', u'boundari object', u'boundari object class', u'boundari poor', u'boundari poornew', u'boundari poornew deep', u'boundari poortheir', u'boundari poortheir abil', u'boundari thepool', u'boundari thepool process', u'boundari theseg', u'boundari theseg imag', u'boundari use', u'boundari use local', u'boundari visual', u'boundari visual difficult', u'briefli', u'briefli review', u'briefli review segnet', u'bright', u'bright color', u'bright color textur', u'budget', u'budget tabl', u'budget tabl segnet', u'build', u'build bollard', u'build bollard extendedto', u'build bollard extendedtre', u'build car', u'build car pedestrian', u'build car pedestriansetc', u'build car pedestrianssemant', u'build henc', u'build henc network', u'build littl', u'build littl effect', u'build need', u'build need cue', u'build pixel', u'build pixel approxim', u'build shape', u'build shape car', u'build side-walk', u'build side-walk main', u'build side-walk sky', u'buildgen', u'buildgen model', u'buildgen model unsupervis', u'buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t', u'buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t 2tabl', u'buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t 2tabl 2tabl', u'buildingpixel', u'buildingpixel class', u'buildingpixel class train', u'buildingpixel domin', u'buildingpixel domin camvid', u'buildw', u'buildw draw', u'buildw draw inspir', u'bulk', u'bulk comput', u'bulk comput timei', u'bus', u'bus class', u'butalreadi', u'butalreadi improv', u'butalreadi improv hand', u'butconsum', u'butconsum memori', u'butconsum memori dure', u'buti', u'buti suitabl', u'buti suitabl practic', u'butlarg', u'butlarg fcn-basic-noaddition-nodimreduct', u'butlarg fcn-basic-noaddition-nodimreduct bigger', u'butless', u'butless effici', u'butless effici model', u'butsegnet', u'butsegnet better', u'butsegnet better g', u'butsegnet use', u'butsegnet use \\u201cflat\\u201d', u'butsmal', u'butsmal class', u'butsmal class dens', u'butsmal size', u'butsmal size class', u'butstor', u'butstor encod', u'butstor encod network', u'buttheir', u'buttheir abil', u'buttheir abil delin', u'butthi', u'butthi lower', u'butthi lower memori', u'butwith', u'butwith addit', u'butwith addit cost', u'butwith connect', u'butwith connect choic', u'bya', u'bya factor', u'bya factor max-pool', u'byadopt', u'byadopt l-bfgs', u'byadopt l-bfgs base', u'byand', u'byand support', u'byand support relationship', u'byboth', u'byboth learn', u'byboth learn produc', u'bycombin', u'bycombin object', u'bycombin object detect', u'bydesign', u'bydesign segment', u'bydesign segment advanc', u'bylearn', u'bylearn decod', u'bylearn decod map', u'bylearn perform', u'bylearn perform deconvolut', u'byleverag', u'byleverag bayesian', u'byleverag bayesian framework', u'byngiam', u'byngiam et', u'byngiam et al', u'bysegment', u'bysegment obtain', u'bysegment obtain higher', u'bytest', u'bytest address', u'bytest address imbal', u'bythi', u'bythi general', u'bythi general applic', u'bywindow', u'bywindow perform', u'bywindow perform result', u'c', u'c berg', u'c berg l', u'c berg \\u201cparsenet', u'c bf', u'c bf metricsand', u'c bf metricssegnet', u'c bf score', u'c c', u'c c lin', u'c coupri', u'c coupri l', u'c d', u'c d correspond', u'c huang', u'c huang p', u'c intersect', u'c intersect union', u'c iscorrect', u'c iscorrect classifi', u'c isth', u'c isth mean', u'c l', u'c l zitnick', u'c liang-chieh', u'c liang-chieh g', u'c lin', u'c lin c', u'c lutz', u'c lutz m', u'c man', u'c man y', u'c mean', u'c mean intersect', u'c miou', u'c miou bf', u'c miou g', u'c mioufix', u'c mioufix upsamplingfix', u'c miouparam', u'c miouparam m', u'c szegedi', u'c szegedi w', u'c-e', u'c-e darker', u'c-e darker colourfigur', u'c-e darker colourrepres', u'ca', u'ca research', u'ca research probabilisticca', u'caff', u'caff convolut', u'caff convolut architectur', u'caff implement', u'caff implement alland', u'caff implement allth', u'caff implement avail', u'caff implement segnet', u'caff implement taski', u'caff implement taskw', u'caff implementationof', u'caff implementationof momentum', u'caff implementationof segnet-bas', u'caff library0', u'caff libraryw', u'caff libraryw implement', u'caff model', u'caff model disk', u'caff time', u'caff time command', u'caffeimplement', u'caffeimplement averag', u'caffeimplement averag measur', u'caffew', u'caffew averag', u'caffew averag time', u'calcul', u'calcul mean', u'calcul mean uncertaintyfig', u'calcul mean uncertaintyvalu', u'calledmap', u'calledmap use', u'calledmap use alreadi', u'calledswitch', u'calledswitch learn', u'calledswitch learn decod', u'cam', u'cambridg', u'cambridg lectur', u'cambridg lectur fellow', u'cambridg u', u'cambridg uk', u'cambridg uk hecurr', u'cambridg uk heinria', u'cambridg uk member', u'cambridg uke-mail', u'cambridg uke-mail vb292', u'cambridg ukunivers', u'cambridg ukunivers cambridg', u'cambridg ukv', u'cambridg ukv badrinarayanan', u'cambridg ukvb292', u'cambridg ukvb292 ah781', u'cambridgein', u'cambridgein m', u'cambridgein mse', u'cambridgein mse electr', u'cambridgeroberto', u'cambridgeroberto cipolla', u'cambridgeroberto cipolla obtain', u'cambridgeroberto cipollaroberto', u'cambridgeroberto cipollaroberto cipollaroberto', u'cambridgeunivers', u'cambridgeunivers cambridgeroberto', u'cambridgeunivers cambridgeroberto cipollaroberto', u'cambridgeunivers cambridgeunivers', u'cambridgeunivers cambridgeunivers cambridgeroberto', u'cambridgeunivers cambridgeunivers cambridgeunivers', u'camera', u'camera posit', u'camera posit near', u'camera reloc', u'camera relocalis', u'camera requir', u'camera requir care', u'camvid', u'camvid a1', u'camvid a1 onlin', u'camvid atask', u'camvid atask practic', u'camvid bayesian', u'camvid bayesian neural', u'camvid center', u'camvid center column', u'camvid consid', u'camvid consid segnet', u'camvid consist', u'camvid consist road', u'camvid data', u'camvid data kitti', u'camvid data result', u'camvid dataset', u'camvid dataset contain', u'camvid dataset need', u'camvid dataset onli', u'camvid dataset train', u'camvid dataset use', u'camvid day', u'camvid day dusk', u'camvid drive', u'camvid drive scenesdataset', u'camvid drive scenesscen', u'camvid kitti', u'camvid kitti dataset', u'camvid kitti indoor', u'camvid pre-train', u'camvid pre-train layer', u'camvid result', u'camvid result fig', u'camvid road', u'camvid road class', u'camvid road scene', u'camvid test', u'camvid test address', u'camvid test per-pixel', u'camvid test recent', u'camvid test set', u'camvid train', u'camvid train set', u'camvid train valu', u'camvid valid', u'camvid valid set', u'camvid video', u'camvid video havealso', u'camvid video havedens', u'camvid video use', u'camvid5', u'camvida', u'camvida compar', u'camvida compar sift-flow', u'camvidaccuraci', u'camvidaccuraci best', u'camvidaccuraci best perform', u'camvidcamvid', u'camvidcamvid road', u'camvidcamvid road scene', u'camviddataset', u'camviddataset contain', u'camviddataset contain train', u'camvidnet', u'camvidnet given', u'camvidnet given standard', u'camvidstil', u'camvidstil imag', u'camvidstil imag dataset', u'camvidtest', u'camvidtest address', u'camvidtest address imbal', u'canabsorb', u'canabsorb larg', u'canabsorb larg train', u'canalso', u'canalso discard', u'canalso discard fulli', u'canimag', u'canimag internet', u'canimag internet fig', u'canno', u'canno class', u'canno class balanc', u'canobserv', u'canobserv weight', u'canobserv weight result', u'canweight', u'canweight train', u'canweight train classif', u'capabl', u'capabl crfslayer', u'capabl crfslayer mimic', u'capabl crfswhile', u'capabl crfswhile exploit', u'capabl infer', u'capabl infer relat', u'capabl structur', u'capabl structur predict', u'capac', u'capac signific', u'captur', u'captur differ', u'captur differ sensor', u'captur encoderdecod', u'captur encoderdecod import', u'captur encoderfeatur', u'captur encoderfeatur map', u'captur froma', u'captur froma car', u'captur fromregion', u'captur fromregion accuraci', u'captur inform', u'captur inform present', u'captureand', u'captureand store', u'captureand store boundari', u'captureboundari', u'captureboundari delin', u'captureboundari delin vital', u'capturedclass', u'capturedclass spatial', u'capturedclass spatial arrang', u'capturedfrom', u'capturedfrom vehicl', u'capturedfrom vehicl camera', u'car', u'car abil', u'car abil model', u'car bicyclistsin', u'car bicyclistsin dataset', u'car bicyclistsmor', u'car bicyclistsmor pedestrian', u'car classcar', u'car classcar classcar', u'car column', u'car column howev', u'car e', u'car easier', u'car easier segment', u'car filledand', u'car filledand class', u'car filledwith', u'car filledwith sidewalk', u'car label', u'car label onli', u'car pedestrian', u'car pedestrian bicyclist', u'car pedestrian pole', u'car pedestrian sign', u'car pedestriansetc', u'car pedestriansetc larg', u'car pedestrianssemant', u'car pedestrianssemant class', u'car reason', u'car reason context', u'car sidewalk', u'car sidewalk given', u'car v', u'car v badrinarayanan', u'car zero', u'car zero thisfeatur', u'car zero thispredict', u'care', u'care post-process', u'care post-process fill-in', u'carlo', u'carlo dropout', u'carlo dropout sampl', u'carlo dropout samplingmont', u'carlo dropout samplingweight', u'carlo dropout uncertainti', u'carlo sampl', u'carlo sampl 90msand', u'carlo sampl 90msper', u'carlo sampl converg', u'carlo sampl dropout', u'carlo sampl obtain', u'carlo sampl requir', u'carlo sampl segnet', u'carlo4', u'carloar', u'carloar shown', u'carloar shown camvid', u'carlodropout', u'carlodropout samplingdropout', u'carlodropout samplingdropout samplingdropout', u'carlomont', u'carlomont carlomont', u'carlomont carlomont carlomont', u'carlomont carlomont carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc', u'carlomont carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc', u'carlomont carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc i/uc', u'carlosampl', u'carlosampl outperform', u'carlosampl outperform weight', u'carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc', u'carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc i/uc', u'carlosamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingsamplingggc i/uc i/uc', u'case', u'case bothcost', u'case bothcost accuraci', u'case bothmemori', u'case bothmemori infer', u'case butsegnet', u'case butsegnet use', u'case butwith', u'case butwith connect', u'case crf-rnn', u'case crf-rnn network', u'case practicalappl', u'case practicalappl henc', u'case practicali', u'case practicali constrain', u'caseoften', u'caseoften appear', u'caseoften appear uncertain', u'casewhen', u'casewhen object', u'casewhen object occlud', u'cast', u'cast dropout', u'cast dropout approxim', u'cat', u'cat dog', u'cat dog train', u'categor', u'categor segment', u'categor segment cvpr', u'categor segment cvpr,2008', u'categor segment particular', u'categor segment particularlybi', u'categor segment particularlydesign', u'categori', u'categori car', u'categori car filledand', u'categori car filledwith', u'categori pole', u'categori pole column', u'categori predict', u'categori predict pixel-wis', u'categori segment', u'categori segment commonattribut', u'categori segment commongroup', u'categori sfmbase', u'categori sfmbase cue', u'categori shape', u'categori shape rang', u'categori shape soft-max', u'categori sharp', u'categori sharp main', u'categories4', u'categories4 experi', u'categories4 experi analysis4', u'categoriesdeep', u'categoriesdeep layer', u'categoriesdeep layer \\u201ctuned\\u201d', u'categoriesin', u'categoriesin agreement', u'categoriesin agreement earlier', u'categoriesto', u'categoriesto top-1', u'categoriesto top-1 layer', u'categoris', u'categoris imag', u'categoris imag detect', u'categorisinglearn', u'categorisinglearn algorithm', u'categorisinglearn algorithm particular', u'categorisingwhol', u'categorisingwhol imag', u'categorisingwhol imag detect', u'categorizationfor', u'categorizationfor pixel', u'categorizationfor pixel wise', u'categorizationhav', u'categorizationhav adopt', u'categorizationhav adopt network', u'caus', u'caus model', u'caus model uncertainti', u'caus network', u'caus network learn', u'caus situat', u'caus wide', u'caus wide varyingarrang', u'caus wide varyings', u'causesquantit', u'causesquantit observ', u'causesth', u'causesth model', u'causesth model uncertain', u'ceil', u'ceil label', u'ceil label comparison', u'ceil tabl', u'ceil tabl chair', u'ceil table,37', u'ceil table,37 indoor', u'ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper11', u'ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376', u'ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376 2273towel', u'ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376 2273towel shower', u'ceilingfloor', u'ceilingfloor mat', u'ceilingfloor mat cloth', u'center', u'center column', u'center column pascal', u'center pixel', u'center pixel featur', u'center pixelfor', u'center pixelfor pixel', u'center pixelthi', u'center pixelthi improv', u'center82', u'centerdropout', u'centerdropout center82', u'centerdropout centerdropout', u'centerdropout centerdropout center82', u'centerdropout centerdropout centerdropout', u'centerfor', u'centerfor pixel', u'centerfor pixel patch', u'centerpixel', u'centerpixel improv', u'centerpixel improv result', u'centr', u'centr 360\\xd7480been', u'centr 360\\xd7480been hand-label', u'centr 360\\xd7480to', u'centr 360\\xd7480to make', u'centr kawasaki', u'centr kawasaki japan', u'centr kawasaki research', u'central', u'central enc-dec', u'central enc-dec variant', u'central encod', u'central encod decod', u'central encoderand', u'central encoderand decod', u'central encodervari', u'central encodervari insert', u'central topic', u'central topic paper', u'central topic paper33a', u'central topic paperfeatur', u'central topic thislow', u'central topic thispap', u'central topic thispaperpaperpaperpaperpaperpaperpaper3', u'centralencod', u'centralencod decod', u'centralencod decod drop', u'centralfit', u'certain', u'certain lead', u'certain lead loss', u'certain rare', u'certain rare challeng', u'certain scene', u'certain scene categoriesdeep', u'certain scene categoriesin', u'chair', u'chair sofa', u'chair sofa orbench', u'chair sofa orsimilar', u'chair sofa task', u'chairsand', u'chairsand tabl', u'chairsand tabl lamp', u'chairsus', u'chairsus segment', u'chairsus segment thinner', u'challeng', u'challeng andbut', u'challeng andbut believ', u'challeng andha', u'challeng andha current', u'challeng class', u'challeng consistsof', u'challeng consistsof segment', u'challeng consiststh', u'challeng consiststh pascal', u'challeng dataset', u'challeng dataset beforefuel', u'challeng dataset beforeth', u'challeng dataset currentbest', u'challeng dataset currentresearch', u'challeng hope', u'challeng hope morearchitectur', u'challeng hope moreattent', u'challeng indoor', u'challeng indoor sceneengag', u'challeng indoor scenetest', u'challeng label', u'challeng label smallercategori', u'challeng label smallerin', u'challeng larg', u'challeng larg dataset', u'challeng larg datasetof', u'challeng larg datasetsun', u'challeng miou', u'challeng miou metric', u'challeng pascal', u'challeng pascal ms-cocopres', u'challeng pascal ms-cocosegment', u'challeng pascal voc12', u'challeng retrospect', u'challeng retrospect intern', u'challeng segment', u'challeng segment architectur', u'challeng segment class', u'challeng segment year', u'challeng segment yearsbeen', u'challeng segment yearshowev', u'challeng whichar', u'challeng whichar increas', u'challeng whichthi', u'challeng whichthi dataset', u'challengingdu', u'challengingdu high', u'challengingdu high variabl', u'challengingglob', u'challengingglob avg', u'challengingglob avgglob', u'challengingglob avgglob avgglob', u'challengingpres', u'challengingpres ani', u'challengingpres ani test', u'challengingt', u'challengingt quantit', u'challengingt quantit result', u'chang', u'chang increas', u'chang increas context', u'chang max', u'chang max pool', u'channel', u'channel ad', u'channel ad element-wis', u'channel asinput', u'channel asinput decod', u'channel asth', u'channel asth number', u'channel befor', u'channel befor pass', u'channel encod', u'channel encod input', u'channel end', u'channel end eachdecod', u'channel end eachnetwork', u'channel final', u'channel final encod', u'channel imag', u'channel imag k', u'channel imag probabl', u'channel improv', u'channel improv segment', u'channel improvedataset', u'channel improvedataset use', u'channel improvesegment', u'channel improvesegment approach', u'channel input', u'channel input depth', u'channel onli', u'channel onli convolvetheir', u'channel onli convolvewher', u'channel perform', u'channel perform convolv', u'channel rgb', u'channel rgb unlik', u'channel rgbalthough', u'channel rgbalthough encod', u'channel rgbd', u'channel rgbd input', u'channel rgbd inputsmod', u'channel rgbd inputsthi', u'channel rgbor', u'channel rgbor rgbd', u'choic', u'choic make', u'choic make benchmarkingan', u'choic make benchmarkingdiffer', u'choic motiv', u'choic motiv reason', u'choos', u'choos camvida', u'choos camvida compar', u'choos camvidstil', u'choos camvidstil imag', u'choos compar', u'choos compar segnet', u'choos featur', u'choos featur map', u'choos model', u'choos model larg', u'chose', u'chose benchmark', u'chose benchmark various', u'chose perform', u'chose perform acontrol', u'chose perform atim', u'choseclass', u'choseclass avg', u'choseclass avgclass', u'choseclass avgclass avgclass', u'chosen', u'chosen imag', u'chosen imag replac', u'chosen provid', u'chosen provid wide', u'chosesemant', u'chosesemant pars', u'chosesemant pars choseclass', u'chosesemant pars chosesemant', u'cipolla', u'cipolla eng', u'cipolla engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl', u'cipolla engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl rang', u'cipolla engcamacukpedestrian', u'cipolla engcamacukpedestrian understand', u'cipolla engcamacukvb292', u'cipolla engcamacukvb292 ah781', u'cipolla machin', u'cipolla machin intellig', u'cipolla obtain', u'cipolla obtain b', u'cipolla obtain ba', u'cipolla senior', u'cipolla senior member', u'cipolla \\u201csegnet', u'cipolla \\u201csegnet deep', u'cipollaarxiv:1511', u'cipollamachin', u'cipollamachin intellig', u'cipollamachin intellig lab', u'cipollaroberto', u'cipollaroberto cipollaarxiv:1511', u'cipollaroberto cipollaroberto', u'cipollaroberto cipollaroberto cipollaarxiv:1511', u'cipollaroberto cipollaroberto cipollaroberto', u'cipollavijay', u'cipollavijay badrinarayanan', u'cipollavijay badrinarayanan ankur', u'citeraey', u'citeraey quantit', u'citeraey quantit analysi', u'cites', u'cityscap', u'cityscap dataset', u'cityscap dataset semanticu', u'cityscap dataset semanticurban', u'class', u'class accuraci', u'class accuraci bayesian', u'class accuraci model', u'class accuraci segnet', u'class accuraci segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax', u'class accuraci segnetse', u'class architectur', u'class architectur perform', u'class arelarg', u'class arelarg differ', u'class areobtain', u'class areobtain reason', u'class asroad', u'class asroad build', u'class asscen', u'class averag', u'class averag accuraci', u'class averag andher', u'class averag andmiou', u'class averag c', u'class averag correl', u'class averag diminsh', u'class averag global', u'class averag highest', u'class averag mean', u'class avg', u'class balanc', u'class balanc cross-entropi', u'class balanc end-to-end', u'class balanc metric', u'class balanc obtain', u'class balanc orequival', u'class balanc orwith', u'class balanc trainingcamvid', u'class balanc trainingsegnet-bas', u'class balanc trainingth', u'class balanc trainingthat', u'class balanc use', u'class balancinganalys', u'class balancinganalys result', u'class balancingfrom', u'class balancingfrom tabl', u'class balancingiter', u'class balancingiter result', u'class bayesian', u'class bayesian segnet', u'class blacken', u'class blackenedfigur', u'class blackenedfigur row', u'class blackenedon', u'class blackenedon soft-max', u'class boundari', u'class boundari architectur', u'class boundari model', u'class boundari object', u'class boundari thepool', u'class boundari theseg', u'class camvid', u'class camvid road', u'class car', u'class car label', u'class challeng', u'class challeng dataset', u'class challeng retrospect', u'class citeraey', u'class citeraey quantit', u'class class', u'class class averag', u'class classfi', u'class classfi poor', u'class classfi poorlydens', u'class classfi poorlyunari', u'class classifi', u'class classifi poor', u'class come', u'class come various', u'class comparison', u'class comparison crf', u'class contour', u'class contour delin', u'class correct', u'class correct ani', u'class dataset', u'class dataset inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow', u'class dataset inuncertainti', u'class dens', u'class dens model', u'class denseclutt', u'class denseclutt row', u'class densesom', u'class densesom scene', u'class distribut', u'class distribut awareimprov', u'class distribut awaretrain', u'class distribut deeplab-larg', u'class domin', u'class domin major', u'class easier', u'class easier occur', u'class edg', u'class edgesform', u'class edgesform becaus', u'class edgesof', u'class edgesof low', u'class fenceclass', u'class fenceclass resembl', u'class fenceperform', u'class fenceperform better', u'class frequenc', u'class frequenc comput', u'class frequenc impli', u'class good', u'class good improv', u'class highest', u'class highest experimentedof', u'class highest experimentedwith', u'class honour', u'class honour fromalex', u'class honour fromth', u'class includ', u'class includ wall', u'class includingar', u'class includingar captur', u'class includingwal', u'class includingwal floor', u'class individ', u'class individ class', u'class indoor', u'class indoor scene', u'class infer', u'class infer dens', u'class informationfeatur', u'class informationfeatur activ', u'class informationrath', u'class informationrath individu', u'class interestfor', u'class interestfor autonom', u'class interestonlin', u'class interestonlin demo', u'class inth', u'class inth train', u'class label', u'class label appear', u'class label measur', u'class label weoften', u'class label wesegment', u'class loss', u'class loss function', u'class lost', u'class lost fcn', u'class lower', u'class lower accuraci', u'class maximum', u'class maximum probabl', u'class meanintersect', u'class meanintersect union', u'class meanth', u'class meanth mean', u'class method', u'class method use', u'class note', u'class note result', u'class note wecould', u'class note welarg', u'class object', u'class object furnitur', u'class observ', u'class observ report', u'class onli', u'class onli centralencod', u'class onli centralfit', u'class pole', u'class pole peopl', u'class predict', u'class predict howev', u'class predict segment', u'class present', u'class present ground', u'class present scene', u'class present testar', u'class present testimag', u'class probabl', u'class probabl center', u'class probabl pixelindepend', u'class probabl pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach', u'class probabl pixelsoft-max', u'class produc', u'class produc smooth', u'class reason', u'class reason size', u'class reasonableaccuraci', u'class reasonableaccuraci smaller', u'class reasonablereport', u'class reasonablereport tabl', u'class remark', u'class remark herethat', u'class remark hereto', u'class resembl', u'class resembl build', u'class road', u'class road build', u'class road side-walk', u'class row', u'class row darker', u'class scene', u'class scene test', u'class segment', u'class segment label', u'class segment problem', u'class segment task', u'class sign', u'class sign pole', u'class sign symbol', u'class signsymbol', u'class signsymbol bicyclist', u'class signth', u'class signth dataset', u'class simultan', u'class simultan task', u'class skew', u'class skew class', u'class sky', u'class sky road', u'class spatial', u'class spatial context', u'class such360', u'class such360 resolut', u'class sucha', u'class sucha road', u'class suchscen', u'class suchscen major', u'class suggest', u'class suggest segnet', u'class sun', u'class sun fig', u'class sun rgb-d', u'class term', u'class term classbalanc', u'class term classth', u'class test', u'class test dataset', u'class train', u'class train set', u'class use', u'class use pascal', u'class varieti', u'class varieti scene', u'class video', u'class video high-definit', u'class wecaff', u'class wecaff prototxt', u'class weus', u'class weus mini-batch', u'class widelyof', u'class widelyof segment', u'class widelyvari', u'class widelyvari background', u'class-label', u'class-label random', u'class-label random forest', u'classaccuraci', u'classaccuraci class', u'classaccuraci class frequenc', u'classal', u'classal classesal', u'classal classesal classesal', u'classand', u'classand recal', u'classand recal valu', u'classbalanc', u'classbalanc use', u'classbalanc use median', u'classboundari', u'classboundari given', u'classboundari given pixel', u'classcar', u'classcar classal', u'classcar classal classesal', u'classcar classcar', u'classcar classcar classal', u'classcar classcar classcar', u'classcarlo', u'classcarlo sampl', u'classcarlo sampl signific', u'classedg', u'classedg error', u'classedg error depth', u'classesal', u'classesal classesal', u'classesal classesal classesal', u'classesal classesal classesfigur', u'classesal classesfigur', u'classesal classesfigur comparison', u'classesand', u'classesand class', u'classesand class car', u'classesand \\u201cfill', u'classesand \\u201cfill in\\u201d', u'classesat', u'classesat depth', u'classesat depth onli', u'classeschair', u'classeschair sofa', u'classescom', u'classescom various', u'classescom various shape', u'classesdo', u'classesdo retain', u'classesdo retain small', u'classesfeatur', u'classesfeatur map', u'classesfeatur map compress', u'classesfigur', u'classesfigur comparison', u'classesfigur comparison uncertainti', u'classesk', u'classesk make', u'classesk make fair', u'classeslay', u'classeslay featur', u'classeslay featur predict', u'classesnumb', u'classesnumb classesnumb', u'classesnumb classesnumb classesnumb', u'classesnumb classesnumb classessegnet', u'classesnumb classessegnet', u'classesnumb classessegnet use', u'classessegnet', u'classessegnet use', u'classessegnet use \\u201cflat\\u201d', u'classesthat', u'classesthat bayesian', u'classesthat bayesian segnet', u'classesus', u'classesus mini-batch', u'classesus mini-batch size', u'classesw', u'classesw use', u'classesw use benchmark', u'classesw use mini-batch', u'classeswhich', u'classeswhich class', u'classeswhich class label', u'classfi', u'classfi poor', u'classfi poorlydens', u'classfi poorlydens depth', u'classfi poorlyunari', u'classfi poorlyunari structur', u'classforest', u'classforest boost', u'classforest boost predict', u'classic', u'classic featur', u'classic featur engin', u'classif', u'classif accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun', u'classif accuracycamvidcamvidcamvidcamvidcamvidcamvidcamvidsun rgbdsun', u'classif accuracypixel-wis', u'classif accuracypixel-wis classif', u'classif architectur', u'classif architectur ranzato', u'classif blocki', u'classif blocki anoth', u'classif dataset', u'classif dataset decod', u'classif imbalanc', u'classif imbalanc label', u'classif increasesin', u'classif increasesin accuraci', u'classif increasesind', u'classif increasesind need', u'classif iniccv', u'classif iniccv pp', u'classif insurpass', u'classif insurpass human-level', u'classif larg', u'classif larg dataset', u'classif layer', u'classif layer architectur', u'classif layer thisarchitectur', u'classif layer thisnetwork', u'classif map', u'classif map produc', u'classif network', u'classif network convolutionallay', u'classif network convolutionalth', u'classif network independ', u'classif network train', u'classif novelti', u'classif novelti segnet', u'classif rgb', u'classif rgb rgbd', u'classif somewhat', u'classif somewhat similardecod', u'classif somewhat similarunsupervis', u'classif transpos', u'classif transpos encod', u'classif typic', u'classif typic patch', u'classif use', u'classif use random', u'classif use randomalso', u'classif use randomforest', u'classifi', u'classifi dataset', u'classifi dataset class', u'classifi deep', u'classifi deep layersloc', u'classifi deep layersof', u'classifi e', u'classifi hidden', u'classifi hidden layer', u'classifi pixel', u'classifi pixel independ', u'classifi pixel-wis', u'classifi pixel-wis classif', u'classifi pixel-wis classificationcvpr', u'classifi pixel-wis classificationto', u'classifi poor', u'classifi poor dens', u'classifi post-process', u'classifi post-process use', u'classifi predict', u'classifi predict ina', u'classifi predict incombin', u'classifi predict pixel', u'classifi produc', u'classifi produc class', u'classifi randomfeatur', u'classifi randomfeatur general', u'classifi randomforest', u'classifi randomforest boost', u'classifi randomr', u'classifi randomr hand', u'classifi second', u'classifi second ablat', u'classifi smoothedbi', u'classifi smoothedbi use', u'classifi smoothedcal', u'classifi smoothedcal unari', u'classifi soft-maxclassifi', u'classifi soft-maxclassifi pixel', u'classifi soft-maxdecod', u'classifi soft-maxdecod fed', u'classifi unlikeor', u'classifi unlikeor rgbd', u'classifi unliketh', u'classifi unliketh decod', u'classifi withno', u'classifi withno bias', u'classifi withth', u'classifi withth object', u'classification-segment', u'classification-segment network', u'classification-segment network classif', u'classification-segment network work', u'classificationand', u'classificationand segment', u'classificationand segment network', u'classificationcvpr', u'classificationcvpr propos', u'classificationcvpr propos idea', u'classificationeach', u'classificationeach decod', u'classificationeach decod fulli', u'classificationindoor', u'classificationindoor rgbd', u'classificationindoor rgbd pixel-wis', u'classificationmulti-dimension', u'classificationmulti-dimension featur', u'classificationmulti-dimension featur pixel', u'classificationne', u'classificationne improv', u'classificationne improv featur', u'classificationobtain', u'classificationobtain featur', u'classificationobtain featur accur', u'classificationregion', u'classificationregion propos', u'classificationregion propos infer', u'classificationth', u'classificationth recent', u'classificationth recent propos', u'classificationto', u'classificationto densifi', u'classificationto densifi featur', u'classifict', u'classifict ofeith', u'classifict ofeith rgb', u'classifict ofof', u'classifict ofof hand', u'classifier84', u'classifierdropout', u'classifierdropout classifier84', u'classifierdropout classifierdropout', u'classifierdropout classifierdropout classifier84', u'classifierdropout classifierdropout classifierdropout', u'classifierfocuss', u'classifierfocuss real-tim', u'classifierfocuss real-tim joint', u'classifiergroup', u'classifiergroup befor', u'classifiergroup befor perform', u'classifiersar', u'classifiersar smooth', u'classifiersar smooth use', u'classifiersegment', u'classifiersegment random', u'classifiersegment random forest', u'classifiersnoisi', u'classifiersnoisi predict', u'classifiersnoisi predict unari', u'classifierth', u'classifierth common', u'classifierth common attribut', u'classlabel', u'classlabel overal', u'classlabel overal measur', u'classprob', u'classprob center', u'classprob center pixel', u'classresolut', u'classresolut lack', u'classresolut lack ground', u'classth', u'classth loss', u'classth loss differ', u'classuncertainti', u'classuncertainti class', u'classvalu', u'classvalu pixel', u'classvalu pixel class', u'classvari', u'classvari measur', u'classvari measur overal', u'clear', u'clear better', u'clear better deconvnet', u'clear better fix', u'clear experi', u'clear experi independ', u'clear illustr', u'clear illustr fig', u'clear larger', u'clear larger class', u'clear noisi', u'clear noisi qualiti', u'clear superior', u'clear superior rest', u'clear worsefor', u'clear worsefor shallow', u'clear worseto', u'clear worseto pole', u'clearlycontour', u'clearlycontour delin', u'clearlycontour delin metric', u'clearlywhen', u'clearlywhen memori', u'clearlywhen memori dure', u'close', u'close class', u'close class edg', u'close class edgesform', u'close class edgesof', u'closest', u'closest input', u'closest input layer', u'closest tonot', u'closest tonot decod', u'closest toth', u'closest toth input', u'closestthat', u'closestthat decod', u'closestthat decod correspond', u'closestto', u'closestto input', u'closestto input imag', u'cloth', u'cloth ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper11', u'cloth ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376', u'cloth ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376 2273towel', u'cloth ceilingfloor', u'cloth ceilingfloor mat', u'cloud', u'cloud eccv', u'cloud eccv marseill', u'cloud inand', u'cloud inand recognit', u'cloud ineccv', u'cloud ineccv marseill', u'clutter', u'clutter note', u'clutter note ofan', u'clutter note ofsegment', u'clutter row', u'clutter row right', u'clutteri', u'clutteri clear', u'clutteri clear noisi', u'clutteri increas', u'clutteri increas result', u'co-adapt', u'co-adapt featur', u'co-author', u'co-author than300', u'co-author than300 paper', u'co-author than300 papers300', u'co-author thanha', u'co-author thanha author', u'co-occurr', u'co-occurr ofobject', u'co-occurr ofobject spatial-context', u'co-occurr ofunderstand', u'co-occurr ofunderstand idea', u'coco', u'coco common', u'coco common object', u'code', u'code avail', u'code avail public', u'code evalu', u'code evalu expens', u'code optimis', u'code optimis train', u'code project', u'code project webpage1', u'code project webpageat', u'code project webpagemi', u'code web2', u'code web2 http', u'code webdemo', u'code webdemodemodemodemodemodemoconverg', u'code webdemodemodemodemodemodemoconverg befor', u'colleg', u'colleg becamea', u'colleg becamea reader', u'colleg becamejapan', u'colleg becamejapan join', u'color', u'color textur', u'color textur cue', u'colour', u'colour indic', u'colour indic uncertain', u'colour mask', u'colour mask correspond', u'colourfigur', u'colourfigur comparison', u'colourfigur comparison uncertainti', u'colourrepres', u'colourrepres larger', u'colourrepres larger valu', u'coloursbayesian', u'coloursbayesian segnet', u'coloursbayesian segnet segment', u'coloursind', u'coloursind uncertain', u'coloursind uncertain predict', u'column', u'column bicyclist', u'column bicyclist column', u'column far', u'column far sidewalk', u'column howev', u'column howev thisbas', u'column howev thispart', u'column increas', u'column increas result', u'column pascal', u'column pascal voc', u'column quantit', u'column quantit result', u'column right', u'column right left', u'column tabl', u'column tabl result', u'column wise', u'column wise pixel', u'column-wis', u'column-wis depth', u'column-wis depth normal', u'column2', u'column2 better', u'column2 better method', u'columndetector', u'columndetector crf', u'columndetector crf model', u'com/cudnncom/cudnncom/cudnncomput', u'com/cudnncom/cudnncom/cudnncomput layer', u'com/cudnncom/cudnncom/cudnncomput layer usingcomput', u'combin', u'combin crf', u'combin crf base', u'combin extern', u'combin extern traineddetector', u'combin extern trainedfigur', u'combin featur', u'combin featur map', u'combin form', u'combin form ensembl', u'combin object', u'combin object detector', u'combin popular', u'combin popular hand', u'combin rgb', u'combin rgb depth', u'combin use', u'combin use trainobtain', u'combin use trainsegnet', u'come', u'come ad', u'come ad new', u'come expens', u'come expens infer', u'come various', u'come various resolut', u'come various shape', u'command', u'command use', u'command use toa', u'command use tocomput', u'commensur', u'commensur withincreas', u'commensur withincreas train', u'commensur withparticular', u'commensur withparticular perform', u'common', u'common attribut', u'common attribut approach', u'common ideai', u'common ideai use', u'common idealay', u'common idealay singl', u'common multi-scal', u'common multi-scal convolut', u'common object', u'common object incontext', u'common object inp', u'common use', u'common use evalu', u'common use perform', u'commonattribut', u'commonattribut approach', u'commonattribut approach use', u'commonfeatur', u'commonfeatur trainabl', u'commonfeatur trainabl paramet', u'commongroup', u'commongroup befor', u'commongroup befor perform', u'commonlytrain', u'commonlytrain data', u'commonlyus', u'commonlyus regular', u'commonlyus regular convolut', u'commonof', u'commonof decod', u'commonof decod network', u'communic', u'communic thea', u'communic theacm', u'communiti', u'communiti doe', u'communiti doe reus', u'compar', u'compar algorithm', u'compar algorithm numer', u'compar analysi', u'compar analysi variant', u'compar class', u'compar class fenceclass', u'compar class fenceperform', u'compar compet', u'compar compet deep', u'compar compet model', u'compar deconvnet', u'compar deconvnetbut', u'compar deconvnetbut segnet', u'compar deconvnetthi', u'compar deconvnetthi seen', u'compar exceed', u'compar exceed method', u'compar fcn', u'compar fcn withevid', u'compar fcn withsegnet-typ', u'compar fcn-basic', u'compar fcn-basic vitali', u'compar fcn-basic vitalto', u'compar input', u'compar input imag', u'compar itand', u'compar itand comput', u'compar iter', u'compar iter segnet', u'compar itwith', u'compar itwith import', u'compar larger', u'compar larger model', u'compar meanfigur', u'compar meanfigur bayesian', u'compar meanmodel', u'compar meanmodel uncertainti', u'compar memorizingfeatur', u'compar memorizingfeatur map', u'compar memorizingi', u'compar memorizingi effici', u'compar method', u'compar method qualit', u'compar method use', u'compar method usecompetit', u'compar method usecrf', u'compar method usesad', u'compar method usesi', u'compar method utilis', u'compar otherachiev', u'compar otherachiev highest', u'compar othermodel', u'compar othermodel deconvnet', u'compar othernetwork', u'compar othernetwork signific', u'compar otherrec', u'compar otherrec architectur', u'compar outdoor', u'compar outdoor scene', u'compar perform', u'compar perform order', u'compar perform weightaverag', u'compar perform weightcamvid', u'compar perform withfcn', u'compar previousbenchmark', u'compar previoust', u'compar previoust result', u'compar promin', u'compar promin deep', u'compar propos', u'compar propos architectur', u'compar quantit', u'compar quantit perform', u'compar segnet', u'compar segnet 14mad', u'compar segnet 14mparamet', u'compar segnet decodingnetwork', u'compar segnet decodingtechniqu', u'compar segnet perform', u'compar segnet sever', u'compar segnet u-net', u'compar segnet-bas', u'compar segnet-bas fcn-basic', u'compar sift-flow', u'compar sift-flow labelm', u'compar studi', u'compar studi byadopt', u'compar studi byngiam', u'compar thelarg', u'compar thelarg model', u'compar thesegnet', u'compar thesegnet superior', u'compar toother', u'compar toother method', u'compar totabl', u'compar totabl result', u'compar version', u'compar version fcn', u'compar weight', u'compar weight averag', u'compar wellknown', u'compar wellknown deep', u'compar wellto', u'compar wellto encourag', u'compar withloc', u'compar withloc patch', u'compar withproduc', u'compar withproduc smooth', u'comparabledeconvnet', u'comparabledeconvnet fulli', u'comparabledeconvnet fulli connect', u'comparableor', u'comparableor higher', u'comparableor higher forward-backward', u'comparedin', u'comparedin accuraci', u'comparedin accuraci achiev', u'comparedshow', u'comparedshow segnet', u'comparedshow segnet provid', u'comparedto', u'comparedto architectur', u'comparedto architectur provid', u'comparedto classic', u'comparedto classic featur', u'comparison', u'comparison abov', u'comparison abov variant', u'comparison comput', u'comparison comput time', u'comparison convolut', u'comparison convolut manner', u'comparison crf', u'comparison crf base', u'comparison deep', u'comparison deep architectur', u'comparison deep network', u'comparison fcn-basicnoaddit', u'comparison fcn-basicnoaddit segnet-basic-singlechanneldecod', u'comparison imag', u'comparison imag indoor', u'comparison larger', u'comparison larger parameter', u'comparison method', u'comparison method segnet', u'comparison nyu', u'comparison nyu dataset', u'comparison reveal', u'comparison reveal memori', u'comparison segnet', u'comparison segnet multi-channelconvolut', u'comparison segnet multi-channeldeconvolut', u'comparison segnet predict', u'comparison segnet tradit', u'comparison sun', u'comparison sun rgb-d', u'comparison term', u'comparison term size', u'comparison uncertainti', u'comparison uncertainti mont', u'comparison withdeconvnet', u'comparison withdeconvnet later', u'comparisondecod', u'comparisondecod featur', u'comparisondecod featur map', u'comparisonfcn-bas', u'comparisonfcn-bas use', u'comparisonfcn-bas use dimension', u'compat', u'compat camvid', u'compat camvid dataset', u'compat implement', u'compat implement segnet', u'compet', u'compet deep', u'compet deep learn', u'compet method', u'compet methodsrec', u'compet methodsrec compet', u'compet methodsth', u'compet methodsth kitti', u'compet model', u'compet model deconvnet', u'competingarchitectur', u'competingarchitectur shown', u'competingarchitectur shown effici', u'competingarchitectur train', u'competingarchitectur train end-to-end', u'competingcomput', u'competingcomput time', u'competingcomput time dure', u'competingwhich', u'competingwhich signific', u'competingwhich signific smaller', u'competit', u'competit accuraci', u'competit accuraci remain', u'competit achiev', u'competit achiev high', u'competit evenfor', u'competit evenfor outdoor', u'competit evenwithout', u'competit evenwithout use', u'competit infer', u'competit infer time', u'competit performancegiven', u'competit performancegiven smallest', u'competit performancelabel', u'competit performancelabel resolut', u'competit result', u'competit result smaller', u'competit resultsalthough', u'competit resultsalthough smaller', u'competit resultsand', u'competit resultsand crf', u'competit tempor', u'competit tempor cue', u'competitiveit', u'competitiveit segnet-bas', u'competitiveit segnet-bas competitiveit', u'competitiveit segnet-bas competitivetrain', u'competitivetrain', u'competitivetrain accuraci', u'competitivetrain accuraci compar', u'competitor', u'complement', u'complement benchmark', u'complement benchmark andrev', u'complement benchmark andthi', u'complement miouauthor', u'complement miouauthor fcn', u'complement mioumetr', u'complement mioumetr boundari', u'complement theireffort', u'complement theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth', u'complement theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth qualit', u'complement theirour', u'complement theirour control', u'complet', u'complet run', u'complet run dataset', u'complex', u'complex task', u'complex task class', u'complex train', u'complex train infer', u'complexmak', u'complexmak easier', u'complexmak easier deep', u'complexsinc', u'complexsinc view', u'complexsinc view point', u'compon', u'compon ofrec', u'compon ofrec architectur', u'compon ofsegnet', u'compon ofsegnet decod', u'compos', u'compos stack', u'compos stack encod', u'compress', u'compress form', u'compress form encod', u'compress k', u'compress k channel', u'compress match', u'compress match number', u'compromis', u'compromis storagecost', u'compromis storagecost accuraci', u'compromis storagewhen', u'compromis storagewhen need', u'compromis toi', u'compromis toi constrain', u'compromis tosom', u'compromis tosom extent', u'compromis tosom extentsom', u'comput', u'comput batch', u'comput batch normalis', u'comput budget', u'comput budget tabl', u'comput camvid', u'comput camvid video', u'comput cost', u'comput cost alsodeconvnet', u'comput cost alsose', u'comput cost success', u'comput dure', u'comput dure pool', u'comput duringeach', u'comput duringeach sampl', u'comput duringpool', u'comput duringpool store', u'comput effort', u'comput effort row', u'comput entir', u'comput entir train', u'comput exposur', u'comput exposur new', u'comput featur', u'comput featur activations/mapsfor', u'comput handl', u'comput handl new', u'comput load', u'comput load import', u'comput max-pool', u'comput max-pool step', u'comput memori', u'comput memori consumpt', u'comput miou', u'comput miou bf', u'comput onlin', u'comput onlin evalu', u'comput perspect', u'comput perspect necessaryfor', u'comput perspect necessaryrepresent', u'comput precisionand', u'comput precisionand recal', u'comput precisionth', u'comput precisionth key', u'comput remot', u'comput remot test', u'comput resourc', u'comput resourc harder', u'comput scienc', u'comput scienc page', u'comput scienc pp', u'comput semant', u'comput semant contour', u'comput statist', u'comput statist tabl', u'comput statisticstest', u'comput statisticstest time', u'comput statisticswhil', u'comput statisticswhil use', u'comput thefor', u'comput thefor sampl', u'comput therootrootrootrootrootsquar', u'comput therootrootrootrootrootsquar valu', u'comput time', u'comput time analys', u'comput time dure', u'comput time hardwar', u'comput time weconclud', u'comput time wesegnet', u'comput timei', u'comput timei order', u'comput timei spent', u'comput use', u'comput use mini-batch', u'comput veri', u'comput veri expens', u'comput vision', u'comput vision challeng', u'comput vision iccv', u'comput vision ijcv', u'comput vision pattern', u'comput vision pp', u'comput vision robot', u'comput vision univers', u'comput vision vol', u'comput vision\\u2013dens', u'comput vision\\u2013dens correspond', u'comput vision\\u2013eccv', u'comput vision\\u2013eccv page', u'comput vision\\u2013eccv pp', u'comput weight', u'comput weight averag', u'computed66', u'computed6696', u'computed6696 240k6696', u'computed6696 240k6696 240k6696', u'computed89', u'computed8971', u'computed8971 140k8971', u'computed8971 140k8971 140k8971', u'computednot', u'computednot computed66', u'computednot computed6696', u'computednot computed6696 240k6696', u'computednot computed89', u'computednot computed8971', u'computednot computed8971 140k8971', u'computednot computednot', u'computednot computednot computed66', u'computednot computednot computed6696', u'computednot computednot computed89', u'computednot computednot computed8971', u'computednot computednot computednot', u'computei', u'computei averag', u'computei averag produc', u'computeth', u'computeth test', u'computeth test set', u'concaten', u'concaten upsampledmax-pool', u'concaten upsampledmax-pool block', u'concaten upsampledth', u'concaten upsampledth correspond', u'concentr', u'concentr layer', u'concentr layer wise', u'conceptu', u'conceptu mimic', u'conceptu mimic larger', u'conclud', u'conclud sec', u'conclud sec 622l', u'conclud sec 6pointer', u'conclusion5', u'conclusion5 conclusion5', u'conclusion5 conclusion5 conclusion5', u'conclusion5 conclusion5 conclusionw', u'conclusion5 conclusionw', u'conclusion5 conclusionw present', u'conclusions6', u'conclusionsw', u'conclusionsw present', u'conclusionsw present bayesian', u'conclusionw', u'conclusionw present', u'conclusionw present segnet', u'condit', u'condit qualit', u'condit qualit comparison', u'condit random', u'condit random field', u'condit randomfield', u'condit randomfield crfs', u'condit randomregion', u'condit randomregion propos', u'confer', u'confer comput', u'confer comput vision', u'confer multimedia', u'confer multimedia pp', u'confer oncomput', u'confer oncomput vision', u'confer onnetwork', u'confer onnetwork proceed', u'confer page', u'confer pages2190\\u20132197', u'confer pagesclass-label', u'confer pagesclass-label random', u'conferenceon', u'conferenceon comput', u'conferenceon comput vision', u'conferenceunderstand', u'conferenceunderstand benchmark', u'conferenceunderstand benchmark suit', u'confid', u'confid class', u'confid class easier', u'confid pixel', u'confid pixel the0th', u'confid pixel thefor', u'confid preval', u'confid preval inth', u'confid preval inthat', u'confid trust', u'confid trust imag', u'confid wefigur', u'confid wefigur bayesian', u'confid wesystem', u'confid wesystem output', u'confidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidence90909050505010101000pixel-wis', u'confidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidence90909050505010101000pixel-wis classif', u'confidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidenceconfidence90909050505010101000pixel-wis classif accuracypixel-wis', u'confidencefor', u'confidencefor 90th', u'confidencefor 90th percentil', u'confidencein', u'confidencein predict', u'confidencemodel', u'confidencemodel uncertainti', u'confidencemodel uncertainti effect', u'confidencet', u'confidencet bayesian', u'confidencet bayesian segnet', u'configur', u'configur bayesianof', u'configur bayesianof variant', u'configur bayesianor', u'configur bayesianor determinist', u'configur drop', u'configur drop deepest', u'conjectur', u'conjectur base', u'conjectur base fact', u'conjunct', u'conjunct miou', u'conjunct miou metric', u'connect', u'connect choic', u'connect choic motiv', u'connect crfs', u'connect crfs iclr', u'connect decod', u'connect decod second', u'connect layer', u'connect layer encod', u'connect layer favour', u'connect layer henc', u'connect layer turn', u'connect layer vgg-16', u'connect layer vgg16', u'connnect', u'connnect layer', u'connnect layer deconvnet', u'consand', u'consand reveal', u'consand reveal pros', u'consequ', u'consequ larger', u'consequ larger spatial', u'consid', u'consid activ', u'consid activ tune', u'consid choos', u'consid choos model', u'consid segnet', u'consid segnet layer', u'consid thesea', u'consid thesea mont', u'consid theseweight', u'consid theseweight requir', u'consid use', u'consid use dropout', u'consider', u'consider smaller', u'consider smaller achiev', u'considerationof', u'considerationof model', u'considerationof model train', u'considerationparticular', u'considerationparticular perform', u'considerationparticular perform gain', u'consist', u'consist 5050tabl', u'consist 5050tabl sun', u'consist 5050test', u'consist 5050test imag', u'consist about90', u'consist about90 paramet', u'consist aboutnetwork', u'consist aboutnetwork howev', u'consist acrossth', u'consist acrossth distribut', u'consist acrossthi', u'consist acrossthi becaus', u'consist encod', u'consist encod network', u'consist filter', u'consist filter bank', u'consist fulli', u'consist fulli connect', u'consist hierarchyof', u'consist hierarchyof decod', u'consist hierarchysegnet', u'consist hierarchysegnet decod', u'consist of367', u'consist of367 train', u'consist ofconvolut', u'consist ofconvolut filter', u'consist ofmodul', u'consist ofmodul encoder-decod', u'consist ofw', u'consist ofw use', u'consist oneand', u'consist oneand correspond', u'consist oneor', u'consist oneor convolut', u'consist region', u'consist region iccv', u'consist road', u'consist road scene', u'consist test', u'consist test imag', u'consistsarchitectur', u'consistsarchitectur illustr', u'consistsarchitectur illustr fig', u'consistsconvolut', u'consistsconvolut encod', u'consistsconvolut encod decod', u'consistsof', u'consistsof convolut', u'consistsof convolut layer', u'consistsof segment', u'consistsof segment salient', u'consistsof sequenc', u'consistsof sequenc non-linear', u'consiststh', u'consiststh pascal', u'consiststh pascal voc12', u'constant', u'constant featur', u'constant featur size', u'constant number', u'constant number featurescrf', u'constant number featuresp', u'constantkernel', u'constantkernel size', u'constantkernel size encod', u'constantnetwork', u'constantnetwork bias', u'constantnetwork bias use', u'constrain', u'constrain compress', u'constrain compress form', u'constrain encod', u'constrain encod featur', u'constrain infer', u'constrain infer time', u'constrain larger', u'constrain larger model', u'constraint', u'constraint instead', u'constraint instead chose', u'construct', u'construct train', u'construct train decod', u'consum', u'consum memori', u'consum memori longer', u'consum memori time', u'consumpt', u'consumpt train', u'consumpt train memori', u'consumptionand', u'consumptionand improv', u'consumptionand improv infer', u'consumptionwithout', u'consumptionwithout sacrif', u'consumptionwithout sacrif perform', u'consw', u'consw evalu', u'consw evalu perform', u'contain', u'contain 11semant', u'contain 11semant class', u'contain 11the', u'contain 11the camvid', u'contain convolut', u'contain convolut layersan', u'contain convolut layersfollow', u'contain train', u'contain train and654', u'contain train andi', u'contain train test', u'contain video', u'contain video sequenc', u'containsfollow', u'containsfollow max', u'containsfollow max pool', u'containson', u'containson convolut', u'containson convolut layer', u'contemporari', u'contemporari deep', u'contemporari deep method', u'context', u'context comput', u'context comput vision\\u2013eccv', u'context differ', u'context differ class', u'context forcan', u'context forcan introduc', u'context forpixel', u'context forpixel label', u'context input', u'context input space', u'context larger', u'context larger potenti', u'context layer', u'context layer segnet', u'context pixel', u'context pixel feature-map', u'context relatedbas', u'context relatedbas cue', u'context relatedclass', u'context relatedclass crf', u'context segnet', u'context segnet overcomesnumb', u'context segnet overcomesthes', u'context smooth', u'context smooth label', u'context spatial', u'context spatial window', u'context use', u'context use deeper', u'context use featur', u'context window', u'context window input', u'context window retain', u'context/class', u'context/class locat', u'context/class locat inform', u'contextfor', u'contextfor pixel-wis', u'contextfor pixel-wis label', u'contextof', u'contextof featur', u'contextof featur encod', u'continu', u'continu advanc', u'continu advanc comput', u'contour', u'contour delin', u'contour delin metric', u'contour delin network', u'contour measur', u'contour measur bf', u'contour score', u'contour score evalu', u'contourmatch', u'contourmatch score', u'contourmatch score common', u'contourmetr', u'contourmetr boundari', u'contourmetr boundari measur', u'contrast', u'contrast dropout', u'contrast dropout uncertainti', u'contrast effect', u'contrast effect clear', u'contrast normal', u'contrast normal channel', u'contrast normal lcn', u'contrast normal rgb', u'contrast shadow', u'contrast shadow ii', u'contribut', u'contribut learn', u'contribut learn anencoder-decod', u'contribut learn angen', u'contribut paper', u'contribut paper analysisof', u'contribut paper analysison', u'contribut paper extend', u'contribut practic', u'contribut practic abl', u'contribut prior', u'contribut prior crf', u'contribut segment', u'contribut segment autonom', u'contribut tobayesian', u'contribut tobayesian segnet', u'contribut tounderstand', u'contribut tounderstand confid', u'control', u'control analysi', u'control analysi complement', u'control benchmark', u'control benchmark segnetand', u'control benchmark segnetarchitectur', u'control benchmark set', u'control benchmark train', u'control benchmark use', u'control mean', u'control mean architectur', u'control set', u'control set deeplab-largefov', u'control step', u'control step size', u'controlleddataset', u'controlleddataset need', u'controlleddataset need verifi', u'controlledfor', u'controlledfor poor', u'controlledfor poor perform', u'converg', u'converg afteraround', u'converg afteraround sampl', u'converg aftersampl', u'converg aftersampl outperform', u'converg observ', u'converg observ furtherreduct', u'converg observ furtherth', u'converg sgd', u'converg sgd work', u'convergeand', u'convergeand perform', u'convergeand perform poor', u'convergear', u'convergear redund', u'convergear redund consum', u'convers', u'convers difficult', u'convers difficult class', u'convers rare', u'convers rare class', u'convers sky', u'convers sky road', u'conveyconvolut', u'conveyconvolut network', u'conveyconvolut network fcn', u'conveyth', u'conveyth practic', u'conveyth practic trade-off', u'convnet', u'convnet 5243d', u'convnet 5243d seman', u'convnet multi-scal', u'convnet multi-scal convnet', u'convnet pool', u'convnet pool layer', u'convnet use', u'convnet use input', u'convolut', u'convolut architectur', u'convolut architectur arxivlabel', u'convolut architectur arxivpreprint', u'convolut architectur forfast', u'convolut architectur guadarrama', u'convolut architectur iccv', u'convolut architectur segment', u'convolut corr', u'convolut corr abs/14094842', u'convolut corr abs/14094842,2014', u'convolut decod', u'convolut decod upsampl', u'convolut deep', u'convolut deep network', u'convolut deep networksin', u'convolut deep networkstop-down', u'convolut dure', u'convolut dure backpropag', u'convolut encoder-decod', u'convolut encoder-decod architectur', u'convolut encoder-decoderarchitectur', u'convolut encoder-decoderarchitectur scene', u'convolut encoder-decoderbayesian', u'convolut encoder-decoderbayesian segnet', u'convolut faster', u'convolut faster noteresolut', u'convolut faster notethat', u'convolut featur', u'convolut featur hierarchi', u'convolut featurehierarchi', u'convolut featurehierarchi visual', u'convolut featurem', u'convolut featurem mathieu', u'convolut feedforwardi', u'convolut feedforwardi spent', u'convolut feedforwardpath', u'convolut feedforwardpath fft', u'convolut filter', u'convolut filter bank', u'convolut incvpr', u'convolut incvpr pp', u'convolut inv', u'convolut inv vanhouck', u'convolut layer', u'convolut layer batch', u'convolut layer correspond', u'convolut layer encod', u'convolut layer follow', u'convolut layer forbatch', u'convolut layer fordeeplab-largefov', u'convolut layer thebi', u'convolut layer thevgg16', u'convolut layer train', u'convolut layer unitseveri', u'convolut layer unitsj', u'convolut layer vgg-16', u'convolut layer vgg16', u'convolut layeron', u'convolut layeron hand', u'convolut layersan', u'convolut layersan encod', u'convolut layersfollow', u'convolut layersfollow max', u'convolut layerweight', u'convolut layerweight vgg', u'convolut manner', u'convolut manner report', u'convolut net', u\"convolut net filter'sa\", u\"convolut net filter'sweight\", u'convolut netsand', u'convolut netsand fulli', u'convolut netsyuill', u'convolut network', u'convolut network architectur', u'convolut network architecturefor', u'convolut network architecturew', u'convolut network basic', u'convolut network eccv', u'convolut network fcn', u'convolut network forj', u'convolut network fork', u'convolut network forlarge-scal', u'convolut network forsemant', u'convolut network imag', u'convolut networkin', u'convolut networkin order', u'convolut networktechniqu', u'convolut networktechniqu wide', u'convolut neural', u'convolut neural network', u'convolut pathway', u'convolut pathway featureextract', u'convolut pathway featurei', u'convolut relu', u'convolut relu non-linear', u'convolut relu nonlinear', u'convolut step', u'convolut step densifi', u'convolut tanh', u'convolut tanh squash', u'convolut trainabl', u'convolut trainabl filter', u'convolut usinga', u'convolut usinga fix', u'convolut usingnetwork', u'convolut usingnetwork upsampl', u'convolut weight', u'convolut weight w', u'convolution-relu-max', u'convolution-relu-max pooling-subsampl', u'convolution-relu-max pooling-subsampl pipelin', u'convolutionaldecod', u'convolutionaldecod techniqu', u'convolutionaldecod techniqu use', u'convolutionalencoder-decod', u'convolutionalencoder-decod architectur', u'convolutionalencoder-decod architectur imageencoder-decod', u'convolutionallay', u'convolutionallay fulli', u'convolutionallay fulli connect', u'convolutionalnetwork', u'convolutionalnetwork classif', u'convolutionalnetwork classif architectur', u'convolutionalnetwork object', u'convolutionalnetwork object classif', u'convolutionalsegnet', u'convolutionalsegnet deep', u'convolutionalsegnet deep convolutionalencoder-decod', u'convolutionalsegnet deep convolutionalsegnet', u'convolutionalth', u'convolutionalth input', u'convolutionalth input imag', u'convolutionalth vgg16', u'convolutionalth vgg16 classif', u'convolutioneach', u'convolutioneach encod', u'convolutioneach encod encod', u'convolutionwith', u'convolutionwith filter', u'convolutionwith filter bank', u'convolv', u'convolv themfeatur', u'convolv themfeatur map', u'convolv themwith', u'convolv themwith k', u'convolv train', u'convolv train decoderfilt', u'convolv train decoderor', u'convolv trainabl', u'convolv trainabl decod', u'convolv trainabl filter', u'convolv witha', u'convolv witha trainabl', u'convolv withillustr', u'convolv withillustr fig', u'convolvedupsampl', u'convolvedupsampl step', u'convolvedupsampl step howev', u'convolvedwith', u'convolvedwith trainabl', u'convolvedwith trainabl multi-channel', u'convolvetheir', u'convolvetheir correspond', u'convolvetheir correspond upsampl', u'convolvewher', u'convolvewher decod', u'convolvewher decod filter', u'cook', u'cook r', u'core', u'core feed-forward', u'core feed-forward segment', u'core feed-forwardsegment', u'core feed-forwardsegment engin', u'core feed-forwardto', u'core feed-forwardto lack', u'core recentarchitectur', u'core recentarchitectur architectur', u'core recentstudi', u'core recentstudi network', u'core segment', u'core segment engin', u'core trainabl', u'core trainabl segment', u'coresegment', u'coresegment engin', u'coresegment engin architectur', u'corew', u'corew seen', u'corew seen method', u'corner', u'corporationfellow', u'corporationfellow engin', u'corporationfellow engin toshiba', u'corporationresearch', u'corporationresearch develop', u'corporationresearch develop centr', u'corpus', u'corpus indoor', u'corpus indoor scene', u'corpus road', u'corpus road scenesquantit', u'corpus road sceneswithout', u'corr', u'corr abs/1409', u'corr abs/14094842', u'corr abs/14094842 deeper', u'corr abs/14094842,2014', u'corr abs/14094842,2014 1i', u'corr network', u'corr network train', u'corr vol', u'corr vol abs/14091556', u'corr vol abs/150203167', u'corr vol abs/150504366', u'corr vol abs/150507293', u'corr vol abs/150604579', u'correct', u'correct ani', u'correct ani label', u'correct edg', u'correct edg categori', u'correct fornon-uniform', u'correct fornon-uniform scene', u'correct forth', u'correct forth advantag', u'correct kavukcuogluet', u'correct kavukcuogluet al', u'correct kavukcuogluinput', u'correct kavukcuogluinput discrep', u'correct lack', u'correct lack sharp', u'correl', u'correl miou', u'correl miou metric', u'correl miou metriccorrel', u'correl miou metricnetworknetworknetworknetworknetworknetworknetworknetworkforward', u'correl miou small', u'correl miou smalland', u'correl miou smallsegnet', u'correl size', u'correl size class', u'correspond', u'correspond 13convolut', u'correspond 13convolut layer', u'correspond 13of', u'correspond 13of convolut', u'correspond decod', u'correspond decod concaten', u'correspond decod layer', u'correspond decod network', u'correspond decod soft-max', u'correspond decod upsampl', u'correspond decodernetwork', u'correspond decodernetwork follow', u'correspond decodersegnet', u'correspond decodersegnet encod', u'correspond deep', u'correspond deep featur', u'correspond deepan', u'correspond deepan imag', u'correspond deepmodel', u'correspond deepmodel predict', u'correspond differ', u'correspond differ scene', u'correspond encod', u'correspond encod closest', u'correspond encod closestthat', u'correspond encod closestto', u'correspond encod decod', u'correspond encod featur', u'correspond encod note', u'correspond encod perform', u'correspond encod theappropri', u'correspond encod theof', u'correspond encod tofeatur', u'correspond encod toperform', u'correspond encod tri', u'correspond encoderfeatur', u'correspond encoderfeatur map', u'correspond encoderthi', u'correspond encoderthi ad', u'correspond good', u'correspond good segmentationand', u'correspond good segmentationof', u'correspond highest', u'correspond highest miou', u'correspond human', u'correspond human qualitativejudg', u'correspond human qualitativethat', u'correspond loss', u'correspond loss spatial', u'correspond model', u'correspond model correspond', u'correspond model correspondinglargest', u'correspond model correspondingto', u'correspond output', u'correspond output featur', u'correspond qualit', u'correspond qualit result', u'correspond resolut', u'correspond resolut encod', u'correspond set', u'correspond set decod', u'correspond theclass', u'correspond theclass maximum', u'correspond thenumb', u'correspond thenumb class', u'correspond upsampl', u'correspond upsampl featur', u'correspond valu', u'correspond valu featur', u'correspondinglargest', u'correspondinglargest model', u'correspondinglargest model longest', u'correspondingto', u'correspondingto highest', u'correspondingto highest miou', u'correspondsconverg', u'correspondsconverg train', u'correspondsconverg train mini-batch', u'correspondsto', u'correspondsto test', u'correspondsto test approxim', u'cost', u'cost alsodeconvnet', u'cost alsodeconvnet compar', u'cost alsose', u'cost alsose tabl', u'cost infer', u'cost infer tabl', u'cost memori', u'cost memori toth', u'cost memori totransf', u'cost ofa', u'cost ofa complex', u'cost ofperform', u'cost ofperform signific', u'cost reduc', u'cost reduc forcomput', u'cost reduc forpract', u'cost success', u'cost success decreasesfor', u'cost success decreasesp', u'costfor', u'costfor pool', u'costfor pool indic', u'costsegnet', u'costsegnet hand', u'costsegnet hand requir', u'couldli', u'couldli inabl', u'couldli inabl deep', u'couldtrain', u'couldtrain techniqu', u'couldtrain techniqu anoth', u'counter', u'counter blinds83', u'counter blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766', u'counter blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766 4029deskdeskdeskdeskdeskshelvesshelvesshelvesshelvesshelvesshelvesshelvesshelvescurtaincurtaincurtaincurtaincurtaincurtaincurtaincurtaindresserdresserdresserdresserdresserdresserdresserdresserpillowpillowpillowpillowpillowpillowpillowmirrormirrormirrormirrormirrormirrormirrorfloor', u'counter blindsdoor', u'counter blindsdoor window', u'coupri', u'coupri l', u'coupri l najman', u'covari', u'covari shift', u'covari shift corr', u'cover', u'cover icml', u'cover icml 8pars', u'cover icml 8top-down', u'cover icml multiscal', u'cover icml,2012', u'cover icml,201220122012201220122012for', u'cover icml,201220122012201220122012for scene', u'creat', u'creat input', u'creat input imag', u'creat variant', u'creat variant fcn-basicmodel', u'creat variant fcn-basicpool', u'crf', u'crf 798boosting+high', u'crf 798boosting+high order', u'crf 856segnet', u'crf 856segnet r', u'crf 856space-tim', u'crf 856space-tim crf', u'crf base', u'crf base method', u'crf base methodstrain', u'crf base methodsvalu', u'crf base result', u'crf boost', u'crf boost pairwis', u'crf boosting+high', u'crf boosting+high order', u'crf contemporari', u'crf contemporari deep', u'crf dens', u'crf dens depth', u'crf dueperceiv', u'crf dueperceiv perform', u'crf dueto', u'crf dueto lack', u'crf framework', u'crf framework result', u'crf improv', u'crf improv accuraci', u'crf improv use', u'crf improv weremad', u'crf improv wereunari', u'crf lessenedalso', u'crf lessenedalso indic', u'crf lessenedwhen', u'crf lessenedwhen suffici', u'crf major', u'crf major class', u'crf model', u'crf model segnet', u'crf multi-scal', u'crf multi-scal networkand', u'crf multi-scal networkextract', u'crf oraid', u'crf oraid region', u'crf orthey', u'crf orthey requir', u'crf post-process', u'crf post-process alsodemonstr', u'crf post-process alsowithout', u'crf post-process produc', u'crf post-process seen', u'crf postprocess', u'crf postprocess techniqu', u'crf produc', u'crf produc high', u'crf recent', u'crf recent work', u'crf result', u'crf result smooth', u'crf smooth', u'crf smooth use', u'crf-rnn', u'crf-rnn network', u'crf-rnn network appendedmad', u'crf-rnn network appendedto', u'crf-rnn revealedtrain', u'crf-rnn revealedtrain fcn-8', u'crf-rnn revealedwhen', u'crf-rnn revealedwhen joint', u'crf-rnn use', u'crf-rnn use recurr', u'crf-rnnquestion', u'crf-rnnquestion perceiv', u'crf-rnnquestion perceiv advantag', u'crf-rnnwould', u'crf-rnnwould reduc', u'crf-rnnwould reduc core', u'crfcompar', u'crfcompar larger', u'crfcompar larger model', u'crfmodel', u'crfmodel various', u'crfmodel various order', u'crfor', u'crfor modal', u'crfor modal classifi', u'crfpost-process', u'crfpost-process produc', u'crfpost-process produc competit', u'crfs', u'crfs crf-rnn', u'crfs crf-rnn use', u'crfs eccv', u'crfs eccv mani', u'crfs eccv page', u'crfs eccv pp', u'crfs iclr', u'crfs iclr 2015connect', u'crfs iclr 2015h', u'crfslayer', u'crfslayer mimic', u'crfslayer mimic sharp', u'crfswhile', u'crfswhile exploit', u'crfswhile exploit featur', u'criteria', u'crop', u'crop centr', u'crop centr 360\\xd7480been', u'crop centr 360\\xd7480to', u'cross', u'cross entropyin', u'cross entropyin shown', u'cross entropyloss', u'cross entropyloss object', u'cross-entropi', u'cross-entropi label', u'cross-entropi label loss', u'cross-entropi label lossoth', u'cross-entropi label lossth', u'cross-entropi loss', u'cross-entropi loss object', u'cross-entropi lossth', u'cross-entropi lossth miou', u'cross-entropi lossthrough', u'cross-entropi lossthrough class', u'cs', u'cscv', u'cscv 2015arxiv:150507293v1', u'cscv 2015arxiv:150507293v1 cscv', u'cscv 2015vijay', u'cscv 2015vijay badrinarayanan', u'cscv oct', u'cscv oct 2016arxiv:151100561v3', u'cscv oct 2016vijay', u'csurka', u'csurka et', u'csurka et al', u'cudnn', u'cudnn acceler', u'cudnn acceler resultsfor', u'cudnn acceler resultsnot', u'cudnn v3', u'cudnn v3 acceler', u'cudnn v3 acceleration480', u'cudnn v3 accelerationw', u'cue', u'cue andoth', u'cue andoth deep', u'cue andshallow', u'cue andshallow architectur', u'cue anoth', u'cue anoth approachand', u'cue anoth approachfocuss', u'cue anotherapproach', u'cue anotherapproach focus', u'cue anotherus', u'cue anotherus combin', u'cue compar', u'cue compar method', u'cue fast', u'cue fast supersed', u'cue ground', u'cue ground plane', u'cue height', u'cue height ground', u'cue ieeeimag', u'cue ieeeimag boundari', u'cue ieeetransact', u'cue ieeetransact pattern', u'cue lack', u'cue lack cue', u'cue methodmethodmethodmethodmethodmethodmethodmulti-scal', u'cue methodmethodmethodmethodmethodmethodmethodmulti-scal convnet', u'cue particular', u'cue particular valuabl', u'cue segnet', u'cue segnet miss', u'cue tempor', u'cue tempor inform', u'cue transferredacross', u'cue transferredacross dataset', u'cue transferredperform', u'cue transferredperform camvid', u'cue use', u'cue use dusk', u'cue usedfor', u'cue usedfor indoor', u'cue usedi', u'cue usedi competit', u'current', u'current applic', u'current applic autonom', u'current avail', u'current avail sensor', u'current practic', u'current practic applic', u'current practic interestfor', u'current practic interesti', u'current state', u'current state code', u'currentbest', u'currentbest perform', u'currentbest perform method', u'currentresearch', u'currentresearch fuell', u'currentresearch fuell challeng', u'curtainboxboxboxboxwhiteboard', u'curtainboxboxboxboxwhiteboard person', u'curtainboxboxboxboxwhiteboard person night', u'curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight', u'curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight standnight', u'curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight standnight standnight', u'curtainshow', u'curtainshow curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight', u'curtainshow curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight standnight', u'curtainshow curtainshow', u'curtainshow curtainshow curtainboxboxboxboxwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardwhiteboardpersonpersonpersonpersonpersonpersonpersonnight', u'curtainshow curtainshow curtainshow', u'curtaintowel', u'curtaintowel shower', u'curtaintowel shower curtainboxboxboxboxwhiteboard', u'curtaintowel shower curtaintowel', u'cv', u'cv 2015arxiv:1505', u'cv 2015vijay', u'cv 2015vijay badrinarayanan', u'cv oct', u'cv oct 2016agk34', u'cv oct 2016arxiv:1511', u'cv oct 2016vijay', u'cvpr', u'cvpr 2007recognit', u'cvpr 2007recognit cvpr', u'cvpr 2007segment', u'cvpr 2007segment wild', u'cvpr 2008imag', u'cvpr 2008imag categor', u'cvpr 2008use', u'cvpr 2008use structur', u'cvpr 2014imag', u'cvpr 2014imag label', u'cvpr 2014label', u'cvpr 2014label descriptor', u'cvpr 2016in', u'cvpr 2016in cvpr', u'cvpr 2016insight', u'cvpr 2016insight applic', u'cvpr 3multimod', u'cvpr 3multimod deep', u'cvpr 3use', u'cvpr 3use divis', u'cvpr 6convolut', u'cvpr 6convolut network', u'cvpr 6semant', u'cvpr 6semant imag', u'cvpr algorithm', u'cvpr forest', u'cvpr forest imag', u'cvpr ieee', u'cvpr ieee confer', u'cvpr novemb', u'cvpr novemb paper', u'cvpr novemb version', u'cvpr page', u'cvpr page ieee', u'cvpr pp', u'cvpr pp 2015c', u'cvpr pp 2015confer', u'cvpr pp 2015semant', u'cvpr pp 3354\\u20133361,201220122012201220122012imag', u'cvpr pp 447\\u2013object', u'cvpr pp drive', u'cvpr pp ieee', u'cvpr pp recognit', u'cvpr propos', u'cvpr propos idea', u'cvpr workshop', u'cvpr workshop deep', u'cvpr workshopon', u'cvpr workshopon deep', u'cvpr workshopsemant', u'cvpr workshopsemant feedback', u'cvpr,2008', u'cvpr,2008 4segment', u'cvpr,2008 4segment support', u'cyclist', u'cyclist andand', u'cyclist andand visual', u'cyclist andpedestrian', u'cyclist andpedestrian class', u'cyclist camvid', u'cyclist camvid result', u'cyclist strong11th', u'cyclist strong11th main', u'cyclist strongclass', u'cyclist strongclass street', u'd', u'd abov', u'd abov boost', u'd abov pascal', u'd anguelov', u'd anguelov d', u'd correspond', u'd correspond valu', u'd du', u'd du c', u'd du s', u'd erhan', u'd erhan c', u'd erhan v', u'd frominria', u'd frominria renn', u'd fromvijay', u'd fromvijay badrinarayanan', u'd university2014', u'd university2014 award', u'd universityof', u'd universityof cambridg', u'darker', u'darker colour', u'darker colour indic', u'darker colourfigur', u'darker colourfigur comparison', u'darker colourrepres', u'darker colourrepres larger', u'darker coloursbayesian', u'darker coloursbayesian segnet', u'darker coloursind', u'darker coloursind uncertain', u'darrel', u'darrel \\u201ccaff', u'darrel \\u201ccaff convolut', u'darrel \\u201cfulli', u'darrel \\u201cfulli convolut', u'data', u'data augment', u'data augment inferencei', u'data augment inferenceprocess', u'data avail', u'data availablein', u'data availablein tabl', u'data availablewhen', u'data availablewhen suffici', u'data improv', u'data improv ourmodel', u'data improv ourwork', u'data independ', u'data independ segment', u'data input', u'data input dure', u'data kitti', u'data kitti test', u'data pascal', u'data pascal voc', u'data prevent', u'data prevent over-fit', u'data result', u'data result poor', u'data use', u'data use tothi', u'data use totrain', u'data x', u'data x label', u'dataand', u'dataand segment', u'dataand segment network', u'databas', u'databas prl', u'databas prl vol', u'databas web-bas', u'databas web-bas tool', u'databaseclass', u'databaseclass video', u'databaseclass video high-definit', u'databaseprl', u'databaseprl 6prl', u'databaseprl 6prl 6prl', u'datafor', u'datafor pre-train', u'datafor pre-train train', u'dataset', u'dataset 35k', u'dataset 35k imag', u'dataset 367camvid', u'dataset 367camvid road', u'dataset 367train', u'dataset 367train imag', u'dataset anoth', u'dataset anoth reason', u'dataset applic', u'dataset applic forautonom', u'dataset applic forroad', u'dataset avail', u'dataset avail fora', u'dataset avail forsemant', u'dataset avail semant', u'dataset balanc', u'dataset balanc label', u'dataset beforefuel', u'dataset beforefuel challeng', u'dataset beforeth', u'dataset beforeth arriv', u'dataset benchmark', u'dataset benchmark perform', u'dataset camvid', u'dataset camvid road', u'dataset canalso', u'dataset canalso discard', u'dataset canweight', u'dataset canweight train', u'dataset class', u'dataset class averag', u'dataset class distribut', u'dataset compar', u'dataset compar toother', u'dataset compar totabl', u'dataset consist', u'dataset consist 5050tabl', u'dataset consist 5050test', u'dataset consist test', u'dataset contain', u'dataset contain 11semant', u'dataset contain 11the', u'dataset contain train', u'dataset contain video', u'dataset currentbest', u'dataset currentbest perform', u'dataset currentresearch', u'dataset currentresearch fuell', u'dataset decod', u'dataset decod network', u'dataset describ', u'dataset describ sec', u'dataset enabl', u'dataset enabl end-to-end', u'dataset expand', u'dataset expand model', u'dataset futur', u'dataset futur addit', u'dataset googl', u'dataset googl indoor', u'dataset hardchalleng', u'dataset hardchalleng segnet', u'dataset hardfig', u'dataset hardfig qualit', u'dataset hasbeen', u'dataset hasbeen use', u'dataset hasceil', u'dataset hasceil label', u'dataset havebeen', u'dataset havebeen hand-label', u'dataset havescen', u'dataset havescen dataset', u'dataset inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow', u'dataset inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow curtainshow', u'dataset indoor', u'dataset indoor scene', u'dataset indoorscen', u'dataset indoorscen train', u'dataset indoorsun', u'dataset indoorsun rgb-d', u'dataset inuncertainti', u'dataset inuncertainti frequenc', u'dataset largest', u'dataset largest public', u'dataset like', u'dataset like tonot', u'dataset like toth', u'dataset make', u'dataset make veri', u'dataset makesit', u'dataset makesit difficult', u'dataset makesrecip', u'dataset makesrecip arriv', u'dataset miou', u'dataset miou metric', u'dataset model', u'dataset model uncertainti', u'dataset need', u'dataset need verifi', u'dataset need weightpixel', u'dataset need weightth', u'dataset nyuv2', u'dataset nyuv2 includ', u'dataset nyuv2 note', u'dataset object', u'dataset object segment', u'dataset obtain', u'dataset obtain combin', u'dataset obtainbatch', u'dataset obtainbatch norm', u'dataset obtainw', u'dataset obtainw perform', u'dataset onli', u'dataset onli layer', u'dataset perform', u'dataset perform increaseepoch', u'dataset perform increasewa', u'dataset performanceclass', u'dataset performanceclass averag', u'dataset performancecorrel', u'dataset performancecorrel size', u'dataset pre-train', u'dataset pre-train mscoco', u'dataset recent', u'dataset recent imag', u'dataset result', u'dataset result segnet', u'dataset segnetperform', u'dataset segnetperform better', u'dataset segnett', u'dataset segnett quantit', u'dataset semanticu', u'dataset semanticu frank', u'dataset semanticurban', u'dataset semanticurban scene', u'dataset shown', u'dataset shown fig', u'dataset small', u'dataset small consist', u'dataset smalland', u'dataset smalland handl', u'dataset smalldemonstr', u'dataset smalldemonstr use', u'dataset sucha', u'dataset sucha camvid', u'dataset sucha larger', u'dataset tabl', u'dataset tabl nyu', u'dataset tabl ourevalu', u'dataset tabl ouri', u'dataset test', u'dataset test paramet', u'dataset therefor', u'dataset therefor experimentedform', u'dataset therefor experimentedwith', u'dataset thisdataset', u'dataset thisdataset use', u'dataset thisgain', u'dataset thisgain popular', u'dataset thisi', u'dataset thisi follow', u'dataset thisperform', u'dataset thisperform segnet', u'dataset toaddit', u'dataset toaddit train', u'dataset tolearn', u'dataset tolearn object', u'dataset tomeasur', u'dataset tomeasur quantit', u'dataset toof', u'dataset toof experi', u'dataset train', u'dataset train 140k', u'dataset train corpus', u'dataset train imag', u'dataset train layer', u'dataset train variant', u'dataset unlik', u'dataset unlik segment', u'dataset use', u'dataset use atfergus', u'dataset use attest', u'dataset use shallow', u'dataset use thisdataset', u'dataset use thisto', u'dataset version', u'dataset version indoor', u'dataset version largest', u'dataset version theirfigur', u'dataset version theirground', u'datasetbenchmark', u'datasetbenchmark dataset', u'datasetbenchmark dataset nyuv2', u'datasetknown', u'datasetknown deep', u'datasetknown deep architectur', u'datasetof', u'datasetof indoor', u'datasetof indoor scene', u'datasetpasc', u'datasetpasc voc', u'datasetpasc voc datasetpasc', u'datasetpasc voc datasetsegnet', u'datasetroad', u'datasetroad scene', u'datasetroad scene imag', u'datasetsegnet', u'datasetsegnet layerssegnet', u'datasetsegnet layerssegnet layerssegnet', u'datasetssegnet', u'datasetssegnet perform', u'datasetssegnet perform competit', u'datasetsto', u'datasetsto achiev', u'datasetsto achiev good', u'datasetsun', u'datasetsun rgb-d', u'datasetsun rgb-d veri', u'datasetth', u'datasetth qualit', u'datasetth qualit result', u'datasetw', u'datasetw use', u'datasetw use cross-entropi', u'datasetwhich', u'datasetwhich perform', u'datasetwhich perform highest', u'day', u'day anddataset', u'day anddataset contain', u'day anddusk', u'day anddusk poor', u'day dusk', u'day dusk scene', u'day dusk test', u'day duskscen', u'day dusktrain', u'day dusktrain imag', u'dcnn', u'dcnn semant', u'dcnn semant imag', u'dealin', u'dealin class', u'dealin class suggest', u'dealwith', u'dealwith scale', u'dealwith scale chang', u'decay', u'decay paramet', u'decay paramet equal', u'decis', u'decis forest', u'decis forest availablenot', u'decis forest local', u'decis forest neural', u'decis make', u'decis subsequ', u'decis subsequ ident', u'decod', u'decod advantag', u'decod advantag deeper', u'decod anencod', u'decod anencod follow', u'decod anencod use', u'decod architectur', u'decod architectur consistsconvolut', u'decod architectur consistsof', u'decod architectur whichha', u'decod architectur whichproduc', u'decod arean', u'decod arean integr', u'decod arejoint', u'decod arejoint supervis', u'decod b', u'decod b c', u'decod concaten', u'decod concaten upsampledmax-pool', u'decod concaten upsampledth', u'decod constant', u'decod constant featur', u'decod correspond', u'decod correspond encod', u'decod decod', u'decod decod network', u'decod decod segnet', u'decod decod upsampl', u'decod decodercvpr', u'decod decodercvpr propos', u'decod decodernetwork', u'decod decodernetwork howev', u'decod dimension', u'decod dimension reduct', u'decod drop', u'decod e', u'decod encod', u'decod encod activ', u'decod encod train', u'decod experi', u'decod experi onc', u'decod featur', u'decod featur map', u'decod filter', u'decod filter alsofilt', u'decod filter alsounti', u'decod filter bank', u'decod filter densifi', u'decod filter fcn', u'decod filter fcnmax-pool', u'decod filter fcnmedian', u'decod filter number', u'decod filter perform', u'decod filter singl', u'decod filter upsampl', u'decod filterbank', u'decod filterbank reconstruct', u'decod filterconvolv', u'decod filterconvolv upsampl', u'decod filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor', u'decod filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor upsamplingfor', u'decod filtersconvolut', u'decod filtersconvolut trainabl', u'decod follow', u'decod follow pixelwis', u'decod fulli', u'decod fulli convolut', u'decod help', u'decod help map', u'decod ignor', u'decod ignor high', u'decod increas', u'decod increas perform', u'decod kernel', u'decod kernel follow', u'decod layer', u'decod layer comparisondecod', u'decod layer comparisonfcn-bas', u'decod layer henc', u'decod layer ischosen', u'decod layer iskernel', u'decod layer reduc', u'decod make', u'decod make memori', u'decod map', u'decod map low', u'decod model', u'decod model requir', u'decod network', u'decod network author', u'decod network consist', u'decod network constantkernel', u'decod network constantnetwork', u'decod network decod', u'decod network followedbi', u'decod network followedterm', u'decod network henc', u'decod network map', u'decod network progressivelyad', u'decod network progressivelyprocess', u'decod network segnet-bas', u'decod network train', u'decod network upsamplesit', u'decod network upsamplesth', u'decod network vari', u'decod networkha', u'decod networkha correspond', u'decod networkha layer', u'decod networkindic', u'decod networkindic featur', u'decod networkto', u'decod networkto achiev', u'decod output', u'decod output featur', u'decod output fed', u'decod outputanoth', u'decod outputanoth memori', u'decod outputfeatur', u'decod outputfeatur map', u'decod pixel-wis', u'decod pixel-wis label', u'decod pool', u'decod pool upsampl', u'decod pool upsamplingdecod', u'decod process', u'decod process sever', u'decod process use', u'decod produc', u'decod produc featur', u'decod second', u'decod second train', u'decod segnet', u'decod segnet larger', u'decod segnet largerboth', u'decod segnet largerterm', u'decod segnet type', u'decod size', u'decod size accuraci', u'decod soft-max', u'decod soft-max layer', u'decod stack', u'decod stack feed', u'decod stackunderstand', u'decod stackunderstand effect', u'decod stackw', u'decod stackw draw', u'decod techniqu', u'decod techniqu compar', u'decod techniqu core', u'decod techniqu fig', u'decod techniqu isfrom', u'decod techniqu isillustr', u'decod techniqu segnet-typ', u'decod techniqu use', u'decod techniqu wide', u'decod thismap', u'decod thismap input', u'decod thisnetwork', u'decod thisnetwork upsampl', u'decod tocreat', u'decod tocreat memori', u'decod toobtain', u'decod toobtain featur', u'decod tosegment', u'decod tosegment engin', u'decod toth', u'decod toth correspond', u'decod unit', u'decod unit befor', u'decod unit containsfollow', u'decod unit containson', u'decod unit result', u'decod unitsfind', u'decod unitsfind drop', u'decod unitsi', u'decod unitsi optim', u'decod unlik', u'decod unlik deconvolut', u'decod upsampl', u'decod upsampl featur', u'decod upsampl featuremap', u'decod upsampl featurepass', u'decod upsampl input', u'decod upsampl itsfig', u'decod upsampl itsinput', u'decod upsampl lower', u'decod use', u'decod use encod', u'decod use max-pool', u'decod use maxpool', u'decod use pool', u'decod variant', u'decod variant dataset', u'decod variant quantifi', u'decod variant use', u'decod weight', u'decod weight initi', u'decod weight unti', u'decod weight untiedmod', u'decod weight untiedsoft-max', u'decoderaft', u'decoderaft convolut', u'decoderaft convolut layer', u'decodercvpr', u'decodercvpr propos', u'decodercvpr propos idea', u'decoderdropout', u'decoderdropout decoderdropout', u'decoderdropout decoderdropout decoderdropout', u'decoderdropout decoderdropout enc-decdropout', u'decoderdropout enc-decdropout', u'decoderdropout enc-decdropout enc-decdropout', u'decoderencod', u'decoderencod network', u'decoderencod network onli', u'decoderfilt', u'decoderfilt perform', u'decoderfilt perform segnet-bas', u'decodernetwork', u'decodernetwork bias', u'decodernetwork bias use', u'decodernetwork choos', u'decodernetwork choos compar', u'decodernetwork follow', u'decodernetwork follow final', u'decodernetwork howev', u'decodernetwork howev encod', u'decodernetwork therefor', u'decodernetwork therefor number', u'decodernot', u'decodernot compress', u'decodernot compress k', u'decoderor', u'decoderor upsampl', u'decoderor upsampl convolv', u'decodersal', u'decodersal encod', u'decodersal encod segnet-bas', u'decodersar', u'decodersar redund', u'decodersar redund consum', u'decodersegnet', u'decodersegnet encod', u'decodersegnet encod network', u'decodersfcn', u'decodersfcn decod', u'decodersfcn decod techniqu', u'decodersmax-pool', u'decodersmax-pool sub-sampl', u'decodersmax-pool sub-sampl encod', u'decoderson', u'decoderson left', u'decoderson left fig', u'decodersterm', u'decodersterm segnet-bas', u'decodersterm segnet-bas encod', u'decoderto', u'decoderto compar', u'decoderto compar quantit', u'decodervari', u'decodervari use', u'decodervari use common', u'decodingnetwork', u'decodingnetwork choos', u'decodingnetwork choos compar', u'decodingon', u'decodingon right', u'decodingon right fig', u'decodingtechniqu', u'decodingtechniqu import', u'decodingtechniqu import design', u'decodingtechniqu wide', u'decodingtechniqu wide use', u'deconv', u'deconv 160k8321', u'deconv 160k8321 160k8321', u'deconv 200k6731', u'deconv 200k6731 200k6731', u'deconv 31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet', u'deconv 31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet deconvnet', u'deconv deconvnet', u'deconv deconvnet deconvnet', u'deconv fcn', u'deconv fcn learn', u'deconv fcn learnt', u'deconvnet', u'deconvnet 1024featur', u'deconvnet 1024featur size', u'deconvnet 1024so', u'deconvnet 1024so enabl', u'deconvnet 260k8526', u'deconvnet 260k8526 260k8526', u'deconvnet 380k5962', u'deconvnet 380k5962 380k5962', u'deconvnet 47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl', u'deconvnet 47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl 6tabl', u'deconvnet andu-net', u'deconvnet andu-net share', u'deconvnet andw', u'deconvnet andw add', u'deconvnet architectur', u'deconvnet architectur comparison', u'deconvnet bf', u'deconvnet bf score', u'deconvnet compar', u'deconvnet compar compet', u'deconvnet deconvnet', u'deconvnet deconvnet 260k8526', u'deconvnet deconvnet 380k5962', u'deconvnet deconvnet 47465474654746547465474654746547465602156021560215602156021560215602159731973197319731973118721872187218721872877877877877tabl', u'deconvnet deconvnet deconvnet', u'deconvnet deconvnet deeplab-largefov-densecrf', u'deconvnet deconvnet fig', u'deconvnet deeplab-largefov-densecrf', u'deconvnet deeplab-largefov-densecrf deeplab-largefov-densecrf', u'deconvnet fcn', u'deconvnet fcn did', u'deconvnet fig', u'deconvnet fig qualit', u'deconvnet fig result', u'deconvnet fig use', u'deconvnet fulli', u'deconvnet fulli connect', u'deconvnet higher', u'deconvnet higher boundari', u'deconvnet isi', u'deconvnet isi clear', u'deconvnet isth', u'deconvnet isth largest', u'deconvnet larger', u'deconvnet larger parameter', u'deconvnet later', u'deconvnet later paper', u'deconvnet match', u'deconvnet match metric', u'deconvnet median', u'deconvnet median frequenc', u'deconvnet miou', u'deconvnet miou comparison', u'deconvnet object', u'deconvnet object understanddeep', u'deconvnet object understandth', u'deconvnet thelargest', u'deconvnet thelargest model', u'deconvnet thepost-process', u'deconvnet thepost-process produc', u'deconvnet useregion', u'deconvnet useregion propos', u'deconvnet usesegment', u'deconvnet usesegment engin', u'deconvnetachiev', u'deconvnetachiev highest', u'deconvnetachiev highest score', u'deconvnetbut', u'deconvnetbut segnet', u'deconvnetbut segnet effici', u'deconvnetfrom', u'deconvnetfrom tabl', u'deconvnetfrom tabl immedi', u'deconvnetthi', u'deconvnetthi seen', u'deconvnetthi seen comput', u'deconvolut', u'deconvolut clear', u'deconvolut clear better', u'deconvolut fcn-basic-noadditionlearn', u'deconvolut fcn-basic-noadditionlearn perform', u'deconvolut fcn-basic-noadditionor', u'deconvolut fcn-basic-noadditionor upsampl', u'deconvolut layer', u'deconvolut layer asfor', u'deconvolut layer asoppos', u'deconvolut network', u'deconvolut network forh', u'deconvolut network forsemant', u'deconvolut network itssemi-supervis', u'deconvolut network itsth', u'deconvolut network make', u'deconvolut network onject', u'deconvolut network onth', u'deconvolut network perform', u'deconvolut network result', u'deconvolut networkback', u'deconvolut networkback imag', u'deconvolut networkth', u'deconvolut networkth segnet', u'deconvolutionalthough', u'deconvolutionalthough smaller', u'deconvolutionalthough smaller class', u'deconvolutioni', u'deconvolutioni clear', u'deconvolutioni clear better', u'deconvolveth', u'deconvolveth input', u'deconvolveth input featur', u'deconvolveto', u'deconvolveto upsampl', u'deconvolveto upsampl learn', u'decor', u'decor object', u'decor object paint', u'decoupl', u'decoupl classification-segment', u'decoupl classification-segment network', u'decoupl network', u'decoupl network use', u'decreas', u'decreas eachadditional/deep', u'decreas eachadditional/deep encoder-decod', u'decreas eachth', u'decreas eachth experi', u'decreasecontext', u'decreasecontext larger', u'decreasecontext larger potenti', u'decreasesfor', u'decreasesfor additional/deep', u'decreasesfor additional/deep encoder-decod', u'decreasesp', u'decreasesp layer', u'decreasesp layer typic', u'decreaseth', u'decreaseth trade-off', u'decreaseth trade-off size', u'deep', u'deep architectur', u'deep architectur base', u'deep architectur caff', u'deep architectur common', u'deep architectur core', u'deep architectur design', u'deep architectur extractcrf', u'deep architectur extractmeaning', u'deep architectur includingclass', u'deep architectur includingsegnet', u'deep architectur larg', u'deep architectur particularlydesign', u'deep architectur particularlynew', u'deep architectur performa', u'deep architectur performrobust', u'deep architectur pursu', u'deep architectur segment', u'deep architectur segnet', u'deep architectur sunrgb-d', u'deep architectur vari', u'deep architecturefor', u'deep architecturefor joint', u'deep architecturew', u'deep architecturew present', u'deep convolut', u'deep convolut encoder-decod', u'deep convolut encoder-decoderarchitectur', u'deep convolut encoder-decoderbayesian', u'deep convolut netsand', u'deep convolut netsyuill', u'deep convolut network', u'deep convolut neural', u'deep convolutionalencoder-decod', u'deep convolutionalencoder-decod architectur', u'deep convolutionalsegnet', u'deep convolutionalsegnet deep', u'deep encod', u'deep encod network', u'deep encoder-decod', u'deep encoder-decod network', u'deep encoder-decoderapproach', u'deep encoder-decoderapproach howev', u'deep encoder-decodernetwork', u'deep encoder-decodernetwork unsupervis', u'deep featur', u'deep featur extract', u'deep fulli', u'deep fulli convolut', u'deep layer', u'deep layer featur', u'deep layersloc', u'deep layersloc patch', u'deep layersof', u'deep layersof featur', u'deep learn', u'deep learn 2009for', u'deep learn 2009semant', u'deep learn appli', u'deep learn approach', u'deep learn architectur', u'deep learn framework', u'deep learn icml', u'deep learn ina', u'deep learn inicml', u'deep learn method', u'deep learn mobil', u'deep learn model', u'deep learn output', u'deep learn scene', u'deep learn seen', u'deep learn seenhug', u'deep learn seenlearn', u'deep learn set', u'deep learn workshop', u'deep method', u'deep network', u'deep network arxivfrom', u'deep network arxivpreprint', u'deep network best', u'deep network comparedin', u'deep network comparedto', u'deep network cvpr', u'deep network difficult', u'deep network imag', u'deep network learn', u'deep network nip', u'deep network semant', u'deep network \\u201cdirection\\u201d', u'deep networksin', u'deep networksin cvpr', u'deep networkstop-down', u'deep networkstop-down semant', u'deep neural', u'deep neural network', u'deep pars', u'deep pars network', u'deep segment', u'deep segment architectur', u'deep segmentationarchitectur', u'deep segmentationarchitectur harder', u'deep segmentationarchitectur like', u'deep segmentationscen', u'deep segmentationscen understand', u'deep segmentationth', u'deep segmentationth metric', u'deep structur', u'deep structur model', u'deep vision', u'deep vision 2014for', u'deep vision 2014on', u'deep vision 3cvpr', u'deep vision 3in', u'deep-learn', u'deep-learn method', u'deep-learn method includ', u'deepan', u'deepan imag', u'deepan imag scene', u'deeparchitectur', u'deeparchitectur share', u'deeparchitectur share low', u'deepconvolut', u'deepconvolut encod', u'deepconvolut encod decod', u'deepconvolut encoder-decod', u'deepconvolut encoder-decod neural', u'deepconvolut neural', u'deepconvolut neural network', u'deepcurr', u'deepcurr work', u'deepcurr work princip', u'deeper', u'deeper convolut', u'deeper convolut corr', u'deeper convolut incvpr', u'deeper convolut inv', u'deeper encoder-decod', u'deeper encoder-decod pair', u'deeper encoder-decod pairsand', u'deeper encoder-decod pairslearn', u'deeper featur', u'deeper featur tune', u'deeper layer', u'deeper layer ad', u'deeper layer differ', u'deeper layer encoderdecod', u'deeper layer fewer', u'deeper layer overal', u'deeper layer pooling-subsamplingcan', u'deeper layer pooling-subsamplingdecod', u'deeper layer shape', u'deeper pair', u'deeper pair subsequ', u'deeper3', u'deeper3 web', u'deeper3 web demo', u'deeperwa', u'deeperwa observ', u'deeperwa observ dropout', u'deepest', u'deepest encod', u'deepest encod output', u'deepest half', u'deepest half encod', u'deepest layer', u'deepest layer featur', u'deepest layer featuresin', u'deepest layer featuresto', u'deepest layer representations/featur', u'deepest layer segnet', u'deeplab', u'deeplab post-process', u'deeplab post-process condit', u'deeplab-larg', u'deeplab-larg fov', u'deeplab-larg fov smallest', u'deeplab-largefov', u'deeplab-largefov 11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn', u'deeplab-largefov 11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn learnt', u'deeplab-largefov 140k8595', u'deeplab-largefov 140k8595 140k8595', u'deeplab-largefov 240k7070', u'deeplab-largefov 240k7070 240k7070', u'deeplab-largefov aand', u'deeplab-largefov aand slight', u'deeplab-largefov alsoher', u'deeplab-largefov alsoher note', u'deeplab-largefov alsoreport', u'deeplab-largefov alsoreport littl', u'deeplab-largefov astand', u'deeplab-largefov astand alon', u'deeplab-largefov deconvnet', u'deeplab-largefov deconvnet architectur', u'deeplab-largefov deeplab-largefov', u'deeplab-largefov deeplab-largefov 11006110061100611006110061100611006160731607316073160731607316073160735618561856185618561819931993199319931993838383fcn', u'deeplab-largefov deeplab-largefov 140k8595', u'deeplab-largefov deeplab-largefov 240k7070', u'deeplab-largefov deeplab-largefov deeplab-largefov', u'deeplab-largefov deeplab-largefov deeplab-largefov-', u'deeplab-largefov deeplab-largefov-', u'deeplab-largefov deeplab-largefov- deeplab-largefov-', u'deeplab-largefov effici', u'deeplab-largefov effici model', u'deeplab-largefov effici modeland', u'deeplab-largefov effici modellarg', u'deeplab-largefov produc', u'deeplab-largefov produc best', u'deeplab-largefov train', u'deeplab-largefov train predictlabel', u'deeplab-largefov train predictsurpris', u'deeplab-largefov-', u'deeplab-largefov- deeplab-largefov-', u'deeplab-largefov- deeplab-largefov- deeplab-largefov-', u'deeplab-largefov- deeplab-largefov- densecrf', u'deeplab-largefov- densecrf', u'deeplab-largefov- densecrf densecrf', u'deeplab-largefov-densecrf', u'deeplab-largefov-densecrf computednot', u'deeplab-largefov-densecrf computednot computednot', u'deeplab-largefov-densecrf deeplab-largefov-densecrf', u'deeplab-largefov-densecrf deeplab-largefov-densecrf computednot', u'deeplab-largefov-densecrf deeplab-largefov-densecrf deeplab-largefov-densecrf', u'deeplab-largefov-densecrf deeplab-largefov-densecrf segnet', u'deeplab-largefov-densecrf globaland', u'deeplab-largefov-densecrf globaland miou', u'deeplab-largefov-densecrf globalth', u'deeplab-largefov-densecrf globalth time', u'deeplab-largefov-densecrf segnet', u'deeplab-largefov-densecrf segnet segnet', u'deeplab-largefovdensecrf', u'deeplab-largefovdensecrf optim', u'deeplab-largefovdensecrf optim set', u'deeplablargfov', u'deeplablargfov deconvnet', u'deeplablargfov deconvnet object', u'deeplearn', u'deeplearn 3learn', u'deeplearn 3learn 3learn', u'deeplearn magic', u'deeplearn magic leap', u'deeplearn method', u'deeplearn method produc', u'deepmani', u'deepmani popular', u'deepmani popular dataset', u'deepmodel', u'deepmodel predict', u'deepmodel predict shown', u'deepmodifi', u'deepmodifi produc', u'deepmodifi produc bayesian', u'deepnetwork', u'deepnetwork scene', u'deepnetwork scene pars', u'deepsect', u'deepsect propos', u'deepsect propos bayesian', u'deepth', u'deepth main', u'deepth main contribut', u'deepth quantit', u'deepth quantit result', u'defin', u'defin bi', u'defin bi j', u'defin j', u'defin j defin', u'defin label', u'defin label transit', u'definit', u'definit defin', u'definit defin label', u'degre', u'degre freedom', u'degre freedom minimizeth', u'degre freedom minimizeunti', u'degre univers', u'degre univers cambridgein', u'degre univers cambridgeroberto', u'delin', u'delin accuracybut', u'delin accuracybut segnet', u'delin accuracymodel', u'delin accuracymodel deconvnet', u'delin boundari', u'delin boundari ascompar', u'delin boundari asfig', u'delin boundari poor', u'delin boundari poornew', u'delin boundari poortheir', u'delin capabl', u'delin capabl crfslayer', u'delin capabl crfswhile', u'delin class', u'delin class road', u'delin ii', u'delin ii reduc', u'delin inter', u'delin inter class', u'delin metric', u'delin metric bf', u'delin network', u'delin network larger', u'delin signific', u'delin signific higher', u'delin vital', u'delin vital therefor', u'delineateobject', u'delineateobject base', u'delineateobject base shape', u'delineatesegment', u'delineatesegment engin', u'delineatesegment engin abil', u'demo', u'demo caff', u'demo caff implement', u'demo footnot', u'demo footnot road', u'demo http', u'demo http //mi', u'demo http //miengcamacfig', u'demo http //miengcamacuk/projects/segnet/index', u'demo http //miengcamacuk/projects/segnet/to', u'demo http //miengcamacuk/projects/segnet/uk/projects/segnet/advantag', u'demo road', u'demo road scene', u'demo sourc', u'demo sourc code', u'demonstr', u'demonstr bayesian', u'demonstr bayesian segnet', u'demonstr effectivenessfin', u'demonstr effectivenessfin section', u'demonstr effectivenessof', u'demonstr effectivenessof model', u'demonstr efficaci', u'demonstr efficaci ofbayesian', u'demonstr efficaci ofthre', u'demonstr efficaci segnet', u'demonstr general', u'demonstr general applic', u'demonstr high', u'demonstr high accuraci', u'demonstr method', u'demonstr method applic', u'demonstr segnet', u'demonstr segnet canabsorb', u'demonstr segnet canimag', u'demonstr superior', u'demonstr superior overrec', u'demonstr superior overwith', u'demonstr themodel', u'demonstr themodel uncertainti', u'demonstr thepercentil', u'demonstr thepercentil dataset', u'denot', u'denot boundari', u'denot boundari f1-measur', u'denot segnet', u'denot segnet l4', u'denot segnet r', u'denot segnet sm', u'dens', u'dens 3d', u'dens 3d semant', u'dens convolut', u'dens convolut relu', u'dens crf', u'dens crf post-process', u'dens depth', u'dens depth map', u'dens depth mapsbut', u'dens depth mapscomput', u'dens featur', u'dens featur map', u'dens featur mapsa', u'dens model', u'dens model better', u'dense-crf', u'dense-crfson', u'dense-crfson reason', u'dense-crfson reason overal', u'dense-crfstim', u'dense-crfstim dense-crfson', u'dense-crfstim dense-crfson reason', u'dense-crfstim dense-crfstim', u'dense-crfstim dense-crfstim dense-crfson', u'dense-crfstim dense-crfstim dense-crfstim', u'dense-crfth', u'dense-crfth grid', u'dense-crfth grid search', u'dense-crfworsen', u'dense-crfworsen bf', u'dense-crfworsen bf score', u'denseclutt', u'denseclutt row', u'denseclutt row right', u'densecrf', u'densecrf densecrf', u'densecrf densecrf densecrf', u'densecrf densecrf fcn', u'densecrf fcn', u'densecrf fcn fcn', u'densecrf fcn learnt', u'densecrf hyperparamet', u'densecrf hyperparamet obtain', u'denseimprov', u'denseimprov obtain', u'denseimprov obtain bf', u'densesom', u'densesom scene', u'densesom scene larg', u'densifi', u'densifi featur', u'densifi featur map', u'densifi spars', u'densifi spars input', u'densifi spars inputar', u'densifi spars inputthi', u'densifi sparseinput', u'densifi sparseinput decod', u'densifi sparsewith', u'densifi sparsewith trainabl', u'depart', u'depart engin', u'depart engin machin', u'depart engin univers', u'depend', u'depend implement', u'deploy', u'deploy forind', u'deploy forind architectur', u'deploy fortest', u'deploy fortest sampl', u'deploy modelsmemori', u'deploy modelsmemori comput', u'deploy modelson', u'deploy modelson specialis', u'depth', u'depth base', u'depth base cue', u'depth channel', u'depth channel improv', u'depth channel improvedataset', u'depth channel improvesegment', u'depth cue', u'depth cue andoth', u'depth cue andshallow', u'depth edg', u'depth edg rgbedg', u'depth edg rgbthis', u'depth imag', u'depth imag fromcurr', u'depth imag frommodifications/redesign', u'depth imagesand', u'depth imagesand tabl', u'depth imagesfrom', u'depth imagesfrom current', u'depth interpol', u'depth interpol anoth', u'depth map', u'depth map 821structur', u'depth map comput', u'depth map dens', u'depth map eccv', u'depth map predict', u'depth map structur', u'depth map tempor', u'depth mapsbut', u'depth mapsbut structur', u'depth mapscomput', u'depth mapscomput camvid', u'depth measur', u'depth modal', u'depth modal necessit', u'depth normal', u'depth normal achiev', u'depth normal multi-scal', u'depth normal use', u'depth onli', u'depth onli fraction', u'depth onli top-1', u'depth perform', u'depth perform local', u'depth segment', u'depth segment merit', u'depth singl', u'depth singl channel', u'depth surfac', u'depth surfac normal', u'depth valu', u'depth valu close', u'depth video', u'depth video and/or', u'depth video frame', u'depth-sift', u'depth-sift locat', u'depth-sift locat input', u'depth-sift pixel', u'depth-sift pixel locat', u'depthand', u'depthand motion', u'depthand motion cue', u'depthand parameteris', u'depthand parameteris howev', u'depthbenchmark', u'depthi', u'depthi increas', u'depthi increas consequ', u'depthmap', u'depthmap predict', u'depthmap predict singl', u'depthsegnet', u'depthsegnet compos', u'depthsegnet compos stack', u'depthto', u'depthto avail', u'depthto avail massiv', u'depthto visualis', u'depthto visualis effect', u'depthus', u'depthus deep', u'depthus deep network', u'depthw', u'depthw observ', u'depthw observ predict', u'descent', u'descent dropout', u'descent dropout randomlyremov', u'descent dropout randomlytrain', u'descent encourag', u'descent encourag themodel', u'descent encourag thenetwork', u'descent perform', u'descent perform control', u'descent sgd', u'descent sgd fix', u'descent sgd train', u'descent witha', u'descent witha stage-wis', u'descent withpropos', u'descent withpropos refer', u'describ', u'describ earlier', u'describ earlier requir', u'describ et', u'describ et al', u'describ sec', u'describ sec discuss', u'describ segnet', u'describ segnet architectur', u'describ segnet2', u'describ segnet2 review', u'describ segnetarchitectur', u'describ segnetarchitectur analysi', u'descriptor', u'descriptor exampl', u'descriptor exampl base', u'descriptor local', u'descriptor local label', u'descriptor n/a807', u'descriptor n/a807 n/a807', u'descriptor super', u'descriptor super pars', u'design', u'design architectur', u'design architectur segment', u'design categor', u'design categor segment', u'design categori', u'design categori predict', u'design effici', u'design effici architectur', u'design effici term', u'design element', u'design element fcn', u'design factorsnecessari', u'design factorsnecessari achiev', u'design factorstheir', u'design factorstheir quantit', u'design featur', u'design featur spatiocombin', u'design featur spatiotempor', u'design object', u'design object categorizationfor', u'design object categorizationhav', u'design objectclassif', u'design objectclassif therefor', u'design objectconvolut', u'design objectconvolut layer', u'design segment', u'design segment architectur', u'design segnet', u'design segnet arisesfeatur', u'design segnet arisesfrom', u'design segnet aros', u'design unsupervis', u'design unsupervis featur', u'designedargu', u'designedargu use', u'designedargu use combin', u'designedfeatur', u'designedfeatur spatio-tempor', u'designedfeatur spatio-tempor super-pixel', u'designmor', u'designmor effici', u'designmor effici architectur', u'designsegment', u'designsegment architectur', u'designsegment architectur gather', u'desir', u'desir know', u'desir know model', u'despit', u'despit small', u'despit small size', u'destroy', u'destroy structur', u'destroy structurescontext', u'destroy structurescontext larger', u'destroy structuresth', u'destroy structuresth input', u'detect', u'detect column-wis', u'detect column-wis depth', u'detect improv', u'detect improv decis', u'detect object', u'detect object imag', u'detect output', u'detect output classifi', u'detect shown', u'detect shown recentfavour', u'detect shown recentwork', u'detector', u'detector crfs', u'detector crfs eccv', u'detector result', u'detector result techniquesind', u'detector result techniqueslearn', u'determin', u'determin map', u'determin map label', u'determin map labelssever', u'determin map labelstim', u'determinist', u'determinist encod', u'determinist encod decod', u'determinist weight', u'develop', u'develop centr', u'develop centr kawasaki', u'develop human', u'develop human knowledg', u'deviat', u'deviat error', u'deviat error bar', u'devic', u'devic exampl', u'devic exampl ar', u'diag', u'diag bi', u'diag bi bi', u'diag bi wi', u'diagon', u'diagon toler', u'diagon toler distanc', u'diagram', u'diagram entir', u'diagram entir pipelin', u'did', u'did attempt', u'did attempt use', u'did improv', u'did improv perfom', u'did use', u'did use anyclass', u'did use anycompar', u'didhierarch', u'didhierarch encod', u'didhierarch encod approach', u'didnot', u'didnot attempt', u'didnot attempt use', u'differ', u'differ approach', u'differ approach islearn', u'differ approach iswith', u'differ approach object', u'differ base', u'differ base true', u'differ benchmark', u'differ benchmark use', u'differ class', u'differ class present', u'differ class road', u'differ configur', u'differ configur bayesianof', u'differ configur bayesianor', u'differ dataset', u'differ dataset test', u'differ dataset therefor', u'differ decoderto', u'differ decoderto compar', u'differ decodervari', u'differ decodervari use', u'differ formident', u'differ formident encod', u'differ formof', u'differ formof decod', u'differ fromdecod', u'differ fromdecod encod', u'differ fromthes', u'differ fromthes architectur', u'differ inpedestrian', u'differ inpedestrian class', u'differ inquantit', u'differ inquantit segment', u'differ knownarchitectur', u'differ knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor', u'differ knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor futur', u'differ knownrev', u'differ knownrev practic', u'differ object', u'differ object arrang', u'differ perform', u'differ perform measur', u'differ pose', u'differ pose withcom', u'differ pose withfrequ', u'differ probabl', u'differ probabl obtain', u'differ reduc', u'differ reduc train', u'differ sampl', u'differ sampl dropout', u'differ scene', u'differ sceneregion', u'differ sceneregion propos', u'differ sceneunderstand', u'differ sceneunderstand idea', u'differ segnet', u'differ segnet use', u'differ sensor', u'differ sensor andhenc', u'differ sensor andof', u'differ sensor henc', u'differ type', u'differ type bedroom', u'differ variant', u'differ variant class', u'differ variantsfcn-bas', u'differ variantsfcn-bas compar', u'differ variantss', u'differ variantss segnet-bas', u'differ view', u'differ view point', u'differentat', u'differentat scale', u'differentat scale correspond', u'differentlay', u'differentlay singl', u'differentlay singl deep', u'difficult', u'difficult achiev', u'difficult achiev use', u'difficult becaus', u'difficult becaus object', u'difficult class', u'difficult class pole', u'difficult class sign', u'difficult evalu', u'difficult evalu perform', u'difficult fromchalleng', u'difficult fromchalleng benchmark', u'difficult fromtheir', u'difficult fromtheir quantit', u'difficult gather', u'difficult gather evid', u'difficult identifyoften', u'difficult identifyoften appear', u'difficult identifysecond', u'difficult identifysecond object', u'difficult object', u'difficult problem', u'difficult problem scene', u'difficult requir', u'difficult requir addit', u'difficult task', u'difficult task approxim', u'difficult toindic', u'difficult toindic larg', u'difficult totrain', u'difficult totrain end-to-end', u'difficult train', u'difficult train largermodel', u'difficult train largersegnet', u'difficult visual', u'difficult visual ambigu', u'difficulti', u'difficulti caus', u'difficulti caus wide', u'difficulti perform', u'difficulti perform end-toend', u'difficulti train', u'difficulti train network', u'difficultsharp', u'difficultsharp class', u'difficultsharp class boundari', u'difficultto', u'difficultto train', u'difficultto train paramet', u'digit', u'digit recognit', u'digit recognit speech', u'dilat', u'dilat network', u'dilat network beennetwork', u'dilat network beenpropos', u'dimens', u'dimens acknowledg', u'dimens acknowledg shortcom', u'dimens howev', u'dimens howev result', u'dimens howev resultingclassif', u'dimens howev resultingimag', u'dimens learn', u'dimens learn decod', u'dimens replic', u'dimens replic featuresmatch', u'dimens replic featureswithin', u'dimens resort', u'dimens resort ad', u'dimens sever', u'dimens sever pool', u'dimens therefor', u'dimens therefor ad', u'dimension', u'dimension convolut', u'dimension convolut layer', u'dimension featur', u'dimension featur represent', u'dimension reduct', u'dimension reduct encodercorrespond', u'dimension reduct encoderfeatur', u'dimension reduct fewer', u'dimension vectorfor', u'dimension vectorfor train', u'dimension vectorth', u'dimension vectorth camvid', u'dimensionalityfcn-bas', u'dimensionalityfcn-bas resolut', u'dimensionalityfcn-bas resolut bit', u'dimensionalityreduct', u'dimensionalityreduct featur', u'dimensionalityreduct featur map', u'dimensionalityreduct max-pool', u'dimensionalityreduct max-pool indic', u'dimensionalitywhen', u'dimensionalitywhen memori', u'dimensionalitywhen memori dure', u'diminsh', u'diminsh howev', u'diminsh howev largeand', u'diminsh howev largeimprov', u'direct', u'direct adopt', u'direct adopt deep', u'direct byboth', u'direct byboth learn', u'direct bylearn', u'direct bylearn perform', u'direct compar', u'direct compar wellknown', u'direct compar wellto', u'directlypredict', u'directlypredict howev', u'directlypredict howev miou', u'directlythrough', u'directlythrough class', u'directlythrough class balanc', u'discard', u'discard decod', u'discard decod encod', u'discard encod', u'discard encod featur', u'discard fulli', u'discard fulli connect', u'discard thedecod', u'discard thedecod encod', u'discard thenetwork', u'discard thenetwork unsupervis', u'discardingboth', u'discardingboth accur', u'discardingboth accur variant', u'discardingdimension', u'discardingdimension reduct', u'discardingdimension reduct fcn-basic', u'disciplin', u'disciplin gear', u'disciplin gear technolog', u'discrep', u'discrep correct', u'discrep correct kavukcuogluet', u'discrep correct kavukcuogluinput', u'discriminantfunct', u'discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw', u'discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw wrote', u'discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw wrote matlab', u'discriminantth', u'discriminantth soft-max', u'discriminantth soft-max layer', u'discuss', u'discuss advantag', u'discuss advantag drawback', u'discuss need', u'discuss need learn', u'discuss regard', u'discuss regard approach', u'disentangl', u'disentangl effectsof', u'disentangl effectsof model', u'disentangl effectsw', u'disentangl effectsw note', u'disentangl key', u'disentangl key design', u'disjoint', u'disjoint train', u'disjoint train classificationand', u'disjoint train classificationregion', u'disk', u'disk segnet', u'disk segnet memori', u'display', u'display afirst', u'display afirst class', u'display ahigh', u'display ahigh level', u'display uncertainti', u'distanc', u'distanc camera', u'distanc f1measur', u'distanc f1measur class', u'distanc use', u'distanc use valu', u'distribut', u'distribut awareimprov', u'distribut awareimprov larger', u'distribut awaretrain', u'distribut awaretrain techniqu', u'distribut convolut', u'distribut convolut net', u'distribut convolut weight', u'distribut deeplab-larg', u'distribut deeplab-larg fov', u'distribut model', u'distribut model becaus', u'distribut montecarlo', u'distribut montecarlo sampl', u'distribut montew', u'distribut montew note', u'distribut network', u'distribut network weight', u\"distribut network'sallow\", u\"distribut network'sallow approxim\", u\"distribut network'sweight\", u'distribut pixel', u'distribut pixel class', u'distribut posterior', u'distribut posterior kl', u'distribut posterior kullback-leibl', u'distribut q', u'distribut q wi', u'distribut random', u'distribut random variablesand', u'distribut random variableswith', u'distribut sampl', u'distribut sampl bernoulli', u'distribut softmax', u'distribut softmax class', u'distribut thesein', u'distribut thesein general', u'distribut theseweight', u'distribut tractabl', u'distribut tractabl therefor', u'distribut weight', u'distribut weight explain', u'distribut weight test', u'diverg', u'diverg approxim', u'diverg approxim distribut', u'diverg term', u'divertedin', u'divertedin benchmark', u'divertedin benchmark experi', u'divertedtoward', u'divertedtoward attain', u'divertedtoward attain rank', u'divis', u'divis normal', u'divis normal cvpr', u'doe', u'doe alway', u'doe alway correspond', u'doe meannot', u'doe meannot doe', u'doe meanon', u'doe meanon featur', u'doe notevalu', u'doe notevalu boundari', u'doe notexampl', u'doe notexampl miou', u'doe result', u'doe result better', u'doe reus', u'doe reus pool', u'doesdo', u'doesdo reveal', u'doesdo reveal true', u'doesind', u'doesind larg', u'doesind larg deep', u'dog', u'dog train', u'dog train bus', u'dolla\\u0301r', u'dolla\\u0301r c', u'dolla\\u0301r c l', u'domest', u'domest robot', u'domin', u'domin camvid', u'domin camvid dataset', u'domin class', u'domin class sky', u'domin major', u'domin major pixel', u'domin sky', u'domin sky road', u'doneaft', u'doneaft deeper', u'doneaft deeper layer', u'doneand', u'doneand decod', u'doneand decod pixel-wis', u'down-sampl', u'down-sampl eachdecod', u'down-sampl eachdecod upsampl', u'down-sampl eachi', u'down-sampl eachi illustr', u'draw', u'draw inspir', u'draw inspir encoder-decod', u'drawback', u'drawback approach', u'drawback approach includ', u'drawback recent', u'drawback recent deep', u'drive', u'drive earli', u'drive earli method', u'drive ismain', u'drive ismain delin', u'drive isth', u'drive isth contribut', u'drive kitti', u'drive kitti vision', u'drive link', u'drive link fig', u'drive relat', u'drive relat problem', u'drive robot', u'drive robot ar', u'drive robot arcurr', u'drive robot arth', u'drive scenesdataset', u'drive scenesscen', u'drive scenesscen understand', u'drive wacv', u'drive wacv 8labelm', u'drive wacv 8paradigm', u'drop', u'drop bf', u'drop bf measur', u'drop connect', u'drop deepest', u'drop deepest half', u'drop everi', u'drop everi encod', u'drop half', u'drop half encod', u'drop modest', u'drop signific', u'drop signific clutteri', u'drop thebf', u'drop thebf measur', u'drop thefor', u'drop thefor better', u'drop unit', u'drop unit test', u'dropout', u'dropout ad', u'dropout ad end', u'dropout approxim', u'dropout approxim bayesian', u'dropout approxim effect', u'dropout central', u'dropout central encod', u'dropout central encoderand', u'dropout central encodervari', u'dropout commonlytrain', u'dropout commonlytrain data', u'dropout commonlyus', u'dropout commonlyus regular', u'dropout encod', u'dropout encod decod', u'dropout fcn', u'dropout fcn dilat', u'dropout percentag', u'dropout performs4', u'dropout performs4 mont', u'dropout performsbett', u'dropout performsbett weight', u'dropout probabl', u'dropout probabl pi', u'dropout randomlyremov', u'dropout randomlyremov unit', u'dropout randomlytrain', u'dropout randomlytrain stochast', u'dropout sampl', u'dropout sampl posterior', u'dropout sampl qualit', u'dropout samplingmont', u'dropout samplingmont carlo', u'dropout samplingweight', u'dropout samplingweight averagingweight', u'dropout simpl', u'dropout simpl way', u'dropout test', u'dropout test time', u'dropout testachiev', u'dropout testachiev mont', u'dropout testtim', u'dropout testtim generat', u'dropout uncertainti', u'dropout uncertainti produc', u'dropout uncertainti softmax', u'dropout use', u'dropout use approxim', u'dropout use test', u'dropout usingfor', u'dropout usingfor segment', u'dropout usingth', u'dropout usingth weight', u'dropout way', u'dropout way gettingcan', u'dropout way gettingsampl', u'dropout82', u'dropouta', u'dropouta fulli', u'dropouta fulli bayesian', u'dropoutaft', u'dropoutaft everi', u'dropoutaft everi convolut', u'dropoutno', u'dropoutno dropout82', u'dropoutno dropoutno', u'dropoutno dropoutno dropout82', u'dropoutno dropoutno dropoutno', u'dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel', u'dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel uncertaintymodel', u'dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel uncertaintymodel uncertaintymodel', u'dropoutstochast', u'dropoutstochast dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel', u'dropoutstochast dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel uncertaintymodel', u'dropoutstochast dropoutstochast', u'dropoutstochast dropoutstochast dropoutsamplessamplessamplessamplessamplessamplessamplessamplesmeanmeanmeanmeanmeansegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationmodel', u'dropoutstochast dropoutstochast dropoutstochast', u'dropoutto', u'dropoutto obtain', u'dropoutto obtain posterior', u'dropoutw', u'dropoutw train', u'dropoutw train model', u'du', u'du c', u'du c huang', u'du s', u'du s zheng', u'duedeep', u'duedeep learn', u'duedeep learn model', u'duefilt', u'duefilt perform', u'duefilt perform segnet-bas', u'dueperceiv', u'dueperceiv perform', u'dueperceiv perform increas', u'dueto', u'dueto avail', u'dueto avail massiv', u'dueto lack', u'dueto lack good', u'dueto larger', u'dueto larger decod', u'dure', u'dure backpropag', u'dure backpropag path', u'dure backpropag visual', u'dure infer', u'dure infer abil', u'dure infer constrain', u'dure infer forward', u'dure infer model', u'dure infer models', u'dure infer modelstor', u'dure infer note', u'dure infer signific', u'dure infer time', u'dure inferencebefor', u'dure inferencebefor sub-sampl', u'dure inferencei', u'dure inferencei constrain', u'dure pool', u'dure pool store', u'dure studi', u'dure studyeach', u'dure studyeach layer', u'dure studyfigur', u'dure studyfigur segnet', u'dure test', u'dure test time', u'dure test timeand', u'dure test timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass', u'dure train', u'dure train test', u'duringa', u'duringa use', u'duringa use region', u'duringaccuraci', u'duringaccuraci differ', u'duringaccuraci differ segnet', u'duringeach', u'duringeach sampl', u'duringeach sampl indic', u'duringinfer', u'duringinfer propos', u'duringinfer propos use', u'duringinfer sinc', u'duringinfer sinc onli', u'duringpool', u'duringpool store', u'duringpool store pass', u'duringprev', u'duringprev overfit', u'duringprev overfit co-adapt', u'duringtrain', u'duringtrain stochast', u'duringtrain stochast gradient', u'dusk', u'dusk scenario', u'dusk scenario sfm', u'dusk scene', u'dusk scene at360', u'dusk scene at367', u'dusk test', u'dusk test sampl', u'dusk test sequenc', u'duskscen', u'dusktrain', u'dusktrain imag', u'dusktrain imag test', u'dynamicnon-uniform', u'dynamicnon-uniform scene', u'dynamicnon-uniform scene illumin', u'dynamicrang', u'dynamicrang increas', u'dynamicrang increas contrast', u'e', u'e locat', u'e locat maximum', u'e number', u'e number featur', u'e ofresolut', u'e ofresolut featur', u'e ofth', u'e ofth layer', u'e onli', u'e onli convolvetheir', u'e onli convolvewher', u'e shelham', u'e shelham t', u'e vgg16', u'e vgg16 differ', u'e-mail', u'e-mail vb292', u'e-mail vb292 agk34', u'eachadditional/deep', u'eachadditional/deep encoder-decod', u'eachadditional/deep encoder-decod pair', u'eachbas', u'eachbas convolut', u'eachbas convolut layer', u'eachclass', u'eachconverg', u'eachconverg befor', u'eachconverg befor epoch', u'eachdecod', u'eachdecod correspond', u'eachdecod correspond encod', u'eachdecod upsampl', u'eachdecod upsampl input', u'eachfor', u'eachfor encod', u'eachfor encod decod', u'eachi', u'eachi illustr', u'eachi illustr fig', u'eachmini-batch', u'eachmini-batch imag', u'eachmini-batch imag pick', u'eachnetwork', u'eachnetwork therefor', u'eachnetwork therefor number', u'eachth', u'eachth experi', u'eachth experi slight', u'eachw', u'eachw present', u'eachw present bayesian', u'earli', u'earli method', u'earli method reli', u'earlier', u'earlier benchmark', u'earlier benchmark dataset', u'earlier requir', u'earlier requir learn', u'earlier term', u'earlier term segnet', u'earlier work', u'earlier work agreement', u'earlier work like', u'earlieranalysi', u'earlieranalysi sec', u'earlieranalysi sec 33analysi', u'earlierbenchmark', u'earlierbenchmark dataset', u'earlierbenchmark dataset nyuv2', u'earlierhigh', u'earlierhigh metric', u'earlierhigh metric far', u'earlieri', u'earlieri scope', u'earlieri scope paper', u'easier', u'easier deep', u'easier deep network', u'easier occur', u'easier occur moremor', u'easier occur moreoften', u'easier optim', u'easier optim thefilt', u'easier optim thenon-linear', u'easier segment', u'easier segment deep', u'easier train', u'easier train mani', u'easilydesc', u'easilydesc sgd', u'easilydesc sgd addit', u'easilyrepeat', u'easilyrepeat design', u'easilyrepeat design segnet', u'easypixel', u'easypixel label', u'easypixel label improv', u'easyto', u'easyto visualis', u'easyto visualis effect', u'eccv', u'eccv convolut', u'eccv convolut network', u'eccv label', u'eccv label descriptor', u'eccv mani', u'eccv mani combin', u'eccv marseill', u'eccv marseill 2008in', u'eccv marseill 2008use', u'eccv page', u'eccv page 4of', u'eccv page 7a', u'eccv page 7torr', u'eccv page convolut', u'eccv page springer', u'eccv pages708\\u2013721', u'eccv pages708\\u2013721 springer', u'eccv pagesof', u'eccv pagesof urban', u'eccv pp', u'eccv pp 2010pp', u'eccv pp springer', u'eccv pp springer,201420142014201420142014imag', u'eccv pp support', u'ed', u'ed vol', u'ed vol ofin', u'ed vol oflectur', u'edg', u'edg categori', u'edg categori sharp', u'edg comput', u'edg comput vision\\u2013eccv', u'edg corner', u'edg inform', u'edg inform apartfrom', u'edg inform apartmap', u'edg lead', u'edg lead network', u'edg low', u'edg low inputlarg', u'edg low inputresolut', u'edg potenti', u'edg potenti nip', u'edg rgbedg', u'edg rgbedg vice-versa', u'edg rgbedg vice-versaedg', u'edg rgbthis', u'edg rgbthis avoid', u'edg vice-versa', u'edgesform', u'edgesform becaus', u'edgesform becaus illumin', u'edgesof', u'edgesof low', u'edgesof low input', u'edit', u'edit 4network', u'edit 4network scene', u'edit 4springer', u'edit 4springer new', u'edit volum', u'edit volum co-author', u'eferencesk', u'eferencesk simonyan', u'eferencesk simonyan zisserman', u'eferencesr', u'eferencesr eferencesk', u'eferencesr eferencesk simonyan', u'eferencesr eferencesr', u'eferencesr eferencesr eferencesk', u'eferencesr eferencesr eferencesr', u'effect', u'effect accuraci', u'effect accuraci structuredbuild', u'effect accuraci structuredbut', u'effect averag', u'effect averag predict', u'effect clear', u'effect clear worsefor', u'effect clear worseto', u'effect featur', u'effect featur activ', u'effect featur perform', u'effect measur', u'effect measur confidencein', u'effect measur confidencemodel', u'effect minimis', u'effect minimis thekullback-leibl', u'effect minimis theloss', u'effect model', u'effect model withbayesian', u'effect model withcontextu', u'effect subset', u'effect subset offeatur', u'effect subset ofrath', u'effect supervis', u'effect supervis pre-train', u'effect whenmeasur', u'effect whenmeasur model', u'effect whenmodel', u'effect whenmodel smaller', u'effective0th', u'effective0th percentil', u'effective0th percentil pixel', u'effectivemeasur', u'effectivemeasur predict', u'effectivemeasur predict accuraci', u'effectivenessfin', u'effectivenessfin section', u'effectivenessof', u'effectivenessof model', u'effectivenessof model uncertainti', u'effectsof', u'effectsof model', u'effectsof model versus', u'effectsw', u'effectsw note', u'effectsw note approach', u'efficaci', u'efficaci ofbayesian', u'efficaci ofbayesian segnet', u'efficaci ofthre', u'efficaci ofthre differ', u'efficaci segnet', u'efficaci segnet present', u'effici', u'effici architectur', u'effici architectur pixel-wis', u'effici architectur real-tim', u'effici architectur road', u'effici compar', u'effici compar deconvnet', u'effici compar deconvnetbut', u'effici compar deconvnetthi', u'effici dure', u'effici dure infer', u'effici infer', u'effici infer memory-wis', u'effici model', u'effici model crfcompar', u'effici model crfpost-process', u'effici model fcn-basic-nodimreduct', u'effici model forbeen', u'effici model forreal-tim', u'effici model slight', u'effici modeland', u'effici modeland crf', u'effici modellarg', u'effici modellarg model', u'effici sinc', u'effici sinc onli', u'effici store', u'effici store compar', u'effici tasksarchitectur', u'effici tasksarchitectur shown', u'effici taskssuch', u'effici taskssuch road', u'effici term', u'effici term infer', u'effici term memori', u'effici term memoryand', u'effici term memoryscen', u'effici viewpoint', u'effici viewpoint feel', u'effici way', u'effici way storeappl', u'effici way storethi', u'effici weight', u'effici weight updat', u'effort', u'effort perform', u'effort perform ablat', u'effort row', u'effort row poor', u'effort row produc', u'effortsar', u'effortsar increas', u'effortsar increas accur', u'effortsin', u'effortsin benchmark', u'effortsin benchmark experi', u'eigen', u'eigen andclass', u'eigen andclass balanc', u'eigen andfergus', u'eigen et', u'eigen et al', u'eigen r', u'eigen r fergus', u'eitheral', u'eitheral measur', u'eitheral measur accuraci', u'eitherus', u'eitherus learn', u'eitherus learn upsampl', u'electr', u'electr engin', u'electr engin fromin', u'electr engin fromth', u'element', u'element fcn', u'element fcn model', u'element suchcomput', u'element suchcomput histogram', u'element suchvector', u'element suchvector sampl', u'element-wis', u'element-wis correspond', u'element-wis correspond encoderfeatur', u'element-wis correspond encoderthi', u'element-wis rectifiedlinear', u'element-wis rectifiedlinear non-linear', u'element-wis tanh', u'element-wis tanh non-linear', u'element-wis tomap', u'element-wis tomap fcn', u'element-wis toth', u'element-wis toth correspond', u'elimin', u'elimin need', u'elimin need learn', u'embed', u'embed devic', u'embed devic exampl', u'embed proceed', u'embed proceed 22nd', u'embeddedappl', u'embeddedappl e', u'embeddedappl store', u'embeddedappl store featur', u'embeddeddur', u'embeddeddur infer', u'embeddeddur infer memori', u'emerg', u'emerg ofbas', u'emerg ofbas classifi', u'emerg ofdeep', u'emerg ofdeep learn', u'emergencelevel', u'emergencelevel visual', u'emergencelevel visual featur', u'emergenceof', u'emergenceof machin', u'emergenceof machin learn', u'emphas', u'emphas need', u'emphas need learndecod', u'emphas need learnperform', u'emphas trade-off', u'emphas trade-off involv', u'empir', u'empir observ', u'empir observ object', u'employ', u'employ data', u'employ data augment', u'employ larg', u'employ larg spatial', u'employ pattern', u'employ pattern trend', u'enabl', u'enabl end-to-end', u'enabl end-to-end train', u'enabl train', u'enabl train batch', u'enabl train moreov', u'enabl train network', u'enc-dec', u'enc-dec variant', u'enc-dec79', u'enc-decdropout', u'enc-decdropout enc-dec79', u'enc-decdropout enc-decdropout', u'enc-decdropout enc-decdropout enc-dec79', u'enc-decdropout enc-decdropout enc-decdropout', u'enchmarkingb', u'enchmarkingb enchmarkingb', u'enchmarkingb enchmarkingb enchmarkingb', u'enchmarkingb enchmarkingb enchmarkingw', u'enchmarkingb enchmarkingw', u'enchmarkingb enchmarkingw quantifi', u'enchmarkingw', u'enchmarkingw quantifi', u'enchmarkingw quantifi perform', u'encod', u'encod activ', u'encod activ use', u'encod and4', u'encod and4 decod', u'encod anddecod', u'encod anddecod strong', u'encod andfix', u'encod andfix total', u'encod andpercentag', u'encod approach', u'encod approach howev', u'encod base', u'encod base convolut', u'encod closest', u'encod closest tonot', u'encod closest toth', u'encod closestthat', u'encod closestthat decod', u'encod closestto', u'encod closestto input', u'encod consist', u'encod consist ofconvolut', u'encod consist ofmodul', u'encod consist oneand', u'encod consist oneor', u'encod correspond', u'encod correspond set', u'encod decod', u'encod decod architectur', u'encod decod constant', u'encod decod correspond', u'encod decod drop', u'encod decod filter', u'encod decod layer', u'encod decod pool', u'encod decod unit', u'encod decod unitsfind', u'encod decod unitsi', u'encod decod weight', u'encod decoderaft', u'encod decoderaft convolut', u'encod decodernetwork', u'encod decodernetwork bias', u'encod decodersal', u'encod decodersal encod', u'encod decodersterm', u'encod decodersterm segnet-bas', u'encod employ', u'encod employ larg', u'encod encod', u'encod encod network', u'encod featur', u'encod featur map', u'encod featur mapsand', u'encod featur mapsbefor', u'encod featur mapsdur', u'encod featur mapsfor', u'encod featur mapsth', u'encod featur mapsto', u'encod featurefrom', u'encod featurefrom train', u'encod featuremap', u'encod featuremap decod', u'encod featuremap store', u'encod featureth', u'encod featureth best', u'encod follow', u'encod follow acorrespond', u'encod follow asegnet', u'encod index', u'encod index terms\\u2014deep', u'encod input', u'encod input channel', u'encod input fix', u'encod input thehigh', u'encod input thesam', u'encod isbas', u'encod isbas convolut', u'encod issegnet-bas', u'encod issegnet-bas base', u'encod kernel', u'encod kernel set', u'encod layer', u'encod layer featureclass', u'encod layer featuremap', u'encod layer retain', u'encod layerha', u'encod layerha correspond', u'encod layerrec', u'encod layerrec architectur', u'encod network', u'encod network consist', u'encod network consistsarchitectur', u'encod network consistsof', u'encod network correspond', u'encod network decodersar', u'encod network decodersmax-pool', u'encod network featur', u'encod network perform', u'encod network producesthes', u'encod network producesto', u'encod network segnet', u'encod network segnet-bas', u'encod network topolog', u'encod network train', u'encod network vgg16', u'encod network weightsar', u'encod network weightslay', u'encod networkdiscard', u'encod networkdiscard fulli', u'encod networkha', u'encod networkha larg', u'encod networklarg', u'encod networklarg size', u'encod networkwhich', u'encod networkwhich enabl', u'encod note', u'encod note trainabl', u'encod output', u'encod output imagepixel', u'encod output imagethes', u'encod output thisalso', u'encod output thishigh', u'encod perform', u'encod perform dens', u'encod perform non-linear', u'encod produc', u'encod produc spars', u'encod segnet-bas', u'encod segnet-bas perform', u'encod sequenc', u'encod sequenc non-linear', u'encod stack', u'encod stack fullclassif', u'encod stack fullinput', u'encod thea', u'encod thea relu', u'encod theappropri', u'encod theappropri decod', u'encod theinputinputinputinputinputinputstochast', u'encod theinputinputinputinputinputinputstochast dropoutstochast', u'encod theof', u'encod theof decod', u'encod theseapproach', u'encod theseapproach howev', u'encod theseful', u'encod theseful imag', u'encod tofeatur', u'encod tofeatur map', u'encod toperform', u'encod toperform non-linear', u'encod train', u'encod train segnet', u'encod tri', u'encod tri generic', u'encod unit', u'encod unit contain', u'encod use', u'encod use class', u'encod use convolution-relu-max', u'encoder-decod', u'encoder-decod architectur', u'encoder-decod architectur imag', u'encoder-decod architectur robust', u'encoder-decod architectur robustsegnet', u'encoder-decod architectur robustsemant', u'encoder-decod architectur sceneuncertainti', u'encoder-decod architectur sceneunderstand', u'encoder-decod network', u'encoder-decod network encod', u'encoder-decod network theencod', u'encoder-decod network thelearn', u'encoder-decod network trainedjoint', u'encoder-decod network trainedthes', u'encoder-decod network unsupervis', u'encoder-decod neural', u'encoder-decod neural network', u'encoder-decod pair', u'encoder-decod pair featur', u'encoder-decod pair minimiseal', u'encoder-decod pair minimiseth', u'encoder-decod pair result', u'encoder-decod pair weight', u'encoder-decod pairfor', u'encoder-decod pairfor additional/deep', u'encoder-decod pairin', u'encoder-decod pairin sec', u'encoder-decod pairsand', u'encoder-decod pairsand train', u'encoder-decod pairslearn', u'encoder-decod pairslearn feed-forward', u'encoder-decod type', u'encoder-decod type architectur', u'encoder-decod weight', u'encoder-decod weight fix', u'encoder-decoder4', u'encoder-decoder4 decod', u'encoder-decoder4 decod experi', u'encoder-decoderapproach', u'encoder-decoderapproach howev', u'encoder-decoderapproach howev did', u'encoder-decoderarchitectur', u'encoder-decoderarchitectur onli', u'encoder-decoderarchitectur onli littl', u'encoder-decoderarchitectur scene', u'encoder-decoderarchitectur scene understandingarchitectur', u'encoder-decoderbayesian', u'encoder-decoderbayesian segnet', u'encoder-decoderbayesian segnet model', u'encoder-decoderconvolut', u'encoder-decoderconvolut encoder-decoderconvolut', u'encoder-decoderconvolut encoder-decoderconvolut encoder-decoderconvolut', u'encoder-decoderconvolut encoder-decoderconvolut encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool', u'encoder-decoderconvolut encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool', u'encoder-decoderconvolut encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool indicespool', u'encoder-decoderform', u'encoder-decoderform upsampl', u'encoder-decoderform upsampl incorpor', u'encoder-decodernetwork', u'encoder-decodernetwork unsupervis', u'encoder-decodernetwork unsupervis featur', u'encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool', u'encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool indicespool', u'encoder-decoderoutputoutputoutputoutputoutputoutputoutputpool indicespool indicespool', u'encoder-decoderstack', u'encoder-decoderstack train', u'encoder-decoderstack train advantag', u'encoder80', u'encoderalso', u'encoderalso reduc', u'encoderalso reduc number', u'encoderand', u'encoderand decod', u'encoderand decod unit', u'encoderconnect', u'encoderconnect layer', u'encoderconnect layer vgg16', u'encodercorrespond', u'encodercorrespond decod', u'encodercorrespond decod dimension', u'encoderdecod', u'encoderdecod architectur', u'encoderdecod architectur dropout', u'encoderdecod fig', u'encoderdecod fig train', u'encoderdecod import', u'encoderdecod import captur', u'encoderdropout', u'encoderdropout encoder80', u'encoderdropout encoderdropout', u'encoderdropout encoderdropout encoder80', u'encoderdropout encoderdropout encoderdropout', u'encoderencod', u'encoderencod use', u'encoderencod use convolution-relu-max', u'encoderfeatur', u'encoderfeatur map', u'encoderfeatur map compress', u'encoderfeatur map inform', u'encoderfeatur map produc', u'encoderfeatur map say', u'encoderit', u'encoderit perform', u'encoderit perform convolut', u'encoderlarg', u'encoderlarg decod', u'encoderlarg decod increas', u'encodermodel', u'encodermodel slight', u'encodermodel slight larger', u'encodernetwork', u'encodernetwork signific', u'encodernetwork signific 134m', u'encodernetwork signific smaller', u'encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb', u'encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb enchmarkingb', u'encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb enchmarkingb enchmarkingb', u'encoderthi', u'encoderthi ad', u'encoderthi ad element-wis', u'encodertrain', u'encodertrain end-to-end', u'encodertrain end-to-end task', u'encodervari', u'encodervari insert', u'encodervari insert dropout', u'encoderweight', u'encount', u'encount difficulti', u'encount difficulti perform', u'encourag', u'encourag control', u'encourag control benchmark', u'encourag notbeen', u'encourag notbeen quit', u'encourag notcategoris', u'encourag notcategoris imag', u'encourag reproduct', u'encourag reproduct result', u'encourag research', u'encourag research direct', u'encourag research toengag', u'encourag research torobust', u'encourag themodel', u'encourag themodel learn', u'encourag thenetwork', u'encourag thenetwork stochast', u'end', u'end deeper3', u'end deeper3 web', u'end deeperwa', u'end deeperwa observ', u'end eachdecod', u'end eachdecod correspond', u'end eachnetwork', u'end eachnetwork therefor', u'end end', u'end end usingmodel', u'end end usingstochast', u'end usingmodel', u'end usingmodel paramet', u'end usingstochast', u'end usingstochast gradient', u'end-to-end', u'end-to-end learn', u'end-to-end learn deep', u'end-to-end ona', u'end-to-end ona relev', u'end-to-end onlarg', u'end-to-end onlarg size', u'end-to-end step', u'end-to-end step lower', u'end-to-end step stage-wis', u'end-to-end task', u'end-to-end task pre-train', u'end-to-end train', u'end-to-end train addedbatch', u'end-to-end train addedon', u'end-to-end train iii', u'end-to-end train perform', u'end-to-end train solver', u'end-to-end use', u'end-to-end use stochast', u'end-to-end withoutoth', u'end-to-end withoutoth aid', u'end-to-end withoutweight', u'end-to-endcomput', u'end-to-endcomput time', u'end-to-endcomput time dure', u'end-to-endin', u'end-to-endin convolut', u'end-to-endin convolut manner', u'end-to-endin order', u'end-to-endin order joint', u'end-to-endmor', u'end-to-endmor comput', u'end-to-endmor comput resourc', u'end-to-endon', u'end-to-endon dataset', u'end-to-endon dataset enabl', u'end-to-endth', u'end-to-endth perform', u'end-to-endth perform architectur', u'end-toend', u'end-toend train', u'end-toend train difficulti', u'endow', u'endow flexibilityand', u'endow flexibilityand henc', u'endow flexibilitynetwork', u'endow flexibilitynetwork fcn-basic', u'eng', u'engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl', u'engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl rang', u'engcamacukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl rang estim', u'engcamacukpedestrian', u'engcamacukpedestrian understand', u'engcamacukpedestrian understand spatial-relationship', u'engcamacukvb292', u'engcamacukvb292 ah781', u'engcamacukvb292 ah781 cipolla', u'engin', u'engin abil', u'engin abil delineateobject', u'engin abil delineatesegment', u'engin architectur', u'engin architectur ad', u'engin base', u'engin base techniqu', u'engin base techniquesth', u'engin base techniquesto', u'engin class', u'engin class honour', u'engin consist', u'engin consist encod', u'engin deepcurr', u'engin deepcurr work', u'engin deeplearn', u'engin deeplearn magic', u'engin degre', u'engin degre univers', u'engin featur', u'engin featur butalreadi', u'engin featur buttheir', u'engin featur classifi', u'engin featur pixel-wis', u'engin freng', u'engin freng in2010', u'engin freng inh', u'engin fromin', u'engin fromin m', u'engin fromin mse', u'engin fromth', u'engin fromth univers', u'engin ismad', u'engin ismad better', u'engin iswould', u'engin iswould reduc', u'engin machin', u'engin machin intellig', u'engin professor', u'engin professor 2000a', u'engin professor 2000he', u'engin segnet', u'engin segnet hand', u'engin toshiba', u'engin toshiba corporationfellow', u'engin toshiba corporationresearch', u'engin univers', u'engin univers cambridg', u'engineeredattribut', u'engineeredattribut approach', u'engineeredattribut approach use', u'engineeredbest', u'engineeredbest perform', u'engineeredbest perform method', u'engineeredfeatur', u'engineeredfeatur classif', u'engineeredfeatur classif rgb', u'engineeredfeatur featur', u'engineeredfeatur featur featur', u'engineeredfeatur general', u'engineeredfeatur general use', u'engineeredpredict', u'engineeredpredict techniqu', u'engineeredpredict techniqu alreadi', u'ensembl', u'ensembl of3433', u'ensembl of3433 imag', u'ensembl ofa', u'ensembl ofa deep', u'ensembl offeatur', u'ensembl offeatur activ', u'ensembl ofw', u'ensembl ofw combin', u'ensur', u'ensur label', u'ensur label consist', u'ensur thateach', u'ensur thateach imag', u'ensur thatmini-batch', u'ensur thatmini-batch imag', u'entir', u'entir disentangl', u'entir disentangl effectsof', u'entir disentangl effectsw', u'entir featur', u'entir featur map', u'entir network', u'entir network make', u'entir pipelin', u'entir pipelin trainedend-to-end', u'entir pipelin trainedfigur', u'entir static', u'entir static scene', u'entir train', u'entir train set', u'entir train setdivid', u'entir train setmedian', u'entropyin', u'entropyin shown', u'entropyin shown minimis', u'entropyloss', u'entropyloss object', u'entropyloss object function', u'epoch', u'epoch denot', u'epoch denot segnet', u'epoch inputepoch', u'epoch inputepoch margin', u'epoch inputsampl', u'epoch inputsampl approxim', u'epoch kitti', u'epoch kitti train', u'epoch pass', u'epoch pass theto', u'epoch pass thetrain', u'epoch run', u'epoch run anoth', u'epoch select', u'epoch select modeleach', u'epoch select modelwhich', u'epoch test', u'epoch test pointcorrespond', u'epoch test pointw', u'epoch train', u'epoch train onli', u'epoch train set', u'epoch use', u'epoch use largerdecod', u'epoch use largersam', u'equal', u'equal import', u'equal import class', u'equal test', u'equal test measur', u'equival', u'equival use', u'equival use natur', u'erhan', u'erhan c', u'erhan c szegedi', u'erhan v', u'erhan v vanhouck', u'error', u'error bar', u'error bar mont', u'error bar shown', u'error depth', u'error depth interpol', u'especi', u'especi difficult', u'especi difficult class', u'essenti', u'essenti decis', u'essenti decis make', u'estim', u'estim absolut', u'estim absolut model', u'estim model', u'estim model uncertainti', u'estim process', u'estim scene', u'estim scene geometri', u'et', u'et al', u'et al acceptful', u'et al acceptpatch', u'et al advoc', u'et al key', u'et al keylearn', u'et al keyour', u'et al multi-scalebeen', u'et al multi-scaledeep', u'et al notecommon', u'et al notethat', u'et al segnet', u'et al simpli', u'et al studi', u'et al train', u'et almain', u'et almain focus', u'et alnetwork', u'et alnetwork classif', u'evalu', u'evalu asbayesian', u'evalu asbayesian neural', u'evalu asshow', u'evalu asshow mean', u'evalu at3', u'evalu at3 web', u'evalu athttp', u'evalu athttp //mi', u'evalu athttp //miengcamacuk/projects/segnet/http', u'evalu expens', u'evalu expens perform', u'evalu f1-measur', u'evalu f1-measur involv', u'evalu fcncompetit', u'evalu fcncompetit accuraci', u'evalu fcndropout', u'evalu fcndropout sampl', u'evalu measur', u'evalu measur semant', u'evalu onlineevalu', u'evalu onlineevalu server', u'evalu onlinet', u'evalu onlinet pascal', u'evalu perform', u'evalu perform architecturediscard', u'evalu perform architecturemak', u'evalu perform segnet', u'evalu server', u'evalu test', u'evalu test model', u'evalu thearchitectur', u'evalu thearchitectur analysi', u'evalu theperform', u'evalu theperform segnet', u'evalu unsupervis', u'evalu unsupervis imagematch', u'evalu unsupervis imagesegment', u'evalu use', u'evalu use mont', u'evalu valid', u'evalu valid set', u'evaluationagainst', u'evaluationagainst accuraci', u'evaluationagainst accuraci increas', u'evaluationof', u'evaluationof fulli', u'evaluationof fulli learnt', u'evaluationw', u'evaluationw perform', u'evaluationw perform complet', u'evaluationw propos', u'evaluationw propos novel', u'evenclass', u'evenclass car', u'evenclass car pedestrian', u'evenfor', u'evenfor outdoor', u'evenfor outdoor indoor', u'evenwhen', u'evenwhen compar', u'evenwhen compar method', u'evenwithout', u'evenwithout use', u'evenwithout use ani', u'everi', u'everi convolut', u'everi convolut layer', u'everi encod', u'everi encod anddecod', u'everi encod andpercentag', u'everi epoch', u'everi epoch pass', u'evid', u'evid todecod', u'evid todecod lead', u'evid tosegnet', u'evid tosegnet good', u'evid true', u'evid true perform', u'eviewl', u'eviewl iteratur', u'eviewl iteratur r', u'eviewsemant', u'eviewsemant pixel-wis', u'eviewsemant pixel-wis segment', u'evolut', u'evolut various', u'evolut various unari', u'exact', u'exact improv', u'exact improv use', u'exampl', u'exampl ar', u'exampl ar applic', u'exampl ar applicationsfrom', u'exampl ar applicationson', u'exampl base', u'exampl base semant', u'exampl base semantich', u'exampl base semanticimag', u'exampl perform', u'exampl perform bayesian', u'exampl testfor', u'exampl testfor autonom', u'exampl testresult', u'exampl testresult produc', u'examplecaff', u'examplecaff prototxt', u'examplecaff prototxt road', u'examplehttp', u'examplehttp //mi', u'examplehttp //miengcamacuk/projects/segnet/tutorialhtml', u'examplehttp //miengcamacuk/projects/segnet/tutorialhtml examplecaff', u'examplehttp //miengcamacuk/projects/segnet/tutorialhtml examplehttp', u'exceed', u'exceed method', u'exceed method usecrf', u'exceed method usesmooth', u'exist', u'exist metric', u'exist metric bias', u'exist train', u'exist train network', u'existbut', u'existbut equal', u'existbut equal import', u'existmeanwhil', u'existmeanwhil indoor', u'existmeanwhil indoor rgbd', u'expand', u'expand deep', u'expand deep encod', u'expand model', u'expand model depthand', u'expand model depthto', u'expect', u'expect fig', u'expect fig goodin', u'expect fig goodperform', u'expens', u'expens given', u'expens given larg', u'expens grid-searchcrf', u'expens grid-searchcrf hyperparamet', u'expens grid-searchprocess', u'expens grid-searchprocess subset', u'expens increas', u'expens increas number', u'expens infer', u'expens infer time', u'expens multipl', u'expens multipl convolut', u'expens perform', u'expens perform largefor', u'expens perform largetrain', u'experi', u'experi analysis4', u'experi analysis4 experi', u'experi analysisa', u'experi analysisa number', u'experi complex', u'experi complex task', u'experi comput', u'experi comput statisticstest', u'experi comput statisticswhil', u'experi divertedin', u'experi divertedin benchmark', u'experi divertedtoward', u'experi divertedtoward attain', u'experi encourag', u'experi encourag research', u'experi independ', u'experi independ benchmark', u'experi introduc', u'experi introduc deeper', u'experi onc', u'experi onc encoder-decoder4', u'experi onc encoder-decoderstack', u'experi slight', u'experi slight decreas', u'experi tabl', u'experi tabl did', u'experi test', u'experi test timeincreas', u'experi test timememori', u'experi train', u'experi train segnet', u'experi use', u'experi use outdoor', u'experi withit', u'experi withit qualit', u'experi withsegnet', u'experi withsegnet sever', u'experiencemachin', u'experiencemachin learn', u'experiencemachin learn facilit', u'experimentaldecod', u'experimentaldecod segment', u'experimentaldecod segment support', u'experimentalevid', u'experimentalevid gather', u'experimentalevid gather author', u'experimentallyfound', u'experimentallyfound comput', u'experimentallyfound comput weight', u'experimentallywhil', u'experimentallywhil use', u'experimentallywhil use dropout', u'experimentedform', u'experimentedform becaus', u'experimentedform becaus illumin', u'experimentedof', u'experimentedof smallest', u'experimentedof smallest class', u'experimentedwith', u'experimentedwith train', u'experimentedwith train differ', u'experimentedwith train variant', u'experiments5', u'experimentsa', u'experimentsa layer', u'experimentsa layer segnet', u'experimentsi', u'experimentsi illustr', u'experimentsi illustr fig', u'experimentsw', u'experimentsw quantifi', u'experimentsw quantifi perform', u'expertis', u'expertis initi', u'expertis initi weight', u'explain', u'explain thedata', u'explain thedata prevent', u'explain themodel', u'explain themodel learn', u'explainbf', u'explainbf measur', u'explainbf measur variant', u'explainth', u'explainth reason', u'explainth reason whi', u'exploit', u'exploit co-occurr', u'exploit co-occurr ofobject', u'exploit co-occurr ofunderstand', u'exploit featur', u'exploit featur learn', u'exploit featur represent', u'exploit understand', u'exploit understand offor', u'exploit understand ofsegment', u'explor', u'explor factor', u'explor factor contribut', u'explor foror', u'explor foror sfm', u'explor forth', u'explor forth camvid', u'explor mani', u'explor mani differ', u'explor numberaft', u'explor numberaft everi', u'explor numberof', u'explor numberof variant', u'explor use', u'explor use variat', u'explor video', u'explor video data', u'explos', u'explos unlik', u'explos unlik expand', u'exposur', u'exposur new', u'exposur new scenario', u'extend', u'extend deepconvolut', u'extend deepconvolut encoder-decod', u'extend deepth', u'extend deepth main', u'extend kavukcuoglu', u'extend kavukcuoglu et', u'extend thissegment', u'extend thissegment qualiti', u'extend thisto', u'extend thisto semant', u'extendedto', u'extendedto pole', u'extendedto pole contrast', u'extendedtre', u'extendedtre build', u'extendedtre build bollard', u'extent', u'extentsegnet-bas', u'extentsegnet-bas similar', u'extentsegnet-bas similar fcn-basic-noaddit', u'extentsom', u'extentsom extentsegnet-bas', u'extentsom extentsegnet-bas similar', u'extentsom extentsom', u'extentsom extentsom extentsegnet-bas', u'extentsom extentsom extentsom', u'extern', u'extern traineddetector', u'extern traineddetector crf', u'extern trainedfigur', u'extern trainedfigur result', u'extra', u'extra comput', u'extra comput effort', u'extra inform', u'extra inform ground', u'extract', u'extract edg', u'extract edg corner', u'extract featur', u'extract featur segment', u'extract imageimport', u'extract imageimport retain', u'extract imagerepresent', u'extract imagerepresent comput', u'extract multipl', u'extract multipl scale', u'extract network', u'extract network ii', u'extractcrf', u'extractcrf abil', u'extractcrf abil deep', u'extractmeaning', u'extractmeaning featur', u'extractmeaning featur input', u'extrem', u'extrem larg', u'extrem larg dimens', u'f1', u'f1 measur', u'f1 measuresbi', u'f1 measuresbi averag', u'f1 measuresw', u'f1 measuresw test', u'f1-measur', u'f1-measur bf', u'f1-measur bf averag', u'f1-measur bf test', u'f1-measur bf toarchitectur', u'f1-measur bf tocompl', u'f1-measur computei', u'f1-measur computei averag', u'f1-measur computeth', u'f1-measur computeth test', u'f1-measur involv', u'f1-measur involv comput', u'f1measur', u'f1measur class', u'f1measur class present', u'facilit', u'facilit continu', u'facilit continu advanc', u'fact', u'fact agre', u'fact agre earlieranalysi', u'fact agre earlierhigh', u'fact joint', u'fact joint train', u'fact object', u'fact object class', u'fact result', u'fact result improv', u'fact share', u'fact share segnet', u'fact smallestmodel', u'fact smallestmodel deeplab-largefov', u'fact smallestthi', u'fact smallestthi conjectur', u'fact train', u'fact train networksinvolv', u'fact train networksresult', u'factor', u'factor contribut', u'factor contribut tobayesian', u'factor contribut tounderstand', u'factor improv', u'factor improv perform', u'factor like', u'factor like memoryand', u'factor make', u'factor make hardest', u'factor make offrequ', u'factor make ofth', u'factor max-pool', u'factor max-pool use', u'factorsnecessari', u'factorsnecessari achiev', u'factorsnecessari achiev good', u'factorstheir', u'factorstheir quantit', u'factorstheir quantit result', u'fail', u'fail label', u'fail label car', u'fair', u'fair comparison', u'fair comparison term', u'fals', u'fals positivemetr', u'fals positivemetr class', u'fals positivepredict', u'fals positivepredict howev', u'far', u'far lesser', u'far lesser time', u'far lower', u'far lower parameteris', u'far satisfactori', u'far satisfactori thelack', u'far satisfactori thewith', u'far sidewalk', u'far sidewalk column2', u'far sidewalk columndetector', u'farabet', u'farabet c', u'farabet c coupri', u'farabet et', u'farabet et al', u'fast', u'fast supersed', u'fast supersed popular', u'faster', u'faster competingarchitectur', u'faster competingarchitectur shown', u'faster competingwhich', u'faster competingwhich signific', u'faster dure', u'faster dure infer', u'faster morengiam', u'faster morengiam et', u'faster morest', u'faster morest converg', u'faster noteresolut', u'faster noteresolut smaller', u'faster notethat', u'faster notethat decod', u'fastest', u'fastest train', u'fastest train time', u'favour', u'favour region', u'favour region smooth', u'favour retainingalso', u'favour retainingalso discard', u'favour retaininghigh', u'favour retaininghigh resolut', u'fcn', u'fcn analysi', u'fcn analysi which1', u'fcn analysi whichfcn-bas', u'fcn anddil', u'fcn anddil network', u'fcn andof', u'fcn andof state', u'fcn architectur', u'fcn architectur learn', u'fcn convolv', u'fcn convolv trainabl', u'fcn cost', u'fcn cost ofa', u'fcn cost ofperform', u'fcn decod', u'fcn decod b', u'fcn decod fulli', u'fcn decod model', u'fcn decod techniqu', u'fcn decod variant', u'fcn deconvnet', u'fcn deconvnet deconvnet', u'fcn deeplablargfov', u'fcn deeplablargfov deconvnet', u'fcn did', u'fcn did improv', u'fcn dilat', u'fcn dilat network', u'fcn fcn', u'fcn fcn deconvnet', u'fcn fcn fcn', u'fcn fcn learn', u'fcn fcn-basic', u'fcn fcn-basic decodingon', u'fcn fcn-basic decodingtechniqu', u'fcn henc', u'fcn henc propos', u'fcn improv', u'fcn improv furtherbi', u'fcn improv furtherth', u'fcn k', u'fcn k channel', u'fcn known', u'fcn known deeplab-largefov', u'fcn learn', u'fcn learn deconv', u'fcn learnt', u'fcn learnt deconv', u'fcn learnt deconvolut', u'fcn learnt deconvolutionalthough', u'fcn learnt deconvolutioni', u'fcn model', u'fcn model isdimension', u'fcn model istechniqu', u'fcn model learn', u'fcn order', u'fcn order conveyconvolut', u'fcn order conveyth', u'fcn recurr', u'fcn recurr neural', u'fcn seen', u'fcn seen comput', u'fcn theyshow', u'fcn theyshow signific', u'fcn theywhil', u'fcn theywhil exploit', u'fcn train', u'fcn train use', u'fcn upsampl', u'fcn upsampl learn', u'fcn use', u'fcn use support', u'fcn variant', u'fcn variant poorer', u'fcn withevid', u'fcn withevid gather', u'fcn withsegnet-typ', u'fcn withsegnet-typ decod', u'fcn,72', u'fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010', u'fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010 4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob', u'fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010 4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob avgglob', u'fcn-16s', u'fcn-16s rgb-hha', u'fcn-16s rgb-hha fcn-16s', u'fcn-32s', u'fcn-32s rgb', u'fcn-32s rgb fcn-32s', u'fcn-32s rgb-d', u'fcn-32s rgb-d fcn-32s', u'fcn-8', u'fcn-8 fcn-8', u'fcn-8 main', u'fcn-8 main advantag', u'fcn-8 thatshow', u'fcn-8 thatshow signific', u'fcn-8 thatthi', u'fcn-8 thatthi differ', u'fcn-basic', u'fcn-basic better', u'fcn-basic better thebalanc', u'fcn-basic better thelarg', u'fcn-basic decodingon', u'fcn-basic decodingon right', u'fcn-basic decodingtechniqu', u'fcn-basic decodingtechniqu import', u'fcn-basic endow', u'fcn-basic endow flexibilityand', u'fcn-basic endow flexibilitynetwork', u'fcn-basic final', u'fcn-basic final encod', u'fcn-basic forand', u'fcn-basic forand henc', u'fcn-basic forth', u'fcn-basic forth number', u'fcn-basic infer', u'fcn-basic infer time', u'fcn-basic isconvolut', u'fcn-basic isconvolut decod', u'fcn-basic isfast', u'fcn-basic isfast dure', u'fcn-basic model', u'fcn-basic model lead', u'fcn-basic requir', u'fcn-basic requir onli', u'fcn-basic segnet-bas', u'fcn-basic segnet-bas segnet-basic-encoderaddit', u'fcn-basic store', u'fcn-basic store encod', u'fcn-basic thatboth', u'fcn-basic thatboth perform', u'fcn-basic thatwhen', u'fcn-basic thatwhen compar', u'fcn-basic use', u'fcn-basic use dimension', u'fcn-basic variant', u'fcn-basic variant high', u'fcn-basic variant learningdecod', u'fcn-basic variant learningus', u'fcn-basic variantanoth', u'fcn-basic variantanoth memori', u'fcn-basic variantimpli', u'fcn-basic variantimpli unlik', u'fcn-basic vitali', u'fcn-basic vitali lower', u'fcn-basic vitalto', u'fcn-basic vitalto captur', u'fcn-basic-noaddit', u'fcn-basic-noaddit addit', u'fcn-basic-noaddit addit abov', u'fcn-basic-noaddit insegnet-bas', u'fcn-basic-noaddit insegnet-bas similar', u'fcn-basic-noaddit interm', u'fcn-basic-noaddit interm decod', u'fcn-basic-noaddit onli', u'fcn-basic-noaddit onli learn', u'fcn-basic-noaddition-nodimreduct', u'fcn-basic-noaddition-nodimreduct bigger', u'fcn-basic-noaddition-nodimreduct bigger butlarg', u'fcn-basic-noaddition-nodimreduct bigger butless', u'fcn-basic-noaddition-nodimreductionmodel', u'fcn-basic-noaddition-nodimreductionmodel slight', u'fcn-basic-noaddition-nodimreductionmodel slight larger', u'fcn-basic-noaddition-nodimreductionth', u'fcn-basic-noaddition-nodimreductionth size', u'fcn-basic-noaddition-nodimreductionth size fcn-basic-noaddition-nodimreductionmodel', u'fcn-basic-noaddition-nodimreductionth size fcn-basic-noaddition-nodimreductionth', u'fcn-basic-noadditioni', u'fcn-basic-noadditioni lower', u'fcn-basic-noadditioni lower compar', u'fcn-basic-noadditionlearn', u'fcn-basic-noadditionlearn perform', u'fcn-basic-noadditionlearn perform deconvolut', u'fcn-basic-noadditionor', u'fcn-basic-noadditionor upsampl', u'fcn-basic-noadditionor upsampl convolv', u'fcn-basic-noadditionto', u'fcn-basic-noadditionto larger', u'fcn-basic-noadditionto larger decod', u'fcn-basic-nodimreduct', u'fcn-basic-nodimreduct segnet-encoderaddit', u'fcn-basic-nodimreduct segnet-encoderaddit area', u'fcn-basic-nodimreduct segnet-encoderaddit areboth', u'fcn-basic-nodimreduct segnetencoderaddit', u'fcn-basic-nodimreduct segnetencoderaddit perform', u'fcn-basicfcn-basicfcn-basic0', u'fcn-basicfcn-basicfcn-basic065065065065065111111242', u'fcn-basicfcn-basicfcn-basic065065065065065111111242 507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238', u'fcn-basicfcn-basicfcn-basic065065065065065111111242 507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238 576fcn-basic-nodimreductionfcn-basic-nodimreductionfcn-basic-nodimreduction162516251625162516251625646464448', u'fcn-basicmodel', u'fcn-basicmodel discard', u'fcn-basicmodel discard encod', u'fcn-basicnoaddit', u'fcn-basicnoaddit segnet-basic-singlechanneldecod', u'fcn-basicnoaddit segnet-basic-singlechanneldecod thatanoth', u'fcn-basicnoaddit segnet-basic-singlechanneldecod thatus', u'fcn-basicnoadditionth', u'fcn-basicnoadditionth reason', u'fcn-basicnoadditionth reason whi', u'fcn-basicnoadditionth size', u'fcn-basicnoadditionth size fcn-basic-noaddition-nodimreductionth', u'fcn-basicpool', u'fcn-basicpool window', u'fcn-basicpool window creat', u'fcn8', u'fcn8 fact', u'fcn8 fact joint', u'fcnbasic-nodimreduct', u'fcnbasic-nodimreductionanoth', u'fcnbasic-nodimreductionanoth comparison', u'fcnbasic-nodimreductionanoth comparison fcn-basicnoaddit', u'fcnbasic-nodimreductiontrain', u'fcnbasic-nodimreductiontrain accuraci', u'fcnbasic-nodimreductiontrain accuraci compar', u'fcncompetit', u'fcncompetit accuraci', u'fcncompetit accuraci method', u'fcndropout', u'fcndropout sampl', u'fcnmax-pool', u'fcnmax-pool layer', u'fcnmax-pool layer includ', u'fcnmedian', u'fcnmedian frequenc', u'fcnmedian frequenc balancingmedian', u'feasibl', u'feasibl train', u'feasibl train seg-net', u'feasibl train seg-train', u'featur', u'featur ablat', u'featur ablat studi', u'featur accur', u'featur accur pixel-wis', u'featur activ', u'featur activ 4each', u'featur activ 4of', u'featur activ base', u'featur activ consid', u'featur activ fewer', u'featur activ layer', u'featur activ mappedback', u'featur activ mappedtrain', u'featur activ miss', u'featur activ s', u'featur activ therefor', u'featur activ use', u'featur activatedlayerlayerlayerlayerlayerlayeral', u'featur activatedlayerlayerlayerlayerlayerlayeral featuresal', u'featur activatedon', u'featur activatedon featur', u'featur activations/mapsfor', u'featur activations/mapsfor given', u'featur activations/mapsfor sampl', u'featur base', u'featur base appear', u'featur base appearanceforest', u'featur base appearanceth', u'featur block', u'featur block matchbi', u'featur block matchimag', u'featur butalreadi', u'featur butalreadi improv', u'featur buttheir', u'featur buttheir abil', u'featur classif', u'featur classif rgb', u'featur classifi', u'featur classifi pixel', u'featur classificationindoor', u'featur classificationindoor rgbd', u'featur classificationne', u'featur classificationne improv', u'featur connect', u'featur connect decod', u'featur consist', u'featur consist acrossth', u'featur consist acrossthi', u'featur e', u'featur embed', u'featur embed proceed', u'featur encod', u'featur encod employ', u'featur engin', u'featur engin base', u'featur extract', u'featur extract edg', u'featur extract multipl', u'featur extract network', u'featur featur', u'featur featur featur', u'featur featur work', u'featur form', u'featur form deeper', u'featur hierarchi', u'featur hierarchi applic', u'featur hierarchi main', u'featur hierarchi similar', u'featur hierarchi visualand', u'featur hierarchi visualrecognit', u'featur imag', u'featur imag dimens', u'featur input', u'featur input decod', u'featur input imag', u'featur input resolutionfor', u'featur input resolutionfrom', u'featur layer', u'featur layer remain', u'featur layer train', u'featur learn', u'featur learn approach', u'featur learn architectur', u'featur learn capabl', u'featur learn map', u'featur learn puriti', u'featur learn reusingmax-pool', u'featur learn reusingtheir', u'featur learn use', u'featur learningarchitectur', u'featur learningarchitectur propos', u'featur learningour', u'featur learningour work', u'featur map', u'featur map add', u'featur map addit', u'featur map address', u'featur map althoughit', u'featur map althoughth', u'featur map aresimpli', u'featur map arethen', u'featur map arew', u'featur map arewith', u'featur map better', u'featur map central', u'featur map compar', u'featur map consum', u'featur map convolv', u'featur map cost', u'featur map decod', u'featur map deepest', u'featur map differentat', u'featur map differentlay', u'featur map dimensionalityreduct', u'featur map dimensionalitywhen', u'featur map direct', u'featur map fcn-basic', u'featur map fed', u'featur map final', u'featur map foreach', u'featur map formax-pool', u'featur map idea', u'featur map increas', u'featur map input', u'featur map is1/8th', u'featur map isimpli', u'featur map islay', u'featur map isnot', u'featur map layer', u'featur map max-pool', u'featur map output', u'featur map perform', u'featur map performbest', u'featur map performencod', u'featur map pool', u'featur map principl', u'featur map produc', u'featur map requir', u'featur map s', u'featur map sames', u'featur map sameth', u'featur map sampl', u'featur map segnet', u'featur map semant', u'featur map sever', u'featur map smaller', u'featur map subsampl', u'featur map thedecod', u'featur map theear', u'featur map theloc', u'featur map thesam', u'featur map thiscompress', u'featur map thisdimension', u'featur map tocombin', u'featur map tomatch', u'featur map toproduc', u'featur map trace', u'featur map turn', u'featur map upsampl', u'featur map use', u'featur map variant', u'featur mapadditional/deep', u'featur mapadditional/deep encoder-decod', u'featur mapalthough', u'featur mapalthough encod', u'featur mapencod', u'featur mapencod featur', u'featur mapresolut', u'featur mapresolut smaller', u'featur mapsa', u'featur mapsa batch', u'featur mapsa trainabl', u'featur mapsand', u'featur mapsand store', u'featur mapsbefor', u'featur mapsbefor sub-sampl', u'featur mapsdur', u'featur mapsdur infer', u'featur mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig', u'featur mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig illustr', u'featur mapsfor', u'featur mapsfor better', u'featur mapsth', u'featur mapsth fcn', u'featur mapsto', u'featur mapsto captur', u'featur mapto', u'featur mapto input', u'featur n', u'featur n activ', u'featur perform', u'featur perform use', u'featur pixel', u'featur pixel classif', u'featur pixel classificationeach', u'featur pixel classificationmulti-dimension', u'featur pixel-wis', u'featur pixel-wis classifict', u'featur predict', u'featur predict entir', u'featur recognit', u'featur recognit success', u'featur replic', u'featur replic result', u'featur represent', u'featur represent fed', u'featur represent output', u'featur represent power', u'featur result', u'featur result predict', u'featur rgb-sift', u'featur rgb-sift depth-sift', u'featur rgb-sift segment', u'featur scene', u'featur scene label', u'featur segment', u'featur segment therefor', u'featur segnet', u'featur segnet column', u'featur set', u'featur set includ', u'featur size', u'featur size of64', u'featur size offor', u'featur spatiocombin', u'featur spatiocombin popular', u'featur spatiotempor', u'featur spatiotempor super-pixel', u'featur thedeep', u'featur thedeep layer', u'featur thefor', u'featur thefor shallow', u'featur train', u'featur train discard', u'featur tune', u'featur tune group', u'featur upsampl', u'featur upsampl learn', u'featur valu', u'featur valu poolingi', u'featur valu poolingwindow', u'featur wereactiv', u'featur wereactiv studyactiv', u'featur werenon-zero', u'featur werenon-zero bin', u'featur work', u'featur work inspir', u'featur work zeiler', u'feature-map', u'feature-map isa', u'feature-map isa spatial', u'feature-map isbacktrack', u'feature-map isbacktrack input', u'featureclass', u'featureclass compress', u'featureclass compress k', u'featureextract', u'featureextract append', u'featureextract append crf', u'featurefrom', u'featurefrom train', u'featurefrom train relat', u'featurehierarchi', u'featurehierarchi visual', u'featurehierarchi visual recognit', u'featurei', u'featurei expens', u'featurei expens multipl', u'featurem', u'featurem mathieu', u'featurem mathieu y', u'featuremap', u'featuremap certain', u'featuremap certain lead', u'featuremap classif', u'featuremap classif network', u'featuremap decod', u'featuremap decod make', u'featuremap fcn', u'featuremap fcn k', u'featuremap input', u'featuremap input decod', u'featuremap pixel-wis', u'featuremap pixel-wis classif', u'featuremap store', u'featuremap store reflect', u'featuremap use', u'featuremap use alreadi', u'featurepass', u'featurepass decod', u'featurepass decod decod', u'featureperform', u'featureperform improv', u'featureperform improv method', u'features100', u'features100 activated100', u'features100 activated100 activated100', u'featuresal', u'featuresal featuresal', u'featuresal featuresal featuresal', u'featuresal featuresal featurestop', u'featuresal featurestop', u'featuresal featurestop featurestop', u'featuresboost', u'featuresboost withboost', u'featuresboost withboost withboost', u'featurescrf', u'featurescrf segnet', u'featurescrf segnet maintain', u'featuresdataset', u'featuresdataset use', u'featuresdataset use depth', u'featuresfor', u'featuresfor pixel-wis', u'featuresfor pixel-wis classif', u'featuresin', u'featuresin accuraci', u'featuresin accuraci come', u'featuresin block', u'featuresin block match', u'featuresmatch', u'featuresmatch input', u'featuresmatch input imag', u'featuresor', u'featuresor modal', u'featuresor modal classifi', u'featuresp', u'featuresp layer', u'featuresp layer typic', u'featuressuch', u'featuressuch rgb-sift', u'featuressuch rgb-sift depth-sift', u'featurestexton', u'featurestexton featuresboost', u'featurestexton featuresboost withboost', u'featurestexton featurestexton', u'featurestexton featurestexton featuresboost', u'featurestexton featurestexton featurestexton', u'featuresto', u'featuresto appli', u'featuresto appli network', u'featurestop', u'featurestop decod', u'featurestop decod ignor', u'featurestop features100', u'featurestop features100 activated100', u'featurestop featurestop', u'featurestop featurestop features100', u'featurestop featurestop featurestop', u'featureswhich', u'featureswhich use', u'featureswhich use accur', u'featureswithin', u'featureswithin block', u'featureswithin block pixel', u'featureth', u'featureth best', u'featureth best perform', u'featureupsampl', u'featureupsampl densifi', u'featureupsampl densifi featur', u'featurevgg16', u'featurevgg16 network', u'featurevgg16 network role', u'fed', u'fed classifi', u'fed classifi e', u'fed classifi randomfeatur', u'fed classifi randomforest', u'fed classifi randomr', u'fed multi-classha', u'fed multi-classha layer', u'fed multi-classsoft-max', u'fed multi-classsoft-max classifi', u'fed soft-max', u'fed soft-max classifi', u'fed trainabl', u'fed trainabl soft-max', u'feed', u'feed soft-maxclassif', u'feed soft-maxclassif layer', u'feed soft-maxcorrespond', u'feed soft-maxcorrespond decod', u'feed-forward', u'feed-forward infer', u'feed-forward infer time', u'feed-forward manner', u'feed-forward manner pixel-wis', u'feed-forward represent', u'feed-forward represent requir', u'feed-forward segment', u'feed-forward segment engin', u'feed-forward testand', u'feed-forward testand joint', u'feed-forward testtim', u'feed-forward testtim requir', u'feed-forwardsegment', u'feed-forwardsegment engin', u'feed-forwardsegment engin segnet', u'feed-forwardto', u'feed-forwardto lack', u'feed-forwardto lack good', u'feedback', u'feedback convolut', u'feedback convolut deep', u'feedforwardi', u'feedforwardi spent', u'feedforwardi spent perform', u'feedforwardpath', u'feedforwardpath fft', u'feedforwardpath fft base', u'feel', u'feel attent', u'feel attent hasbeen', u'feel attent hasfrom', u'fei-fei', u'fei-fei journal', u'fei-fei journal comput', u'fei-fei karpathi', u'fei-fei karpathi khosla', u'fellow', u'fellow jesus', u'fellow jesus colleg', u'fellow royal', u'fellow royal academi', u'fenceclass', u'fenceclass resembl', u'fenceclass resembl build', u'fenceperform', u'fenceperform better', u'fenceperform better global', u'fergus', u'fergus intrigu', u'fergus intrigu properti', u'fergus \\u201cpredict', u'fergus \\u201cpredict depth', u'fewer', u'fewer fcn-basic', u'fewer fcn-basic use', u'fewer featur', u'fewer featur activ', u'fewer featur map', u'fewer morefin', u'fewer morefin tune', u'fewer morewith', u'fewer morewith sidewalk', u'ff11i', u'ff11i ntroductioni', u'ff11i ntroductioni ntroductioni', u'fft', u'fft base', u'fft base convolut', u'field', u'field recurr', u'field recurr neural', u'field recurr neuralc', u'field recurr neuralnetwork', u'fig', u'fig 1are', u'fig 1are shown', u'fig 1the', u'fig 1the remaind', u'fig 3top', u'fig 3top n', u'fig 3we', u'fig 3we observ', u'fig decod', u'fig decod techniqu', u'fig demonstr', u'fig demonstr segnet', u'fig encod', u'fig encod network', u'fig encod perform', u'fig exampl', u'fig exampl testfor', u'fig exampl testresult', u'fig fcn', u'fig fcn fcn-basic', u'fig featur', u'fig featur map', u'fig goodin', u'fig goodin scenario', u'fig goodperform', u'fig goodperform camvid', u'fig high', u'fig high dimension', u'fig observerec', u'fig observerec sun', u'fig observesom', u'fig observesom scene', u'fig predict', u'fig predict arelarg', u'fig predict areth', u'fig qualit', u'fig qualit assess', u'fig qualit resultsdeep', u'fig qualit resultsshow', u'fig result', u'fig result camvid', u'fig segnetmeet', u'fig segnetmeet room', u'fig segnetobtain', u'fig segnetobtain reason', u'fig thedusk', u'fig thedusk poor', u'fig thequalit', u'fig thequalit result', u'fig train', u'fig train weight', u'fig use', u'fig use decodersfcn', u'fig use decoderson', u'fig use segmentdecor', u'fig use segmentof', u'fig use structur', u'figur', u'figur bayesian', u'figur bayesian segnet', u'figur qualit', u'figur qualit perform', u'figur softmax', u'figur softmax regress', u'figur strong', u'figur strong invers', u'fill-in', u'fill-in missingcurr', u'fill-in missingcurr camera', u'fill-in missingdepth', u'fill-in missingdepth measur', u'fill-in missingmeasur', u'fill-in missingmeasur requir', u'fill-in missingmodif', u'fill-in missingmodif care', u'filledand', u'filledand class', u'filledand class car', u'filledwith', u'filledwith sidewalk', u'filledwith sidewalk reason', u'filter', u'filter alsofilt', u'filter alsofilt pair', u'filter alsounti', u'filter alsounti provid', u'filter bank', u'filter bank convolut', u'filter bank element-wis', u'filter bank fcn', u'filter bank produc', u'filter bank reconstructswitch', u'filter bank reconstructth', u'filter bank reludecod', u'filter bank relunon-linear', u'filter bankinput', u'filter bankinput use', u'filter bankit', u'filter bankit perform', u'filter bankpervis', u'filter bankpervis manner', u'filter bankto', u'filter bankto densifi', u'filter densifi', u'filter densifi sparseinput', u'filter densifi sparsewith', u'filter fcn', u'filter fcnmax-pool', u'filter fcnmax-pool layer', u'filter fcnmedian', u'filter fcnmedian frequenc', u'filter k', u'filter k number', u'filter number', u'filter number channel', u'filter perform', u'filter perform afterconvolut', u'filter perform afterupsampl', u'filter produc', u'filter produc dens', u'filter singl', u'filter singl channel', u'filter upsampl', u'filter upsampl segnet-bas', u\"filter'sa\", u\"filter'sa bernoulli\", u\"filter'sa bernoulli distribut\", u\"filter'sweight\", u\"filter'sweight requir\", u\"filter'sweight requir ani\", u'filterbank', u'filterbank reconstruct', u'filterbank reconstruct input', u'filterconvolv', u'filterconvolv upsampl', u'filterconvolv upsampl map', u'filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor', u'filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor upsamplingfor', u'filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor upsamplingfor upsamplingfor', u'filtersconvolut', u'filtersconvolut trainabl', u'filtersconvolut trainabl decod', u'final', u'final decod', u'final decod output', u'final down-sampl', u'final down-sampl eachdecod', u'final down-sampl eachi', u'final encod', u'final encod featur', u'final encod layer', u'final encoderfeatur', u'final encoderfeatur map', u'final encodermodel', u'final encodermodel slight', u'final layer', u'final layer soft-max', u'final pascal', u'final pascal voc', u'final pixelwis', u'final pixelwis classif', u'final pleas', u'final pleas note', u'final predict', u'final predict resolut', u'final section', u'finaldecod', u'finaldecod fed', u'finaldecod fed trainabl', u'finalhigh', u'finalhigh dimension', u'finalhigh dimension featur', u'finda', u'finda larger', u'finda larger perform', u'findth', u'findth best', u'findth best perform', u'fine', u'fine grainedcontour', u'fine grainedcontour inform', u'fine grainedfeatur', u'fine grainedfeatur map', u'fine tune', u'fine tune activ', u'fine-grain', u'fine-grain local', u'fine-grain local cvpr', u'fisher', u'fisher scholarship', u'fisher scholarship studi', u'fit', u'fit column', u'fit column wise', u'fit poorer', u'fit poorer test', u'fix', u'fix andconvolut', u'fix andconvolut trainabl', u'fix andsimpli', u'fix andsimpli upsampl', u'fix bi-linear', u'fix bi-linear interpol', u'fix bilinear', u'fix bilinear upsampl', u'fix deeper', u'fix deeper pair', u'fix experi', u'fix experi introduc', u'fix learn', u'fix learn rate', u'fix learn rateof', u'fix learn rateus', u'fix noteth', u'fix noteth shallow', u'fix notethat', u'fix notethat object', u'fix pool', u'fix pool window', u'fix themodel', u'fix themodel gaussian', u'fix thestandard', u'fix thestandard probabl', u'fix trainabl', u'fix trainabl multi-channel', u'fj', u'fj jnni', u'fj jnni given', u'flexibilityand', u'flexibilityand henc', u'flexibilityand henc achiev', u'flexibilitynetwork', u'flexibilitynetwork fcn-basic', u'flexibilitynetwork fcn-basic endow', u'float', u'float point', u'float point precis', u'float precis', u'float precis later', u'floor', u'floor ceil', u'floor ceil tabl', u'floor ceil table,37', u'focus', u'focus layer-wis', u'focus layer-wis featur', u'focus real-tim', u'focus real-tim joint', u'focus studi', u'focus studi predict', u'follow', u'follow acorrespond', u'follow acorrespond decod', u'follow asegnet', u'follow asegnet compos', u'follow batch', u'follow batch normal', u'follow byand', u'follow byand support', u'follow bysegment', u'follow bysegment obtain', u'follow convolut', u'follow convolut layer', u'follow convolut step', u'follow correspond', u'follow correspond decod', u'follow crf', u'follow crf recent', u'follow encod', u'follow encod unit', u'follow final', u'follow final pixelwis', u'follow general', u'follow general discuss', u'follow max-pool', u'follow max-pool window', u'follow non-linear', u'follow non-linear pool', u'follow non-overlap', u'follow non-overlap maxpool', u'follow pixelwis', u'follow pixelwis classifi', u'follow sec2', u'follow sec2 review', u'follow secth', u'follow secth remaind', u'follow sub-sampl', u'follow sub-sampl obtain', u'follow success', u'follow success object', u'follow upsampl', u'follow upsampl layer', u'followedbi', u'followedbi pixel-wis', u'followedbi pixel-wis classif', u'followedterm', u'followedterm segnet', u'followedterm segnet core', u'followinggener', u'followinggener point', u'followinggener pointsgener', u'followinggener pointsgener pointsgener', u'followingw', u'followingw summar', u'followingw summar abov', u'footnot', u'footnot road', u'footnot road scene', u'fora', u'fora number', u'fora number outdoor', u'foraddit', u'foraddit tabl', u'foraddit tabl segment', u'foralso', u'foralso observ', u'foralso observ signific', u'forand', u'forand henc', u'forand henc achiev', u'forautonom', u'forautonom drive', u'forbank', u'forbank reconstruct', u'forbank reconstruct input', u'forbatch', u'forbatch normal', u'forbatch normal layer', u'forbeen', u'forbeen paid', u'forbeen paid smaller', u'forcan', u'forcan introduc', u'forcan introduc increas', u'forcan trust', u'forcan trust semant', u'forclear', u'forclear interpret', u'forclear interpret note', u'forcomput', u'forcomput parallel', u'forcomput parallel gpu', u'fordecis', u'fordecis make', u'fordeeplab-largefov', u'fordeeplab-largefov chang', u'fordeeplab-largefov chang max', u'foreach', u'foreach sampl', u'foreach sampl indic', u'foregroundclass', u'foregroundclass surround', u'foregroundclass surround high', u'foregroundhowev', u'foregroundhowev major', u'foregroundhowev major task', u'forest', u'forest anoth', u'forest anoth approachargu', u'forest anoth approachfor', u'forest available51', u'forest available514', u'forest available514 725neural', u'forest availablenot', u'forest availablenot availablenot', u'forest availablestructur', u'forest availablestructur random', u'forest base', u'forest base unari', u'forest basedpixel', u'forest basedpixel improv', u'forest basedunari', u'forest basedunari structur', u'forest boost', u'forest boost combin', u'forest imag', u'forest imag categor', u'forest local', u'forest local label', u'forest neural', u'forest neural decis', u'forest semant', u'forest semant imag', u'forest semant imagelabel', u'forest semant imagestructur', u'forest structur', u'forest structur random', u'forest use', u'forest use benchmark', u'forest use classifierfocuss', u'forest use classifiergroup', u'forest use classifiersegment', u'forest use classifierth', u'forest withrandom', u'forest withrandom forest', u'forest withsfmsfmsfmsfmtexton', u'forest withsfmsfmsfmsfmtexton featurestexton', u'forestbas', u'forestbas classifi', u'foresttextonboost', u'foresttextonboost textonforest', u'foresttextonboost textonforest random', u'foreveri', u'foreveri k', u'foreveri k k', u'forfast', u'forfast featur', u'forfast featur embed', u'forh', u'forh noh', u'forh noh s', u'forher', u'forher approxim', u'forher approxim variat', u'forind', u'forind architectur', u'forind architectur potenti', u'forj', u'forj long', u'forj long e', u'fork', u'fork simonyan', u'fork simonyan zisserman', u'forlarge-scal', u'forlarge-scal imag', u'forlarge-scal imag recognit', u'form', u'form decoderencod', u'form decoderencod network', u'form decodernetwork', u'form decodernetwork choos', u'form deeper', u'form deeper layer', u'form encod', u'form encod featur', u'form ensembl', u'form ensembl of3433', u'form ensembl ofw', u'form probabilist', u'form probabilist encoderdecod', u'formanc', u'formax-pool', u'formax-pool sub-sampl', u'formax-pool sub-sampl obtain', u'formident', u'formident encod', u'formident encod network', u'formof', u'formof decod', u'formof decod network', u'formula', u'formula propos', u'formula propos eigen', u'fornon-uniform', u'fornon-uniform scene', u'fornon-uniform scene illumin', u'foror', u'foror sfm', u'foror sfm appear', u'forpixel', u'forpixel label', u'forpixel label result', u'forpract', u'forpract applic', u'forreal-tim', u'forreal-tim applic', u'forreal-tim applic road', u'forroad', u'forroad scene', u'forroad scene understand', u'forsegnet', u'forsemant', u'forsemant pars', u'forsemant pars chosesemant', u'forsemant segment', u'forsemant segment cvpr', u'forsemant segment iccv', u'forshallow', u'forshallow layer', u'forshallow layer produc', u'forsmal', u'forsmal dataset', u'forsmal dataset model', u'fortest', u'fortest sampl', u'fortest sampl test', u'forth', u'forth advantag', u'forth advantag step', u'forth camvid', u'forth camvid road', u'forth number', u'forth number iter', u'fortrain', u'fortrain network', u'fortrain network loss', u'forunsupervis', u'forunsupervis pre-train', u'forunsupervis pre-train classif', u'forvari', u'forvari level', u'forvari level confid', u'forvisu', u'forvisu scene', u'forvisu scene understand', u'forw', u'forw use', u'forw use cross-entropi', u'forward', u'forward evaluationof', u'forward evaluationof fulli', u'forward evaluationw', u'forward evaluationw propos', u'forward pass', u'forward pass anoth', u'forward pass caffeimplement', u'forward pass caffew', u'forward pass ms', u'forward-backward', u'forward-backward pass', u'forward-backward pass time', u'foundthi', u'foundthi qualit', u'foundthi qualit produc', u'foundwhich', u'foundwhich agre', u'foundwhich agre class', u'fourcamvid', u'fourcamvid dataset', u'fourvari', u'fourvari produc', u'fourvari produc similar', u'fov', u'fov smallest', u'fov smallest effici', u'fraction', u'fraction featur', u'fraction featur activ', u'frame', u'frame post-process', u'frame post-process withcrf', u'frame post-process withcu', u'frame titan', u'frame titan x', u'frameand', u'frameand bayesian', u'frameand bayesian segnet', u'framefor', u'framefor sampl', u'framefor sampl fig', u'framesmeasur', u'framesmeasur requir', u'framesmeasur requir use', u'framesto', u'framesto robust', u'framesto robust extract', u'framework', u'framework methodleverag', u'framework methodleverag bayesian', u'framework methodobtain', u'framework methodobtain improv', u'framework pixel-wis', u'framework pixel-wis semant', u'framework probabilisticpixel-wis', u'framework probabilisticpixel-wis semant', u'framework probabilisticw', u'framework probabilisticw present', u'framework result', u'framework result techniqu', u'framework semant', u'framework semant segment', u'franc', u'franc senior', u'franc senior post-doctor', u'frank', u'frank s', u'frank s roth', u'freedom', u'freedom minimizeth', u'freedom minimizeth object', u'freedom minimizeunti', u'freedom minimizeunti provid', u'freng', u'freng in2010', u'freng in2010 research', u'freng inh', u'freng inh becam', u'frequenc', u'frequenc areoth', u'frequenc areoth dataset', u'frequenc arestil', u'frequenc arestil imag', u'frequenc atmodel', u'frequenc atmodel uncertainti', u'frequenc atwhich', u'frequenc atwhich class', u'frequenc balanc', u'frequenc balanc thebalanc', u'frequenc balanc theweight', u'frequenc balanc webenchmark', u'frequenc balanc wemodel', u'frequenc balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto', u'frequenc balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto compar', u'frequenc balancingequival', u'frequenc balancingequival use', u'frequenc balancingmedian', u'frequenc balancingmedian frequenc', u'frequenc balancingnatur', u'frequenc balancingnatur frequenc', u'frequenc balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam', u'frequenc balancingstoragestoragestoragestoragestoragestoragestoragestorageinferinferinferinferinferinfertesttesttesttesttesttraintraintraintraintraintraintesttesttesttesttesttraintraintraintraintraintrainvariantvariantvariantvariantvariantvariantvariantvariantparam m', u'frequenc bycombin', u'frequenc bycombin object', u'frequenc bytest', u'frequenc bytest address', u'frequenc canno', u'frequenc canno class', u'frequenc canobserv', u'frequenc canobserv weight', u'frequenc class', u'frequenc class balanc', u'frequenc class dataset', u'frequenc comput', u'frequenc comput entir', u'frequenc exist', u'frequenc existbut', u'frequenc existbut equal', u'frequenc existmeanwhil', u'frequenc existmeanwhil indoor', u'frequenc impli', u'frequenc impli larger', u'frequenc larg', u'frequenc larg imbal', u'frequenc lead', u'frequenc lead toear', u'frequenc lead tosharp', u'frequenc median', u'frequenc median frequencybalanc', u'frequenc median frequencysemant', u'frequenc road', u'frequenc road sky', u'frequenc usingaddit', u'frequenc usingaddit train', u'frequenc usingaddress', u'frequenc usingaddress imbal', u'frequencybalanc', u'frequencybalanc includ', u'frequencybalanc includ trend', u'frequencybalanc train', u'frequencybalanc train loss', u'frequencybuild', u'frequencybuild pixel', u'frequencybuild pixel apart', u'frequencyclass', u'frequencyclass balanc', u'frequencyclass balanc metric', u'frequencyclass balanc use', u'frequencyfollow', u'frequencyfollow train', u'frequencyfollow train segnet', u'frequencyor', u'frequencyor ani', u'frequencyor ani learn', u'frequencysemant', u'frequencysemant contour', u'frequencysemant contour measur', u'frequencystand', u'frequencystand alon', u'frequencystand alon experi', u'frequencyweight', u'frequencyweight class', u'frequencyweight class correct', u'frequent', u'frequent partial', u'frequent partial occlus', u'froma', u'froma car', u'froma car easier', u'fromalex', u'fromalex kendal', u'fromalex kendal graduat', u'fromand', u'fromand depth', u'fromand depth map', u'fromappropri', u'fromappropri decod', u'fromappropri decod use', u'fromchalleng', u'fromchalleng benchmark', u'fromchalleng benchmark unfortun', u'fromclassif', u'fromclassif therefor', u'fromclassif therefor initi', u'fromcurr', u'fromcurr camera', u'fromcurr camera requir', u'fromdecod', u'fromdecod encod', u'fromdecod encod train', u'fromdeep', u'fromdeep segment', u'fromdeep segment architectur', u'fromgoogl', u'fromgoogl indoor', u'fromgoogl indoor test', u'fromin', u'fromin m', u'fromin mse', u'fromin mse electr', u'frominria', u'frominria renn', u'frominria renn franc', u'frominterest', u'frominterest estim', u'frominterest estim model', u'fromlow', u'fromlow resolut', u'fromlow resolut featur', u'frommodifications/redesign', u'frommodifications/redesign qualiti', u'frommodifications/redesign qualiti depth', u'fromregion', u'fromregion accuraci', u'fromregion accuraci clear', u'fromresult', u'fromresult produc', u'fromresult produc random', u'fromrgb', u'fromrgb scene', u'fromrgb scene camvid', u'fromth', u'fromth correspond', u'fromth correspond encod', u'fromth nyu', u'fromth nyu dataset', u'fromth univers', u'fromth univers auckland', u'fromth univers pennsylvania', u'fromtheir', u'fromtheir quantit', u'fromtheir quantit result', u'fromthes', u'fromthes architectur', u'fromthes architectur deep', u'fromvijay', u'fromvijay badrinarayanan', u'fromvijay badrinarayanan obtain', u'fromweight', u'fromweight train', u'fromweight train classif', u'fuell', u'fuell challeng', u'fuell challeng dataset', u'fullclassif', u'fullclassif layer', u'fullclassif layer decod', u'fulli', u'fulli bayesian', u'fulli bayesian network', u'fulli connect', u'fulli connect crfs', u'fulli connect layer', u'fulli connnect', u'fulli connnect layer', u'fulli convolut', u'fulli convolut architectur', u'fulli convolut network', u'fulli convolut networkin', u'fulli convolut networktechniqu', u'fulli convolut neural', u'fulli learnt', u'fulli learnt function', u'fulli su-encoder-decod', u'fulli su-encoder-decod stack', u'fulli su-w', u'fulli su-w propos', u'fulli trainabl', u'fulli trainabl deep', u'fullinput', u'fullinput imag', u'fullinput imag size', u'fullyconnect', u'fullyconnect layer', u'fullyconnect layer vgg16', u'fullyconnect layersconnect', u'fullyconnect layersconnect layersconnect', u'fullyconvolut', u'fullyconvolut network', u'fullyconvolut network fcn', u'fullyof', u'fullyof segnet', u'fullyof segnet decod', u'fullyreport', u'fullyreport littl', u'fullyreport littl loss', u'fullyth', u'fullyth convolut', u'fullyth convolut layer', u'function', u'function approxim', u'function approxim relat', u'function confidencefor', u'function confidencefor 90th', u'function confidencet', u'function confidencet bayesian', u'function effect', u'function effect minimis', u'function fortrain', u'function fortrain network', u'function forw', u'function forw use', u'function max', u'function max pool', u'function obtain', u'function obtain smooth', u'function ratio', u'function ratio themedian', u'function ratio theweight', u'function segnet-bas', u'function segnet-bas perform', u'furnitur', u'furnitur wall', u'furnitur wall ceil', u'furnitur wall,654', u'furnitur wall,654 test', u'furtherbi', u'furtherbi append', u'furtherbi append fcn', u'furtherreduct', u'furtherreduct train', u'furtherreduct train loss', u'furtherth', u'furtherth network', u'furtherth network converg', u'furtherth predict', u'furtherth predict perform', u'fusion', u'fusion mani', u'fusion mani framesmeasur', u'fusion mani framesto', u'futur', u'futur addit', u'futur addit resultscan', u'futur addit resultsnyu', u'futur like', u'futur like exploit', u'futur work', u'futur work sec', u'futur workd', u'futur workd iscuss', u'futur workdeep', u'futur workdeep learn', u'futurescen', u'futurescen understand', u'futurescen understand dataset', u'futurework', u'futurework intend', u'futurework intend explor', u'g', u'g c', u'g c bf', u'g c miou', u'g c mioufix', u'g c miouparam', u'g class', u'g class averag', u'g measur', u'g measur percentag', u'g papandreou', u'g papandreou kokkino', u'g road', u'g road sky', u'gain', u'gain commensur', u'gain commensur withincreas', u'gain commensur withparticular', u'gain https', u'gain https //develop', u'gain https //developernvidia3', u'gain https //developernvidiacom/cudnncom/cudnncom/cudnncomput', u'gain insight', u'gain insight intoabout', u'gain insight intow', u'gain popular', u'gain popular sinc', u'gal', u'gal andghahramani', u'gal andghahramani link', u'gal andsampl', u'gal andsampl posterior', u'gal ghahramani', u'gal ghahramani cast', u'gather', u'gather analysi', u'gather analysi designmor', u'gather analysi designsegment', u'gather author', u'gather author compar', u'gather evid', u'gather evid true', u'gaussian', u'gaussian n', u'gaussian n normal', u'gaussian process', u'gear', u'gear technolog', u'gear technolog develop', u'general', u'general applic', u'general applic method', u'general applicability5', u'general applicabilityto', u'general applicabilityto demonstr', u'general discuss', u'general discuss regard', u'general observ', u'general observ high', u'general observ highgener', u'general observ highmodel', u'general point', u'general posterior', u'general posterior distribut', u'general unseen', u'general unseen imag', u'general use', u'general use per-pixel', u'generat', u'generat posterior', u'generat posterior distribut', u'generat probabilist', u'generat probabilist output', u'generic', u'generic variant', u'generic variant featur', u'geometr', u'geometr semant', u'geometr semant consist', u'geometri', u'geometri infer', u'geometri infer support-relationship', u'geometryand', u'geometryand object', u'geometryand object support', u'geometrysignific', u'geometrysignific pose', u'geometrysignific pose appear', u'getbacktrack', u'getbacktrack input', u'getbacktrack input imag', u'getsmooth', u'getsmooth layer', u'getsmooth layer ad', u'gettingcan', u'gettingcan therefor', u'gettingcan therefor consid', u'gettingsampl', u'gettingsampl posterior', u'gettingsampl posterior distribut', u'ghahramani', u'ghahramani cast', u'ghahramani cast dropout', u'given', u'given aacross', u'given aacross dataset', u'given analysisin', u'given analysisin sec', u'given analysisnetwork', u'given analysisnetwork train', u'given asmal', u'given asmal comput', u'given encoderlarg', u'given encoderlarg decod', u'given encodernetwork', u'given encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb', u'given encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb enchmarkingb', u'given input', u'given input sampl', u'given larg', u'given larg inferencegrid', u'given larg inferencetim', u'given layer', u'given layer assign', u'given layer comput', u'given pixel', u'given pixel toler', u'given standard', u'given standard gpu', u'given theand', u'given theand \\u201cfill', u'given thefeatur', u'given thefeatur s', u'givenfor', u'givenfor bayesian', u'givenfor bayesian segnet', u'givenour', u'givenour observ', u'givenour observ train', u'global', u'global accuraci', u'global accuraci addit', u'global accuraci correspond', u'global accuraci g', u'global accuraci global', u'global accuraci highest', u'global accuraci indic', u'global accuraci out-perform', u'global accuraci toresult', u'global accuraci toth', u'global accuracyi', u'global accuracyi highest', u'global accuracytrain', u'global accuracytrain set', u'global averag', u'global averag highest', u'global avg', u'global compar', u'global compar class', u'global context', u'global context use', u'global g', u'global g class', u'global segment', u'global segment accuraci', u'globaland', u'globaland class', u'globaland class averag', u'globaland miou', u'globaland miou improv', u'globalarchitectur', u'globalarchitectur share', u'globalarchitectur share low', u'globalth', u'globalth time', u'globalth time point', u'good', u'good architectur', u'good architectur segment', u'good decod', u'good decod techniqu', u'good improv', u'good improv class', u'good perform', u'good perform competit', u'good perform dataset', u'good perform larg', u'good perform therefor', u'good predict', u'good predict perform', u'good qualiti', u'good qualiti segment', u'good result', u'good result small', u'good segment', u'good segment perform', u'good segment performanceaccuraci', u'good segment performancesegnet', u'good segmentationand', u'good segmentationand high', u'good segmentationof', u'good segmentationof import', u'goodfellow', u'goodfellow r', u'goodfellow r fergus', u'goodin', u'goodin scenario', u'goodin scenario segnet', u'goodperform', u'goodperform camvid', u'goodperform camvid pre-train', u'googl', u'googl indoor', u'googl indoor test', u'gpu', u'gpu compat', u'gpu compat implement', u'gpu cost', u'gpu cost reduc', u'gpu cudnn', u'gpu cudnn v3', u'gpu infer', u'gpu infer memori', u'gpu reason', u'gpu reason time', u'gpu train', u'gpu train memori', u'gpu usag', u'gpu usag andavoid', u'gpu usag andw', u'gpu-acceler', u'gpu-acceler deep', u'gpu-acceler deep neural', u'gpu-cpu', u'gpu-cpu memori', u'gpu-cpu memori transfer', u'gpus', u'gpus initi', u'gpus initi weight', u'gpus makegeforc', u'gpus makegeforc 880m', u'gpus makeour', u'gpus makeour light-weight', u'gradient', u'gradient back-propag', u'gradient back-propag imperfect', u'gradient descent', u'gradient descent dropout', u'gradient descent encourag', u'gradient descent perform', u'gradient descent sgd', u'gradient descent witha', u'gradient descent withpropos', u'gradientan', u'gradientan effici', u'gradientan effici weight', u'gradientdesc', u'gradientdesc sgd', u'gradientdesc sgd addit', u'graduat', u'graduat bachelor', u'graduat bachelor engin', u'grainedcontour', u'grainedcontour inform', u'grainedcontour inform notic', u'grainedfeatur', u'grainedfeatur map', u'grainedfeatur map inform', u'grangier', u'graphic', u'graphic model', u'graphic model deep', u'grid', u'grid search', u'grid search base', u'grid-searchcrf', u'grid-searchcrf hyperparamet', u'grid-searchcrf hyperparamet obtain', u'grid-searchprocess', u'grid-searchprocess subset', u'grid-searchprocess subset train', u'ground', u'ground depth', u'ground depth normal', u'ground plane', u'ground plane detect', u'ground plane fit', u'ground truth', u'ground truth classand', u'ground truth classboundari', u'ground truth classedg', u'ground truth classresolut', u'ground truth databas', u'ground truth databaseclass', u'ground truth databaseprl', u'ground truth ground', u'ground truth label', u'ground truth public', u'ground truth segnet', u'ground truth shown', u'ground truth test', u'ground truthinput', u'ground truthinput abl', u'ground truthlabel', u'ground truthlabel shown', u'group', u'group relat', u'group relat categori', u'group relat categories4', u'group relat categoriesto', u'grow', u'grow semant', u'grow semant pixelwis', u'grown', u'grown untilad', u'grown untilad exist', u'grown untilno', u'grown untilno increas', u'growth', u'growth isno', u'growth isno increas', u'growth isstop', u'growth isstop decod', u'gtxgeforce780', u'gtxgeforce780 gpus', u'gtxgeforce780 gpus makegeforc', u'gtxgeforce780 gpus makeour', u'guadarrama', u'guadarrama t', u'guadarrama t darrel', u'gupta', u'gupta et', u'gupta et al', u'h', u'h schulz', u'h schulz s', u'h torr', u'h torr \\u201ccondit', u'half', u'half encod', u'half encod decod', u'han', u'han \\u201clearn', u'han \\u201clearn deconvolut', u'hand', u'hand alreadi', u'hand alreadi signific', u'hand design', u'hand design featur', u'hand designedargu', u'hand designedargu use', u'hand designedfeatur', u'hand designedfeatur spatio-tempor', u'hand effici', u'hand effici sinc', u'hand engin', u'hand engin featur', u'hand engineeredattribut', u'hand engineeredattribut approach', u'hand engineeredbest', u'hand engineeredbest perform', u'hand engineeredfeatur', u'hand engineeredfeatur classif', u'hand engineeredfeatur featur', u'hand engineeredfeatur general', u'hand engineeredpredict', u'hand engineeredpredict techniqu', u'hand optim', u'hand optim reconstruct', u'hand requir', u'hand requir neglig', u'hand use', u'hand use decod', u'hand use pre-train', u'hand-label', u'hand-label class', u'hand-label class infer', u'handa', u'handa r', u'handa r cipolla', u'handa roberto', u'handa roberto cipollamachin', u'handa roberto cipollavijay', u'handl', u'handl miss', u'handl miss data', u'handl new', u'handl new situat', u'handwritten', u'handwritten digit', u'handwritten digit recognit', u'hard', u'hard train', u'hard train end-to-end', u'hardbi', u'hardbi fact', u'hardbi fact object', u'hardchalleng', u'hardchalleng segnet', u'hardchalleng segnet predict', u'harder', u'harder challeng', u'harder challeng hope', u'harder train', u'harder train end-to-endin', u'harder train end-to-endmor', u'hardest', u'hardest challeng', u'hardest challeng segment', u'hardest segment', u'hardest segment challeng', u'hardest segmentationchalleng', u'hardest segmentationchalleng onli', u'hardest segmentationimag', u'hardest segmentationimag factor', u'hardfig', u'hardfig qualit', u'hardfig qualit assess', u'hardwal', u'hardwal floor', u'hardwal floor ceil', u'hardwar', u'hardwar resourc', u'hardwar resourc requir', u'hasa', u'hasa spatial', u'hasa spatial context', u'hasand', u'hasand non-overlap', u'hasand non-overlap max', u'hasbeen', u'hasbeen benchmark', u'hasbeen benchmark challeng', u'hasbeen paid', u'hasbeen paid smaller', u'hasbeen use', u'hasbeen use benchmark', u'hasceil', u'hasceil label', u'hasceil label comparison', u'hasfrom', u'hasfrom overal', u'hasfrom overal effici', u'hasrgb-d', u'hasrgb-d indoor', u'hasrgb-d indoor scene', u'havealso', u'havealso use', u'havealso use input', u'havebeen', u'havebeen hand-label', u'havebeen hand-label class', u'havedens', u'havedens depth', u'havedens depth map', u'haveident', u'haveident encod', u'haveident encod network', u'havemann', u'havemann train', u'havemann train mani', u'havescen', u'havescen dataset', u'havescen dataset recent', u'haveth', u'haveth practic', u'haveth practic trade-off', u'haveus', u'haveus host', u'haveus host support', u'he2010', u'he2010 research', u'he2010 research comput', u'hecurr', u'hecurr work', u'hecurr work princip', u'heha', u'heha author', u'heha author book', u'height', u'height ground', u'height ground depth', u'heinria', u'heinria renn', u'heinria renn franc', u'held-outal', u'held-outal measur', u'held-outal measur perform', u'held-outcamvid', u'held-outcamvid test', u'held-outcamvid test set', u'help', u'help map', u'help map low', u'help shown', u'help shown recentresult', u'help shown recentwhen', u'henc', u'henc achiev', u'henc achiev higher', u'henc come', u'henc come various', u'henc decod', u'henc decod arean', u'henc decod arejoint', u'henc decod networkha', u'henc design', u'henc design effici', u'henc fcn-basic', u'henc fcn-basic isconvolut', u'henc fcn-basic isfast', u'henc isimport', u'henc isimport retain', u'henc isobject', u'henc isobject base', u'henc network', u'henc network produc', u'henc onli', u'henc onli convolut', u'henc onli report', u'henc propos', u'henc propos complement', u'henc propos effici', u'herecontour', u'herecontour inform', u'herecontour inform notic', u'hereit', u'hereit segnet-bas', u'hereit segnet-bas competitiveit', u'heremodel', u'heremodel uncertainti', u'heremodel uncertainti camera', u'herethat', u'herethat use', u'herethat use median', u'hereto', u'hereto segment', u'hereto segment small', u'herew', u'herew appli', u'herew appli pixel-wis', u'hft', u'hft h', u'hft h schulz', u'hidden', u'hidden layer', u'hidden layer denot', u'hidden layer unknown', u'hierarch', u'hierarch encod', u'hierarch encod theseapproach', u'hierarch encod theseful', u'hierarchi', u'hierarchi applic', u'hierarchi applic objectlearn', u'hierarchi applic objectrecognit', u'hierarchi main', u'hierarchi main contribut', u'hierarchi similar', u'hierarchi similar decod', u'hierarchi visualand', u'hierarchi visualand y', u'hierarchi visualrecognit', u'hierarchi visualrecognit nip', u'hierarchicalc', u'hierarchicalc farabet', u'hierarchicalc farabet c', u'hierarchicalfeatur', u'hierarchicalfeatur scene', u'hierarchicalfeatur scene label', u'hierarchyof', u'hierarchyof decod', u'hierarchyof decod correspond', u'hierarchysegnet', u'hierarchysegnet decod', u'hierarchysegnet decod network', u'high', u'high accuraci', u'high accuraci compar', u'high accuraci dataset', u'high bf', u'high bf score', u'high bfbest', u'high bfbest perform', u'high bfscore', u'high bfscore onc', u'high dimension', u'high dimension featur', u'high frequenc', u'high frequenc lead', u'high global', u'high global accuraci', u'high level', u'high level uncertainti', u'high levelsof', u'high levelsof accuraci', u'high levelsvari', u'high levelsvari level', u'high model', u'high model uncertainti', u'high qualiti', u'high qualiti predict', u'high qualiti unari', u'high qualityacross', u'high qualityacross class', u'high qualitysegment', u'high qualitysegment especi', u'high resolut', u'high resolut featuremap', u'high resolut featurestop', u'high score', u'high score roadscen', u'high score roadsegnet', u'high vari', u'high vari background', u'high variabl', u'high variabl indoor', u'high-definit', u'high-definit ground', u'high-definit ground truth', u'higher', u'higher accuraci', u'higher accuraci follow', u'higher accuraci recent', u'higher accuraci tempor', u'higher boundari', u'higher boundari delin', u'higher forward-backward', u'higher forward-backward pass', u'higher level', u'higher level featur', u'higher miou', u'higher miou butsegnet', u'higher miou butsmal', u'higher model', u'higher model uncertainti', u'higher model uncertaintyal', u'higher model uncertaintyat', u'higher modelsymbol', u'higher modelsymbol bicyclist', u'higher modeluncertainti', u'higher order', u'higher order crf', u'higher otherarchitectur', u'higher otherarchitectur deconvnet', u'higher othernetwork', u'higher othernetwork train', u'higher segnet', u'higher segnet deconvnet', u'higher segnet perform', u'higher tabl', u'higher tabl agre', u'higher tabl class', u'higher train', u'higher train accuraci', u'higheraccuraci', u'higheraccuraci best', u'higheraccuraci best perform', u'higheraccuraci follow', u'higheraccuraci follow crf', u'higherfeatur', u'higherfeatur set', u'higherfeatur set includ', u'higherfeatur spatio-tempor', u'higherfeatur spatio-tempor super-pixel', u'highest', u'highest evalu', u'highest evalu valid', u'highest evenclass', u'highest evenclass car', u'highest evenwhen', u'highest evenwhen compar', u'highest experimentedof', u'highest experimentedof smallest', u'highest experimentedwith', u'highest experimentedwith train', u'highest miou', u'highest miou accuraci', u'highest oftencorrespond', u'highest oftencorrespond low', u'highest oftennumer', u'highest oftennumer perform', u'highest overal', u'highest overal class', u'highest perform', u'highest perform result', u'highest score', u'highest score metric', u'highest valid', u'highest valid dataset', u'highest valid datasetw', u'highest valid datasetwhich', u'highest weightingmetr', u'highest weightingmetr global', u'highest weightingsinc', u'highest weightingsinc major', u'highestresolut', u'highestresolut featur', u'highestresolut featur map', u'highestw', u'highestw size', u'highestw size trainabl', u'highgener', u'highgener veri', u'highgener veri high', u'highlight', u'highlight edg', u'highlight edg lead', u'highlight need', u'highlight need better', u'highlight propos', u'highlight propos architectur', u'highlight pseudo', u'highlight pseudo depth', u'highmodel', u'highmodel uncertainti', u'highmodel uncertainti predomin', u'highwayimag', u'highwayimag internet', u'highwayimag internet fig', u'highwaypract', u'highwaypract applic', u'highwaypract applic random', u'histogram', u'histogram mostactiv', u'histogram mostactiv featur', u'histogram mostvector', u'histogram mostvector sampl', u'histogram n', u'histogram n element', u'hoc', u'hoc featur', u'hoc featur upsampl', u'hoc method', u'hoc method upsampl', u'hoc techniqu', u'hoc techniqu use', u'hold', u'hold preceed', u'hold preceed pair', u'hold true', u'hold true natur', u'holdingth', u'holdingth shallow', u'holdingth shallow layer', u'holdingw', u'holdingw train', u'holdingw train encoder-decod', u'hong', u'hong b', u'hong b han', u'honour', u'honour fromalex', u'honour fromalex kendal', u'honour fromth', u'honour fromth univers', u'hope', u'hope experi', u'hope experi encourag', u'hope morearchitectur', u'hope morearchitectur harder', u'hope moreattent', u'hope moreattent paid', u'hope thatoptim', u'hope thatoptim non-convex', u'hope thatthi', u'hope thatthi control', u'host', u'host support', u'host support techniqu', u'howev', u'howev boundari', u'howev boundari accuraci', u'howev compar', u'howev compar outdoor', u'howev csurka', u'howev csurka et', u'howev deeplearn', u'howev deeplearn method', u'howev deepmani', u'howev deepmani popular', u'howev did', u'howev did attempt', u'howev didhierarch', u'howev didhierarch encod', u'howev didnot', u'howev didnot attempt', u'howev doesdo', u'howev doesdo reveal', u'howev doesind', u'howev doesind larg', u'howev enabl', u'howev enabl end-to-end', u'howev encod', u'howev encod network', u'howev experimentallyfound', u'howev experimentallyfound comput', u'howev experimentallywhil', u'howev experimentallywhil use', u'howev fastest', u'howev fastest train', u'howev feed-forward', u'howev feed-forward testand', u'howev feed-forward testtim', u'howev fix', u'howev fix themodel', u'howev fix thestandard', u'howev foundthi', u'howev foundthi qualit', u'howev foundwhich', u'howev foundwhich agre', u'howev higher', u'howev higher level', u'howev import', u'howev import problem', u'howev infer', u'howev infer time', u'howev largeand', u'howev largeand miou', u'howev largeimprov', u'howev largeimprov obtain', u'howev major', u'howev major task', u'howev miou', u'howev miou metric', u'howev model', u'howev model uncertainti', u'howev noneof', u'howev noneof propos', u'howev noneth', u'howev noneth output', u'howev note', u'howev note approach', u'howev practic', u'howev practic factor', u'howev practic strong', u'howev rais', u'howev rais thea', u'howev rais thequest', u'howev recent', u'howev recent approach', u'howev result', u'howev result classif', u'howev resultingclassif', u'howev resultingclassif blocki', u'howev resultingimag', u'howev resultingimag dimens', u'howev sampl', u'howev sampl come', u'howev segment', u'howev segment want', u'howev tabl', u'howev tabl differ', u'howev thebenchmark', u'howev thebenchmark control', u'howev thecompet', u'howev thecompet architectur', u'howev thisbas', u'howev thisbas cue', u'howev thispart', u'howev thispart veri', u'howev understand', u'howev understand model', u'howev upsampl', u'howev upsampl map', u'html', u'html 4forest', u'html 4forest imag', u'html 4fr/', u'html 4fr/ mschmidt/software/minfunc', u'html examplecaff', u'html examplecaff prototxt', u'html examplehttp', u'html examplehttp //mi', u'htmlfor', u'htmlfor code', u'htmlstatist', u'htmlstatist http', u'htmlstatist http //mi', u'http', u'http //arxiv', u'http //host', u'http //mi', u'http //miengcamacfig', u'http //miengcamacfig segnet', u'http //miengcamacuk/projects/segnet/', u'http //miengcamacuk/projects/segnet/ segnet', u'http //miengcamacuk/projects/segnet/index', u'http //miengcamacuk/projects/segnet/index terms\\u2014deep', u'http //miengcamacuk/projects/segnet/to', u'http //miengcamacuk/projects/segnet/to architectur', u'http //miengcamacuk/projects/segnet/tutorialhtmlfor', u'http //miengcamacuk/projects/segnet/tutorialhtmlfor code', u'http //miengcamacuk/projects/segnet/tutorialhtmlstatist', u'http //miengcamacuk/projects/segnet/tutorialhtmlstatist http', u'http //miengcamacuk/projects/segnet/uk/projects/segnet/advantag', u'http //miengcamacuk/projects/segnet/uk/projects/segnet/advantag improv', u'https', u'https //arxiv', u'https //arxivorg/pdf/160506211v1pdf', u'https //arxivorg/pdf/160506211v1pdf 2016imag', u'https //arxivorg/pdf/160506211v1pdf 2016semant', u'https //develop', u'https //developernvidia3', u'https //developernvidia3 speedup', u'https //developernvidiacom/cudnncom/cudnncom/cudnncomput', u'https //developernvidiacom/cudnncom/cudnncom/cudnncomput layer', u'huang', u'huang p', u'huang p h', u'huge', u'huge success', u'huge success late', u'human', u'human knowledg', u'human knowledg machin', u'human pose', u'human pose recognit', u'human qualitativejudg', u'human qualitativejudg rank', u'human qualitativethat', u'human qualitativethat metric', u'human rank', u'human rank segment', u'human-level', u'human-level perform', u'human-level perform imagenet', u'hundredsfeatur', u'hundredsfeatur trainabl', u'hundredsfeatur trainabl paramet', u'hundredsof', u'hundredsof million', u'hundredsof million encount', u'hypercolumn', u'hypercolumn deconvnet', u'hypercolumn deconvnet useregion', u'hypercolumn deconvnet usesegment', u'hyperparamet', u'hyperparamet dense-crfth', u'hyperparamet dense-crfth grid', u'hyperparamet dense-crfworsen', u'hyperparamet dense-crfworsen bf', u'hyperparamet obtain', u'hyperparamet obtain expens', u'hypothesi', u'hypothesis55d', u'hypothesis55d iscuss', u'hypothesis55d iscuss futur', u'hypothesisdataset', u'hypothesisdataset need', u'hypothesisdataset need verifi', u'i/u', u'i/u75', u'i/u94', u'i/uc', u'i/uc i/u94', u'i/uc i/uc', u'i/uc i/uc i/u94', u'i/uc i/uc i/un/a', u'i/uc i/uc i/uno', u'i/uc i/un/a', u'i/uc i/un/a n/a', u'i/uc i/uno', u'i/uc i/uno dropoutno', u'i/umean', u'i/umean i/u75', u'i/umean i/umean', u'i/umean i/umean i/u75', u'i/umean i/umean i/umean', u'i/un/a', u'i/un/a n/a', u'i/un/a n/a n/a81', u'i/uno', u'i/uno dropoutno', u'i/uno dropoutno dropoutno', u'iccv', u'iccv class-label', u'iccv class-label random', u'iccv geometr', u'iccv geometr semant', u'iccv ieee', u'iccv ieee intern', u'iccv label', u'iccv label common', u'iccv page', u'iccv page 3m', u'iccv page 3what', u'iccv page ieee', u'iccv pp', u'iccv pp 2009surpass', u'iccv pp 2015c', u'iccv pp 2015pp', u'iccv pp 2015semant', u'iccv pp 2146\\u2013best', u'iccv pp ieee', u'iclr', u'iclr 2015connect', u'iclr 2015connect crfs', u'iclr 2015h', u'iclr 2015h noh', u'icml', u'icml 2015insight', u'icml 2015insight applic', u'icml 2015uncertainti', u'icml 2015uncertainti deep', u'icml 8pars', u'icml 8pars multiscal', u'icml 8top-down', u'icml 8top-down semant', u'icml multiscal', u'icml multiscal featur', u'icml page', u'icml page 201111springer', u'icml page 2011multimod', u'icml page 3and', u'icml page 3network', u'icml pp', u'icml pp 129\\u2013and', u'icml pp 2011s', u'icml pp 2014a', u'icml pp 2014for', u'icml workshop', u'icml workshop deep', u'icml workshop deeplearn', u'icml workshop deepnetwork', u'icml,2012', u'icml,201220122012201220122012for', u'icml,201220122012201220122012for scene', u'icml,201220122012201220122012for scene pars', u'icra', u'icra 2014indoor', u'icra 2014indoor scene', u'icra 2014recognit', u'icra 2014recognit indoor', u'icra map', u'icra map indoor', u'icra,2014', u'icra,2014 8advanc', u'icra,2014 8advanc artifici', u'id', u'id 1468a', u'id 1468a similar', u'id paper', u'id paper id', u'idea', u'idea comput', u'idea comput semant', u'idea decod', u'idea decod decodercvpr', u'idea decod decodernetwork', u'idea exploit', u'idea exploit co-occurr', u'idea inspir', u'idea inspir architectur', u'ideai', u'ideai use', u'ideai use featur', u'idealay', u'idealay singl', u'idealay singl deep', u'ident', u'ident convolut', u'ident convolut layer', u'ident situationssegnet', u'ident situationssegnet deep', u'ident toth', u'ident toth convolut', u'ident toth encod', u'identifyoften', u'identifyoften appear', u'identifyoften appear uncertain', u'identifysecond', u'identifysecond object', u'identifysecond object visual', u'ieee', u'ieee 2,88and', u'ieee 2,88and lopezand', u'ieee 2009a', u'ieee 2009a databas', u'ieee 2009and', u'ieee 2009and semant', u'ieee 2010and', u'ieee 2010and y', u'ieee 2010network', u'ieee 2010network cvpr', u'ieee 2011pp', u'ieee 2011pp ieee', u'ieee 2011scene', u'ieee 2011scene use', u'ieee 2012algorithm', u'ieee 2012algorithm cvpr', u'ieee 2012indoor', u'ieee 2012indoor scene', u'ieee 2013ieee', u'ieee 2013ieee 2013ieee', u'ieee 5network', u'ieee 5network scene', u'ieee 5page', u'ieee 5page ieee', u'ieee 6classif', u'ieee 6classif deep', u'ieee 6label', u'ieee 6label iccv', u'ieee 8cvpr', u'ieee 8cvpr page', u'ieee 8map', u'ieee 8map indoor', u'ieee abstract\\u2014w', u'ieee abstract\\u2014w present', u'ieee algorithm', u'ieee algorithm cvpr', u'ieee confer', u'ieee confer comput', u'ieee confer page', u'ieee conferenceon', u'ieee conferenceon comput', u'ieee conferenceunderstand', u'ieee conferenceunderstand benchmark', u'ieee intern', u'ieee intern confer', u'ieee pami', u'ieee pami vol', u'ieee vijay', u'ieee vijay badrinarayanan', u'ieeeimag', u'ieeeimag boundari', u'ieeeimag boundari use', u'ieeeintern', u'ieeeintern confer', u'ieeeintern confer comput', u'ieeesegment', u'ieeesegment deep', u'ieeesegment deep pars', u'ieeetransact', u'ieeetransact pattern', u'ieeetransact pattern analysi', u'ignor', u'ignor high', u'ignor high resolut', u'ii', u'ii benefici', u'ii benefici train', u'ii combin', u'ii combin featur', u'ii highlight', u'ii highlight edg', u'ii initi', u'ii initi parameterstrain', u'ii initi parameterswith', u'ii reduc', u'ii reduc theadvantag', u'ii reduc thenumb', u'iii', u'iii classifi', u'iii classifi hidden', u'iii easypixel', u'iii easypixel label', u'iii easyto', u'iii easyto visualis', u'iii initi', u'iii initi paramet', u'iii thisform', u'iii thisform upsampl', u'iii thisnumb', u'iii thisnumb paramet', u'ijcv', u'ijcv 5fr/', u'ijcv 5fr/ mschmidt/software/minfunc', u'ijcv 5labelm', u'ijcv 5labelm databas', u'ijcv pp', u'ijcv pp april', u'ijcv vol', u'ijcv vol databas', u'ijcv vol pp', u'illumin', u'illumin reduc', u'illumin reduc dynamicnon-uniform', u'illumin reduc dynamicrang', u'illumin relat', u'illumin relat differ', u'illustr', u'illustr fig', u'illustr fig encod', u'illustr segnet', u'illustr segnet architectur', u'illustr segnet fcn', u'imag', u'imag 360x480', u'imag 360x480 pixel', u'imag alsosinc', u'imag alsosinc input', u'imag alsous', u'imag alsous segment', u'imag annot', u'imag annot ijcv', u'imag appear', u'imag appear infrequ', u'imag architectur', u'imag architectur use', u'imag author', u'imag author discuss', u'imag author map', u'imag boundari', u'imag boundari use', u'imag captur', u'imag captur differ', u'imag captur froma', u'imag captur fromregion', u'imag categor', u'imag categor segment', u'imag class', u'imag class object', u'imag context', u'imag context spatial', u'imag cvpr', u'imag cvpr pp', u'imag dataset', u'imag dataset anoth', u'imag dataset havebeen', u'imag dataset havescen', u'imag day', u'imag day anddataset', u'imag day anddusk', u'imag day dusk', u'imag day duskscen', u'imag day dusktrain', u'imag detect', u'imag detect object', u'imag diagon', u'imag diagon toler', u'imag dimens', u'imag dimens howev', u'imag dimens learn', u'imag dimens replic', u'imag dimens sever', u'imag eccv', u'imag eccv pp', u'imag f1', u'imag f1 measur', u'imag f1 measuresbi', u'imag f1 measuresw', u'imag f1-measur', u'imag f1-measur computei', u'imag f1-measur computeth', u'imag featur', u'imag featur map', u'imag fromcurr', u'imag fromcurr camera', u'imag fromgoogl', u'imag fromgoogl indoor', u'imag frommodifications/redesign', u'imag frommodifications/redesign qualiti', u'imag fromresult', u'imag fromresult produc', u'imag ground', u'imag ground truthinput', u'imag ground truthlabel', u'imag icra', u'imag icra 2014indoor', u'imag icra 2014recognit', u'imag icra map', u'imag icra,2014', u'imag icra,2014 8advanc', u'imag imagesar', u'imag imagesar captur', u'imag imagesscen', u'imag imagesscen train', u'imag ina', u'imag ina feed-forward', u'imag indoor', u'imag indoor scene', u'imag ineccv', u'imag ineccv page', u'imag infor', u'imag infor joint', u'imag input', u'imag input output', u'imag insegment', u'imag insegment support', u'imag itabsorb', u'imag itabsorb larg', u'imag italso', u'imag italso indic', u'imag k', u'imag k thenumb', u'imag k theoutput', u'imag label', u'imag label cvpr', u'imag label eccv', u'imag label iccv', u'imag label segnet', u'imag limit', u'imag limit variat', u'imag map', u'imag map accurateand', u'imag map accuratemeaning', u'imag of360', u'imag of360 week', u'imag ofdeep', u'imag ofdeep segnet', u'imag particular', u'imag particular noteworthi', u'imag pick', u'imag pick order', u'imag pixel', u'imag pixel smallcontext', u'imag pixel smallsiz', u'imag pixel space', u'imag pixelsa', u'imag pixelsa context', u'imag pixelsth', u'imag pixelsth trade-off', u'imag probabl', u'imag probabl k', u'imag produc', u'imag produc multi-channel', u'imag recognit', u'imag recognit arxiv', u'imag recognit corr', u'imag reduc', u'imag reduc total', u'imag replac', u'imag replac mini-batch', u'imag replac mini-batchavoid', u'imag replac mini-batchth', u'imag represent', u'imag represent benefici', u'imag representationslearn', u'imag representationslearn decod', u'imag representationsto', u'imag representationsto pixel-wis', u'imag resolut', u'imag resolut predict', u'imag resolut use', u'imag resolutionlow', u'imag resolutionlow resolut', u'imag resolutionpredict', u'imag resolutionpredict techniqu', u'imag scene', u'imag scene ground', u'imag scene segment', u'imag score', u'imag score comput', u'imag seen', u'imag seen grow', u'imag segment', u'imag segment deep', u'imag segment miccai', u'imag segment \\u201darxiv', u'imag segment \\u201dsemi-supervis', u'imag segnet', u'imag segnet predict', u'imag size', u'imag size approxim', u'imag size featur', u'imag size input', u'imag sub-sampl', u'imag sub-sampl resultsin', u'imag sub-sampl resultsov', u'imag super-resolut', u'imag super-resolut depth', u'imag super-resolut depthmap', u'imag super-resolut depthus', u'imag super-resolut eccv', u'imag super-resolut use', u'imag task', u'imag test', u'imag test imag', u'imag theinput', u'imag theinput discrep', u'imag thepatch', u'imag thepatch dure', u'imag therei', u'imag therei activ', u'imag therewhol', u'imag therewhol imag', u'imag train', u'imag train segnet', u'imag train test', u'imag train train', u'imag use', u'imag use multi-scal', u'imag use onli', u'imag video', u'imag video base', u'imag withfigur', u'imag withfigur bayesian', u'imag withth', u'imag withth ground', u'image0', u'image075', u'image075 imag', u'image075 imag diagon', u'imageand', u'imageand high', u'imageand high global', u'imageconv', u'imageconv batch', u'imageconv batch normalis', u'imagedeep', u'imagedeep learn', u'imagedeep learn architectur', u'imageencoder-decod', u'imageencoder-decod architectur', u'imageencoder-decod architectur imageencoder-decod', u'imageencoder-decod architectur imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:1511', u'imageencoder-decod architectur imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3', u'imagei', u'imagei averag', u'imagei averag produc', u'imageimport', u'imageimport retain', u'imageimport retain boundari', u'imagelabel', u'imagelabel iccv', u'imagelabel iccv page', u'imagematch', u'imagematch score', u'imagematch score common', u'imagenet', u'imagenet classif', u'imagenet classif iniccv', u'imagenet classif insurpass', u'imagenet object', u'imagenet object classif', u'imagenetwork', u'imagenetwork fcn', u'imagenetwork fcn dilat', u'imagepixel', u'imagepixel label', u'imagepixel label test', u'imagerepresent', u'imagerepresent comput', u'imagerepresent comput perspect', u'imagergb', u'imagergb imageconv', u'imagergb imageconv batch', u'imagergb imagergb', u'imagergb imagergb imageconv', u'imagergb imagergb imagergb', u'images/featur', u'images/featur map', u'images/featur map learnet', u'images/featur map learnhierarch', u'imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw', u'imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw present', u'imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw present deep', u'imagesand', u'imagesand tabl', u'imagesand tabl lamp', u'imagesar', u'imagesar captur', u'imagesar captur differ', u'imagesegment', u'imagesegment qualiti', u'imagesegment qualiti csurka', u'imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:1511', u'imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3', u'imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3 cscv', u'imagesegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationarxiv:151100561v3 cscv oct', u'imageseith', u'imageseith rgb', u'imageseith rgb rgbd', u'imagesfeatur', u'imagesfeatur classif', u'imagesfeatur classif rgb', u'imagesfrom', u'imagesfrom current', u'imagesfrom current avail', u'imagesinput', u'imagesinput imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw', u'imagesinput imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw present', u'imagesinput imagesinput', u'imagesinput imagesinput imagesabstractabstractabstractabstractabstractabstractabstractabstractabstractw', u'imagesinput imagesinput imagesinput', u'imageski', u'imageski class', u'imageski class domin', u'imagesscen', u'imagesscen train', u'imagesscen train test', u'imagesth', u'imagesth applic', u'imagesth applic deep', u'imagesth success', u'imagesth success deep', u'imagestructur', u'imagestructur class-label', u'imagestructur class-label random', u'imagethes', u'imagethes problem', u'imagethes problem learn', u'imbal', u'imbal frequenc', u'imbal frequenc larg', u'imbal frequenc road', u'imbal label', u'imbal label frequenc', u'imbalanc', u'imbalanc label', u'imbalanc label frequenc', u'imbalancesin', u'imbalancesin train', u'imbalancesin train set', u'imbalancesweight', u'imbalancesweight class', u'imbalancesweight class correct', u'immedi', u'immedi interesttask', u'immedi interesttask indoor', u'immedi interestto', u'immedi interestto sever', u'immedi segnet', u'immedi segnet deconvnetachiev', u'immedi segnet deconvnetfrom', u'impact', u'impact dens', u'impact dens crf', u'imperfect', u'imperfect theinvolv', u'imperfect theinvolv gradient', u'imperfect theoptim', u'imperfect theoptim non-convex', u'implement', u'implement alland', u'implement alland perform', u'implement allth', u'implement allth variant', u'implement avail', u'implement avail evalu', u'implement bayesian', u'implement bayesian segnet', u'implement run', u'implement run segnet', u'implement segnet', u'implement segnet use', u'implement segnet web', u'implement taski', u'implement taski road', u'implement taskw', u'implement taskw quantifi', u'implementationof', u'implementationof momentum', u'implementationof momentum use', u'implementationof segnet-bas', u'implementationof segnet-bas train', u'impli', u'impli larger', u'impli larger class', u'implicitlyclass', u'implicitlyclass surround', u'implicitlyclass surround high', u'implicitlyfavour', u'implicitlyfavour techniqu', u'implicitlyfavour techniqu use', u'import', u'import achiev', u'import achiev high', u'import advantag', u'import advantag retain', u'import captur', u'import captur encoderdecod', u'import captur encoderfeatur', u'import categori', u'import categori sfmbase', u'import choic', u'import choic make', u'import class', u'import class observ', u'import class sign', u'import considerationof', u'import considerationof model', u'import considerationparticular', u'import considerationparticular perform', u'import deploy', u'import deploy modelsmemori', u'import deploy modelson', u'import design', u'import design element', u'import drawback', u'import drawback recent', u'import forcan', u'import forcan trust', u'import fordecis', u'import fordecis make', u'import problem', u'import problem use', u'import problemattent', u'import problemattent paid', u'import problemr', u'import problemr eferencesr', u'import step', u'import step understand', u'import tool', u'import tool forsegnet', u'import tool forvisu', u'import tool scene', u'import variant', u'import variant reveal', u'importantand', u'importantand comput', u'importantand comput time', u'importantautonom', u'importantautonom drive', u'importantfactor', u'importantfactor consid', u'importantfactor consid choos', u'importantfor', u'importantfor domest', u'importantfor domest robot', u'importantto', u'importantto understand', u'importantto understand addit', u'importanttrain', u'importanttrain time', u'importanttrain time particular', u'imposea', u'imposea bernoulli', u'imposea bernoulli distribut', u'imposeshow', u'imposeshow dropout', u'imposeshow dropout use', u'improv', u'improv accuraci', u'improv accuraci domin', u'improv accuraci iii', u'improv accuraci recent', u'improv accuraci smaller/thinn', u'improv boundari', u'improv boundari delin', u'improv class', u'improv class averag', u'improv classif', u'improv classif increasesin', u'improv classif increasesind', u'improv coresegment', u'improv coresegment engin', u'improv corew', u'improv corew seen', u'improv decis', u'improv decis subsequ', u'improv fcn-8', u'improv fcn-8 thatshow', u'improv fcn-8 thatthi', u'improv featur', u'improv featur classif', u'improv featur classificationindoor', u'improv featur classificationne', u'improv furtherbi', u'improv furtherbi append', u'improv furtherth', u'improv furtherth predict', u'improv hand', u'improv hand engin', u'improv hand engineeredfeatur', u'improv hand engineeredpredict', u'improv infer', u'improv infer time', u'improv infer timeand', u'improv infer timeour', u'improv method', u'improv method use', u'improv orepoch', u'improv orepoch observ', u'improv orwhen', u'improv orwhen over-fit', u'improv ourmodel', u'improv ourmodel scene', u'improv ourwork', u'improv ourwork intend', u'improv perfom', u'improv perfom longer', u'improv perform', u'improv perform foralso', u'improv perform forsmal', u'improv perform onbeen', u'improv perform onchalleng', u'improv perform particular', u'improv perform smoothingfield', u'improv perform smoothingth', u'improv point', u'improv rang', u'improv rang architectur', u'improv result', u'improv result random', u'improv segmenationaccuraci', u'improv segmenationaccuraci appli', u'improv segmenationbroad', u'improv segmenationbroad applic', u'improv segment', u'improv segment approach', u'improv segment perform', u'improv segmentationdropout', u'improv segmentationdropout sampl', u'improv segmentationperform', u'improv segmentationperform deep', u'improv smaller', u'improv smaller dataset', u'improv strikinglyat', u'improv strikinglyat depth', u'improv strikinglyvari', u'improv strikinglyvari depth', u'improv use', u'improv use propos', u'improv use richerfeatur', u'improv use richersmooth', u'improv weremad', u'improv weremad use', u'improv wereunari', u'improv wereunari smooth', u'improv withcrf', u'improv withcrf post-process', u'improv withlarg', u'improv withlarg train', u'improvedataset', u'improvedataset use', u'improvedataset use depth', u'improvementbeyond', u'improvementbeyond approxim', u'improvementbeyond approxim sampl', u'improvementlarg', u'improvementlarg train', u'improvementlarg train set', u'improvementobtain', u'improvementobtain use', u'improvementobtain use pre-train', u'improvementsin', u'improvementsin accuraci', u'improvementsin accuraci achiev', u'improvementsthi', u'improvementsthi user', u'improvementsthi user perspect', u'improvementw', u'improvementw observ', u'improvementw observ addit', u'improveperform', u'improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg', u'improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg decod', u'improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg decod increas', u'improvesegment', u'improvesegment approach', u'improvesegment approach use', u'improvewith', u'improvewith appropri', u'improvewith appropri decod', u'in2010', u'in2010 research', u'in2010 research comput', u'in2014', u'in2014 award', u'in2014 award woolf', u'ina', u'ina crf', u'ina crf framework', u'ina feed-forward', u'ina feed-forward manner', u'ina mont', u'ina mont carlo', u'ina y', u'ina y ng', u'inabl', u'inabl deep', u'inabl deep architectur', u'inand', u'inand recognit', u'inand recognit use', u'inappl', u'inappl deep', u'inappl deep learn', u'inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow', u'inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow curtainshow', u'inbagbagbagbagtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplamptoweltoweltoweltoweltoweltowelshow curtainshow curtainshow', u'inbi', u'inbi fact', u'inbi fact object', u'incan', u'incan produc', u'incan produc probabilist', u'inclassif', u'inclassif deep', u'inclassif deep convolut', u'includ', u'includ comput', u'includ comput time', u'includ dataset', u'includ dataset tabl', u'includ datasetbenchmark', u'includ datasetbenchmark dataset', u'includ datasetroad', u'includ datasetroad scene', u'includ lbp', u'includ lbp region', u'includ lbp regionmad', u'includ lbp regionsegment', u'includ random', u'includ random forest', u'includ segnet', u'includ segnetmulti-scal', u'includ segnetmulti-scal deep', u'includ segnetto', u'includ segnetto ani', u'includ shallow', u'includ shallow method', u'includ sub-sampl', u'includ sub-sampl correspond', u'includ therefor', u'includ therefor believeour', u'includ therefor believesometim', u'includ trend', u'includ trend bf', u'includ use', u'includ use depth', u'includ wall', u'includ wall floor', u'includeth', u'includeth camvid', u'includeth camvid test', u'includeweb', u'includeweb demo', u'includeweb demo footnot', u'includingar', u'includingar captur', u'includingar captur differ', u'includingclass', u'includingclass blanc', u'includingclass blanc train', u'includingsegnet', u'includingsegnet becaus', u'includingsegnet becaus difficult', u'includingwal', u'includingwal floor', u'includingwal floor ceil', u'incombin', u'incombin object', u'incombin object detect', u'incontext', u'incontext comput', u'incontext comput vision\\u2013eccv', u'incontrast', u'incontrast dropout', u'incontrast dropout uncertainti', u'incorpor', u'incorpor ani', u'incorpor ani encoder-decoderarchitectur', u'incorpor ani encoder-decoderform', u'incorrect', u'incorrect class', u'incorrect class label', u'incorrect label', u'incorrect label model', u'increas', u'increas accur', u'increas accur complex', u'increas consequ', u'increas consequ larger', u'increas context', u'increas context use', u'increas contrast', u'increas contrast shadow', u'increas inferenceinfer', u'increas inferenceinfer propos', u'increas inferencetim', u'increas inferencetim signific', u'increas lossi', u'increas lossi boundari', u'increas model', u'increas model capac', u'increas note', u'increas note evaluationagainst', u'increas note evaluationw', u'increas number', u'increas number modelinterpret', u'increas number modelparamet', u'increas obtain', u'increas obtain use', u'increas perform', u'increas perform given', u'increas perform observ', u'increas perform unfortunatelydo', u'increas perform unfortunatelyvalu', u'increas result', u'increas result sampl', u'increas spatial', u'increas spatial context', u'increas success', u'increas success duedeep', u'increas success dueto', u'increas trend', u'increas trendfor', u'increas trendfor fcn', u'increas trendmetr', u'increas trendmetr increas', u'increasedeach', u'increasedeach deeper', u'increasedeach deeper encoder-decod', u'increasedspati', u'increasedspati context', u'increasedspati context layer', u'increaseepoch', u'increaseepoch dataset', u'increaseepoch dataset perform', u'increasesin', u'increasesin accuraci', u'increasesin accuraci come', u'increasesind', u'increasesind need', u'increasesind need improv', u'increasewa', u'increasewa observ', u'increasewa observ dropout', u'incvpr', u'incvpr pp', u'incvpr pp 2015cvpr', u'inde', u'inde control', u'inde control benchmark', u'independ', u'independ benchmark', u'independ benchmark outdoor', u'independ classif', u'independ classif typic', u'independ crf', u'independ crf postprocess', u'independ output', u'independ output soft-maxclassifi', u'independ segment', u'independ segment benchmarknot', u'independ segment benchmarkon', u'independ segment networkperform', u'independ segment networkweak', u'independ segnet', u'independ segnet submit', u'independ theno', u'independ theno bias', u'independ theoutput', u'independ theoutput soft-max', u'independ typic', u'independ typic patch', u'independ use', u'independ use featur', u'index', u'index mostcommon', u'index mostcommon use', u'index mostth', u'index mostth miou', u'index terms\\u2014deep', u'index terms\\u2014deep convolut', u'indic', u'indic 17mb', u'indic 17mb store', u'indic batch', u'indic batch normal', u'indic calledmap', u'indic calledmap use', u'indic calledswitch', u'indic calledswitch learn', u'indic comput', u'indic comput max-pool', u'indic contribut', u'indic contribut prior', u'indic convolv', u'indic convolv trainabl', u'indic decod', u'indic decod process', u'indic deeper', u'indic deeper featur', u'indic encod', u'indic encod produc', u'indic encod sequenc', u'indic encoderencod', u'indic encoderencod use', u'indic encoderit', u'indic encoderit perform', u'indic inform', u'indic inform involv', u'indic insteadimag', u'indic insteadimag communiti', u'indic insteadtransf', u'indic insteadtransf entir', u'indic isbalanc', u'indic isbalanc train', u'indic istherefor', u'indic istherefor memori', u'indic itconvolv', u'indic itconvolv upsampl', u'indic itpool', u'indic itpool store', u'indic locat', u'indic locat maximum', u'indic max', u'indic max locat', u'indic need', u'indic need use', u'indic network', u'indic network abl', u'indic ofencod', u'indic ofencod consist', u'indic ofth', u'indic ofth max', u'indic otherhand', u'indic otherhand fcn-basic', u'indic otherinfer', u'indic otherinfer sinc', u'indic perceptu', u'indic perceptu noisycorrespond', u'indic perceptu noisysegment', u'indic performloc', u'indic performloc encod', u'indic performnon-linear', u'indic performnon-linear upsampl', u'indic receiv', u'indic receiv fromappropri', u'indic receiv fromth', u'indic storag', u'indic storag memori', u'indic store', u'indic store usedreduct', u'indic store usedwith', u'indic thea', u'indic thea crf', u'indic thene', u'indic thene improv', u'indic uncertain', u'indic uncertain predict', u'indic upsampl', u'indic upsampl overal', u'indic upsampl perform', u'indic upsamplingar', u'indic upsamplingar use', u'indic upsamplingcr', u'indic upsamplingcr memori', u'indic usedfor', u'indic usedfor upsampl', u'indic usednetwork', u'indic usednetwork object', u'indicesfig', u'indicesfig illustr', u'indicesfig illustr segnet', u'indicesfrom', u'indicesfrom correspond', u'indicesfrom correspond encod', u'indicesit', u'indicesit input', u'indicesit input featur', u'indicespool', u'indicespool indicespool', u'indicespool indicespool indicespool', u'indicespool indicespool indicesrgb', u'indicespool indicesrgb', u'indicespool indicesrgb imagergb', u'indicesrgb', u'indicesrgb imagergb', u'indicesrgb imagergb imagergb', u'indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic1', u'indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526', u'indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526 733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530', u'indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526 733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530 689segnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecodersegnet-basic-singlechanneldecoder06250625062506250625062511331', u'indicesto', u'indicesto upsampl', u'indicesto upsampl learn', u'indicesupsampl', u'indicesupsampl use', u'indicesupsampl use max-pool', u'indiffer', u'indiffer pose', u'indiffer pose frequent', u'individ', u'individ class', u'individ class frequenc', u'individu', u'individu class', u'individu class accuraci', u'individu unit', u'individu unit featur', u'indoor', u'indoor rgbd', u'indoor rgbd pixel-wis', u'indoor rgbd scene', u'indoor scene', u'indoor scene class', u'indoor scene classesus', u'indoor scene classesw', u'indoor scene complexmak', u'indoor scene complexsinc', u'indoor scene conjectur', u'indoor scene dataset', u'indoor scene fromrgb', u'indoor scene fromth', u'indoor scene importantautonom', u'indoor scene importantfor', u'indoor scene need', u'indoor scene note', u'indoor scene nyu', u'indoor scene rgb-d', u'indoor scene road', u'indoor scene segment', u'indoor scene therefor', u'indoor scene train', u'indoor scene tri', u'indoor scene understand', u'indoor scene veri', u'indoor scene vgg', u'indoor sceneengag', u'indoor sceneengag attent', u'indoor scenesof', u'indoor scenesof differ', u'indoor scenessun', u'indoor scenessun rgb-d', u'indoor scenesth', u'indoor scenesth qualit', u'indoor scenetest', u'indoor scenetest sampl', u'indoor sunscen', u'indoor sunscen understand', u'indoor sunsmal', u'indoor sunsmal dataset', u'indoor test', u'indoor test scene', u'indooroth', u'indooroth deep', u'indooroth deep architectur', u'indoorscen', u'indoorscen train', u'indoorscen train test', u'indoorscen understand', u'indoorscen understand dataset', u'indoorscen understand effici', u'indoorsun', u'indoorsun rgb-d', u'indoorsun rgb-d veri', u'indoorwa', u'indoorwa need', u'indoorwa need design', u'ineccv', u'ineccv marseill', u'ineccv marseill 6eccv', u'ineccv page', u'ineccv page springer', u'ineffici', u'ineffici train', u'ineffici train predictionsdo', u'ineffici train predictionsth', u'inencod', u'inencod featur', u'inencod featur map', u'infer', u'infer abil', u'infer abil train', u'infer aid', u'infer aid ascan', u'infer aid asregion', u'infer aid object', u'infer anoth', u'infer anoth commonfeatur', u'infer anoth commonof', u'infer approxim', u'infer bayesian', u'infer bayesian neural', u'infer believ', u'infer believ theaid', u'infer believ theperceiv', u'infer compar', u'infer compar analysi', u'infer constrain', u'infer constrain compress', u'infer crf', u'infer crf oraid', u'infer crf orthey', u'infer dens', u'infer dens 3d', u'infer differ', u'infer differ object', u'infer disjoint', u'infer disjoint train', u'infer distribut', u'infer distribut network', u'infer forward', u'infer forward pass', u'infer howev', u'infer howev rais', u'infer memori', u'infer memori batchcommand', u'infer memori batchsiz', u'infer memori intens', u'infer memori mb', u'infer memory-wis', u'infer memory-wis comparedshow', u'infer memory-wis comparedto', u'infer model', u'infer models', u'infer models model', u'infer modelstor', u'infer modelstor encod', u'infer network', u'infer network weight', u'infer note', u'infer note theoret', u'infer relat', u'infer relat probabl', u'infer rgbd', u'infer rgbd imag', u'infer scene', u'infer scene geometryand', u'infer scene geometrysignific', u'infer segment', u'infer segment model', u'infer signific', u'infer signific smaller', u'infer support-relationship', u'infer support-relationship amongfrom', u'infer support-relationship amongobject', u'infer support-relationship object', u'infer tabl', u'infer tabl compar', u'infer time', u'infer time best', u'infer time compromis', u'infer time constrain', u'infer time depend', u'infer time effici', u'infer time howev', u'infer time memori', u'infer time memorybest', u'infer time memoryha', u'infer time memoryi', u'infer time memoryspars', u'infer time mont', u'infer time requir', u'infer time segnet', u'infer time sever', u'infer time signific', u'infer time significantlyon', u'infer time significantlyparamet', u'infer time whenfollow', u'infer time whenprovid', u'infer timeand', u'infer timeand improv', u'infer timeour', u'infer timeour work', u'infer togeth', u'infer togeth use', u'infer togetherclass', u'infer togetherclass segment', u'infer togetherus', u'infer togetherus combin', u'inference4', u'inference86868685', u'inferencebefor', u'inferencebefor sub-sampl', u'inferencebefor sub-sampl perform', u'inferenceghahramani', u'inferenceghahramani link', u'inferenceghahramani link techniqu', u'inferencegrid', u'inferencegrid search', u'inferencegrid search process', u'inferencei', u'inferencei constrain', u'inferencei constrain encod', u'inferencei expens', u'inferencei expens multipl', u'inferencein', u'inferencein bayesian', u'inferencein bayesian convolut', u'inferenceinfer', u'inferenceinfer propos', u'inferenceinfer propos use', u'inferenceprocess', u'inferenceprocess employ', u'inferenceprocess employ data', u'inferencetim', u'inferencetim dense-crf', u'inferencetim dense-crfstim', u'inferencetim dense-crfstim dense-crfstim', u'inferencetim signific', u'inferencetim signific benchmark', u'info/scen', u'info/scen parsing/encod', u'info/scen parsing/encod follow', u'info/scen parsing/http', u'info/scen parsing/http //david', u'infor', u'infor joint', u'infor joint featur', u'inform', u'inform apartfrom', u'inform apartfrom train', u'inform apartmap', u'inform apartmap certain', u'inform encod', u'inform encod featur', u'inform engin', u'inform engin professor', u'inform extract', u'inform extract imageimport', u'inform extract imagerepresent', u'inform ground', u'inform ground plane', u'inform inencod', u'inform inencod featur', u'inform involv', u'inform involv store', u'inform learn', u'inform learn better', u'inform notic', u'inform notic drop', u'inform present', u'inform present encod', u'inform process', u'inform process page', u'inform similar', u'inform similar learn', u'inform similar tree', u'inform use', u'inform use better', u'informationfeatur', u'informationfeatur activ', u'informationfeatur activ encod', u'informationrath', u'informationrath individu', u'informationrath individu unit', u'infrequ', u'infrequ accuraciesa', u'infrequ accuraciesa small', u'infrequ accuraciesreport', u'infrequ accuraciesreport tabl', u'inh', u'inh becam', u'inh becam fellow', u'iniccv', u'iniccv pp', u'iniccv pp 2015iccv', u'inicml', u'inicml page', u'inicml page 4icml', u'initi', u'initi approach', u'initi approach withsemant', u'initi approach withtextonboost', u'initi denot', u'initi denot segnet', u'initi paramet', u'initi paramet camvid', u'initi parameterstrain', u'initi parameterstrain layer', u'initi parameterswith', u'initi parameterswith camvid', u'initi train', u'initi train process', u'initi use', u'initi use kitti', u'initi use thetechniqu', u'initi use theth', u'initi weight', u'initi weight appropri', u'initi weight layer', u'initialis', u'initialis fcn-basicfcn-basicfcn-basic0', u'initialis fcn-basicfcn-basicfcn-basic065065065065065111111242', u'initialis fcn-basicfcn-basicfcn-basic065065065065065111111242 507fcn-basic-noadditionfcn-basic-noadditionfcn-basic-noaddition065065065065065n/a238', u'initialis learn', u'initialis learn upsampl', u'initialis remain', u'initialis remain fix', u'initializationor', u'initializationor ani', u'initializationor ani learn', u'initializationwithout', u'initializationwithout need', u'initializationwithout need special', u'initializedoutput', u'initializedoutput decod', u'initializedoutput decod featur', u'initializedus', u'initializedus bilinear', u'initializedus bilinear interpol', u'inmodel', u'inmodel uncertainti', u'inmodel uncertainti camera', u'innip', u'innip page', u'innip page 4nip', u'inof', u'inof cambridg', u'inof cambridg u', u'inof cambridg uk', u'inp', u'inp dolla\\u0301r', u'inp dolla\\u0301r c', u'inpedestrian', u'inpedestrian class', u'input', u'input advantag', u'input advantag step', u'input channel', u'input channel rgb', u'input channel rgbalthough', u'input channel rgbor', u'input classif', u'input classif use', u'input decod', u'input decod anencod', u'input decod architectur', u'input decod network', u'input depth', u'input depth singl', u'input dimens', u'input dimens resort', u'input dimens therefor', u'input dure', u'input dure test', u'input extra', u'input extra inform', u'input featur', u'input featur map', u'input fix', u'input fix pool', u'input imag', u'input imag architectur', u'input imag context', u'input imag dimens', u'input imag ina', u'input imag infor', u'input imag map', u'input imag pixel', u'input imag pixelsa', u'input imag pixelsth', u'input imag produc', u'input imag resolut', u'input imag resolutionlow', u'input imag resolutionpredict', u'input imag segnet', u'input imag sub-sampl', u'input imag train', u'input imag withfigur', u'input imag withth', u'input layer', u'input layer soft-max', u'input learn', u'input learn hierarch', u'input modal', u'input modal onli', u'input neural', u'input neural network', u'input neural networkclassifi', u'input neural networkdepth-sift', u'input normal', u'input normal depth', u'input nvidia', u'input nvidia titan', u'input output', u'input output semant', u'input post-process', u'input post-process class', u'input post-process tabl', u'input resolut', u'input resolut andsometim', u'input resolut andtrain', u'input resolut featuremap', u'input resolut featurevgg16', u'input resolut interpol', u'input resolutionfor', u'input resolutionfor pixel-wis', u'input resolutionfrom', u'input resolutionfrom need', u'input rgbimag', u'input rgbimag task', u'input rgbto', u'input rgbto sever', u'input sampl', u'input sampl note', u'input segnet', u'input segnet ani', u'input space', u'input space top-1', u'input thehigh', u'input thehigh dimension', u'input thesam', u'input thesam number', u'input use', u'input use memor', u'input use predict', u'input use transfer', u'input usingal', u'input usingal encod', u'input usingth', u'input usingth receiv', u'inputar', u'inputar use', u'inputar use follow', u'inputcomput', u'inputcomput camvid', u'inputcomput camvid video', u'inputepoch', u'inputepoch margin', u'inputepoch margin note', u'inputfeatur', u'inputfeatur map', u'inputfeatur map s', u'inputfor', u'inputfor classif', u'inputfor classif use', u'inputfor upsampl', u'inputfor upsampl architectur', u'inputlarg', u'inputlarg correct', u'inputlarg correct lack', u'inputmain', u'inputmain focus', u'inputmain focus layer-wis', u'inputmap', u'inputmap pixel-wis', u'inputmap pixel-wis classif', u'inputpatch', u'inputpatch dure', u'inputpatch dure test', u'inputpatch extend', u'inputpatch extend kavukcuoglu', u'inputperform', u'inputperform local', u'inputperform local contrast', u'inputresolut', u'inputresolut lack', u'inputresolut lack ground', u'inputsampl', u'inputsampl approxim', u'inputsampl approxim \\u201cinfluences\\u201d', u'inputsmod', u'inputsmod rgb', u'inputsmod rgb contrast', u'inputsthi', u'inputsthi avoid', u'inputsthi avoid highlight', u'inputth', u'inputth encod', u'inputth encod decod', u'inputthi', u'inputthi ad', u'inputthi ad element-wis', u'inquantit', u'inquantit segment', u'inquantit segment perform', u'inrepres', u'inrepres larger', u'inrepres larger valu', u'insect', u'insect propos', u'insect propos bayesian', u'insegment', u'insegment support', u'insegment support infer', u'insegnet-bas', u'insegnet-bas similar', u'insegnet-bas similar fcn-basic-noaddit', u'insert', u'insert dropout', u'insert dropout central', u'insight', u'insight applic', u'insight applic deep', u'insight intoabout', u'insight intoabout segnet', u'insight intow', u'insight intow perform', u'inspir', u'inspir architectur', u'inspir architectur design', u'inspir encoder-decod', u'inspir encoder-decod type', u'inspir unsupervis', u'inspir unsupervis featur', u'instanc', u'instanc autonomousdecis', u'instanc autonomousdecis make', u'instanc autonomousvehicl', u'instanc autonomousvehicl segment', u'instead', u'instead chose', u'instead chose perform', u'insteadimag', u'insteadimag communiti', u'insteadimag communiti doe', u'insteadtransf', u'insteadtransf entir', u'insteadtransf entir featur', u'insurpass', u'insurpass human-level', u'insurpass human-level perform', u'integr', u'integr network', u'integr network test', u'intellig', u'intellig ai', u'intellig ai disciplin', u'intellig c', u'intellig c lutz', u'intellig lab', u'intellig lab depart', u'intellig laboratori', u'intellig laboratori depart', u'intellig laboratori inappl', u'intellig laboratori inof', u'intellig research', u'intellig vol', u'intellig vol pp', u'intellig vol transact', u'intellig volum', u'intellig volum lectureadv', u'intellig volum lecturenot', u'intend', u'intend explor', u'intend explor video', u'intens', u'intens embeddedappl', u'intens embeddedappl e', u'intens embeddedappl store', u'intens embeddeddur', u'intens embeddeddur infer', u'intens fcn-basic', u'intens fcn-basic variantanoth', u'intens fcn-basic variantimpli', u'intens test', u'intens test time', u'intens variant', u'intens variant segnet', u'inter', u'inter class', u'inter class boundari', u'inter-class', u'inter-class boundari', u'inter-class boundari delin', u'interact', u'interact autonom', u'interact autonom drive', u'interestfor', u'interestfor autonom', u'interestfor autonom drive', u'interestfor various', u'interestfor various autonom', u'interesti', u'interesti road', u'interesti road scene', u'interestinglarg', u'interestinglarg differ', u'interestinglarg differ view', u'interestingsinc', u'interestingsinc input', u'interestingsinc input modal', u'interestonlin', u'interestonlin demo', u'interestonlin demo road', u'interesttask', u'interesttask indoor', u'interesttask indoor scene', u'interestto', u'interestto sever', u'interestto sever augment', u'interm', u'interm decod', u'interm decod decod', u'intern', u'intern confer', u'intern confer comput', u'intern confer oncomput', u'intern confer onnetwork', u'intern confer pages2190\\u20132197', u'intern confer pagesclass-label', u'intern covari', u'intern covari shift', u'intern journal', u'intern journal comput', u'intern publish', u'intern publish 1note', u'intern publish 1what', u'internationalconfer', u'internationalconfer multimedia', u'internationalconfer multimedia pp', u'internationalfast', u'internationalfast featur', u'internationalfast featur embed', u'internationalimag', u'internationalimag understand', u'internationalimag understand multi-class', u'internationaljourn', u'internationaljourn comput', u'internationaljourn comput vision', u'internationallectur', u'internationallectur note', u'internationallectur note comput', u'internationalpublish', u'internationalpublish 2014publish', u'internationalpublish 2014publish 2014publish', u'internet', u'internet fig', u'internet fig demonstr', u'interpol', u'interpol anoth', u'interpol anoth reason', u'interpol basedfrom', u'interpol basedfrom tabl', u'interpol basedupsampl', u'interpol basedupsampl ani', u'interpol depth', u'interpol depth valu', u'interpol weight', u'interpol weight fcn', u'interpol weight improv', u'interpol weight therefor', u'interpol weight use', u'interpret', u'interpret note', u'interpret note forclear', u'interpret note forshallow', u'intersect', u'intersect overth', u'intersect overth highest', u'intersect overunion', u'intersect overunion score', u'intersect union', u'intersect union i/u', u'intersect union miou', u'inth', u'inth dataset', u'inth impact', u'inth impact dens', u'inth time', u'inth time point', u'inth train', u'inth train set', u'inth univers', u'inth univers auckland', u'inthat', u'inthat bayesian', u'inthat bayesian segnet', u'intoabout', u'intoabout segnet', u'intoabout segnet featur', u'intow', u'intow perform', u'intow perform ablat', u'intrigu', u'intrigu properti', u'intrigu properti neurali', u'intrigu properti neuralnetwork', u'introduc', u'introduc deeper', u'introduc deeper layer', u'introduc increas', u'introduc increas spatial', u'introduction1', u'introduction1 introduction1', u'introduction1 introduction1 introduction1', u'introduction1 introduction1 introductionsemant', u'introduction1 introductionsemant', u'introduction1 introductionsemant segment', u'introductionsemant', u'introductionsemant segment', u'introductionsemant segment import', u'introductionsemant segment requir', u'inuncertainti', u'inuncertainti frequenc', u'inuncertainti frequenc class', u'inv', u'inv vanhouck', u'inv vanhouck rabinovich', u'invari', u'invari featur', u'invari featur hierarchi', u'invari robustclassif', u'invari robustclassif correspond', u'invari robustsub-sampl', u'invari robustsub-sampl achiev', u'invariancea', u'invariancea factor', u'invariancea factor max-pool', u'invarianceov', u'invarianceov small', u'invarianceov small spatial', u'invers', u'invers convolut', u'invers convolut usinga', u'invers convolut usingnetwork', u'invers frequencyor', u'invers frequencyor ani', u'invers frequencyweight', u'invers frequencyweight class', u'invers relationship', u'invers relationship class', u'invers relationship model', u'invers relationship uncertainti', u'involv', u'involv achiev', u'involv achiev good', u'involv betweenmemori', u'involv betweenmemori accuraci', u'involv betweenscor', u'involv betweenscor onc', u'involv comput', u'involv comput precisionand', u'involv comput precisionth', u'involv design', u'involv design segment', u'involv differ', u'involv differ knownarchitectur', u'involv differ knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor', u'involv differ knownrev', u'involv store', u'involv store onli', u'in\\u201d', u'in\\u201d miss', u'in\\u201d miss car', u'iou', u'iou result', u'iou result method', u'ioumethodmethodmethodmethodmethodmethodmethoddil', u'ioumethodmethodmethodmethodmethodmethodmethoddil network', u'iouparamet', u'iouparamet pascal', u'iouparamet pascal voc', u'is1/8th', u'is1/8th input', u'is1/8th input dimens', u'isa', u'isa spatial', u'isa spatial context', u'isaccuraci', u'isaccuraci class', u'isaccuraci class frequenc', u'isbacktrack', u'isbacktrack input', u'isbacktrack input imag', u'isbalanc', u'isbalanc train', u'isbalanc train loss', u'isbas', u'isbas convolut', u'isbas convolut layer', u'isbroad', u'isbroad applic', u'isbroad applic number', u'iscan', u'iscan wide', u'iscan wide vari', u'ischosen', u'ischosen provid', u'ischosen provid wide', u'isconvolut', u'isconvolut decod', u'isconvolut decod network', u'iscorrect', u'iscorrect classifi', u'iscorrect classifi dataset', u'iscuss', u'iscuss futur', u'iscuss futur workd', u'iscuss futur workdeep', u'isdimension', u'isdimension reduct', u'isdimension reduct step', u'isedg', u'isedg error', u'isedg error depth', u'isfast', u'isfast dure', u'isfast dure infer', u'isfrom', u'isfrom correspond', u'isfrom correspond encod', u'isgener', u'isgener veri', u'isgener veri high', u'isi', u'isi clear', u'isi clear better', u'isillustr', u'isillustr fig', u'isillustr fig featur', u'isimpli', u'isimpli unlik', u'isimpli unlik fcn-basic', u'isimport', u'isimport retain', u'isimport retain boundari', u'iskernel', u'iskernel size', u'iskernel size encod', u'islay', u'islay use', u'islay use time', u'islearn', u'islearn feed-forward', u'islearn feed-forward represent', u'ismad', u'ismad better', u'ismad better ani', u'ismain', u'ismain delin', u'ismain delin class', u'ismodel', u'ismodel predict', u'ismodel predict incorrect', u'ismor', u'ismor confid', u'ismor confid class', u'ismoreov', u'ismoreov section', u'isno', u'isno increas', u'isno increas perform', u'isnot', u'isnot compress', u'isnot compress k', u'isobject', u'isobject base', u'isobject base shape', u'isrow', u'isrow segnet', u'isrow segnet pre-train', u'issegnet-bas', u'issegnet-bas base', u'issegnet-bas base model', u'isstop', u'isstop decod', u'isstop decod ignor', u'issu', u'issu need', u'issu need reus', u'issu trainingher', u'issu trainingher note', u'issu trainingthes', u'issu trainingthes larger', u'istechniqu', u'istechniqu import', u'istechniqu import design', u'isth', u'isth contribut', u'isth contribut segment', u'isth hardest', u'isth hardest challeng', u'isth largest', u'isth largest model', u'isth mean', u'isth mean predict', u'isth vgg16', u'isth vgg16 classif', u'isthat', u'isthat differ', u'isthat differ dataset', u'istherefor', u'istherefor memori', u'istherefor memori effici', u'isthes', u'isthes low', u'isthes low resolut', u'istrain', u'istrain epoch', u'istrain epoch kitti', u'iswith', u'iswith deeper', u'iswith deeper layer', u'iswould', u'iswould reduc', u'iswould reduc core', u'itabsorb', u'itabsorb larg', u'itabsorb larg train', u'italso', u'italso indic', u'italso indic contribut', u'itand', u'itand comput', u'itand comput time', u'itconvolv', u'itconvolv upsampl', u'itconvolv upsampl map', u'iter', u'iter atleast', u'iter atleast 150epoch', u'iter atleast 150we', u'iter global', u'iter global accuracyi', u'iter global accuracytrain', u'iter mini', u'iter mini batch', u'iter mini-batch', u'iter mini-batch 10epoch', u'iter mini-batch 10the', u'iter ofoptim', u'iter ofoptim camvid', u'iter ofw', u'iter ofw test', u'iter overal', u'iter overal segnet-basicha', u'iter overal segnet-basicth', u'iter segnet', u'iter segnet theirmetr', u'iter segnet theirthes', u'iter whichbenchmark', u'iter whichbenchmark perform', u'iter whichgiven', u'iter whichgiven mini-batch', u'iteratur', u'iteratur r', u'iteratur r eviewl', u'iteratur r eviewsemant', u'iterggc', u'iterggc miou', u'iterggc miou bfc', u'itermax', u'itermax iterggc', u'itermax iterggc miou', u'itermax itermax', u'itermax itermax iterggc', u'itermax itermax itermax', u'itpool', u'itpool store', u'itpool store pass', u'itsfig', u'itsfig illustr', u'itsfig illustr segnet', u'itsinput', u'itsinput use', u'itsinput use transfer', u'itssemi-supervis', u'itssemi-supervis variant', u'itssemi-supervis variant decoupl', u'itsth', u'itsth recent', u'itsth recent propos', u'itwith', u'itwith import', u'itwith import variant', u'j', u'j bernoulli', u'j bernoulli pi', u'j defin', u'j defin bi', u'j defin j', u'j fj', u'j fj jnni', u'jacard', u'jacard index', u'jacard index mostcommon', u'jacard index mostth', u'japan', u'japan join', u'japan join depart', u'jayasumana', u'jayasumana b', u'jayasumana b romera-pared', u'jesus', u'jesus colleg', u'jesus colleg becamea', u'jesus colleg becamejapan', u'jia', u'jia p', u'jia p sermanet', u'jiang', u'jiang local', u'jiang local label', u'jnni', u'jnni given', u'jnni given layer', u'join', u'join depart', u'join depart engin', u'joint', u'joint featur', u'joint featur learn', u'joint model', u'joint model textur', u'joint optimis', u'joint optimis weight', u'joint reconstruct', u'joint reconstruct semant', u'joint reconstruct semanticapproach', u'joint reconstruct semanticsegment', u'joint train', u'joint train architectur', u'joint train help', u'joint train howev', u'journal', u'journal artifici', u'journal artifici intellig', u'journal comput', u'journal comput vision', u'journal machin', u'journal machin learn', u'just', u'just begun', u'just begun attemptsha', u'just begun attemptsto', u'just epoch', u'just epoch denot', u'just epoch train', u'justifi', u'justifi setagainst', u'justifi setagainst accuraci', u'justifi setto', u'justifi setto understand', u'k', u'k channel', u'k channel ad', u'k channel befor', u'k channel final', u'k channel imag', u'k dimension', u'k dimension convolut', u'k k', u'k k dimension', u'k murphi', u'k murphi yuill', u'k number', u'k number ofclass', u'k number ofwith', u'k theclassifi', u'k theclassifi k', u'k thenumb', u'k thenumb class', u'k thenumb classesnumb', u'k theoutput', u'k theoutput soft-max', u'k trainabl', u'k trainabl filter', u'karpathi', u'karpathi khosla', u'karpathi khosla m', u'kavukcuoglu', u'kavukcuoglu et', u'kavukcuoglu et al', u'kavukcuogluet', u'kavukcuogluet al', u'kavukcuogluet al use', u'kavukcuogluinput', u'kavukcuogluinput discrep', u'kavukcuogluinput discrep correct', u'kawasaki', u'kawasaki japan', u'kawasaki japan join', u'kawasaki research', u'kawasaki research develop', u'kendal', u'kendal graduat', u'kendal graduat bachelor', u'kendal r', u'kendal r cipolla', u'kendal roberto', u'kendal roberto cipolla', u'kendallalex', u'kendallalex kendallalex', u'kendallalex kendallalex kendallalex', u'kendallalex kendallalex kendallvijay', u'kendallalex kendallvijay', u'kendallalex kendallvijay badrinarayananvijay', u'kendallvijay', u'kendallvijay badrinarayananvijay', u'kendallvijay badrinarayananvijay badrinarayananvijay', u'kernel', u'kernel decreasecontext', u'kernel decreasecontext larger', u'kernel decreaseth', u'kernel decreaseth trade-off', u'kernel fcn-basic-noaddit', u'kernel fcn-basic-noaddit addit', u'kernel fcn-basic-noaddit onli', u'kernel follow', u'kernel follow non-linear', u'kernel initializedoutput', u'kernel initializedoutput decod', u'kernel initializedus', u'kernel initializedus bilinear', u'kernel set', u'kernel set decod', u'kernel set thea', u'kernel set thekernel', u'kernel size', u'kernel size layer', u'kernel unit', u'kernel unit l2', u'kernelsand', u'kernelsand non-overlap', u'kernelsand non-overlap max', u'kernelsspati', u'kernelsspati context', u'kernelsspati context layer', u'key', u'key compon', u'key compon ofrec', u'key compon ofsegnet', u'key design', u'key design factorsnecessari', u'key design factorstheir', u'key idea', u'key idea comput', u'key learningarchitectur', u'key learningarchitectur propos', u'key learningmodul', u'key learningmodul encoder-decod', u'keylearn', u'keylearn modul', u'keylearn modul encoder-decod', u'keyour', u'keyour work', u'keyour work inspir', u'khosla', u'khosla m', u'khosla m bernstein', u'ki', u'ki advancesin', u'ki advancesin artifici', u'ki advancesscen', u'ki advancesscen gpu-acceler', u'ki bi', u'ki bi j', u'ki wi', u'ki wi mi', u'kitti', u'kitti dataset', u'kitti dataset contain', u'kitti dataset largest', u'kitti dataset segnetperform', u'kitti dataset segnett', u'kitti dataset train', u'kitti indoor', u'kitti indoor scene', u'kitti sampl', u'kitti sampl onli', u'kitti test', u'kitti test set', u'kitti train', u'kitti train set', u'kitti train setar', u'kitti train setrow', u'kitti vision', u'kitti vision benchmark', u'kl', u'kl diverg', u'kl diverg approxim', u'kl q', u'kl q w', u'know', u'know confid', u'know confid wefigur', u'know confid wesystem', u'know model', u'know model uncertainti', u'knowledg', u'knowledg machin', u'knowledg machin learn', u'knowledgefor', u'knowledgefor pixel-wis', u'knowledgefor pixel-wis label', u'knowledgethi', u'knowledgethi deep', u'knowledgethi deep learn', u'known', u'known algorithm', u'known algorithm unari', u'known asbayesian', u'known asbayesian neural', u'known asneur', u'known asneur network', u'known benchmark', u'known benchmark dataset', u'known datasetssegnet', u'known datasetssegnet perform', u'known datasetsto', u'known datasetsto achiev', u'known deep', u'known deep architectur', u'known deeplab-largefov', u'known deeplab-largefov deconvnet', u'known dropout', u'known dropout commonlytrain', u'known dropout commonlyus', u'known jacard', u'known jacard index', u'knownarchitectur', u'knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor', u'knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor futur', u'knownarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesarchitecturesfor futur like', u'knownrev', u'knownrev practic', u'knownrev practic trade-off', u'kokkino', u'kokkino k', u'kokkino k murphi', u'kullback-leibl', u'kullback-leibl kl', u'kullback-leibl kl diverg', u'l', u'l fei-fei', u'l fei-fei journal', u'l fei-fei karpathi', u'l najman', u'l najman y', u'l zitnick', u'l zitnick \\u201cmicrosoft', u'l-bfgs', u'l-bfgs base', u'l-bfgs base compar', u'l-bfgs faster', u'l-bfgs faster morengiam', u'l-bfgs faster morest', u'l-bfgs particular', u'l-bfgs particular auto-encod', u'l2', u'l2 norm', u'l2 normth', u'l2 normth soft-max', u'l2 normw', u'l2 normw obtain', u'l4', u'l4 830segnet', u'l4 830segnet sm', u'l4 high', u'l4 high qualiti', u'l4 segnet', u'l4 segnet l4', u'lab', u'lab depart', u'lab depart engin', u'label', u'label aconst', u'label aconst kernel', u'label activ', u'label activ semant', u'label addit', u'label addit ofeach', u'label addit ofpervis', u'label apixel', u'label apixel deepest', u'label appear', u'label appear dataset', u'label best', u'label best knowledgefor', u'label best knowledgethi', u'label car', u'label car column', u'label car reason', u'label common', u'label common multi-scal', u'label compar', u'label compar withloc', u'label compar withproduc', u'label comparison', u'label comparison nyu', u'label consist', u'label corr', u'label corr vol', u'label cvpr', u'label cvpr 2014imag', u'label cvpr 2014label', u'label cvpr 6convolut', u'label cvpr 6semant', u'label data', u'label data independ', u'label descriptor', u'label descriptor exampl', u'label descriptor local', u'label descriptor n/a807', u'label descriptor super', u'label eccv', u'label eccv label', u'label eccv page', u'label eccv pp', u'label frequenc', u'label frequenc areoth', u'label frequenc arestil', u'label frequenc bycombin', u'label frequenc bytest', u'label frequenc exist', u'label frequenc existbut', u'label frequenc existmeanwhil', u'label frequenc usingaddit', u'label frequenc usingaddress', u'label given', u'label given input', u'label iccv', u'label iccv class-label', u'label iccv pp', u'label icml', u'label icml page', u'label icml pp', u'label ieee', u'label ieee pami', u'label imbalancesin', u'label imbalancesin train', u'label imbalancesweight', u'label imbalancesweight class', u'label improv', u'label improv accuraci', u'label improv strikinglyat', u'label improv strikinglyvari', u'label initi', u'label initi approach', u'label layer', u'label layer shown', u'label loss', u'label lossoth', u'label lossoth applic', u'label lossth', u'label lossth cross-entropi', u'label measur', u'label measur model', u'label method', u'label method lack', u'label model', u'label model uncertainti', u'label onli', u'label onli featur', u'label pixelchosen', u'label pixelchosen provid', u'label pixelin', u'label pixelin deepest', u'label predict', u'label predict fulli', u'label predict pixel', u'label problem', u'label problem howev', u'label recent', u'label recent approach', u'label result', u'label result smooth', u'label result veri', u'label resultand', u'label resultand smooth', u'label resulther', u'label resulther larg', u'label segnet', u'label segnet sever', u'label shown', u'label shown black', u'label smallercategori', u'label smallercategori dataset', u'label smallerin', u'label smallerin dataset', u'label space', u'label space ani', u'label test', u'label test perform', u'label transit', u'label weoften', u'label weoften observ', u'label wesegment', u'label wesegment especi', u'label y', u'labelcross-entropi', u'labelcross-entropi loss', u'labelcross-entropi loss mini-batch', u'labeleffect', u'labeleffect featur', u'labeleffect featur activ', u'labellingarxiv:1505', u'labellingarxiv:150507293v1', u'labellingarxiv:150507293v1 cscv', u'labellingarxiv:150507293v1 cscv 2015arxiv:150507293v1', u'labellingof', u'labellingof recent', u'labellingof recent approach', u'labellingsemant', u'labellingsemant pixel-wis', u'labellingsemant pixel-wis labellingarxiv:1505', u'labellingsemant pixel-wis labellingarxiv:150507293v1', u'labellingsemant pixel-wis labellingsemant', u'labellingthi', u'labellingthi primarili', u'labellingthi primarili becaus', u'labelm', u'labelm size', u'labelm size thea', u'labelm size thetrain', u'labelsa', u'labelsa feed-forward', u'labelsa feed-forward manner', u'labelsa highlight', u'labelsa highlight propos', u'labelsboth', u'labelsboth qualit', u'labelsboth qualit numer', u'labelsfor', u'labelsfor pixel', u'labelsfor pixel patch', u'labelslow', u'labelslow resolut', u'labelslow resolut encod', u'labelspac', u'labelspac recent', u'labelspac recent studi', u'labelsproduc', u'labelsproduc high', u'labelsproduc high qualiti', u'labelssever', u'labelssever recent', u'labelssever recent propos', u'labelstim', u'labelstim requir', u'labelstim requir optim', u'labelsto', u'labelsto produc', u'labelsto produc high', u'labelthat', u'labelthat object', u'labelthat object remain', u'laboratori', u'laboratori depart', u'laboratori depart engin', u'laboratori differ', u'laboratori differ type', u'laboratori inappl', u'laboratori inappl deep', u'laboratori inof', u'laboratori inof cambridg', u'laboratori meet', u'laboratori meet room', u'lack', u'lack cue', u'lack cue height', u'lack cue segnet', u'lack good', u'lack good decod', u'lack ground', u'lack ground truth', u'lack mechan', u'lack mechan tofor', u'lack mechan tomap', u'lack sharp', u'lack sharp edg', u'lamp', u'lamp difficult', u'lamp difficult achiev', u'languag', u'languag recurs', u'languag recurs neural', u'larg', u'larg bankfactor', u'larg bankfactor consid', u'larg bankof', u'larg bankof model', u'larg class', u'larg class denseclutt', u'larg class densesom', u'larg class remark', u'larg class sucha', u'larg class suchscen', u'larg dataset', u'larg dataset canalso', u'larg dataset canweight', u'larg dataset indoor', u'larg dataset indoorscen', u'larg dataset indoorsun', u'larg datasetof', u'larg datasetof indoor', u'larg datasetsun', u'larg datasetsun rgb-d', u'larg deep', u'larg deep network', u'larg dimens', u'larg dimens acknowledg', u'larg drop', u'larg drop thebf', u'larg drop thefor', u'larg imagenet', u'larg imagenet object', u'larg imbal', u'larg imbal frequenc', u'larg inferencegrid', u'larg inferencegrid search', u'larg inferencetim', u'larg inferencetim dense-crf', u'larg inferencetim dense-crfstim', u'larg input', u'larg input imag', u'larg known', u'larg known datasetssegnet', u'larg known datasetsto', u'larg number', u'larg number class', u'larg number trainabl', u'larg ofon', u'larg ofon hand', u'larg oftrain', u'larg oftrain data', u'larg perform', u'larg perform improv', u'larg set', u'larg set ofweak', u'larg set ofwher', u'larg spatial', u'larg spatial contextfor', u'larg spatial contextof', u'larg static', u'larg static scene', u'larg sun', u'larg sun rgb-d', u'larg train', u'larg train dataset', u'larg train set', u'larg variabl', u'larg variabl indoor', u'larg variat', u'larg variat number', u'large-scal', u'large-scal imag', u'large-scal imag recognit', u'largeand', u'largeand miou', u'largeand miou improv', u'largebatch', u'largebatch use', u'largebatch use maxim', u'largefor', u'largefor code', u'largefor code evalu', u'largeimprov', u'largeimprov obtain', u'largeimprov obtain bf', u'larger', u'larger architectur', u'larger class', u'larger class individ', u'larger class inth', u'larger class reasonableaccuraci', u'larger class reasonablereport', u'larger comput', u'larger comput cost', u'larger dataset', u'larger dataset like', u'larger decod', u'larger decod increas', u'larger decod size', u'larger decod use', u'larger model', u'larger model fcnbasic-nodimreduct', u'larger model fcnbasic-nodimreductionanoth', u'larger model fcnbasic-nodimreductiontrain', u'larger model sinc', u'larger model sucha', u'larger model suchmemori', u'larger model train', u'larger network', u'larger network importantto', u'larger network importanttrain', u'larger number', u'larger number class', u'larger parameter', u'larger parameter deconvnet', u'larger parameter needsdiffer', u'larger parameter needsmor', u'larger perform', u'larger perform improv', u'larger potenti', u'larger potenti destroy', u'larger segnet-bas', u'larger segnet-bas sinc', u'larger size', u'larger size dataset', u'larger spatial', u'larger spatial context', u'larger valu', u'largerboth', u'largerboth learn', u'largerboth learn produc', u'largerdecod', u'largerdecod import', u'largerdecod import captur', u'largerdecod lead', u'largerdecod lead better', u'largermodel', u'largermodel deconvnet', u'largermodel deconvnet median', u'largernetwork', u'largernetwork fcn-basic', u'largernetwork fcn-basic endow', u'largersam', u'largersam number', u'largersam number train', u'largersegnet', u'largersegnet becaus', u'largersegnet becaus difficult', u'largerterm', u'largerterm decod', u'largerterm decod decod', u'largerth', u'largerth decod', u'largerth decod network', u'largerus', u'largerus max-pool', u'largerus max-pool indic', u'largest', u'largest benchmark', u'largest benchmark dataset', u'largest converg', u'largest converg sgd', u'largest model', u'largest model ineffici', u'largest public', u'largest public avail', u'largetrain', u'largetrain set', u'largetrain set henc', u'late', u'late handwritten', u'late handwritten digit', u'later', u'later paper', u'later paper sec', u'later work', u'later work featur', u'later work lower', u'layer', u'layer 4segnet', u'layer 4segnet layer', u'layer 505tabl', u'layer 505tabl quantit', u'layer ad', u'layer ad demonstr', u'layer ad result', u'layer andbatch', u'layer andbatch use', u'layer andth', u'layer andth soft-max', u'layer architectur', u'layer architectur encod', u'layer asfor', u'layer asfor fcn', u'layer asoppos', u'layer asoppos fix', u'layer assign', u'layer assign map', u'layer astudi', u'layer astudi effect', u'layer atrain', u'layer atrain network', u'layer batch', u'layer batch normalis', u'layer bayesiansegnet', u'layer bayesiansegnet add', u'layer bayesianth', u'layer bayesianth central', u'layer chosen', u'layer chosen provid', u'layer classifi', u'layer classifi pixel', u'layer comparison', u'layer comparison method', u'layer comparisondecod', u'layer comparisondecod featur', u'layer comparisonfcn-bas', u'layer comparisonfcn-bas use', u'layer comput', u'layer comput featur', u'layer convolut', u'layer convolut layer', u'layer convolut network', u'layer correspond', u'layer correspond 13convolut', u'layer correspond 13of', u'layer decod', u'layer decod help', u'layer deconvnet', u'layer deconvnet 1024featur', u'layer deconvnet 1024so', u'layer deconvolut', u'layer deconvolut network', u'layer denot', u'layer denot segnet', u'layer differ', u'layer differ approach', u'layer doe', u'layer doe result', u'layer dure', u'layer dure studi', u'layer dure studyeach', u'layer dure studyfigur', u'layer e', u'layer eachbas', u'layer eachbas convolut', u'layer eachfor', u'layer eachfor encod', u'layer empir', u'layer empir observ', u'layer encod', u'layer encod correspond', u'layer encod decoderaft', u'layer encod decodernetwork', u'layer encod network', u'layer encod sequenc', u'layer encoder-decod', u'layer encoder-decod weight', u'layer encoderdecod', u'layer encoderdecod fig', u'layer everi', u'layer everi convolut', u'layer favour', u'layer favour retainingalso', u'layer favour retaininghigh', u'layer featur', u'layer featur block', u'layer featur imag', u'layer featur map', u'layer featureclass', u'layer featureclass compress', u'layer featuremap', u'layer featuremap input', u'layer featuresin', u'layer featuresin block', u'layer featuresto', u'layer featuresto appli', u'layer fewer', u'layer fewer morefin', u'layer fewer morewith', u'layer final', u'layer final decod', u'layer follow', u'layer follow upsampl', u'layer forbatch', u'layer forbatch normal', u'layer fordeeplab-largefov', u'layer fordeeplab-largefov chang', u'layer hasa', u'layer hasa spatial', u'layer hasand', u'layer hasand non-overlap', u'layer henc', u'layer henc decod', u'layer henc onli', u'layer ii', u'layer ii benefici', u'layer includ', u'layer includ sub-sampl', u'layer indic', u'layer indic deeper', u'layer ischosen', u'layer ischosen provid', u'layer iskernel', u'layer iskernel size', u'layer isrow', u'layer isrow segnet', u'layer istrain', u'layer istrain epoch', u'layer max-pool', u'layer max-pool andin', u'layer max-pool andsub-sampl', u'layer mimic', u'layer mimic sharp', u'layer model', u'layer model prevent', u'layer network', u'layer network encod', u'layer non-overlap', u'layer non-overlap max-pooling-subsamplingbeen', u'layer non-overlap max-pooling-subsamplinglay', u'layer ofa', u'layer ofa deep', u'layer ofappl', u'layer ofappl e', u'layer ofappl store', u'layer offcn-bas', u'layer offcn-bas resolut', u'layer ofspac', u'layer ofspac recent', u'layer onli', u'layer onli better', u'layer onli class', u'layer onli reli', u'layer order', u'layer order avoid', u'layer overal', u'layer overal result', u'layer pixel', u'layer pixel labeleffect', u'layer pixel labelspac', u'layer pooling-subsamplingcan', u'layer pooling-subsamplingcan introduc', u'layer pooling-subsamplingdecod', u'layer pooling-subsamplingdecod learn', u'layer produc', u'layer produc qualit', u'layer question', u'layer question vari', u'layer reduc', u'layer reduc number', u'layer remain', u'layer remain case', u'layer representations/featur', u'layer representations/featur map', u'layer retain', u'layer retain high', u'layer segnet', u'layer segnet architectur', u'layer segnet given', u'layer segnet just', u'layer segnet kernelsand', u'layer segnet kernelsspati', u'layer segnet nowcomput', u'layer segnet nowfor', u'layer segnet random', u'layer segnet variant', u'layer segnet-basicarchitectur', u'layer segnet-basicarchitectur test', u'layer segnet-basicfor', u'layer segnet-basicfor analysi', u'layer shape', u'layer shape andcontextu', u'layer shape andwith', u'layer shown', u'layer shown fig', u'layer soft-max', u'layer soft-max classifi', u'layer soft-max layer', u'layer suggest', u'layer suggest subset', u'layer thebi', u'layer thebi pixel-wis', u'layer thevgg16', u'layer thevgg16 network', u'layer thisarchitectur', u'layer thisarchitectur illustr', u'layer thisnetwork', u'layer thisnetwork follow', u'layer toextrem', u'layer toextrem add', u'layer toth', u'layer toth correspond', u'layer trace', u'layer trace acontext', u'layer trace ain', u'layer train', u'layer train random', u'layer train set', u'layer train slowli', u'layer train use', u'layer turn', u'layer turn convolut', u'layer typic', u'layer typic set', u'layer unitseveri', u'layer unitseveri k', u'layer unitsj', u'layer unitsj defin', u'layer unknown', u'layer unknown class', u'layer use', u'layer use featur', u'layer usingcomput', u'layer usingcomput layer', u'layer usingth', u'layer usingth entir', u'layer vgg-16', u'layer vgg-16 network', u'layer vgg-16 networkat', u'layer vgg-16 networkend-to-end', u'layer vgg16', u'layer vgg16 encod', u'layer vgg16 make', u'layer vgg16 network', u'layer vgg16 remov', u'layer wise', u'layer wise featur', u'layer \\u201ctuned\\u201d', u'layer \\u201ctuned\\u201d certain', u'layer-wis', u'layer-wis featur', u'layer-wis featur learn', u'layer-wis train', u'layer-wis train segnet-bas', u'layer-wis weight', u'layer-wis weight initializationor', u'layer-wis weight initializationwithout', u'layer3', u'layer3 speedup', u'layer3 speedup gain', u'layer75', u'layer750', u'layer750 843boost', u'layer750 843boost pairwis', u'layerdeep', u'layerdeep segnet', u'layerdeep segnet camvid', u'layerencod', u'layerencod featur', u'layerencod featur map', u'layerfeatur', u'layerfeatur activ', u'layerfeatur activ layer3', u'layerfeatur activ layerfeatur', u'layerha', u'layerha correspond', u'layerha correspond decod', u'layerlayerlayerlayerlayerlayeral', u'layerlayerlayerlayerlayerlayeral featuresal', u'layerlayerlayerlayerlayerlayeral featuresal featuresal', u'layeron', u'layeron hand', u'layeron hand use', u'layerrec', u'layerrec architectur', u'layerrec architectur tabl', u'layersan', u'layersan encod', u'layersan encod unit', u'layersconnect', u'layersconnect layersconnect', u'layersconnect layersconnect layersconnect', u'layersconnect layersconnect layersin', u'layersconnect layersin', u'layersconnect layersin order', u'layersegnet', u'layersegnet layer75', u'layersegnet layer750', u'layersegnet layer750 843boost', u'layersegnet layersegnet', u'layersegnet layersegnet layer75', u'layersegnet layersegnet layer750', u'layersegnet layersegnet layersegnet', u'layersfollow', u'layersfollow max', u'layersfollow max pool', u'layersin', u'layersin order', u'layersin order perform', u'layersloc', u'layersloc patch', u'layersloc patch base', u'layersof', u'layersof featur', u'layersof featur encod', u'layerssegnet', u'layerssegnet layerssegnet', u'layerssegnet layerssegnet layerssegnet', u'layerssegnet layerssegnet layerswith', u'layerssegnet layerswith', u'layerssegnet layerswith onli', u'layerswith', u'layerswith onli', u'layerswith onli localwith', u'layerth', u'layerth current', u'layerth current state', u'layertherefor', u'layertherefor memori', u'layertherefor memori effici', u'layerweight', u'layerweight vgg', u'layerweight vgg net', u'layout', u'layout context', u'lbp', u'lbp region', u'lbp region segment', u'lbp regionmad', u'lbp regionmad use', u'lbp regionsegment', u'lbp regionsegment obtain', u'lcn', u'lcn pre-process', u'lcn pre-process step', u'lead', u'lead better', u'lead better perform', u'lead loss', u'lead loss edg', u'lead network', u'lead network learn', u'lead thebest', u'lead thebest perform', u'lead thedimension', u'lead thedimension reduct', u'lead toear', u'lead toear encod', u'lead tosharp', u'lead tosharp class', u'leader', u'leader board', u'leader board http', u'leaderboardhost', u'leaderboardth', u'leaderboardth bayesian', u'leaderboardth bayesian approach', u'leap', u'leap mountain', u'leap mountain view', u'learn', u'learn 2009for', u'learn 2009for scene', u'learn 2009semant', u'learn 2009semant feedback', u'learn allow', u'learn allow comput', u'learn anencoder-decod', u'learn anencoder-decod stack', u'learn angen', u'learn angen model', u'learn appli', u'learn appli imag', u'learn approach', u'learn approach reconstruct', u'learn approach scene', u'learn approach whichhav', u'learn approach whichinput', u'learn approxim', u'learn approxim 12m', u'learn architectur', u'learn architectur pixel', u'learn architectur propos', u'learn architectur trainedw', u'learn architectur trainedwith', u'learn artifici', u'learn artifici intellig', u'learn better', u'learn better particular', u'learn capabl', u'learn capabl structur', u'learn categori', u'learn categori shape', u'learn class', u'learn class spatial', u'learn convolut', u'learn convolut featurehierarchi', u'learn convolut featurem', u'learn dcnn', u'learn dcnn semant', u'learn decod', u'learn decod advantag', u'learn decod filter', u'learn deconv', u'learn deconv deconvnet', u'learn deconv fcn', u'learn deconvolut', u'learn deconvolut layer', u'learn deconvolveth', u'learn deconvolveth input', u'learn deconvolveto', u'learn deconvolveto upsampl', u'learn deep', u'learn deep segmentationarchitectur', u'learn deep segmentationscen', u'learn distribut', u'learn distribut network', u'learn distribut weight', u'learn facilit', u'learn facilit continu', u'learn featur', u'learn featur hierarchi', u'learn featur map', u'learn framework', u'learn framework probabilisticpixel-wis', u'learn framework probabilisticw', u'learn hierarch', u'learn hierarch encod', u'learn icml', u'learn icml page', u'learn ina', u'learn ina y', u'learn inicml', u'learn inicml page', u'learn invari', u'learn invari featur', u'learn magic', u'learn magic leap', u'learn map', u'learn map deepest', u'learn map encod', u'learn map input', u'learn maplow', u'learn maplow resolut', u'learn mapthi', u'learn mapthi deep', u'learn method', u'learn method learn', u'learn method use', u'learn mobil', u'learn mobil robot', u'learn mobil roboticsappl', u'learn mobil roboticsroberto', u'learn model', u'learn model achiev', u'learn model infer', u'learn model usingperform', u'learn model usingth', u'learn output', u'learn output measur', u'learn perform', u'learn perform worst', u'learn produc', u'learn produc dens', u'learn puriti', u'learn puriti tree', u'learn rate', u'learn rate momentum', u'learn rate momentumof', u'learn rate momentumsgd', u'learn rate smaller', u'learn rate tune', u'learn rateof', u'learn rateof momentum', u'learn rateus', u'learn rateus stochast', u'learn research', u'learn research r', u'learn research,15', u'learn reusingmax-pool', u'learn reusingmax-pool indic', u'learn reusingtheir', u'learn reusingtheir input', u'learn scene', u'learn scene segmentationha', u'learn scene segmentationth', u'learn scheme3', u'learn scheme3 segnet', u'learn schemea', u'learn schemea layer', u'learn seen', u'learn seen huge', u'learn seenhug', u'learn seenhug success', u'learn seenlearn', u'learn seenlearn algorithm', u'learn segment', u'learn segment robust', u'learn set', u'learn set benchmark', u'learn spatial', u'learn spatial context/class', u'learn task', u'learn task henc', u'learn techniqu', u'learn techniqu problem', u'learn toperform', u'learn toperform better', u'learn towithout', u'learn towithout class', u'learn upsampl', u'learn upsampl base', u'learn upsampl bilinear', u'learn upsampl fcn-basic', u'learn upsampl fromand', u'learn upsampl fromlow', u'learn upsampl input', u'learn upsampl kernel', u'learn upsampl low', u'learn upsampl upsampl', u'learn use', u'learn use small', u'learn veri', u'learn veri slowli', u'learn workshop', u'learn workshop icml', u'learndecod', u'learndecod segment', u'learndecod segment support', u'learnet', u'learnet al', u'learnet al use', u'learnhierarch', u'learnhierarch encod', u'learnhierarch encod approach', u'learningarchitectur', u'learningarchitectur propos', u'learningarchitectur propos ranzato', u'learningdecod', u'learningdecod filter', u'learningdecod filter upsampl', u'learningmodul', u'learningmodul encoder-decod', u'learningmodul encoder-decod network', u'learningour', u'learningour work', u'learningour work inspir', u'learningus', u'learningus learn', u'learningus learn upsampl', u'learnperform', u'learnperform signific', u'learnperform signific better', u'learnt', u'learnt deconv', u'learnt deconv 160k8321', u'learnt deconv 200k6731', u'learnt deconv 31709317093170931709317093170931709484114841148411484114841148411484119735973597359735973518061806180618061806539539539539deconvnet', u'learnt deconv deconvnet', u'learnt deconv fcn', u'learnt deconvolut', u'learnt deconvolut clear', u'learnt deconvolutionalthough', u'learnt deconvolutionalthough smaller', u'learnt deconvolutioni', u'learnt deconvolutioni clear', u'learnt function', u'learnt function obtain', u'leav', u'leav particular', u'leav particular suscept', u'lectur', u'lectur fellow', u'lectur fellow jesus', u'lectureadv', u'lectureadv artifici', u'lectureadv artifici intellig', u'lecturenot', u'lecturenot comput', u'lecturenot comput scienc', u'lecun', u'lecun learn', u'lecun learn convolut', u'lecun \\u201clearn', u'lecun \\u201clearn convolut', u'lecun \\u201clearn hierarchicalc', u'lecun \\u201clearn hierarchicalfeatur', u'led', u'led research', u'led research exploit', u'ledof', u'ledof million', u'ledof million encount', u'ledto', u'ledto multi-stag', u'ledto multi-stag train', u'left', u'left camvid', u'left camvid center', u'left fig', u'left fig decod', u'left predict', u'left predict obtain', u'leg', u'leg chairsand', u'leg chairsand tabl', u'leg chairsus', u'leg chairsus segment', u'lend', u'lend evid', u'lend evid todecod', u'lend evid tosegnet', u'lessenedalso', u'lessenedalso indic', u'lessenedalso indic contribut', u'lessenedwhen', u'lessenedwhen suffici', u'lessenedwhen suffici train', u'lesser', u'lesser time', u'lesser time fact', u'level', u'level confid', u'level fcn-basic', u'level fcn-basic requir', u'level featur', u'level featur consist', u'level featur form', u'level import', u'level import tool', u'level uncertainti', u'levelsof', u'levelsof accuraci', u'levelsof accuraci valu', u'levelsvari', u'levelsvari level', u'levelsvari level confid', u'leverag', u'leverag thisdistribut', u'leverag thisdistribut network', u'leverag thismethod', u'leverag thismethod perform', u'liang-chieh', u'liang-chieh g', u'liang-chieh g papandreou', u'library0', u'librarygeforc', u'librarygeforc 880m', u'librarygeforc 880m gtxgeforce780', u'libraryw', u'libraryw implement', u'libraryw implement bayesian', u'libraryw wrote', u'libraryw wrote matlab', u'lie', u'lie manner', u'lie manner decod', u'light', u'light condit', u'light condit qualit', u'light-weight', u'light-weight matlab', u'light-weight matlab code', u'like', u'like add', u'like add effort', u'like boundari', u'like boundari f1-measur', u'like exploit', u'like exploit understand', u'like memoryand', u'like memoryand comput', u'like memoryand parameteris', u'like segnet', u'like segnet learn', u'like tonot', u'like tonot anoth', u'like toth', u'like toth camvid', u'like typic', u'like typic obtain', u'limit', u'limit variabl', u'limit variabl view', u'limit variat', u'limit variat term', u'lin', u'lin c', u'lin c man', u'linear', u'linear discriminantfunct', u'linear discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw', u'linear discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw wrote', u'linear discriminantth', u'linear discriminantth soft-max', u'link', u'link fig', u'link fig exampl', u'link techniqu', u'link techniqu variat', u'literatur', u'literatur describ', u'literatur describ segnet', u'literatur describ segnet2', u'literatur describ segnetarchitectur', u'literatur review2', u'literatur review2 literatur', u'literatur reviewsemant', u'literatur reviewsemant pixel-wis', u'littl', u'littl effect', u'littl effect accuraci', u'littl loss', u'littl loss perform', u'littl modif', u'littl modificationarchitectur', u'littl modificationarchitectur onli', u'littl modificationon', u'littl modificationon main', u'liu', u'liu et', u'liu et al', u'liu rabinovich', u'liu rabinovich c', u'liu y', u'liu y jia', u'live', u'live room', u'live room laboratori', u'load', u'load import', u'load import deploy', u'local', u'local bright', u'local bright color', u'local contrast', u'local contrast normal', u'local cvpr', u'local cvpr pp', u'local label', u'local label descriptor', u'localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm', u'localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm rgbnormal', u'localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm rgbnormal rgbnormal', u'localizationour', u'localizationour architectur', u'localizationour architectur segnet', u'localizationwhich', u'localizationwhich use', u'localizationwhich use accur', u'localwith', u'localwith onli', u'localwith onli localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm', u'localwith onli localwith', u'locat', u'locat comput', u'locat comput dure', u'locat comput duringeach', u'locat comput duringpool', u'locat inform', u'locat inform similar', u'locat input', u'locat input neural', u'locat maximum', u'locat maximum featur', u'long', u'long e', u'long e shelham', u'long time', u'long time given', u'longer', u'longer convergeand', u'longer convergeand perform', u'longer convergear', u'longer convergear redund', u'longer trainingfcn', u'longer trainingfcn did', u'longer trainingfor', u'longer trainingfor poor', u'longest', u'longest train', u'longest train time', u'look', u'look model', u'look model uncertainti', u'look wider', u'look wider seebett', u'look wider seew', u'loos', u'loos small', u'loos small class', u'lopez', u'lopezand', u'lopezand lopezand', u'lopezand lopezand lopezand', u'lopezand lopezand lopezvision-bas', u'lopezand lopezvision-bas', u'lopezand lopezvision-bas offline-onlin', u'lopezvision-bas', u'lopezvision-bas offline-onlin', u'lopezvision-bas offline-onlin perceptionvision-bas', u'loss', u'loss accuraci', u'loss accuraci buti', u'loss accuraci butthi', u'loss differ', u'loss differ base', u'loss edg', u'loss edg inform', u'loss function', u'loss function ratio', u'loss function segnet-bas', u'loss mini-batch', u'loss mini-batch unlik', u'loss object', u'loss object function', u'loss perform', u'loss perform reduc', u'loss spatial', u'loss spatial resolutionclassif', u'loss spatial resolutionof', u'loss sum', u'loss sum pixelsin', u'loss sum pixelstrain', u'loss2', u'loss2 http', u'loss2 http //miengcamacuk/projects/segnet/', u'lossconverg', u'lossconverg train', u'lossconverg train mini-batch', u'lossi', u'lossi boundari', u'lossi boundari featur', u'lossi boundari imag', u'lossof', u'lossof segnet-bas', u'lossof segnet-bas train', u'lossoptim', u'lossoptim camvid', u'lossoptim camvid valid', u'lossoth', u'lossoth applic', u'lossoth applic pixel', u'lossth', u'lossth cross-entropi', u'lossth cross-entropi label', u'lossth miou', u'lossth miou metric', u'lossthrough', u'lossthrough class', u'lossthrough class balanc', u'lost', u'lost fcn', u'lost fcn learnt', u'lot', u'lot regularityin', u'lot regularityin number', u'lot regularitysinc', u'lot regularitysinc view', u'low', u'low global', u'low global accuraci', u'low input', u'low input resolut', u'low inputlarg', u'low inputlarg correct', u'low inputresolut', u'low inputresolut lack', u'low level', u'low level featur', u'low miou', u'low miou boundari', u'low resolut', u'low resolut encod', u'low resolut featur', u'low resolut imag', u'low resolut predictionsneur', u'low resolut predictionsto', u'low resolut represent', u'low resolutiondiscuss', u'low resolutiondiscuss need', u'low resolutionfeatur', u'low resolutionfeatur map', u'low-level', u'low-level vision', u'low-level vision cue', u'lower', u'lower accuraci', u'lower accuraci beaccuraci', u'lower accuraci beimprov', u'lower compar', u'lower compar fcn-basic', u'lower layer', u'lower layer convolut', u'lower memori', u'lower memori storag', u'lower miou', u'lower miou deeplab-largefov', u'lower parameteris', u'lower parameteris competitor', u'lower resolut', u'lower resolut inputfeatur', u'lower resolut inputmap', u'lower thesam', u'lower thesam number', u'lower thesegnet-bas', u'lower thesegnet-bas test', u'lower train', u'lower train fit', u'lower trainingdecod', u'lower trainingdecod strong', u'lower trainingfit', u'lowlevel', u'lowlevel vision', u'lowlevel vision cue', u'lowlevel visual', u'lowlevel visual featur', u'lowprevi', u'lowprevi approach', u'lowprevi approach scene', u'lutz', u'lutz m', u'lutz m thielscher', u'm', u'm bernstein', u'm bernstein c', u'm multipli', u'm multipli time', u'm thielscher', u'm thielscher ed', u'machin', u'machin intellig', u'machin intellig lab', u'machin intellig laboratori', u'machin intellig vol', u'machin learn', u'machin learn allow', u'machin learn artifici', u'machin learn research', u'machin learn research,15', u'machin learn techniqu', u'machinelearn', u'machinelearn algorithm', u'machinelearn algorithm particular', u'machineobject', u'machineobject autonom', u'machineobject autonom drive', u'machinevehicl', u'machinevehicl drive', u'machinevehicl drive earli', u'madeoth', u'madeoth applic', u'madeoth applic pixel', u'madeus', u'madeus deep', u'madeus deep network', u'magic', u'magic leap', u'magic leap mountain', u'magnitud', u'magnitud adapt', u'magnitud adapt appropri', u'magnitud deep', u'magnitud deep learn', u'main', u'main advantag', u'main advantag crf-rnn', u'main becauselarg', u'main becauselarg correct', u'main becauseof', u'main becauseof low', u'main concentr', u'main concentr layer', u'main contribut', u'main contribut learn', u'main contribut paper', u'main delin', u'main delin class', u'main fact', u'main fact train', u'main focus', u'main focus layer-wis', u'main motiv', u'main motiv segnetfor', u'main motiv segnetwa', u'main result', u'main result improv', u'maintain', u'maintain competit', u'maintain competit accuraci', u'maintain constant', u'maintain constant number', u'maintain far', u'maintain far lower', u'major', u'major class', u'major class comparison', u'major pixel', u'major pixel belong', u'major pixel imageand', u'major pixel imageski', u'major scene', u'major scene domin', u'major task', u'major task foregroundclass', u'major task foregroundhowev', u'make', u'make benchmarkingan', u'make benchmarkingan import', u'make benchmarkingdiffer', u'make benchmarkingdiffer deep', u'make compat', u'make compat camvid', u'make convolut', u'make convolut faster', u'make easier', u'make easier optim', u'make fair', u'make fair comparison', u'make feasibl', u'make feasibl train', u'make hard', u'make hard train', u'make hardest', u'make hardest segmentationchalleng', u'make hardest segmentationimag', u'make memori', u'make memori intens', u'make offrequ', u'make offrequ partial', u'make ofth', u'make ofth hardest', u'make overal', u'make overal largernetwork', u'make overal largerth', u'make segnet', u'make segnet encoderconnect', u'make segnet encodernetwork', u'make training90', u'make training90 paramet', u'make trainingof', u'make trainingof network', u'make uncertain', u'make uncertain predict', u'make veri', u'make veri challeng', u'makegeforc', u'makegeforc 880m', u'makegeforc 880m gtxgeforce780', u'makeour', u'makeour light-weight', u'makeour light-weight matlab', u'makesit', u'makesit difficult', u'makesit difficult gather', u'makesrecip', u'makesrecip arriv', u'makesrecip arriv high', u'man', u'man y', u'man y ng', u'mani', u'mani architectur', u'mani architectur havemann', u'mani architectur haveus', u'mani combin', u'mani combin object', u'mani correct', u'mani correct fornon-uniform', u'mani correct forth', u'mani differ', u'mani differ class', u'mani differ variantsfcn-bas', u'mani differ variantss', u'mani framesmeasur', u'mani framesmeasur requir', u'mani framesto', u'mani framesto robust', u'mani occupya', u'mani occupya small', u'mani occupyon', u'mani occupyon reason', u'mani othernetwork', u'mani othernetwork signific', u'mani otherrec', u'mani otherrec architectur', u'manner', u'manner decod', u'manner decod upsampl', u'manner pixel-wis', u'manner pixel-wis label', u'manner pixel-wis semant', u'manner report', u'manner report sever', u'manner upsampl', u'manner upsampl term', u'map', u'map 542segnet', u'map 542segnet layer', u'map 821structur', u'map 821structur random', u'map 863d', u'map 863d seman', u'map accurateand', u'map accurateand smooth', u'map accuratemeaning', u'map accuratemeaning featur', u'map add', u'map add correspond', u'map addit', u'map addit step', u'map address', u'map address import', u'map althoughit', u'map althoughit encod', u'map althoughth', u'map althoughth input', u'map aresimpli', u'map aresimpli upsampl', u'map arethen', u'map arethen batch', u'map arew', u'map arew tri', u'map arewith', u'map arewith filter', u'map better', u'map better class', u'map central', u'map central topic', u'map compar', u'map compar propos', u'map compress', u'map compress match', u'map comput', u'map comput camvid', u'map consum', u'map consum memori', u'map convolv', u'map convolv witha', u'map convolv withillustr', u'map convolvedupsampl', u'map convolvedupsampl step', u'map convolvedwith', u'map convolvedwith trainabl', u'map cost', u'map cost memori', u'map decod', u'map decod layer', u'map deepest', u'map deepest encod', u'map deepest layer', u'map dens', u'map dens depth', u'map differentat', u'map differentat scale', u'map differentlay', u'map differentlay singl', u'map dimensionalityreduct', u'map dimensionalityreduct max-pool', u'map dimensionalitywhen', u'map dimensionalitywhen memori', u'map direct', u'map direct byboth', u'map direct bylearn', u'map eccv', u'map eccv pages708\\u2013721', u'map eccv pagesof', u'map eccv pp', u'map encod', u'map encod output', u'map fcn-basic', u'map fcn-basic segnet-bas', u'map fed', u'map fed soft-max', u'map final', u'map final decod', u'map foreach', u'map foreach sampl', u'map formax-pool', u'map formax-pool sub-sampl', u'map idea', u'map idea inspir', u'map increas', u'map increas lossi', u'map indoor', u'map indoor scene', u'map infer', u'map infer crf', u'map inform', u'map inform learn', u'map input', u'map input dimens', u'map input imag', u'map input resolut', u'map is1/8th', u'map is1/8th input', u'map isimpli', u'map isimpli unlik', u'map islay', u'map islay use', u'map isnot', u'map isnot compress', u'map label', u'map labelssever', u'map labelssever recent', u'map labelstim', u'map labelstim requir', u'map layer', u'map layer ofappl', u'map layer offcn-bas', u'map layer toextrem', u'map layer toth', u'map layer trace', u'map learnet', u'map learnet al', u'map learnhierarch', u'map learnhierarch encod', u'map low', u'map low resolut', u'map max-pool', u'map max-pool sub-sampl', u'map max-pool sub-samplingth', u'map max-pool sub-samplingw', u'map note', u'map note imag', u'map output', u'map output encod', u'map output themax-pool', u'map output theth', u'map perform', u'map perform best', u'map performbest', u'map performbest effici', u'map performencod', u'map performencod featur', u'map pool', u'map pool indic', u'map predict', u'map predict singl', u'map principl', u'map principl use', u'map principl window', u'map produc', u'map produc decod', u'map produc featuresfor', u'map produc featureswhich', u'map produc theoutput', u'map produc theth', u'map requir', u'map requir 19mb', u'map resolut', u'map resolut motiv', u'map s', u'map s andarchitectur', u'map s andcombin', u'map s convolv', u'map s e', u'map s float', u'map s perform', u'map s rgb', u'map s segnet', u'map s specif', u'map s step', u'map s use', u'map sames', u'map sames encod', u'map sameth', u'map sameth decod', u'map sampl', u'map sampl indic', u'map say', u'map say channel', u'map segnet', u'map segnet decod', u'map segnet use', u'map semant', u'map semant label', u'map semant labelsboth', u'map semant labelslow', u'map sever', u'map sever layer', u'map singl', u'map singl valu', u'map small', u'map small resolut', u'map smaller', u'map smaller variant', u'map spars', u'map spars thenconvolv', u'map spars thenperform', u'map structur', u'map structur random', u'map subsampl', u'map subsampl store', u'map tempor', u'map tempor cue', u'map thedecod', u'map thedecod network', u'map theear', u'map theear encod', u'map theloc', u'map theloc global', u'map thesam', u'map thesam number', u'map thiscompress', u'map thiscompress encod', u'map thisdimension', u'map thisdimension reduct', u'map tocombin', u'map tocombin correspond', u'map tomatch', u'map tomatch input', u'map toproduc', u'map toproduc input', u'map trace', u'map trace toa', u'map trace topixel', u'map turn', u'map turn set', u'map upsampl', u'map upsampl featuremap', u'map upsampl featureupsampl', u'map upsampl kernel', u'map use', u'map use decod', u'map use store', u'map use thecompress', u'map use thecorrespond', u'map use trainabl', u'map valu', u'map valu pixelfeatur', u'map valu pixeli\\u2208i', u'map variant', u'map variant segnetbasic-singlechanneldecod', u'map \\u2200j', u'map \\u2200j q', u'map \\u2200j squar', u'mapadditional/deep', u'mapadditional/deep encoder-decod', u'mapadditional/deep encoder-decod pair', u'mapalthough', u'mapalthough encod', u'mapalthough encod input', u'mapencod', u'mapencod featur', u'mapencod featur mapencod', u'mapencod featur mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig', u'maplow', u'maplow resolut', u'maplow resolut encod', u'mapof', u'mapof normal', u'mapof normal depth', u'mappedback', u'mappedback imag', u'mappedback imag pixel', u'mappedtrain', u'mappedtrain network', u'mappedtrain network featur', u'mapresolut', u'mapresolut smaller', u'mapresolut smaller make', u'mapsa', u'mapsa batch', u'mapsa batch normal', u'mapsa trainabl', u'mapsa trainabl decod', u'mapsand', u'mapsand store', u'mapsand store boundari', u'mapsbefor', u'mapsbefor sub-sampl', u'mapsbefor sub-sampl perform', u'mapsbut', u'mapsbut structur', u'mapsbut structur class', u'mapscomput', u'mapscomput camvid', u'mapscomput camvid video', u'mapsdur', u'mapsdur infer', u'mapsdur infer memori', u'mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig', u'mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig illustr', u'mapsegnetsegnetsegnetsegnetsegnetsegnetsegnetfcnfcnfcnfcnfig illustr segnet', u'mapsfor', u'mapsfor better', u'mapsfor better perform', u'mapsnot', u'mapsnot decod', u'mapsnot decod correspond', u'mapsth', u'mapsth fcn', u'mapsth fcn decod', u'mapsto', u'mapsto captur', u'mapsto captur inform', u'mapth', u'mapth input', u'mapth input segnet', u'mapthi', u'mapthi deep', u'mapthi deep learn', u'mapto', u'mapto input', u'mapto input imag', u'margin', u'margin note', u'margin note epoch', u'marseill', u'marseill 2008in', u'marseill 2008in bmvc', u'marseill 2008use', u'marseill 2008use structur', u'marseill 6eccv', u'marseill 6eccv marseill', u'marseill 6semant', u'marseill 6semant imag', u'mask', u'mask correspond', u'mask correspond deepan', u'mask correspond deepmodel', u'massiv', u'massiv dataset', u'massiv dataset expand', u'mat', u'mat cloth', u'mat cloth ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper11', u'mat cloth ceilingbooksbooksbooksbooksbooksbooksfridgefridgefridgefridgefridgefridgefridgetvtvtvpaperpaperpaperpaperpaperpaper1192119211921192119211921145114511451145114511456656665666566656665666565273527352735273527352734380438043804380438043802630263026302630263026300000000000000003431343134313431343134317411741174117411741174115377537753775377537753772985298529852985298529853376', u'mat cloth ceilingfloor', u'match', u'match imag', u'match imag dimens', u'match metric', u'match metric segnet', u'match number', u'match number classesfeatur', u'match number classesk', u'match thesecriteria', u'match thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath', u'match thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath encod', u'match theserepeat', u'match theserepeat design', u'matchbi', u'matchbi replic', u'matchbi replic deepest', u'matchimag', u'matchimag dimens', u'matchimag dimens howev', u'matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur', u'matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur bayesian', u'matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur bayesian segnet', u'materi', u'material5', u'material5 conclusion5', u'material5 conclusion5 conclusion5', u'materialcan', u'materialcan view', u'materialcan view supplementari', u'matfloor', u'matfloor matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur', u'matfloor matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur bayesian', u'matfloor matfloor', u'matfloor matfloor matclothesclothesclothesclothesclothesclothesclothesclothesceilingceilingceilingceilingceilingceilingceilingceilingfigur', u'matfloor matfloor matfloor', u'mathieu', u'mathieu y', u'mathieu y lecun', u'matlab', u'matlab code', u'matlab code avail', u'matlab gpu', u'matlab gpu compat', u'max', u'max locat', u'max locat comput', u'max pool', u'max pool follow', u'max pool indicesfig', u'max pool indicesto', u'max pool layer', u'max pool stride', u'max pool sub-sampl', u'max pool window', u'max x', u'max x appli', u'max-pool', u'max-pool andin', u'max-pool andin featur', u'max-pool andsub-sampl', u'max-pool andsub-sampl achiev', u'max-pool block', u'max-pool block u-net', u'max-pool indic', u'max-pool indic batch', u'max-pool indic inform', u'max-pool indic isbalanc', u'max-pool indic istherefor', u'max-pool indic locat', u'max-pool indic otherhand', u'max-pool indic otherinfer', u'max-pool indic receiv', u'max-pool indic store', u'max-pool indic upsampl', u'max-pool indicesfrom', u'max-pool indicesfrom correspond', u'max-pool indicesit', u'max-pool indicesit input', u'max-pool indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic1', u'max-pool indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526', u'max-pool indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526 733segnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderadditionsegnet-basic-encoderaddition142514251425142514251425646464530', u'max-pool indicesupsampl', u'max-pool indicesupsampl use', u'max-pool layer', u'max-pool layer includ', u'max-pool step', u'max-pool step correspond', u'max-pool sub-sampl', u'max-pool sub-sampl obtain', u'max-pool sub-samplingth', u'max-pool sub-samplingth layer', u'max-pool sub-samplingw', u'max-pool sub-samplingw averag', u'max-pool subsampl', u'max-pool subsampl correspond', u'max-pool use', u'max-pool use achiev', u'max-pool window', u'max-pool window stride', u'max-pooling-subsamplingbeen', u'max-pooling-subsamplingbeen quit', u'max-pooling-subsamplingbeen quit satisfactori', u'max-pooling-subsamplinglay', u'max-pooling-subsamplinglay use', u'max-pooling-subsamplinglay use time', u'max-poolingindic', u'max-poolingindic featur', u'max-poolingindic featur map', u'max-poolingoth', u'max-poolingoth hand', u'max-poolingoth hand effici', u'maxim', u'maxim gpu', u'maxim gpu usag', u'maxim throughput', u'maxim throughput power', u'maximum', u'maximum featur', u'maximum featur valu', u'maximum number', u'maximum number iter', u'maximum probabl', u'maximum probabl pixel', u'maximum probabl pixelclass', u'maximum probabl pixelw', u'maxloc', u'maxloc encod', u'maxloc encod featur', u'maxpool', u'maxpool indic', u'maxpool indic encod', u'maxpool sub-sampl', u'maxsemi-supervis', u'maxsemi-supervis variant', u'maxsemi-supervis variant decoupl', u'mb', u'mb forward', u'mb forward pass', u'mb gpu', u'mb gpu infer', u'mb model', u'mb model size', u'mb segnetsegnetsegnetsegnetsegnetsegnetsegnet422', u'mb segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov', u'mb segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov deeplab-largefov', u'mean', u'mean architectur', u'mean architectur wasbenchmark', u'mean architectur wastrain', u'mean classuncertainti', u'mean classuncertainti class', u'mean classvari', u'mean classvari measur', u'mean intersect', u'mean intersect overth', u'mean intersect overunion', u'mean intersect union', u'mean iou', u'mean iou result', u'mean predict', u'mean predict accuraci', u'mean sampl', u'mean sampl segment', u'mean uncertaintyfig', u'mean uncertaintyvalu', u'mean uncertaintyvalu pixel', u'mean unit', u'mean unit varianc', u'meanfigur', u'meanfigur bayesian', u'meanfigur bayesian segnet', u'meaning', u'meaning measur', u'meaning measur ofuncertainti', u'meaning measur ofvisu', u'meanintersect', u'meanintersect union', u'meanintersect union miou', u'meanmodel', u'meanmodel uncertainti', u'meanmodel uncertainti class', u'meannot', u'meannot doe', u'meannot doe meannot', u'meannot doe meanon', u'meanon', u'meanon featur', u'meanon featur activ', u'meanon featur activatedon', u'meanpp11iithththi', u'meanpp11iithththi 2i', u'meanpp11iithththi 2i 2i', u'meanq', u'meanq meanpp11iithththi', u'meanq meanpp11iithththi 2i', u'meanq meanq', u'meanq meanq meanpp11iithththi', u'meanq meanq meanq', u'meanth', u'meanth mean', u'meanth mean predict', u'meanwhil', u'meanwhil indoor', u'meanwhil indoor rgbd', u'measur', u'measur accuraci', u'measur accuraci inter-class', u'measur accuraci method', u'measur base', u'measur base berkeley', u'measur bf', u'measur bf test', u'measur confidencein', u'measur confidencein predict', u'measur confidencemodel', u'measur confidencemodel uncertainti', u'measur global', u'measur global accuraci', u'measur herecontour', u'measur herecontour inform', u'measur hereit', u'measur hereit segnet-bas', u'measur model', u'measur model uncertainti', u'measur model uncertainty3', u'measur model uncertaintylabel', u'measur ofaccuraci', u'measur ofaccuraci differ', u'measur ofboth', u'measur ofboth perform', u'measur ofmodel', u'measur ofmodel uncertainti', u'measur ofthi', u'measur ofthi qualit', u'measur ofuncertainti', u'measur ofuncertainti essenti', u'measur ofvisu', u'measur ofvisu scene', u'measur overal', u'measur overal measur', u'measur percentag', u'measur percentag pixelscorrect', u'measur percentag pixelsglob', u'measur perform', u'measur perform point', u'measur predict', u'measur predict accuraci', u'measur quantit', u'measur quantit perform', u'measur segnetbas', u'measur segnetbas perform', u'measur semant', u'measur semant segment', u'measur semanticcontour', u'measur semanticcontour accuraci', u'measur semanticto', u'measur semanticto semant', u'measur testdataset', u'measur testdataset differ', u'measur teston', u'measur teston small', u'measur uncertainti', u'measur use', u'measur use input', u'measur use toof', u'measur use tounderstand', u'measur use \\xd7implement', u'measur variant', u'measur variant explainbf', u'measur variant explainth', u'measur variant use', u'measuresbi', u'measuresbi averag', u'measuresbi averag imag', u'measuresw', u'measuresw test', u'measuresw test architectur', u'mechan', u'mechan tofor', u'mechan tofor pixel', u'mechan tomap', u'mechan tomap deep', u'median', u'median frequenc', u'median frequenc balanc', u'median frequenc balancingmedian', u'median frequenc class', u'median frequencybalanc', u'median frequencybalanc train', u'median frequencyclass', u'median frequencyclass balanc', u'median frequencyfollow', u'median frequencyfollow train', u'median frequencysemant', u'median frequencysemant contour', u'median frequencystand', u'median frequencystand alon', u'medicala', u'medicala compar', u'medicala compar segnet', u'medicalimag', u'medicalimag communiti', u'medicalimag communiti doe', u'meet', u'meet room', u'meet room bathroom', u'member', u'member ieee', u'member ieee abstract\\u2014w', u'member ieee vijay', u'member machin', u'member machin intellig', u'memor', u'memor encod', u'memor encod featur', u'memor max-pool', u'memor max-pool indicesfrom', u'memor max-pool indicesit', u'memor pool', u'memor pool indic', u'memori', u'memori accuraci', u'memori accuraci segment', u'memori andcomput', u'memori andcomput time', u'memori andfor', u'memori andfor network', u'memori andsegnet', u'memori andsegnet primarili', u'memori batchcommand', u'memori batchcommand comput', u'memori batchsiz', u'memori batchsiz model', u'memori comput', u'memori comput use', u'memori constraint', u'memori constraint instead', u'memori consumpt', u'memori consumpt train', u'memori consumptionand', u'memori consumptionand improv', u'memori consumptionwithout', u'memori consumptionwithout sacrif', u'memori dure', u'memori dure infer', u'memori dure inferencebefor', u'memori dure inferencei', u'memori duringaccuraci', u'memori duringaccuraci differ', u'memori duringinfer', u'memori duringinfer sinc', u'memori effici', u'memori effici dure', u'memori intens', u'memori intens embeddedappl', u'memori intens embeddeddur', u'memori intens fcn-basic', u'memori intens test', u'memori intens variant', u'memori longer', u'memori longer convergeand', u'memori longer convergear', u'memori mb', u'memori mb gpu', u'memori mb model', u'memori ofresolut', u'memori ofresolut featur', u'memori ofth', u'memori ofth layer', u'memori requir', u'memori requir report', u'memori storag', u'memori storag result', u'memori time', u'memori time effici', u'memori time segnet-bas', u'memori toth', u'memori toth correspond', u'memori totransf', u'memori totransf entir', u'memori transfer', u'memori transfer typic', u'memori versus', u'memori versus accuraci', u'memori versusaccuraci', u'memori versusaccuraci trade-off', u'memori versusand', u'memori versusand known', u'memorizingfeatur', u'memorizingfeatur map', u'memorizingfeatur map s', u'memorizingi', u'memorizingi effici', u'memorizingi effici store', u'memory-wis', u'memory-wis comparedshow', u'memory-wis comparedshow segnet', u'memory-wis comparedto', u'memory-wis comparedto architectur', u'memoryand', u'memoryand comput', u'memoryand comput time', u'memoryand parameteris', u'memoryand parameteris howev', u'memorybest', u'memorybest effici', u'memorybest effici term', u'memoryha', u'memoryha advantag', u'memoryha advantag fcn-basic', u'memoryi', u'memoryi constrain', u'memoryi constrain infer', u'memoryscen', u'memoryscen understand', u'memoryscen understand effici', u'memoryspars', u'memoryspars array', u'memoryspars array indic', u'merg', u'merg sever', u'merg sever low', u'merg severalin', u'merg severalin block', u'merg severallow', u'merg severallow resolut', u'merit', u'merit separ', u'merit separ bodi', u'method', u'method ablefig', u'method ablefig clear', u'method ableto', u'method ableto segment', u'method alreadyselect', u'method alreadyselect state-of-the-art', u'method alreadytrain', u'method alreadytrain respect', u'method appli', u'method appli deep', u'method applic', u'method applic general', u'method boost', u'method boost combin', u'method camvid', u'method camvid road', u'method comput', u'method comput miou', u'method deep', u'method deep learn', u'method demonstr', u'method demonstr general', u'method eitheral', u'method eitheral measur', u'method eitherus', u'method eitherus learn', u'method evalu', u'method evalu asbayesian', u'method evalu asshow', u'method generat', u'method generat probabilist', u'method improv', u'method improv coresegment', u'method improv corew', u'method improv perform', u'method includ', u'method includ random', u'method includ shallow', u'method includ use', u'method lack', u'method lack mechan', u'method learn', u'method learn maplow', u'method learn mapthi', u'method mostlyr', u'method mostlyr hand', u'method mostlyth', u'method mostlyth arriv', u'method perform', u'method perform probabilist', u'method produc', u'method produc overal', u'method produc probabilist', u'method qualit', u'method qualit result', u'method reli', u'method reli hand', u'method reli low-level', u'method reli lowlevel', u'method segnet', u'method segnet perform', u'method segnetoth', u'method segnetoth method', u'method segnetpredict', u'method segnetpredict accur', u'method shown', u'method shown fig', u'method showsset', u'method showsset use', u'method showsth', u'method showsth benefit', u'method tabl', u'method tabl quantit', u'method term', u'method term g', u'method upsampl', u'method upsampl featur', u'method use', u'method use addit', u'method use featuremap', u'method use featureperform', u'method use smaller', u'method use stochast', u'method use structur', u'method usecompetit', u'method usecompetit result', u'method usecrf', u'method usecrf abil', u'method usecrf segnet', u'method user', u'method user perspect', u'method usesad', u'method usesad hoc', u'method usesi', u'method usesi therefor', u'method usesmooth', u'method usesmooth layer', u'method utilis', u'method utilis depth', u'method utilis depthand', u'method utilis depthbenchmark', u'methodleverag', u'methodleverag bayesian', u'methodleverag bayesian framework', u'methodmethodmethodmethodmethodmethodmethodggrgbrgbrgbrgbfcn-32', u'methodmethodmethodmethodmethodmethodmethodggrgbrgbrgbrgbfcn-32 rgb', u'methodmethodmethodmethodmethodmethodmethodggrgbrgbrgbrgbfcn-32 rgb fcn-32s', u'methodmethodmethodmethodmethodmethodmethodmulti-scal', u'methodmethodmethodmethodmethodmethodmethodmulti-scal convnet', u'methodmethodmethodmethodmethodmethodmethodmulti-scal convnet multi-scal', u'methodmethodmethodmethodmethodmethodmethodspace-tim', u'methodmethodmethodmethodmethodmethodmethodspace-tim crf', u'methodobtain', u'methodobtain improv', u'methodobtain improv rang', u'methodsin', u'methodsin comput', u'methodsin comput vision', u'methodsrec', u'methodsrec compet', u'methodsrec compet methodsrec', u'methodsrec compet methodsth', u'methodsth', u'methodsth hardest', u'methodsth hardest challeng', u'methodsth kitti', u'methodsth kitti dataset', u'methodstrain', u'methodstrain dataset', u'methodstrain dataset pre-train', u'methodsvalu', u'methodsvalu increas', u'methodsvalu increas perform', u'metric', u'metric agreescontour', u'metric agreescontour accuraci', u'metric agreesmor', u'metric agreesmor human', u'metric bf', u'metric bf clear', u'metric bf clearlycontour', u'metric bf clearlywhen', u'metric bias', u'metric bias towardscompl', u'metric bias towardsregion', u'metric chose', u'metric chose benchmark', u'metric compar', u'metric compar otherachiev', u'metric compar othermodel', u'metric deeplab-largefovdensecrf', u'metric deeplab-largefovdensecrf optim', u'metric doe', u'metric doe alway', u'metric far', u'metric far lesser', u'metric global', u'metric global accuraci', u'metric globaland', u'metric globaland class', u'metric globalarchitectur', u'metric globalarchitectur share', u'metric higher', u'metric higher tabl', u'metric increas', u'metric increas trend', u'metric obtain', u'metric obtain larg', u'metric optim', u'metric optim directlypredict', u'metric optim directlythrough', u'metric otherwis', u'metric otherwis known', u'metric segnet', u'metric segnet larger', u'metric stagesin', u'metric stagesin train', u'metric stageswhen', u'metric stageswhen over-fit', u'metric stringentintersect', u'metric stringentintersect union', u'metric stringentmetr', u'metric stringentmetr class', u'metric time', u'metric time pointsin', u'metric time pointstrain', u'metric vari', u'metric vari train', u'metric vari withtrain', u'metriccorrel', u'metriccorrel size', u'metriccorrel size class', u'metricnetworknetworknetworknetworknetworknetworknetworknetworkforward', u'metricnetworknetworknetworknetworknetworknetworknetworknetworkforward pass', u'metricnetworknetworknetworknetworknetworknetworknetworknetworkforward pass ms', u'metrics3208', u'metrics3208 180k', u'metrics3208 180k metrics3208', u'metrics3208 180k metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi', u'metricsand', u'metricsand slight', u'metricsand slight lower', u'metricscould', u'metricscould access', u'metricscould access predict', u'metricsdeconvnet', u'metricsdeconvnet fulli', u'metricsdeconvnet fulli connect', u'metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi', u'metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi clear', u'metricsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi clear noisi', u'metricssegnet', u'metricssegnet outperform', u'metricssegnet outperform method', u'mi', u'mi diag', u'mi diag bi', u'mi obtain', u'mi obtain approximateand', u'mi obtain approximatemodel', u'miccai', u'miccai pp', u'miccai pp springer', u'miccai pp springer,201520152015201520152015201020102010201020102010learn', u'microsoft', u'microsoft coco', u'microsoft coco common', u'middl', u'middl column', u'middl column increas', u'middl column quantit', u'middl row', u'middl row showsbayesian', u'middl row showsfigur', u'million', u'million encount', u'million encount difficulti', u'mimic', u'mimic larger', u'mimic larger architectur', u'mimic sharp', u'mimic sharp boundari', u'minfunc', u'minfunc optim', u'minfunc optim librarygeforc', u'minfunc optim libraryw', u'mini', u'mini batch', u'mini batch size', u'mini-batch', u'mini-batch 10epoch', u'mini-batch 10epoch layer', u'mini-batch 10the', u'mini-batch 10the optim', u'mini-batch larg', u'mini-batch larg variat', u'mini-batch maxim', u'mini-batch maxim gpu', u'mini-batch size', u'mini-batch size 441414141road', u'mini-batch size 4we', u'mini-batch size correspondsconverg', u'mini-batch size correspondsto', u'mini-batch size indoor', u'mini-batch size infer', u'mini-batch size train', u'mini-batch unlik', u'mini-batch unlik unsupervis', u'mini-batchavoid', u'mini-batchavoid gpu-cpu', u'mini-batchavoid gpu-cpu memori', u'mini-batchth', u'mini-batchth optim', u'mini-batchth optim run', u'minim', u'minim labelcross-entropi', u'minim labelcross-entropi loss', u'minim labelthat', u'minim labelthat object', u'minimis', u'minimis cross', u'minimis cross entropyin', u'minimis cross entropyloss', u'minimis thekullback-leibl', u'minimis thekullback-leibl diverg', u'minimis theloss', u'minimis theloss object', u'minimiseal', u'minimiseal encoder-decod', u'minimiseal encoder-decod pair', u'minimiseth', u'minimiseth cross-entropi', u'minimiseth cross-entropi label', u'minimisingth', u'minimisingth kullback-leibl', u'minimisingth kullback-leibl kl', u'minimisingweight', u'minimizeth', u'minimizeth object', u'minimizeth object final', u'minimizeunti', u'minimizeunti provid', u'minimizeunti provid addit', u'miou', u'miou accuraci', u'miou accuraci tabl', u'miou acomparison', u'miou acomparison decod', u'miou asemant', u'miou asemant contour', u'miou bf', u'miou bf g', u'miou bf metric', u'miou bf metricscould', u'miou bf metricsdeconvnet', u'miou bfc', u'miou bfc miou', u'miou bfggc', u'miou bfggc miou', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet70', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet7073 240k7073', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet88', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881', u'miou bfsegnetsegnetsegnetsegnetsegnetsegnetsegnet8881 140k8881', u'miou boundari', u'miou boundari metric', u'miou butsegnet', u'miou butsegnet better', u'miou butsmal', u'miou butsmal size', u'miou class', u'miou class use', u'miou comparison', u'miou comparison larger', u'miou deeplab-largefov', u'miou deeplab-largefov aand', u'miou deeplab-largefov astand', u'miou favour', u'miou favour region', u'miou g', u'miou g c', u'miou improv', u'miou improv class', u'miou metric', u'miou metric agreescontour', u'miou metric agreesmor', u'miou metric obtain', u'miou metric optim', u'miou metric otherwis', u'miou metric stringentintersect', u'miou metric stringentmetr', u'miou metriccorrel', u'miou metriccorrel size', u'miou metricnetworknetworknetworknetworknetworknetworknetworknetworkforward', u'miou metricnetworknetworknetworknetworknetworknetworknetworknetworkforward pass', u'miou small', u'miou smalland', u'miou smalland class', u'miou smallsegnet', u'miou smallsegnet outperform', u'miouauthor', u'miouauthor fcn', u'miouauthor fcn henc', u'mioufix', u'mioufix upsamplingfix', u'mioufix upsamplingfix upsamplingfix', u'mioumetr', u'mioumetr boundari', u'mioumetr boundari measur', u'mioumetr global', u'mioumetr global accuraci', u'miouparam', u'miouparam m', u'miouparam m multipli', u'miouth', u'miouth variant', u'miouth variant particular', u'miss', u'miss car', u'miss car e', u'miss car sidewalk', u'miss categori', u'miss categori car', u'miss data', u'miss data input', u'miss label', u'miss label car', u'miss sever', u'miss sever import', u'missingcurr', u'missingcurr camera', u'missingcurr camera requir', u'missingdepth', u'missingdepth measur', u'missingmeasur', u'missingmeasur requir', u'missingmeasur requir use', u'missingmodif', u'missingmodif care', u'missingmodif care post-process', u'mobil', u'mobil robot', u'mobil roboticsappl', u'mobil roboticsappl deep', u'mobil roboticsroberto', u'mobil roboticsroberto cipolla', u'modal', u'modal classifi', u'modal classifi post-process', u'modal necessit', u'modal necessit architecturalmodif', u'modal necessit architecturalmodifications/redesign', u'modal necessit architecturaltest', u'modal necessit architecturalus', u'modal onli', u'modal onli rgb', u'modal train', u'modal train andchalleng', u'modal train andtest', u'modal use', u'modal use experi', u'model', u'model achiev', u'model achiev increas', u'model analysi', u'model analysi sinc', u'model appear', u'model appear road', u'model becaus', u'model becaus better', u'model better', u'model better butsmal', u'model better butwith', u'model capac', u'model capac signific', u'model correspond', u'model correspond highest', u'model correspondinglargest', u'model correspondinglargest model', u'model correspondingto', u'model correspondingto highest', u'model crfcompar', u'model crfcompar larger', u'model crfpost-process', u'model crfpost-process produc', u'model deconvnet', u'model deconvnet match', u'model deep', u'model deep learn', u'model deeplab-largefov', u'model deeplab-largefov effici', u'model depthand', u'model depthand parameteris', u'model depthto', u'model depthto avail', u'model disk', u'model disk segnet', u'model display', u'model display afirst', u'model display ahigh', u'model display uncertainti', u'model dropout', u'model dropout sampl', u'model fcn-basic-nodimreduct', u'model fcn-basic-nodimreduct segnetencoderaddit', u'model fcnbasic-nodimreduct', u'model fcnbasic-nodimreductionanoth', u'model fcnbasic-nodimreductionanoth comparison', u'model fcnbasic-nodimreductiontrain', u'model fcnbasic-nodimreductiontrain accuraci', u'model forbeen', u'model forbeen paid', u'model forreal-tim', u'model forreal-tim applic', u'model ineffici', u'model ineffici train', u'model infer', u'model infer distribut', u'model isaccuraci', u'model isaccuraci class', u'model isdimension', u'model isdimension reduct', u'model ismor', u'model ismor confid', u'model istechniqu', u'model istechniqu import', u'model larg', u'model larg bankfactor', u'model larg bankof', u'model lead', u'model lead thebest', u'model lead thedimension', u'model learn', u'model learn deconvolut', u'model longest', u'model longest train', u'model paramet', u'model perform', u'model perform fcn', u'model posterior', u'model posterior areoften', u'model posterior areperform', u'model predict', u'model predict shown', u'model prevent', u'model prevent overfit', u'model requir', u'model requir store', u'model resiz', u'model resiz input', u'model resiz theinput', u'model resiz thevari', u'model rise', u'model rise bayesian', u'model run', u'model run real', u'model scene', u'model scene understand', u'model segnet', u'model segnet predict', u'model semant', u'model semant segment', u'model shelf', u'model shelf evalu', u'model sinc', u'model sinc compar', u'model size', u'model size mb', u'model size size', u'model slight', u'model slight higher', u'model sucha', u'model sucha fcn-basic-nodimreduct', u'model suchmemori', u'model suchmemori infer', u'model term', u'model term parameterizationand', u'model term parameterizationgiven', u'model textur', u'model textur layout', u'model thisbatch', u'model thisbatch norm', u'model thisstatist', u'model thisstatist http', u'model train', u'model train control', u'model train end', u'model train time', u'model uncertain', u'model uncertain object', u'model uncertain plot', u'model uncertainti', u'model uncertainti abov', u'model uncertainti averag', u'model uncertainti averagedacross', u'model uncertainti averagedtruth', u'model uncertainti class', u'model uncertainti deep', u'model uncertainti eachclass', u'model uncertainti eachw', u'model uncertainti effect', u'model uncertainti estim', u'model uncertainti frequenc', u'model uncertainti ground', u'model uncertainti improv', u'model uncertainti isgener', u'model uncertainti ismodel', u'model uncertainti known', u'model uncertainti output', u'model uncertainti output1', u'model uncertainti outputbayesian', u'model uncertainti predict', u'model uncertainti predomin', u'model uncertainti requir', u'model uncertainti respect', u'model uncertainti result', u'model uncertainti veri', u'model uncertainti whenth', u'model uncertainty3', u'model uncertainty5', u'model uncertaintyal', u'model uncertaintyal class', u'model uncertaintyat', u'model uncertaintyat object', u'model uncertaintylabel', u'model uncertaintylabel overal', u'model uncertaintyqualit', u'model uncertaintyqualit observ', u'model unsupervis', u'model unsupervis learn', u'model usingperform', u'model usingperform deep', u'model usingth', u'model usingth bayesian', u'model various', u'model various order', u'model versus', u'model versus solver', u'model withbayesian', u'model withbayesian weight', u'model withcontextu', u'model withcontextu relationship', u'model work', u'model work bayesian', u'model work:68', u'modeland', u'modeland crf', u'modeland crf post-process', u'modeleach', u'modeleach imag', u'modeleach imag use', u'modelinterpret', u'modelinterpret deep', u'modelinterpret deep learn', u'modellarg', u'modellarg model', u'modellarg model deeplab-largefov', u'modelledth', u'modelledth distribut', u'modelledth distribut model', u'modelledwith', u'modelledwith determinist', u'modelledwith determinist weight', u'modelparamet', u'modelparamet increas', u'modelparamet increas model', u'models', u'models model', u'models model size', u'models1', u'models1 introduction1', u'models1 introduction1 introduction1', u'modelscrf', u'modelscrf models1', u'modelscrf models1 introduction1', u'modelscrf modelscrf', u'modelscrf modelscrf models1', u'modelscrf modelscrf modelscrf', u'modelsher', u'modelsher note', u'modelsher note author', u'modelsmemori', u'modelsmemori comput', u'modelsmemori comput load', u'modelson', u'modelson specialis', u'modelson specialis embed', u'modelsso', u'modelsso enabl', u'modelsso enabl train', u'modelstor', u'modelstor encod', u'modelstor encod network', u'modelsymbol', u'modelsymbol bicyclist', u'modelsymbol bicyclist bayesian', u'modelto', u'modelto obtain', u'modelto obtain posterior', u'modeluncertainti', u'modeluncertainti class', u'modelwhich', u'modelwhich perform', u'modelwhich perform highest', u'modest', u'modif', u'modificationarchitectur', u'modificationarchitectur onli', u'modificationarchitectur onli littl', u'modificationon', u'modificationon main', u'modificationon main contribut', u'modul', u'modul encoder-decod', u'modul encoder-decod network', u'modular', u'modular doneaft', u'modular doneaft deeper', u'modular doneand', u'modular doneand decod', u'modular fulli', u'modular fulli su-encoder-decod', u'modular fulli su-w', u'momentum', u'momentum paramet', u'momentum paramet control', u'momentum use', u'momentum use caff', u'momentumof', u'momentumof optim', u'momentumof optim perform', u'momentumsgd', u'momentumsgd solver', u'momentumsgd solver fix', u'mont', u'mont carlo', u'mont carlo dropout', u'mont carlo sampl', u'mont carlo4', u'mont carloar', u'mont carloar shown', u'mont carlodropout', u'mont carlodropout samplingdropout', u'mont carlosampl', u'mont carlosampl outperform', u'montecarlo', u'montecarlo sampl', u'montecarlo sampl signific', u'montew', u'montew note', u'montew note probabl', u'moor', u'morearchitectur', u'morearchitectur harder', u'morearchitectur harder challeng', u'moreattent', u'moreattent paid', u'moreattent paid import', u'morefin', u'morefin tune', u'morefin tune activ', u'morefin tune activationsfin', u'moremor', u'moremor confid', u'moremor confid class', u'morengiam', u'morengiam et', u'morengiam et al', u'moreoften', u'moreoften certain', u'moreoften certain rare', u'moreov', u'moreov duringa', u'moreov duringa use', u'moreov duringinfer', u'moreov duringinfer propos', u'moreov section', u'morest', u'morest converg', u'morest converg sgd', u'morewith', u'morewith sidewalk', u'morewith sidewalk reason', u'mostactiv', u'mostactiv featur', u'mostactiv featur layer', u'mostcommon', u'mostcommon use', u'mostcommon use benchmark', u'mostconclud', u'mostconclud pointer', u'mostconclud pointer futur', u'mostlyr', u'mostlyr hand', u'mostlyr hand engin', u'mostlyth', u'mostlyth arriv', u'mostlyth arriv deep', u'mostof', u'mostof experi', u'mostof experi use', u'mostth', u'mostth miou', u'mostth miou metric', u'mostvector', u'mostvector sampl', u'mostvector sampl histogram', u'motion', u'motion crf', u'motion crf dens', u'motion cue', u'motion depth', u'motion depth cue', u'motion point', u'motion point cloud', u'motion structur', u'motion structur video', u'motionbas', u'motionbas cue', u'motionbas cue lack', u'motionoth', u'motionoth method', u'motionoth method shown', u'motiv', u'motiv design', u'motiv design segnet', u'motiv propos', u'motiv propos segnet', u'motiv reason', u'motiv reason avoid', u'motiv scene', u'motiv scene understand', u'motiv segnetfor', u'motiv segnetfor semant', u'motiv segnetwa', u'motiv segnetwa need', u'mountain', u'mountain view', u'mountain view ca', u'mountain view learn', u'ms', u'ms backward', u'ms backward pass', u'ms g', u'ms g c', u'ms gpu', u'ms gpu train', u'ms-cocopres', u'ms-cocopres ani', u'ms-cocopres ani test', u'ms-cocosegment', u'ms-cocosegment challeng', u'ms-cocosegment challeng pascal', u'mschmidt/software/minfunc', u'mschmidt/software/minfunc html', u'mschmidt/software/minfunc html 4forest', u'mschmidt/software/minfunc html 4fr/', u'mscoco', u'mscoco train', u'mscoco train infer', u'mse', u'mse electr', u'mse electr engin', u'multi-channel', u'multi-channel decod', u'multi-channel decod filter', u'multi-channel featur', u'multi-channel featur map', u'multi-channel featur mapalthough', u'multi-channel featur mapto', u'multi-channel upsampl', u'multi-channel upsampl kernel', u'multi-channelconvolut', u'multi-channelconvolut use', u'multi-channelconvolut use trainabl', u'multi-channeldeconvolut', u'multi-channeldeconvolut note', u'multi-channeldeconvolut note comparison', u'multi-class', u'multi-class object', u'multi-class object recognit', u'multi-classha', u'multi-classha layer', u'multi-classha layer final', u'multi-classsoft-max', u'multi-classsoft-max classifi', u'multi-classsoft-max classifi produc', u'multi-dimension', u'multi-dimension featur', u'multi-dimension featur pixel', u'multi-scal', u'multi-scal convnet', u'multi-scal convnet 5243d', u'multi-scal convnet multi-scal', u'multi-scal convnet pool', u'multi-scal convnet use', u'multi-scal convolut', u'multi-scal convolut architectur', u'multi-scal deep', u'multi-scal deep architectur', u'multi-scal deep network', u'multi-scal input', u'multi-scal input use', u'multi-scal networkand', u'multi-scal networkand joint', u'multi-scal networkextract', u'multi-scal networkextract append', u'multi-scalebeen', u'multi-scalebeen use', u'multi-scalebeen use benchmark', u'multi-scaledeep', u'multi-scaledeep learn', u'multi-scaledeep learn approach', u'multi-stag', u'multi-stag architectur', u'multi-stag architectur object', u'multi-stag train', u'multi-stag train append', u'multi-stag trainingprocess', u'multi-stag trainingprocess employ', u'multi-stag trainingrecip', u'multi-stag trainingrecip arriv', u'multi-stag trainingto', u'multi-stag trainingto train', u'multi-stag trainingus', u'multi-stag trainingus host', u'multi-stagetoward', u'multi-stagetoward attain', u'multi-stagetoward attain rank', u'multi-stagetrain', u'multi-stagetrain dataset', u'multi-stagetrain dataset pre-train', u'multichannel', u'multichannel imag', u'multichannel imag featur', u'multimedia', u'multimedia pp', u'multimedia pp acm', u'multimod', u'multimod deep', u'multimod deep learn', u'multipl', u'multipl convolut', u'multipl convolut pathway', u'multipl scale', u'multipl scale provid', u'multipli', u'multipli time', u'multipli time ms', u'multiscal', u'multiscal featur', u'multiscal featur learn', u'murphi', u'murphi yuill', u'murphi yuill c', u'murphi yuill connect', u'n', u'n activ', u'n activ deeper', u'n element', u'n element suchcomput', u'n element suchvector', u'n featur', u'n featur activ', u'n normal', u'n normal kernel', u'n/a', u'n/a n/a81', u'n/a80', u'n/a807', u'n/a807 n/a807', u'n/a807 n/a807 n/a807', u'n/a807 n/a807 n/a980', u'n/a807 n/a980', u'n/a807 n/a980 736super', u'n/a81', u'n/a98', u'n/a980', u'n/a980 736super', u'n/a980 736super pars', u'najman', u'najman y', u'najman y lecun', u'natur', u'natur ani', u'natur ani predictivesystem', u'natur ani predictiveuncertainti', u'natur frequenc', u'natur frequenc balanc', u'natur frequenc balancing33333333analysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisanalysisto', u'natur frequenc balancingequival', u'natur frequenc canno', u'natur frequenc canobserv', u'natur frequenc median', u'natur frequencybalanc', u'natur frequencybalanc includ', u'natur frequencybuild', u'natur frequencybuild pixel', u'natur languag', u'natur languag recurs', u'natur scenesand', u'natur scenesand natur', u'natur scenesr', u'natur scenesr socher', u'near', u'near alwaysfrom', u'near alwaysfrom vehicl', u'near alwaysparallel', u'near alwaysparallel road', u'near border', u'near border segmentationsand', u'near border segmentationsthat', u'necessari', u'necessari captureand', u'necessari captureand store', u'necessari captureboundari', u'necessari captureboundari delin', u'necessaryfor', u'necessaryfor network', u'necessaryfor network effici', u'necessaryrepresent', u'necessaryrepresent comput', u'necessaryrepresent comput perspect', u'necessit', u'necessit architecturalmodif', u'necessit architecturalmodif care', u'necessit architecturalmodifications/redesign', u'necessit architecturalmodifications/redesign qualiti', u'necessit architecturaltest', u'necessit architecturaltest use', u'necessit architecturalus', u'necessit architecturalus depth', u'need', u'need achiev', u'need achiev better', u'need approxim', u'need approxim distribut', u'need better', u'need better pixel-wis', u'need compromis', u'need compromis storagecost', u'need compromis storagewhen', u'need cue', u'need cue tempor', u'need design', u'need design effici', u'need improv', u'need improv classif', u'need improv featur', u'need learn', u'need learn upsampl', u'need learndecod', u'need learndecod segment', u'need learnperform', u'need learnperform signific', u'need map', u'need map low', u'need match', u'need match thesecriteria', u'need match thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath', u'need match theserepeat', u'need reus', u'need reus encod', u'need segmenta', u'need segmenta larger', u'need segmentdu', u'need segmentdu high', u'need special', u'need special layer-wis', u'need suffici', u'need suffici expertis', u'need use', u'need use inform', u'need verifi', u'need verifi hypothesi', u'need verifi hypothesis55d', u'need verifi hypothesisdataset', u'need weightpixel', u'need weightpixel domin', u'need weightth', u'need weightth loss', u'needfor', u'needfor sampl', u'needfor sampl fig', u'needsdiffer', u'needsdiffer deconvnet', u'needsdiffer deconvnet larger', u'needsmor', u'needsmor comput', u'needsmor comput resourc', u'needweight', u'needweight averag', u'needweight averag techniqu', u'neglig', u'neglig storag', u'neglig storag costfor', u'neglig storag costsegnet', u'net', u'net architectur', u'net architectur segnet', u\"net filter'sa\", u\"net filter'sa bernoulli\", u\"net filter'sweight\", u\"net filter'sweight requir\", u'net pre-train', u'net pre-train weight', u'net pre-train weights31313131decod', u'net pre-train weightsweight', u'netsand', u'netsand fulli', u'netsand fulli connect', u'netsyuill', u'network', u'network abl', u'network abl toa', u'network abl tocop', u'network abl tolearn', u'network abl topredict', u'network addit', u'network addit parametris', u'network appendedmad', u'network appendedmad better', u'network appendedto', u'network appendedto ani', u'network architectur', u'network architectur bayesian', u'network architectur leav', u'network architectur semant', u'network architecturefor', u'network architecturefor semant', u'network architecturew', u'network architecturew present', u'network arxivfrom', u'network arxivfrom singl', u'network arxivpreprint', u'network arxivpreprint arxiv:14062283', u'network author', u'network author ofnon-linear', u'network author ofthes', u'network basic', u'network basic featur', u'network beennetwork', u'network beennetwork fcn', u'network beenpropos', u'network beenpropos refer', u'network bernoullidistribut', u'network bernoullidistribut network', u'network bernoulliin', u'network bernoulliin bayesian', u'network best', u'network best perform', u'network classif', u'network classif network', u'network classifi', u'network classifi predict', u'network comparedin', u'network comparedin accuraci', u'network comparedto', u'network comparedto classic', u'network comput', u'network comput onlin', u'network consist', u'network consist about90', u'network consist aboutnetwork', u'network consist fulli', u'network consist hierarchyof', u'network consist hierarchysegnet', u'network consistsarchitectur', u'network consistsarchitectur illustr', u'network consistsof', u'network consistsof convolut', u'network constantkernel', u'network constantkernel size', u'network constantnetwork', u'network constantnetwork bias', u'network converg', u'network converg observ', u'network convolutionallay', u'network convolutionallay fulli', u'network convolutionalth', u'network convolutionalth vgg16', u'network core', u'network core recentarchitectur', u'network core recentstudi', u'network correspond', u'network correspond decod', u'network correspond decodernetwork', u'network correspond decodersegnet', u'network cvpr', u'network cvpr pp', u'network cvpr workshopon', u'network cvpr workshopsemant', u'network decod', u'network decod thismap', u'network decod thisnetwork', u'network decodersar', u'network decodersar redund', u'network decodersmax-pool', u'network decodersmax-pool sub-sampl', u'network design', u'network design categor', u'network design object', u'network design objectclassif', u'network design objectconvolut', u'network difficult', u'network difficult task', u'network difficult toindic', u'network difficult totrain', u'network eccv', u'network eccv page', u'network effici', u'network effici term', u'network encod', u'network encod and4', u'network encod andfix', u'network encod consist', u'network fcn', u'network fcn architectur', u'network fcn decod', u'network fcn order', u'network featur', u'network featur activ', u'network featur connect', u'network featur map', u'network follow', u'network follow correspond', u'network followedbi', u'network followedbi pixel-wis', u'network followedterm', u'network followedterm segnet', u'network forh', u'network forh noh', u'network forj', u'network forj long', u'network fork', u'network fork simonyan', u'network forlarge-scal', u'network forlarge-scal imag', u'network forsemant', u'network forsemant segment', u'network framework', u'network framework pixel-wis', u'network grown', u'network grown untilad', u'network grown untilno', u'network henc', u'network henc fcn-basic', u'network icml', u'network icml pp', u'network ii', u'network ii combin', u'network imag', u'network imag super-resolut', u'network importantto', u'network importantto understand', u'network importanttrain', u'network importanttrain time', u'network inclassif', u'network inclassif deep', u'network independ', u'network independ crf', u'network innip', u'network innip page', u'network itssemi-supervis', u'network itssemi-supervis variant', u'network itsth', u'network itsth recent', u'network ki', u'network ki advancesin', u'network ki advancesscen', u'network larger', u'network larger decod', u'network learn', u'network learn categori', u'network learn segment', u'network learn veri', u'network ledof', u'network ledof million', u'network ledto', u'network ledto multi-stag', u'network like', u'network like segnet', u'network loss', u'network loss sum', u'network make', u'network make easier', u'network make hard', u'network make training90', u'network make trainingof', u'network map', u'network map low', u'network merg', u'network merg sever', u'network merg severalin', u'network merg severallow', u'network model', u'network model uncertainti', u'network network', u'network network grown', u'network nip', u'network nip pp', u'network objectclassif', u'network objectclassif recent', u'network objectth', u'network objectth success', u'network onject', u'network onject layer', u'network onli', u'network onli layer', u'network onli vari', u'network onth', u'network onth hand', u'network overfit', u'network perform', u'network perform convolutioneach', u'network perform convolutionwith', u'network perform signific', u'network pre-trainedarchitectur', u'network pre-trainedarchitectur fcn', u'network pre-trainedto', u'network pre-trainedto multi-stag', u'network proceed', u'network proceed ieeeintern', u'network proceed ieeesegment', u'network produc', u'network produc featur', u'network produc smootha', u'network produc smoothsegment', u'network producesthes', u'network producesthes low', u'network producesto', u'network producesto pixel-wis', u'network progressivelyad', u'network progressivelyad exist', u'network progressivelyprocess', u'network progressivelyprocess decod', u'network random', u'network random drop', u'network reduc', u'network reduc width', u'network result', u'network result deconvolut', u'network rnn', u'network rnn append', u'network rnn layer', u'network role', u'network role decod', u'network segnet', u'network segnet topolog', u'network segnet-bas', u'network segnet-bas make', u'network segnet-bas thefcn', u'network segnet-bas theshar', u'network semant', u'network semant pixel-wis', u'network semant segment', u'network test', u'network test time', u'network test timean', u'network test timeoth', u'network theencod', u'network theencod consist', u'network thelearn', u'network thelearn modul', u'network topolog', u'network topolog ident', u'network toprev', u'network toprev overfit', u'network tous', u'network tous regular', u'network train', u'network train dropouta', u'network train dropoutaft', u'network train infer', u'network train larg', u'network train reduc', u'network train setind', u'network train setobtain', u'network trainedjoint', u'network trainedjoint supervis', u'network trainedthes', u'network trainedthes architectur', u'network unsupervis', u'network unsupervis featur', u'network upsamplesit', u'network upsamplesit input', u'network upsamplesth', u'network upsamplesth appropri', u'network use', u'network use addit', u'network use maxloc', u'network use maxsemi-supervis', u'network use relev', u'network use weight', u'network usingan', u'network usingan effici', u'network usingin', u'network usingin order', u'network vari', u'network vari thesear', u'network vari thesearchitectur', u'network veri', u'network veri difficult', u'network vgg16', u'network vgg16 differ', u'network weight', u'network weight q', u'network weightsar', u'network weightsar typic', u'network weightslay', u'network weightslay fulli', u'network whichcan', u'network whichcan produc', u'network whichconvolut', u'network whichconvolut encoder-decod', u'network work', u'network work decoupl', u'network \\u201cdirection\\u201d', u'network \\u201cdirection\\u201d \\u201cspace\\u201d', u\"network'sallow\", u\"network'sallow approxim\", u\"network'sallow approxim posterior\", u\"network'sweight\", u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax', u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax itermax', u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax itermax itermax', u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi', u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi clear', u'network/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsi clear noisi', u'networkand', u'networkand joint', u'networkand joint train', u'networkat', u'networkat test', u'networkat test time', u'networkback', u'networkback imag', u'networkback imag pixel', u'networkclassifi', u'networkclassifi predict', u'networkclassifi predict pixel', u'networkdepth-sift', u'networkdepth-sift pixel', u'networkdepth-sift pixel locat', u'networkdiscard', u'networkdiscard fulli', u'networkdiscard fulli connect', u'networkend-to-end', u'networkend-to-end step', u'networkend-to-end step stochast', u'networkextract', u'networkextract append', u'networkextract append crf', u'networkha', u'networkha correspond', u'networkha correspond decod', u'networkha larg', u'networkha larg number', u'networkha layer', u'networkha layer final', u'networkin', u'networkin order', u'networkin order analys', u'networkindic', u'networkindic featur', u'networkindic featur map', u'networklarg', u'networklarg size', u'networklarg size network', u'networknetworknetworknetworknetworknetworknetworknetworkforward', u'networknetworknetworknetworknetworknetworknetworknetworkforward pass', u'networknetworknetworknetworknetworknetworknetworknetworkforward pass ms', u'networkperform', u'networkperform improv', u'networkperform improv method', u'networksa', u'networksa segment', u'networksa segment attempt', u'networksdesign', u'networksdesign object', u'networksdesign object categor', u'networksin', u'networksin cvpr', u'networksin cvpr workshop', u'networksinvolv', u'networksinvolv gradient', u'networksinvolv gradient back-propag', u'networksresult', u'networksresult main', u'networksresult main fact', u'networkstop-down', u'networkstop-down semant', u'networkstop-down semant feedback', u'networktechniqu', u'networktechniqu wide', u'networktechniqu wide use', u'networkth', u'networkth segnet', u'networkth segnet architectur', u'networkto', u'networkto achiev', u'networkto achiev good', u'networkw', u'networkw obtain', u'networkw obtain good', u'networkweak', u'networkweak label', u'networkweak label data', u'networkwhich', u'networkwhich enabl', u'networkwhich enabl train', u'networkwithout', u'networkwithout need', u'networkwithout need special', u'neural', u'neural comput', u'neural decis', u'neural decis forest', u'neural inform', u'neural inform process', u'neural network', u'neural network abl', u'neural network architectur', u'neural network bernoullidistribut', u'neural network bernoulliin', u'neural network classifi', u'neural network comput', u'neural network difficult', u'neural network framework', u'neural network icml', u'neural network inclassif', u'neural network innip', u'neural network ki', u'neural network merg', u'neural network model', u'neural network objectclassif', u'neural network objectth', u'neural network overfit', u'neural network rnn', u'neural network semant', u'neural network toprev', u'neural network tous', u'neural network whichcan', u'neural network whichconvolut', u'neural networkclassifi', u'neural networkclassifi predict', u'neural networkdepth-sift', u'neural networkdepth-sift pixel', u'neuralc', u'neuralc huang', u'neuralc huang p', u'neurali', u'neurali goodfellow', u'neurali goodfellow r', u'neuralnetwork', u'neuralnetwork arxiv', u'neuralnetwork arxiv preprint', u'neuralnetwork proceed', u'neuralnetwork proceed ieee', u'new', u'new benchmark', u'new benchmark class', u'new featuresin', u'new featuresin accuraci', u'new featuresor', u'new featuresor modal', u'new scenario', u'new scenario test', u'new situat', u'new situat analysi', u'new york', u'new york 2nd', u'new zealand', u'new zealand in2014', u'new zealand inth', u'newer', u'newer deep', u'newer deep architectur', u'ng', u'ng optim', u'ng optim method', u'ng \\u201cpars', u'ng \\u201cpars natur', u'night', u'night standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag19', u'night standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t', u'night standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t 5tabl', u'night standwhiteboard', u'night standwhiteboard person', u'nip', u'nip 2011imag', u'nip 2011imag label', u'nip 2011potenti', u'nip 2011potenti nip', u'nip 6gaussian', u'nip 6gaussian edg', u'nip 6structur', u'nip 6structur class-label', u'nip page', u'nip page 1090\\u2013hierarchi', u'nip page 4gaussian', u'nip pp', u'nip pp 2010network', u'nip pp 2010recognit', u'nip pp 2014imag', u'nip pp 2014network', u'nofix', u'nofix bilinear', u'nofix bilinear interpol', u'noh', u'noh s', u'noh s hong', u'noisi', u'noisi predict', u'noisi predict oftencal', u'noisi predict oftenth', u'noisi predict restrict', u'noisi qualiti', u'noisi qualiti drop', u'noisi scene', u'noisi scene clutter', u'noisi unari', u'noisi unari thenclassifi', u'noisi unari thensmooth', u'noisycorrespond', u'noisycorrespond low', u'noisycorrespond low global', u'noisysegment', u'noisysegment output', u'noisysegment outputsegment', u'noisysegment outputsegment outputsegment', u'noisysuch', u'noisysuch rgb-sift', u'noisysuch rgb-sift depth-sift', u'noisyunari', u'noisyunari smooth', u'noisyunari smooth use', u'nolearn', u'nolearn upsampl', u'nolearn upsampl bilinear-interpol', u'non', u'non deep-learn', u'non deep-learn method', u'non-convex', u'non-convex problem', u'non-convex problem extrem', u'non-linear', u'non-linear convolut', u'non-linear convolut filter', u'non-linear follow', u'non-linear follow non-overlap', u'non-linear max-pool', u'non-linear max-pool sub-sampl', u'non-linear non-overlap', u'non-linear non-overlap max', u'non-linear pool', u'non-linear pool indic', u'non-linear process', u'non-linear process layer', u'non-linear relu', u'non-linear relu max', u'non-linear upsampl', u'non-linear upsampl elimin', u'non-linear upsampl ofth', u'non-linear upsampl oftheir', u'non-overlap', u'non-overlap max', u'non-overlap max pool', u'non-overlap max-pooling-subsamplingbeen', u'non-overlap max-pooling-subsamplingbeen quit', u'non-overlap max-pooling-subsamplinglay', u'non-overlap max-pooling-subsamplinglay use', u'non-overlap maxpool', u'non-overlap maxpool sub-sampl', u'non-overlap pixel', u'non-overlap pixel use', u'non-overlappingmax-pool', u'non-overlappingmax-pool window', u'non-overlappingmax-pool window stride', u'non-overlappingwindow', u'non-overlappingwindow perform', u'non-overlappingwindow perform result', u'non-zero', u'non-zero featur', u'non-zero featur activ', u'noneof', u'noneof propos', u'noneof propos segment', u'noneth', u'noneth output', u'noneth output ensur', u'nonlinear', u'nonlinear present', u'nonlinear present decod', u'norm', u'norm statist', u'norm statist evalu', u'normal', u'normal achiev', u'normal achiev better', u'normal channel', u'normal channel input', u'normal cvpr', u'normal cvpr 3multimod', u'normal cvpr 3use', u'normal depth', u'normal depth perform', u'normal element-wis', u'normal element-wis rectifiedlinear', u'normal kernel', u'normal kernel unit', u'normal layer', u'normal layer convolut', u'normal lcn', u'normal lcn pre-process', u'normal multi-scal', u'normal multi-scal input', u'normal rgb', u'normal rgb input', u'normal rgb inputperform', u'normal rgb inputth', u'normal semanticd', u'normal semanticd eigen', u'normal semanticlabel', u'normal semanticlabel common', u'normal step', u'normal step appli', u'normal tocontrol', u'normal tocontrol benchmark', u'normal toenabl', u'normal toenabl end-to-end', u'normal use', u'normal use need', u'normal usedaft', u'normal usedaft convolut', u'normal usedth', u'normal usedth receiv', u'normalis', u'normalis anda', u'normalis anda relu', u'normalis andor', u'normalis andor convolut', u'normalis layer', u'normalis layer everi', u'normalis reluconv', u'normalis reluconv batch', u'normalis reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur', u'normalis reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur schemat', u'normalis relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig', u'normalis relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig illustr', u'normalis statist', u'normalis statist train', u'normth', u'normth soft-max', u'normth soft-max weight', u'normw', u'normw obtain', u'normw obtain good', u'notbeen', u'notbeen quit', u'notbeen quit satisfactori', u'notcategoris', u'notcategoris imag', u'notcategoris imag detect', u'notclear', u'notclear interpret', u'notclear interpret note', u'note', u'note approach', u'note approach entir', u'note author', u'note author deeplab-largefov', u'note class', u'note class averag', u'note comparison', u'note comparison segnet', u'note comput', u'note comput scienc', u'note decod', u'note decod correspond', u'note densecrf', u'note densecrf hyperparamet', u'note denseimprov', u'note denseimprov obtain', u'note doe', u'note doe meannot', u'note earlier', u'note earlier benchmark', u'note earlierbenchmark', u'note earlierbenchmark dataset', u'note earlieri', u'note earlieri scope', u'note encod', u'note encod decod', u'note encourag', u'note encourag reproduct', u'note epoch', u'note epoch inputepoch', u'note epoch inputsampl', u'note evaluationagainst', u'note evaluationagainst accuraci', u'note evaluationw', u'note evaluationw perform', u'note forclear', u'note forclear interpret', u'note forshallow', u'note forshallow layer', u'note imag', u'note imag ground', u'note imag size', u'note larg', u'note larg drop', u'note learn', u'note learn approxim', u'note ofan', u'note ofan imag', u'note ofsegment', u'note ofsegment qualiti', u'note onli', u'note onli thequantit', u'note onli thergb', u'note onli use', u'note over-fit', u'note over-fit issu', u'note probabl', u'note probabl distribut', u'note qualiti', u'note qualiti label', u'note result', u'note result correspond', u'note segnet', u'note segnet train', u'note sinc', u'note sinc train', u'note thatan', u'note thatan encod', u'note thator', u'note thator determinist', u'note theoret', u'note theoret memori', u'note trainabl', u'note trainabl decod', u'note upsampl', u'note upsampl layer', u'note wecould', u'note wecould access', u'note welarg', u'note welarg dataset', u'notecommon', u'notecommon use', u'notecommon use benchmark', u'noteresolut', u'noteresolut smaller', u'noteresolut smaller make', u'noteth', u'noteth shallow', u'noteth shallow layer', u'notethat', u'notethat decod', u'notethat decod correspond', u'notethat metric', u'notethat metric doe', u'notethat object', u'notethat object remain', u'notevalu', u'notevalu boundari', u'notevalu boundari accuraci', u'noteworthi', u'noteworthi areinclud', u'noteworthi areinclud shallow', u'noteworthi areth', u'noteworthi areth signific', u'noteworthi signific', u'noteworthi signific improv', u'notexampl', u'notexampl miou', u'notexampl miou favour', u'notic', u'notic drop', u'notic drop bf', u'notw', u'notw like', u'notw like add', u'novel', u'novel deep', u'novel deep architectur', u'novel practic', u'novel practic deep', u'novelti', u'novelti segnet', u'novelti segnet lie', u'novemb', u'novemb paper', u'novemb paper id', u'novemb version', u'novemb version submit', u'nowcomput', u'nowcomput histogram', u'nowcomput histogram n', u'nowfor', u'nowfor train', u'nowfor train sampl', u'ntroductioni', u'ntroductioni ntroductioni', u'ntroductioni ntroductioni ntroductioni', u'ntroductioni ntroductioni ntroductionsemant', u'ntroductioni ntroductionsemant', u'ntroductioni ntroductionsemant segment', u'ntroductionsemant', u'ntroductionsemant segment', u'ntroductionsemant segment wide', u'number', u'number channel', u'number channel asinput', u'number channel asth', u'number channel end', u'number class', u'number class present', u'number class segment', u'number class simultan', u'number classesfeatur', u'number classesfeatur map', u'number classesk', u'number classesk make', u'number featur', u'number featur layer', u'number featurescrf', u'number featurescrf segnet', u'number featuresp', u'number featuresp layer', u'number iter', u'number iter atleast', u'number iter overal', u'number modelinterpret', u'number modelinterpret deep', u'number modelparamet', u'number modelparamet increas', u'number network', u'number network reduc', u'number ofclass', u'number ofclass compress', u'number ofconvolut', u'number ofconvolut decod', u'number offeatur', u'number offeatur map', u'number offigur', u'number offigur global', u'number ofin', u'number ofin mini-batch', u'number ofmodel', u'number ofmodel paramet', u'number ofmont', u'number ofmont carlo', u'number ofpixel', u'number ofpixel class', u'number ofseg', u'number ofseg imag', u'number ofwith', u'number ofwith k', u'number outdoor', u'number outdoor scene', u'number paramet', u'number paramet segnet', u'number paramet significantlyth', u'number paramet significantlywithout', u'number road', u'number road scene', u'number size', u'number size channel', u'number state', u'number state art', u'number techniqu', u'number techniqu propos', u'number train', u'number train epoch', u'number trainabl', u'number trainabl paramet', u'number trainableparamet', u'number trainableparamet infer', u'number trainabletheir', u'number trainabletheir correspond', u'number upsampl', u'number upsampl featur', u'numberaft', u'numberaft everi', u'numberaft everi convolut', u'numberof', u'numberof state', u'numberof state art', u'numberof variant', u'numberof variant differ', u'numbertim', u'numbertim generat', u'numbertim generat posterior', u'numer', u'numer accuraci', u'numer accuraci segnetboth', u'numer accuraci segnetfor', u'numer demonstr', u'numer demonstr superior', u'numer result', u'numer result analysi', u'numer result analysisin', u'numer result analysisw', u'nvidia', u'nvidia titan', u'nvidia titan gpu', u'nvidia-smi', u'nvidia-smi unixcommand', u'nvidia-smi unixcommand comput', u'nvidia-smi unixcomput', u'nvidia-smi unixcomput time', u'nyu', u'nyu dataset', u'nyu dataset hasbeen', u'nyu dataset hasceil', u'nyu dataset result', u'nyu dataset thisdataset', u'nyu dataset thisgain', u'nyu dataset version', u'nyu v2', u'nyu v2 segnet', u'nyudataset', u'nyudataset differ', u'nyudataset differ perform', u'nyudataset use', u'nyudataset use depth', u'nyumeanwhil', u'nyumeanwhil indoor', u'nyumeanwhil indoor rgbd', u'nyuparamet', u'nyuparamet method', u'nyuparamet method use', u'nyuv2', u'nyuv2 includ', u'nyuv2 includ dataset', u'nyuv2 includ datasetbenchmark', u'nyuv2 includ datasetroad', u'nyuv2 note', u'nyuv2 note earlier', u'nyuv2 rgb-d', u'nyuv2 rgb-d dataset', u'ob-input', u'ob-input layer', u'ob-input layer question', u'ob-ject', u'ob-ject layer', u'ob-ject layer deconvolut', u'object', u'object appear', u'object appear visual', u'object arrang', u'object arrang observ', u'object autonomousappl', u'object autonomousappl rang', u'object autonomousvehicl', u'object autonomousvehicl drive', u'object boundari', u'object boundari difficult', u'object boundari visual', u'object categor', u'object categor segment', u'object categorizationfor', u'object categorizationfor pixel', u'object categorizationhav', u'object categorizationhav adopt', u'object class', u'object class challeng', u'object class come', u'object class reason', u'object class scene', u'object class varieti', u'object class widelyof', u'object class widelyvari', u'object classeschair', u'object classeschair sofa', u'object classescom', u'object classescom various', u'object classif', u'object classif dataset', u'object classif transpos', u'object cyclist', u'object cyclist andand', u'object cyclist andpedestrian', u'object detect', u'object detect output', u'object detector', u'object detector crfs', u'object detector result', u'object final', u'object final layer', u'object function', u'object function effect', u'object function fortrain', u'object function forw', u'object furnitur', u'object furnitur wall', u'object furnitur wall,654', u'object imag', u'object imag seen', u'object imag therei', u'object imag therewhol', u'object incontext', u'object incontext comput', u'object inp', u'object inp dolla\\u0301r', u'object occlud', u'object occlud distanc', u'object paint', u'object paint wall', u'object pedestrian', u'object plateaus', u'object plateaus epoch', u'object propos', u'object propos post-process', u'object recognit', u'object recognit iccv', u'object recognit imagedeep', u'object recognit imagenetwork', u'object recognit segment', u'object remain', u'object remain minim', u'object segment', u'object segment fine-grain', u'object segment occupi', u'object spatial-context', u'object spatial-context perform', u'object support', u'object support relationship', u'object understanddeep', u'object understanddeep architectur', u'object understandth', u'object understandth perform', u'object use', u'object use trainingal', u'object use trainingnot', u'object visual', u'object visual difficult', u'objectclassif', u'objectclassif recent', u'objectclassif recent led', u'objectclassif therefor', u'objectclassif therefor initi', u'objectconvolut', u'objectconvolut layer', u'objectconvolut layer vgg16', u'objectiveth', u'objectiveth hand', u'objectiveth hand optim', u'objectivewith', u'objectivewith deeper', u'objectivewith deeper layer', u'objectlearn', u'objectlearn invari', u'objectlearn invari featur', u'objectrecognit', u'objectrecognit cvpr', u'objectrecognit cvpr 2007recognit', u'objectth', u'objectth success', u'objectth success deep', u'observ', u'observ accuraci', u'observ accuraci improv', u'observ addit', u'observ addit perform', u'observ betweenbench', u'observ betweenbench tabl', u'observ betweencat', u'observ betweencat dog', u'observ drop', u'observ drop everi', u'observ dropout', u'observ dropout ad', u'observ experiencemachin', u'observ experiencemachin learn', u'observ furtherreduct', u'observ furtherreduct train', u'observ furtherth', u'observ furtherth network', u'observ growth', u'observ growth isno', u'observ growth isstop', u'observ high', u'observ high model', u'observ high qualityacross', u'observ high qualitysegment', u'observ higher', u'observ higher model', u'observ highgener', u'observ highgener veri', u'observ highmodel', u'observ highmodel uncertainti', u'observ improv', u'observ improv segmentationdropout', u'observ improv segmentationperform', u'observ invers', u'observ invers relationship', u'observ object', u'observ object plateaus', u'observ predict', u'observ predict smoother', u'observ qualit', u'observ qualit fourcamvid', u'observ qualit fourvari', u'observ report', u'observ report thenumer', u'observ report theof', u'observ scene', u'observ scene wide', u'observ segmentationpredict', u'observ segmentationpredict smooth', u'observ segmentationvoc', u'observ segmentationvoc result', u'observ signific', u'observ signific improv', u'observ similar', u'observ similar result', u'observ train', u'observ train data', u'observ use', u'observ use dropout', u'observ veri', u'observ veri high', u'observerec', u'observerec sun', u'observerec sun rgb-d', u'observesom', u'observesom scene', u'observesom scene larg', u'obtain', u'obtain 180k', u'obtain 180k metrics3208', u'obtain approximateand', u'obtain approximateand variat', u'obtain approximatemodel', u'obtain approximatemodel gaussian', u'obtain atfigur', u'obtain atfigur segnet', u'obtain atvari', u'obtain atvari depth', u'obtain b', u'obtain ba', u'obtain ba engin', u'obtain bf', u'obtain bf score', u'obtain combin', u'obtain combin use', u'obtain expens', u'obtain expens grid-searchcrf', u'obtain expens grid-searchprocess', u'obtain featur', u'obtain featur accur', u'obtain featur map', u'obtain good', u'obtain good perform', u'obtain good predict', u'obtain higher', u'obtain higher accuraci', u'obtain higheraccuraci', u'obtain higheraccuraci best', u'obtain higheraccuraci follow', u'obtain higherfeatur', u'obtain higherfeatur set', u'obtain higherfeatur spatio-tempor', u'obtain highest', u'obtain highest perform', u'obtain improv', u'obtain improv rang', u'obtain larg', u'obtain larg train', u'obtain ph', u'obtain phd', u'obtain phd frominria', u'obtain phd fromvijay', u'obtain posterior', u'obtain posterior distribut', u'obtain segnet', u'obtain segnet better', u'obtain smooth', u'obtain smooth label', u'obtain softmax', u'obtain softmax classifi', u'obtain start', u'obtain start pre-train', u'obtain use', u'obtain use crf', u'obtain withcrf', u'obtain withcrf post-process', u'obtain withqual', u'obtain withqual segment', u'obtainbatch', u'obtainbatch norm', u'obtainbatch norm statist', u'obtaincompetit', u'obtaincompetit result', u'obtaincompetit result compar', u'obtaineddenot', u'obtaineddenot segnet', u'obtaineddenot segnet l4', u'obtainedin', u'obtainedin scenario', u'obtainedin scenario segnet', u'obtainsand', u'obtainsand motion', u'obtainsand motion cue', u'obtainsth', u'obtainsth highest', u'obtainsth highest overal', u'obtainth', u'obtainth result', u'obtainth result tabl', u'obtainw', u'obtainw perform', u'obtainw perform complet', u'occlud', u'occlud distanc', u'occlud distanc camera', u'occlus', u'occlus sinc', u'occlus sinc therear', u'occlus sinc therediffer', u'occupi', u'occupi research', u'occupi research believ', u'occupi research salient', u'occupya', u'occupya small', u'occupya small imag', u'occupyon', u'occupyon reason', u'occupyon reason overal', u'occur', u'occur moremor', u'occur moremor confid', u'occur moreoften', u'occur moreoften certain', u'oct', u'oct 2016agk34', u'oct 2016agk34 vb292', u'oct 2016arxiv:1511', u'oct 2016arxiv:151100561v3', u'oct 2016arxiv:151100561v3 cscv', u'oct 2016vijay', u'oct 2016vijay badrinarayanan', u'of0', u'of075', u'of075 imag', u'of075 imag diagon', u'of1', u'of1 version', u'of1 version submit', u'of2', u'of2 stride', u'of2 stride non-overlap', u'of3433', u'of3433 imag', u'of3433 imag train', u'of360', u'of360 week', u'of360 week unoptim', u'of367', u'of367 train', u'of367 train test', u'of64', u'ofa', u'ofa complex', u'ofa complex train', u'ofa deep', u'ofa deep network', u'ofaccuraci', u'ofaccuraci differ', u'ofaccuraci differ segnet', u'ofan', u'ofan imag', u'ofan imag scene', u'ofappl', u'ofappl e', u'ofappl store', u'ofappl store featur', u'ofbas', u'ofbas classifi', u'ofbayesian', u'ofbayesian segnet', u'ofbayesian segnet wide', u'ofboth', u'ofboth perform', u'ofboth perform equal', u'ofboundari', u'ofboundari given', u'ofboundari given pixel', u'ofclass', u'ofclass compress', u'ofclass compress k', u'ofclass road', u'ofclass road scene', u'ofconvolut', u'ofconvolut decod', u'ofconvolut decod network', u'ofconvolut filter', u'ofconvolut filter bank', u'ofd', u'ofdeep', u'ofdeep learn', u'ofdeep learn architectur', u'ofdeep segnet', u'ofdeep segnet camvid', u'ofdphil', u'ofdphil comput', u'ofdphil comput vision', u'ofeach', u'ofeach deeper', u'ofeach deeper encoder-decod', u'ofeith', u'ofeith rgb', u'ofeith rgb rgbd', u'ofencod', u'ofencod consist', u'ofencod consist filter', u'offcn-bas', u'offcn-bas resolut', u'offcn-bas resolut bit', u'offeatur', u'offeatur activ', u'offeatur activ encod', u'offeatur activ layer', u'offeatur activ layerfeatur', u'offeatur map', u'offeatur map decod', u'offer', u'offer probabilisticbayesian', u'offer probabilisticbayesian neural', u'offer probabilisticinterpret', u'offer probabilisticinterpret deep', u'offigur', u'offigur global', u'offigur global segment', u'offline-onlin', u'offline-onlin perceptionparadigm', u'offline-onlin perceptionparadigm autonom', u'offline-onlin perceptionvision-bas', u'offline-onlin perceptionvision-bas offline-onlin', u'offor', u'offor encod', u'offor encod decod', u'offor futur', u'offor futur like', u'offrequ', u'offrequ partial', u'offrequ partial occlus', u'ofin', u'ofin artifici', u'ofin artifici intellig', u'ofin mini-batch', u'ofin mini-batch larg', u'ofk', u'ofk make', u'ofk make fair', u'oflectur', u'oflectur note', u'oflectur note comput', u'ofmiou', u'ofmiou comparison', u'ofmiou comparison larger', u'ofmodel', u'ofmodel deeplab-largefov', u'ofmodel deeplab-largefov produc', u'ofmodel paramet', u'ofmodel uncertainti', u'ofmodul', u'ofmodul encoder-decod', u'ofmodul encoder-decod network', u'ofmont', u'ofmont carlo', u'ofmont carlo sampl', u'ofnon-linear', u'ofnon-linear upsampl', u'ofnon-linear upsampl decod', u'ofobject', u'ofobject spatial-context', u'ofobject spatial-context perform', u'ofof', u'ofof hand', u'ofof hand engin', u'ofon', u'ofon hand', u'ofon hand alreadi', u'ofoptim', u'ofoptim camvid', u'ofoptim camvid valid', u'ofoxford', u'ofoxford toshibaoxford', u'ofoxford toshibaoxford toshibaoxford', u'ofperform', u'ofperform signific', u'ofperform signific better', u'ofpervis', u'ofpervis manner', u'ofpervis manner pixel-wis', u'ofpixel', u'ofpixel class', u'ofpixel class train', u'ofrath', u'ofrath individu', u'ofrath individu unit', u'ofrec', u'ofrec architectur', u'ofrec architectur key', u'ofresearch', u'ofresearch fuell', u'ofresearch fuell challeng', u'ofresolut', u'ofresolut featur', u'ofresolut featur map', u'ofseg', u'ofseg imag', u'ofseg imag reduc', u'ofsegment', u'ofsegment architectur', u'ofsegment architectur gather', u'ofsegment qualiti', u'ofsegment qualiti better', u'ofsegnet', u'ofsegnet decod', u'ofsegnet decod network', u'ofsemant', u'ofsemant pixel-wis', u'ofsemant pixel-wis segment', u'ofsemant segment', u'ofsemant segment import', u'ofsiz', u'ofsiz encod', u'ofsiz encod input', u'ofspac', u'ofspac recent', u'ofspac recent studi', u'oftencal', u'oftencal unari', u'oftencal unari term', u'oftencorrespond', u'oftencorrespond low', u'oftencorrespond low global', u'oftennumer', u'oftennumer perform', u'oftennumer perform class', u'oftenth', u'oftenth camvid', u'oftenth camvid test', u'ofth', u'ofth correspond', u'ofth correspond encod', u'ofth hardest', u'ofth hardest segment', u'ofth layer', u'ofth layer featur', u'ofth max', u'ofth max locat', u'ofth model', u'ofth model perform', u'ofth overal', u'ofth overal scene', u'oftheir', u'oftheir input', u'oftheir input featur', u'ofthes', u'ofthes architectur', u'ofthes architectur independ', u'ofthi', u'ofthi qualit', u'ofthi qualit produc', u'ofthre', u'ofthre differ', u'ofthre differ benchmark', u'oftrain', u'oftrain data', u'ofuncertainti', u'ofuncertainti essenti', u'ofuncertainti essenti decis', u'ofunderstand', u'ofunderstand idea', u'ofunderstand idea exploit', u'ofvisu', u'ofvisu scene', u'ofvisu scene understand', u'ofw', u'ofw combin', u'ofw combin form', u'ofw test', u'ofw test architectur', u'ofw use', u'ofw use camvid', u'ofweak', u'ofweak label', u'ofweak label data', u'ofwher', u'ofwher classif', u'ofwher classif network', u'ofwith', u'ofwith k', u'ofwith k trainabl', u'older', u'older method', u'older method comput', u'ona', u'ona relev', u'ona relev task', u'onal', u'onal measur', u'onal measur accuraci', u'onand', u'onand model', u'onand model uncertainti', u'onbeen', u'onbeen popular', u'onbeen popular factor', u'onc', u'onc emphas', u'onc emphas trade-off', u'onc encoder-decoder4', u'onc encoder-decoder4 decod', u'onc encoder-decoderstack', u'onc encoder-decoderstack train', u'onc epoch', u'onc epoch select', u'oncamvid', u'oncamvid road', u'oncamvid road scene', u'onchalleng', u'onchalleng benchmark', u'onchalleng benchmark unfortun', u'onclusionc', u'onclusionc onclusionc', u'onclusionc onclusionc onclusionc', u'onclusionc onclusionc onclusionw', u'onclusionc onclusionw', u'onclusionc onclusionw present', u'onclusionw', u'onclusionw present', u'onclusionw present segnet', u'oncomput', u'oncomput vision', u'oncomput vision pp', u'oneand', u'oneand correspond', u'oneand correspond set', u'oneor', u'oneor convolut', u'oneor convolut layer', u'oneth', u'oneth number', u'oneth number upsampl', u'onewher', u'onewher decod', u'onewher decod filter', u'ongo', u'ongo topic', u'ongo topic ofresearch', u'ongo topic ofsemant', u'onin', u'onin particular', u'onin particular deep', u'onject', u'onject layer', u'onject layer deconvolut', u'onlarg', u'onlarg size', u'onlarg size network', u'onli', u'onli 4th', u'onli 4th layer', u'onli better', u'onli better multi-scal', u'onli capabl', u'onli capabl infer', u'onli center', u'onli center pixel', u'onli center pixelfor', u'onli center pixelthi', u'onli centerfor', u'onli centerfor pixel', u'onli centerpixel', u'onli centerpixel improv', u'onli centralencod', u'onli centralencod decod', u'onli centralfit', u'onli class', u'onli class suggest', u'onli convolut', u'onli convolut decod', u'onli convolvetheir', u'onli convolvetheir correspond', u'onli convolvewher', u'onli convolvewher decod', u'onli featur', u'onli featur activ', u'onli fraction', u'onli fraction featur', u'onli inabl', u'onli inabl deep', u'onli just', u'onli just begun', u'onli layer', u'onli layer eachbas', u'onli layer eachfor', u'onli layer isrow', u'onli layer istrain', u'onli learn', u'onli learn upsampl', u'onli littl', u'onli littl modif', u'onli littl modificationarchitectur', u'onli littl modificationon', u'onli localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm', u'onli localcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastcontrastnorm rgbnormal', u'onli localwith', u'onli localwith onli', u'onli max-pool', u'onli max-pool indic', u'onli onc', u'onli onc epoch', u'onli pre-her', u'onli pre-her test', u'onli pre-train', u'onli pre-train segnet', u'onli reli', u'onli reli linear', u'onli report', u'onli report metric', u'onli requir', u'onli requir forward', u'onli rgb', u'onli rgb rgb', u'onli rgbaverag', u'onli rgbaverag class', u'onli rgbinput', u'onli rgbinput abl', u'onli size', u'onli size layerencod', u'onli size layertherefor', u'onli soft-max', u'onli soft-max classifi', u'onli soft-maxclassifi', u'onli soft-maxclassifi hidden', u'onli soft-maxwith', u'onli soft-maxwith camvid', u'onli store', u'onli store max-pool', u'onli store max-poolingindic', u'onli store max-poolingoth', u'onli thequantit', u'onli thequantit comparison', u'onli thergb', u'onli thergb modal', u'onli top-1', u'onli top-1 featur', u'onli use', u'onli use rgb', u'onli vari', u'onli vari form', u'onlin', u'onlin demo', u'onlin demo sourc', u'onlin evalu', u'onlin evalu server', u'onlin web', u'onlin web demo', u'onlineevalu', u'onlineevalu server', u'onlinet', u'onlinet pascal', u'onlinet pascal voc12', u'onmani', u'onmani popular', u'onmani popular dataset', u'onnetwork', u'onnetwork proceed', u'onnetwork proceed ieee', u'onth', u'onth central', u'onth central enc-dec', u'onth hand', u'onth hand optim', u'onth vgg', u'onth vgg architectur', u'onthre', u'onthre differ', u'onthre differ benchmark', u'onupsampl', u'onupsampl ani', u'onupsampl ani learn', u'onw', u'onw quantifi', u'onw quantifi perform', u'onw therefor', u'onw therefor benchmark', u'open', u'open sourc', u'open sourc model', u'oppos', u'oppos onli', u'oppos onli center', u'oppos onli centerfor', u'oppos onli centerpixel', u'optim', u'optim achiev', u'optim achiev particularof', u'optim achiev particularresult', u'optim anoth', u'optim anoth recent', u'optim configur', u'optim cover', u'optim cover icml', u'optim cover icml,2012', u'optim cover icml,201220122012201220122012for', u'optim determin', u'optim determin map', u'optim directlypredict', u'optim directlypredict howev', u'optim directlythrough', u'optim directlythrough class', u'optim hyperparamet', u'optim hyperparamet dense-crfth', u'optim hyperparamet dense-crfworsen', u'optim librarygeforc', u'optim librarygeforc 880m', u'optim libraryw', u'optim libraryw wrote', u'optim method', u'optim method deep', u'optim perform', u'optim perform 100epoch', u'optim perform 100of', u'optim reconstruct', u'optim reconstruct objectiveth', u'optim reconstruct objectivewith', u'optim result', u'optim result class', u'optim run', u'optim run iter', u'optim set', u'optim set perhap', u'optim thefilt', u'optim thefilt pair', u'optim thenon-linear', u'optim thenon-linear use', u'optim time', u'optim timessampl', u'optim timessampl approxim', u'optim timesw', u'optim timesw train', u'optimis', u'optimis step', u'optimis step dure', u'optimis train', u'optimis train layerdeep', u'optimis train layerth', u'optimis use', u'optimis use cudnn', u'optimis weight', u'optimis weight network', u'oraid', u'oraid region', u'oraid region propos', u'orbench', u'orbench tabl', u'order', u'order 2secs/fram', u'order 2secs/fram bulk', u'order 838boosting+detectors+crf', u'order 838boosting+detectors+crf boosting+detectors+crf', u'order analys', u'order analys segnet', u'order avoid', u'order avoid upsampl', u'order boosting+detectors+crf', u'order boosting+detectors+crf boosting+detectors+crf', u'order boosting+high', u'order boosting+high order', u'order conveyconvolut', u'order conveyconvolut network', u'order conveyth', u'order conveyth practic', u'order crf', u'order crf improv', u'order crf produc', u'order crf smooth', u'order ensur', u'order ensur thateach', u'order ensur thatmini-batch', u'order hundredsfeatur', u'order hundredsfeatur trainabl', u'order hundredsof', u'order hundredsof million', u'order joint', u'order joint optimis', u'order main', u'order main result', u'order perform', u'order perform control', u'orepoch', u'orepoch observ', u'orepoch observ accuraci', u'orequival', u'orequival use', u'orequival use natur', u'org/pdf/1505', u'org/pdf/1605', u'organ', u'organ follow', u'organ follow sec2', u'organ follow secth', u'orient', u'orient withcurr', u'orient withcurr applic', u'orient withindoor', u'orient withindoor scene', u'orsimilar', u'orsimilar class', u'orsimilar class sun', u'orthey', u'orthey requir', u'orthey requir map', u'orwhen', u'orwhen over-fit', u'orwhen over-fit set', u'orwith', u'orwith train', u'orwith train differ', u'otherachiev', u'otherachiev highest', u'otherachiev highest score', u'otherarchitectur', u'otherarchitectur deconvnet', u'otherarchitectur deconvnet bf', u'otherclass', u'otherclass street', u'otherclass street sign', u'othercompet', u'othercompet architectur', u'othercompet architectur use', u'otherdecod', u'otherdecod network', u'otherdecod network produc', u'otherdeep', u'otherdeep architectur', u'otherdeep architectur seen', u'otherextrem', u'otherextrem add', u'otherextrem add encod', u'otherhand', u'otherhand fcn-basic', u'otherhand fcn-basic store', u'otherinfer', u'otherinfer sinc', u'otherinfer sinc onli', u'otherit', u'otherit encod', u'otherit encod input', u'otherlearn', u'otherlearn upsampl', u'otherlearn upsampl bilinear-interpol', u'othermodel', u'othermodel deconvnet', u'othermodel deconvnet higher', u'othernetwork', u'othernetwork signific', u'othernetwork signific 134m', u'othernetwork signific smaller', u'othernetwork train', u'othernetwork train veri', u'otheron', u'otheron road', u'otheron road scene', u'otherrec', u'otherrec architectur', u'otherrec architectur key', u'otherrec architectur tabl', u'otherth', u'otherth boundari', u'otherth boundari accuraci', u'otherth qualit', u'otherth qualit comparison', u'othervehicl', u'othervehicl segment', u'othervehicl segment object', u'otherwis', u'otherwis known', u'otherwis known jacard', u'ourevalu', u'ourevalu subset', u'ourexampl', u'ourexampl featur', u'ourexampl featur result', u'ouri', u'ouri includ', u'ouri includ dataset', u'ourmodel', u'ourmodel scene', u'ourmodel scene understand', u'ourwithin', u'ourwithin block', u'ourwithin block pixel', u'ourwork', u'ourwork intend', u'ourwork intend explor', u'out-perform', u'out-perform previous', u'out-perform previous benchmark', u'outdoor', u'outdoor anda', u'outdoor anda larger', u'outdoor andindoor', u'outdoor andindoor scene', u'outdoor camvid', u'outdoor camvid drive', u'outdoor indoor', u'outdoor indoor scene', u'outdoor rgb', u'outdoor rgb road', u'outdoor scene', u'outdoor scene dataset', u'outdoor scene imag', u'outdoor scene segment', u'outdoorpixel', u'outdoorpixel label', u'outdoorpixel label test', u'outdoorrgb', u'outdoorrgb scene', u'outdoorrgb scene camvid', u'outperform', u'outperform fcn-basicnoaddit', u'outperform fcn-basicnoadditionth', u'outperform fcn-basicnoadditionth reason', u'outperform fcn-basicnoadditionth size', u'outperform method', u'outperform method includ', u'outperform method tabl', u'outperform method term', u'outperform previousbenchmark', u'outperform previousbenchmark includ', u'outperform previousoth', u'outperform previousoth method', u'outperform theother', u'outperform theother method', u'outperform thequantit', u'outperform thequantit comparison', u'outperform weight', u'outperform weight averag', u'outperformsmodel', u'outperformsmodel smaller', u'outperformsmodel smaller dataset', u'outperformsshallow', u'outperformsshallow architectur', u'outperformsshallow architectur use', u'output', u'output classifi', u'output classifi predict', u'output encod', u'output encod stack', u'output ensur', u'output ensur label', u'output featur', u'output featur map', u'output fed', u'output fed multi-classha', u'output fed multi-classsoft-max', u'output finaldecod', u'output finaldecod fed', u'output finalhigh', u'output finalhigh dimension', u'output imagepixel', u'output imagepixel label', u'output imagethes', u'output imagethes problem', u'output import', u'output import forcan', u'output import fordecis', u'output measur', u'output measur model', u'output modelto', u'output modelto obtain', u'output modeluncertainti', u'output modeluncertainti class', u'output semant', u'output semant segmentational', u'output semant segmentationrgb', u'output soft-maxclassifi', u'output soft-maxclassifi k', u'output soft-maxclassifi pixel', u'output sub-sampl', u'output sub-sampl bya', u'output sub-sampl bywindow', u'output themax-pool', u'output themax-pool layer', u'output theth', u'output theth input', u'output thisalso', u'output thisalso reduc', u'output thishigh', u'output thishigh resolut', u'output1', u'outputanoth', u'outputanoth memori', u'outputanoth memori intens', u'outputbayesian', u'outputbayesian segnet', u'outputbayesian segnet model', u'outputbayesian segnet segment', u'outputfeatur', u'outputfeatur map', u'outputfeatur map produc', u'outputin', u'outputin tabl', u'outputin tabl report', u'outputsegment', u'outputsegment outputin', u'outputsegment outputin tabl', u'outputsegment outputsegment', u'outputsegment outputsegment outputin', u'outputsegment outputsegment outputsegment', u'outputsmor', u'outputsmor human', u'outputsmor human rank', u'outputsth', u'outputsth key', u'outputsth key idea', u'over-fit', u'over-fit issu', u'over-fit issu trainingher', u'over-fit issu trainingthes', u'over-fit larg', u'over-fit larg ofon', u'over-fit larg oftrain', u'over-fit set', u'over-fit set report', u'overal', u'overal class', u'overal class averag', u'overal effici', u'overal effici viewpoint', u'overal largerdecod', u'overal largerdecod lead', u'overal largernetwork', u'overal largernetwork fcn-basic', u'overal largerth', u'overal largerth decod', u'overal largerus', u'overal largerus max-pool', u'overal measur', u'overal measur model', u'overal model', u'overal model uncertainti', u'overal poor', u'overal poor perform', u'overal result', u'overal result far', u'overal rhechalleng', u'overal rhechalleng segnet', u'overal rhesegment', u'overal rhesegment qualiti', u'overal scene', u'overal scene inde', u'overal scene theother', u'overal scene thequalit', u'overal segnet-basicha', u'overal segnet-basicha advantag', u'overal segnet-basicth', u'overal segnet-basicth number', u'overal smooth', u'overal smooth predict', u'overal smooth segment', u'overal smoothqual', u'overal smoothqual segment', u'overal smoothsegnet-bas', u'overal smoothsegnet-bas segnet', u'overcomesnumb', u'overcomesnumb pool', u'overcomesnumb pool layer', u'overcomesthes', u'overcomesthes problem', u'overcomesthes problem learn', u'overfit', u'overfit co-adapt', u'overfit co-adapt featur', u'overfit seeconvolut', u'overfit seeconvolut layer', u'overfit seehttp', u'overfit seehttp //mi', u'overfit seehttp //miengcamacuk/projects/segnet/tutorialhtml', u'overrec', u'overrec compet', u'overrec compet method', u'overrec compet methodsrec', u'overth', u'overth highest', u'overth highest overal', u'overunion', u'overunion score', u'overunion score signific', u'overwith', u'overwith addit', u'overwith addit cost', u'ox', u'p', u'p h', u'p h torr', u'p sermanet', u'p sermanet s', u'p w', u'p w x', u'page', u'page 1090\\u2013hierarchi', u'page 1090\\u2013hierarchi visual', u'page 201111springer', u'page 201111springer new', u'page 2011multimod', u'page 2011multimod deep', u'page 2348\\u2013advanc', u'page 2348\\u2013advanc neural', u'page 3and', u'page 3and algorithm', u'page 3m', u'page 3m mathieu', u'page 3network', u'page 3network scene', u'page 3what', u'page 3what best', u'page 4gaussian', u'page 4gaussian edg', u'page 4icml', u'page 4icml page', u'page 4nip', u'page 4nip page', u'page 4of', u'page 4of urban', u'page 4torr', u'page 4torr mani', u'page 4use', u'page 4use divis', u'page 6cvpr', u'page 6cvpr page', u'page 6into', u'page 6into geometr', u'page 7a', u'page 7a y', u'page 7torr', u'page 7torr mani', u'page convolut', u'page convolut network', u'page ieee', u'page ieee 2,88and', u'page ieee 5page', u'page ieee 6classif', u'page ieee 6label', u'page ieee 8cvpr', u'page ieee 8map', u'page ieee algorithm', u'page springer', u'page springer 3page', u'page springer 6convolut', u'page springer 6imag', u'page springer 8abs/14091556', u'page springer 8eccv', u'page springer intern', u'page understand', u'page understand benchmark', u'pages2190\\u20132197', u'pages708\\u2013721', u'pages708\\u2013721 springer', u'pages708\\u2013721 springer springer', u'pagesclass-label', u'pagesclass-label random', u'pagesclass-label random forest', u'pagesof', u'pagesof urban', u'pagesof urban scene', u'paid', u'paid import', u'paid import problem', u'paid import problemattent', u'paid import problemr', u'paid smaller', u'paid smaller memori', u'paint', u'paint wall', u'paint wall ar', u'pair', u'pair encod', u'pair encod decod', u'pair featur', u'pair featur mapadditional/deep', u'pair featur mapresolut', u'pair minimiseal', u'pair minimiseal encoder-decod', u'pair minimiseth', u'pair minimiseth cross-entropi', u'pair result', u'pair result increasedeach', u'pair result increasedspati', u'pair subsequ', u'pair subsequ train', u'pair weight', u'pair weight closest', u'pair weightsand', u'pair weightsand train', u'pair weightsfix', u'pair weightsfix total', u'pair-wis', u'pair-wis higher', u'pair-wis higher order', u'pairfor', u'pairfor additional/deep', u'pairfor additional/deep encoder-decod', u'pairin', u'pairin sec', u'pairin sec review', u'pairsand', u'pairsand train', u'pairsand train hold', u'pairslearn', u'pairslearn feed-forward', u'pairslearn feed-forward represent', u'pairwis', u'pairwis crf', u'pairwis crf 798boosting+high', u'pairwis crf boost', u'pairwis crf boosting+high', u'pami', u'pami vol', u'pami vol pp', u'papandreou', u'papandreou kokkino', u'papandreou kokkino k', u'paper', u'paper analysisof', u'paper analysisof segnet', u'paper analysison', u'paper analysison main', u'paper extend', u'paper extend deepconvolut', u'paper extend deepth', u'paper howev', u'paper howev thebenchmark', u'paper howev thecompet', u'paper id', u'paper id 1468a', u'paper id paper', u'paper note', u'paper note earlierbenchmark', u'paper note earlieri', u'paper organ', u'paper organ follow', u'paper sec', u'paper sec 4as', u'paper sec 4deconvnet', u'paper1', u'paper1 segnet-bas', u'paper1 segnet-bas earlier', u'paper33a', u'paper33a rchitecturea', u'paper33a rchitecturea rchitecturea', u'paperfeatur', u'paperfeatur map', u'paperfeatur map central', u'papers300', u'papers300 papers300', u'papers300 papers300 papers300', u'papers300 papers300 papersbayesian', u'papers300 papersbayesian', u'papers300 papersbayesian segnet', u'papersbayesian', u'papersbayesian segnet', u'papersbayesian segnet model', u'papershar', u'papershar encod', u'papershar encod network', u'parallel', u'parallel gpu', u'parallel gpu cost', u'paramet', u'paramet camvid', u'paramet camvid train', u'paramet compar', u'paramet compar segnet', u'paramet competingarchitectur', u'paramet competingarchitectur train', u'paramet competingcomput', u'paramet competingcomput time', u'paramet control', u'paramet control step', u'paramet enabl', u'paramet enabl end-to-end', u'paramet encod', u'paramet encod networkha', u'paramet encod networklarg', u'paramet entir', u'paramet entir network', u'paramet equal', u'paramet explos', u'paramet explos unlik', u'paramet highestresolut', u'paramet highestresolut featur', u'paramet highestw', u'paramet highestw size', u'paramet increas', u'paramet increas model', u'paramet infer', u'paramet infer time', u'paramet mi', u'paramet mi obtain', u'paramet order', u'paramet order hundredsfeatur', u'paramet order hundredsof', u'paramet pascal', u'paramet pascal voc', u'paramet segnet', u'paramet segnet encoderalso', u'paramet segnet encodernetwork', u'paramet segnet remain', u'paramet significantlyth', u'paramet significantlyth benefit', u'paramet significantlywithout', u'paramet significantlywithout sacrif', u'paramet size', u'paramet size multi-stag', u'parameter', u'parameter convolut', u'parameter convolut network', u'parameter deconvnet', u'parameter deconvnet fcn', u'parameter deconvnet miou', u'parameter needsdiffer', u'parameter needsdiffer deconvnet', u'parameter needsmor', u'parameter needsmor comput', u'parameter thediffer', u'parameter thediffer deep', u'parameter themann', u'parameter themann train', u'parameteris', u'parameteris competitor', u'parameteris howev', u'parameteris howev practic', u'parameterizationand', u'parameterizationand fastest', u'parameterizationand fastest train', u'parameterizationgiven', u'parameterizationgiven smallest', u'parameterizationgiven smallest model', u'parameterstrain', u'parameterstrain layer', u'parameterstrain layer segnet', u'parameterswith', u'parameterswith camvid', u'parameterswith camvid train', u'parametris', u'pars', u'pars 833segnet', u'pars 833segnet layersegnet', u'pars benchmarkdeep', u'pars benchmarkdeep learn', u'pars benchmarki', u'pars benchmarki therefor', u'pars boosting+detectors+crf', u'pars boosting+detectors+crf boosting+detectors+crf', u'pars choseclass', u'pars choseclass avgclass', u'pars chosesemant', u'pars chosesemant pars', u'pars icml', u'pars icml workshop', u'pars network', u'pars network proceed', u'pars segnet', u'pars segnet 35k', u'pars super', u'pars super pars', u'parsing/encod', u'parsing/encod follow', u'parsing/encod follow correspond', u'parsing/http', u'parsing/http //david', u'parsing/http //davidgrangierinfo/scen', u'parsing/http //davidgrangierinfo/scen parsing/encod', u'parsing/http //davidgrangierinfo/scen parsing/http', u'parsinga', u'parsinga number', u'parsinga number road', u'parsingus', u'parsingus camvid', u'parsingus camvid dataset', u'partial', u'partial occlus', u'partial occlus sinc', u'particular', u'particular abil', u'particular abil delin', u'particular auto-encod', u'particular auto-encod l-bfgs', u'particular becaus', u'particular becaus thergb', u'particular becaus thesmal', u'particular bf', u'particular bf score', u'particular class', u'particular class averag', u'particular deep', u'particular deep learn', u'particular discardingboth', u'particular discardingboth accur', u'particular discardingdimension', u'particular discardingdimension reduct', u'particular finda', u'particular finda larger', u'particular findth', u'particular findth best', u'particular fine', u'particular fine grainedcontour', u'particular fine grainedfeatur', u'particular interestinglarg', u'particular interestinglarg differ', u'particular interestingsinc', u'particular interestingsinc input', u'particular larger', u'particular larger network', u'particular note', u'particular note larg', u'particular noteworthi', u'particular noteworthi areinclud', u'particular noteworthi areth', u'particular noteworthi signific', u'particular replic', u'particular replic deepest', u'particular suscept', u'particular suscept over-fit', u'particular valuabl', u'particular valuabl row', u'particularlybi', u'particularlybi replic', u'particularlybi replic deepest', u'particularlydesign', u'particularlydesign object', u'particularlydesign object categor', u'particularlydesign segment', u'particularlydesign segment advanc', u'particularlyinvolv', u'particularlyinvolv design', u'particularlyinvolv design architectur', u'particularlynew', u'particularlynew deep', u'particularlynew deep architectur', u'particularlysegnet', u'particularlysegnet good', u'particularlysegnet good architectur', u'particularlytrain', u'particularlytrain time', u'particularlytrain time memori', u'particularlywhen', u'particularlywhen need', u'particularlywhen need compromis', u'particularof', u'particularof model', u'particularof model versus', u'particularresult', u'particularresult main', u'particularresult main fact', u'pascal', u'pascal ms-cocopres', u'pascal ms-cocopres ani', u'pascal ms-cocosegment', u'pascal ms-cocosegment challeng', u'pascal observ', u'pascal observ betweenbench', u'pascal observ betweencat', u'pascal result', u'pascal result clear', u'pascal visual', u'pascal visual object', u'pascal voc', u'pascal voc afor', u'pascal voc argb', u'pascal voc dataset', u'pascal voc datasetpasc', u'pascal voc right', u'pascal voc test', u'pascal voc12', u'pascal voc12 challeng', u'pascal voc12 comput', u'pascal voc12 hasbeen', u'pascal voc12 hasrgb-d', u'pascal voc12 salient', u'pascal voc12 segment', u'pascal voc12 test', u'pascal voc5', u'pascal vocth', u'pascal vocth pascal', u'pascalcamvid', u'pascalcamvid road', u'pascalcamvid road scene', u'pascalvoc', u'pascalvoc result', u'pass', u'pass anoth', u'pass anoth perspect', u'pass caffeimplement', u'pass caffeimplement averag', u'pass caffew', u'pass caffew averag', u'pass decod', u'pass decod decod', u'pass decodernetwork', u'pass decodernetwork therefor', u'pass decodernot', u'pass decodernot compress', u'pass ms', u'pass ms backward', u'pass ms gpu', u'pass theto', u'pass theto test', u'pass thetrain', u'pass thetrain set', u'pass time', u'pass time refer', u'patch', u'patch base', u'patch base classifi', u'patch fed', u'patch fed classifi', u'patch oppos', u'patch oppos onli', u'path', u'path fft', u'path fft base', u'pathway', u'pathway featureextract', u'pathway featureextract append', u'pathway featurei', u'pathway featurei expens', u'pattern', u'pattern analysi', u'pattern analysi machin', u'pattern recognit', u'pattern recognit cvpr', u'pattern recognit page', u'pattern recognit pp', u'pattern recognition22label', u'pattern recognitionand', u'pattern recognitionand zisserman', u'pattern recognitionin', u'pattern recognitionin video', u'pattern recognitionlett', u'pattern recognitionsegment', u'pattern recognitionsegment wild', u'pattern recognitionvideo', u'pattern recognitionvideo high-definit', u'pattern trend', u'pattern trend detect', u'pdf', u'pedestrian', u'pedestrian bicyclist', u'pedestrian bicyclist class', u'pedestrian highlight', u'pedestrian highlight need', u'pedestrian model', u'pedestrian model display', u'pedestrian pole', u'pedestrian pole maintain', u'pedestrian pole sign-symbol', u'pedestrian sign', u'pedestrian sign pole', u'pedestriansetc', u'pedestriansetc larg', u'pedestriansetc larg imbal', u'pedestrianssemant', u'pedestrianssemant class', u'pedestrianssemant class road', u'penal', u'penal fals', u'penal fals positivemetr', u'penal fals positivepredict', u'pennsylvania', u'pennsylvania ad', u'pennsylvania adphil', u'pennsylvania adphil comput', u'pennsylvania ath', u'pennsylvania ath univers', u'peopl', u'peopl cyclist', u'per-ar', u'per-ar train', u'per-ar train afresh', u'per-pixel', u'per-pixel independ', u'per-pixel independ classif', u'per-pixel noisi', u'per-pixel noisi predict', u'per-pixelnoisi', u'per-pixelnoisi predict', u'per-pixelnoisi predict unari', u'per-pixelth', u'per-pixelth camvid', u'per-pixelth camvid road', u'per-train', u'per-train segnet', u'per-train segnet use', u'perceiv', u'perceiv advantag', u'perceiv advantag crf-rnnquestion', u'perceiv advantag crf-rnnwould', u'percentag', u'percentag activ', u'percentag activ featur', u'percentag improvementlarg', u'percentag improvementlarg train', u'percentag improvementobtain', u'percentag improvementobtain use', u'percentag natur', u'percentag natur frequenc', u'percentag pixelscorrect', u'percentag pixelscorrect classifi', u'percentag pixelsglob', u'percentag pixelsglob accuraci', u'percentag samplesa', u'percentag samplesa measur', u'percentag sampleswhich', u'percentag sampleswhich agre', u'percentil', u'percentil confid', u'percentil confid pixel', u'percentil pixel', u'percept', u'percept problem', u'percept problemsalex', u'percept problemsalex kendal', u'percept problemsgraph', u'percept problemsgraph model', u'perceptionparadigm', u'perceptionparadigm autonom', u'perceptionparadigm autonom drive', u'perceptionvision-bas', u'perceptionvision-bas offline-onlin', u'perceptionvision-bas offline-onlin perceptionparadigm', u'perceptionvision-bas offline-onlin perceptionvision-bas', u'perceptu', u'perceptu noisycorrespond', u'perceptu noisycorrespond low', u'perceptu noisysegment', u'perceptu noisysegment output', u'perceptu noisysegment outputsegment', u'perfom', u'perfom longer', u'perfom longer trainingfcn', u'perfom longer trainingfor', u'perform', u'perform 100epoch', u'perform 100epoch dataset', u'perform 100of', u'perform 100of optim', u'perform 40k', u'perform 40k 80k', u'perform ablat', u'perform ablat studi', u'perform achiev', u'perform achiev encod', u'perform acontrol', u'perform acontrol benchmark', u'perform afterconvolut', u'perform afterconvolut use', u'perform afterupsampl', u'perform afterupsampl densifi', u'perform architectur', u'perform architectur controlleddataset', u'perform architectur controlledfor', u'perform architectur train', u'perform architecturediscard', u'perform architecturediscard fulli', u'perform architecturemak', u'perform architecturemak difficult', u'perform atim', u'perform atim memori', u'perform bayesian', u'perform bayesian segnet', u'perform benchmark', u'perform benchmark promin', u'perform best', u'perform best butconsum', u'perform best butstor', u'perform best sever', u'perform better', u'perform better class', u'perform better multi-scal', u'perform better shorter', u'perform better sky', u'perform better variant', u'perform better variantsless', u'perform better variantsw', u'perform boost', u'perform boost post-process', u'perform categori', u'perform categori segment', u'perform class', u'perform class averag', u'perform compar', u'perform compar meanfigur', u'perform compar meanmodel', u'perform compar thelarg', u'perform compar thesegnet', u'perform competit', u'perform competit achiev', u'perform competit infer', u'perform complet', u'perform complet run', u'perform control', u'perform control benchmark', u'perform convolut', u'perform convolut trainabl', u'perform convolutioneach', u'perform convolutioneach encod', u'perform convolutionwith', u'perform convolutionwith filter', u'perform convolv', u'perform convolv themfeatur', u'perform convolv themwith', u'perform couldli', u'perform couldli inabl', u'perform couldtrain', u'perform couldtrain techniqu', u'perform dataset', u'perform dataset smalland', u'perform dataset smalldemonstr', u'perform decod', u'perform decod variant', u'perform deconvolut', u'perform deconvolut fcn-basic-noadditionlearn', u'perform deconvolut fcn-basic-noadditionor', u'perform deep', u'perform deep architectur', u'perform dens', u'perform dens convolut', u'perform differ', u'perform differ decoderto', u'perform differ decodervari', u'perform drop', u'perform drop modest', u'perform end-toend', u'perform end-toend train', u'perform equal', u'perform equal test', u'perform fcn', u'perform fcn improv', u'perform fcn variant', u'perform fcn-basic', u'perform fcn-basic better', u'perform fcn-basic variant', u'perform fix', u'perform fix learn', u'perform foralso', u'perform foralso observ', u'perform forsmal', u'perform forsmal dataset', u'perform gain', u'perform gain commensur', u'perform given', u'perform given encoderlarg', u'perform given encodernetwork', u'perform given encodernetworknetworknetworknetworknetworknetworknetworknetworknetworkb', u'perform highest', u'perform highest valid', u'perform imagenet', u'perform imagenet classif', u'perform improv', u'perform improv class', u'perform improv smaller', u'perform improvementbeyond', u'perform improvementbeyond approxim', u'perform improvementw', u'perform improvementw observ', u'perform increas', u'perform increas obtain', u'perform increaseepoch', u'perform increaseepoch dataset', u'perform increasewa', u'perform increasewa observ', u'perform infer', u'perform infer bayesian', u'perform invers', u'perform invers convolut', u'perform larg', u'perform larg known', u'perform larg number', u'perform largefor', u'perform largefor code', u'perform largetrain', u'perform largetrain set', u'perform lend', u'perform lend evid', u'perform level', u'perform level fcn-basic', u'perform local', u'perform local contrast', u'perform max-pool', u'perform max-pool subsampl', u'perform measur', u'perform measur global', u'perform measur testdataset', u'perform measur teston', u'perform measur variant', u'perform memori', u'perform memori dure', u'perform method', u'perform method mostlyr', u'perform method mostlyth', u'perform method reli', u'perform metric', u'perform metric global', u'perform networkw', u'perform networkw obtain', u'perform networkwithout', u'perform networkwithout need', u'perform non-linear', u'perform non-linear upsampl', u'perform numberof', u'perform numberof state', u'perform numbertim', u'perform numbertim generat', u'perform observ', u'perform observ growth', u'perform onbeen', u'perform onbeen popular', u'perform onchalleng', u'perform onchalleng benchmark', u'perform order', u'perform order analys', u'perform particular', u'perform particular abil', u'perform particular bf', u'perform particular note', u'perform point', u'perform point held-outal', u'perform point held-outcamvid', u'perform poor', u'perform poor final', u'perform poor particular', u'perform probabilist', u'perform probabilist infer', u'perform quitepoor', u'perform quitepoor comparison', u'perform quitespars', u'perform quitespars array', u'perform reduc', u'perform reduc memori', u'perform reduc size', u'perform result', u'perform result camvid', u'perform result output', u'perform rgb', u'perform rgb method', u'perform robust', u'perform robust segment', u'perform robust segmentationobject', u'perform robust segmentationto', u'perform segment', u'perform segment performancecan', u'perform segment performancemap', u'perform segnet', u'perform segnet othercompet', u'perform segnet otheron', u'perform segnet outdoorpixel', u'perform segnet outdoorrgb', u'perform segnet scene', u'perform segnet-bas', u'perform segnet-bas superior', u'perform signific', u'perform signific better', u'perform smoothingfield', u'perform smoothingfield crfs', u'perform smoothingth', u'perform smoothingth output', u'perform strong', u'perform strong regularis', u'perform techniqu', u'perform techniqu camvid', u'perform techniqu camvidaccuraci', u'perform techniqu camvidtest', u'perform tensor', u'perform tensor convolut', u'perform therefor', u'perform therefor analysednecessari', u'perform therefor analysedth', u'perform underit', u'perform underit difficult', u'perform undertim', u'perform undertim memori', u'perform unfortunatelydo', u'perform unfortunatelydo reveal', u'perform unfortunatelyvalu', u'perform unfortunatelyvalu increas', u'perform use', u'perform use additionalcu', u'perform use additionalstate-of-the-art', u'perform use decod', u'perform use global', u'perform weightaverag', u'perform weightaverag mont', u'perform weightcamvid', u'perform weightcamvid dataset', u'perform widelyadopt', u'perform widelyadopt fulli', u'perform widelyin', u'perform widelyin tabl', u'perform withfcn', u'perform withfcn decod', u'perform worst', u'perform worst base', u'performa', u'performa car', u'performa car easier', u'performance2', u'performance2 literatur', u'performance2 literatur review2', u'performance5', u'performanceaccuraci', u'performanceaccuraci trade-off', u'performanceaccuraci trade-off involv', u'performancecan', u'performancecan boost', u'performancecan boost use', u'performanceclass', u'performanceclass averag', u'performanceclass averag accuraci', u'performancecorrel', u'performancecorrel size', u'performancecorrel size class', u'performancegiven', u'performancegiven smallest', u'performancegiven smallest model', u'performancelabel', u'performancelabel resolut', u'performancelabel resolut produc', u'performancelack', u'performancelack cue', u'performancelack cue height', u'performancemap', u'performancemap classif', u'performancemap classif network', u'performancemeasur', u'performancemeasur quantit', u'performancemeasur quantit performance2', u'performancemeasur quantit performancemeasur', u'performancesegnet', u'performancesegnet primarili', u'performancesegnet primarili motiv', u'performancet', u'performancet segnet', u'performancet segnet bayesian', u'performanceth', u'performanceth qualit', u'performanceth qualit result', u'performbest', u'performbest effici', u'performbest effici term', u'performencod', u'performencod featur', u'performencod featur map', u'performloc', u'performloc encod', u'performloc encod featur', u'performnon-linear', u'performnon-linear upsampl', u'performnon-linear upsampl decod', u'performrobust', u'performrobust hope', u'performrobust hope experi', u'performs4', u'performs4 mont', u'performs4 mont carlo', u'performsbett', u'performsbett weight', u'performsbett weight averag', u'perhap', u'perhap thegrid', u'perhap thegrid search', u'perhap theworsen', u'perhap theworsen bf', u'person', u'person night', u'person night standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag19', u'person night standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t', u'person night standwhiteboard', u'perspect', u'perspect decod', u'perspect decod network', u'perspect faster', u'perspect faster dure', u'perspect improvementsin', u'perspect improvementsin accuraci', u'perspect improvementsthi', u'perspect improvementsthi user', u'perspect necessaryfor', u'perspect necessaryfor network', u'perspect necessaryrepresent', u'perspect necessaryrepresent comput', u'pervis', u'pervis manner', u'pervis manner pixel-wis', u'ph', u'phase', u'phase reveal', u'phase reveal metric', u'phasefrom', u'phasefrom tabl', u'phasefrom tabl immedi', u'phasein', u'phasein train', u'phasein train phasefrom', u'phasein train phasein', u'phd', u'phd frominria', u'phd frominria renn', u'phd fromvijay', u'phd fromvijay badrinarayanan', u'phd university2014', u'phd university2014 award', u'phd universityof', u'phd universityof cambridg', u'phil', u'pi', u'pi j', u'pi optimis', u'pick', u'pick order', u'pick order ensur', u'pictur', u'pictur counter', u'pictur counter blinds83', u'pictur counter blinds8342834283428342834283429343934393439343934393436337633763376337633763377318731873187318731873187592759275927592759275925957595759575957595759576418641864186418641864185250525052505250525052505751575157515751575157514205420542054205420542055617561756175617561756173766', u'pictur counter blindsdoor', u'pipelin', u'pipelin decod', u'pipelin decod upsampl', u'pipelin trainedend-to-end', u'pipelin trainedend-to-end step', u'pipelin trainedfigur', u'pipelin trainedfigur schemat', u'pixel', u'pixel apart', u'pixel apart infer', u'pixel approxim', u'pixel approxim timesmor', u'pixel approxim timesroad', u'pixel belong', u'pixel belong larg', u'pixel block', u'pixel block ourexampl', u'pixel block ourwithin', u'pixel class', u'pixel class label', u'pixel class test', u'pixel classif', u'pixel classificationeach', u'pixel classificationeach decod', u'pixel classificationmulti-dimension', u'pixel classificationmulti-dimension featur', u'pixel depth', u'pixel depth normal', u'pixel featur', u'pixel featur base', u'pixel feature-map', u'pixel feature-map isa', u'pixel feature-map isbacktrack', u'pixel imageand', u'pixel imageand high', u'pixel imageski', u'pixel imageski class', u'pixel independ', u'pixel independ output', u'pixel independ theno', u'pixel independ theoutput', u'pixel independ typic', u'pixel independ use', u'pixel label', u'pixel label improv', u'pixel label initi', u'pixel label space', u'pixel labeleffect', u'pixel labeleffect featur', u'pixel labelspac', u'pixel labelspac recent', u'pixel level', u'pixel level import', u'pixel locat', u'pixel locat input', u'pixel patch', u'pixel patch oppos', u'pixel smallcontext', u'pixel smallcontext window', u'pixel smallsiz', u'pixel smallsiz segnet-bas', u'pixel space', u'pixel space use', u'pixel the0th', u'pixel the0th percentil', u'pixel thefor', u'pixel thefor 90th', u'pixel toler', u'pixel toler distanc', u'pixel train', u'pixel train testingof', u'pixel train testingw', u'pixel unari', u'pixel unari noisi', u'pixel unari noisysuch', u'pixel unari noisyunari', u'pixel use', u'pixel use this2', u'pixel use thissmal', u'pixel wise', u'pixel wise imag', u'pixel wise label', u'pixel wise predict', u'pixel wise segment', u'pixel-wis', u'pixel-wis classif', u'pixel-wis classif imbalanc', u'pixel-wis classif layer', u'pixel-wis classif map', u'pixel-wis classif novelti', u'pixel-wis classificationcvpr', u'pixel-wis classificationcvpr propos', u'pixel-wis classificationobtain', u'pixel-wis classificationobtain featur', u'pixel-wis classificationth', u'pixel-wis classificationth recent', u'pixel-wis classificationto', u'pixel-wis classificationto densifi', u'pixel-wis classifict', u'pixel-wis classifict ofeith', u'pixel-wis classifict ofof', u'pixel-wis label', u'pixel-wis label activ', u'pixel-wis label addit', u'pixel-wis label best', u'pixel-wis label given', u'pixel-wis label recent', u'pixel-wis label result', u'pixel-wis labellingarxiv:1505', u'pixel-wis labellingarxiv:150507293v1', u'pixel-wis labellingarxiv:150507293v1 cscv', u'pixel-wis labellingof', u'pixel-wis labellingof recent', u'pixel-wis labellingsemant', u'pixel-wis labellingsemant pixel-wis', u'pixel-wis labellingthi', u'pixel-wis labellingthi primarili', u'pixel-wis predict', u'pixel-wis predict encod', u'pixel-wis segment', u'pixel-wis segment activ', u'pixel-wis segment indoor', u'pixel-wis segment ongo', u'pixel-wis segmentationabstract\\u2014w', u'pixel-wis segmentationabstract\\u2014w present', u'pixel-wis segmentationterm', u'pixel-wis segmentationterm segnet', u'pixel-wis semant', u'pixel-wis semant label', u'pixel-wis semant labelsa', u'pixel-wis semant segment', u'pixel-wiselabel', u'pixel-wiselabel corr', u'pixel-wiselabel corr vol', u'pixel-wisev', u'pixel-wisev badrinarayanan', u'pixel-wisev badrinarayanan handa', u'pixelchosen', u'pixelchosen provid', u'pixelchosen provid wide', u'pixelclass', u'pixelclass maximum', u'pixelclass maximum probabl', u'pixelfeatur', u'pixelfeatur map', u'pixelfeatur map valu', u'pixelfor', u'pixelfor pixel', u'pixelfor pixel patch', u'pixelin', u'pixelin deepest', u'pixelin deepest layer', u'pixelin featur', u'pixelin featur map', u'pixelin larg', u'pixelin larg input', u'pixelindepend', u'pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach', u'pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach encod', u'pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach encod encod', u'pixeli\\u2208i', u'pixeli\\u2208i j', u'pixeli\\u2208i j fj', u'pixelsa', u'pixelsa context', u'pixelsa context window', u'pixelscorrect', u'pixelscorrect classifi', u'pixelscorrect classifi dataset', u'pixelsglob', u'pixelsglob accuraci', u'pixelsglob accuraci g', u'pixelsin', u'pixelsin mini-batch', u'pixelsin mini-batch larg', u'pixelsoft-max', u'pixelsoft-max classifi', u'pixelsoft-max classifi produc', u'pixelsth', u'pixelsth trade-off', u'pixelsth trade-off size', u'pixelstrain', u'pixelstrain network', u'pixelstrain network loss', u'pixelthi', u'pixelthi improv', u'pixelthi improv result', u'pixelw', u'pixelw add', u'pixelw add architectur', u'pixelwis', u'pixelwis class', u'pixelwis class label', u'pixelwis classif', u'pixelwis classif layer', u'pixelwis classifi', u'pixelwis label', u'pixelwis label problem', u'plan', u'plan studi', u'plan studi thenyu', u'plan studi thethat', u'plane', u'plane detect', u'plane detect column-wis', u'plane fit', u'plane fit column', u'plateaus', u'plateaus epoch', u'plateaus epoch run', u'pleas', u'pleas note', u'pleas note encourag', u'pleas onlin', u'pleas onlin web', u'plot', u'plot relationshipbetween', u'plot relationshipbetween uncertainti', u'plot relationshipth', u'plot relationshipth model', u'point', u'point allud', u'point allud recent', u'point cloud', u'point cloud eccv', u'point cloud inand', u'point cloud ineccv', u'point deeplab-largefov-densecrf', u'point deeplab-largefov-densecrf globaland', u'point deeplab-largefov-densecrf globalth', u'point held-outal', u'point held-outal measur', u'point held-outcamvid', u'point held-outcamvid test', u'point particular', u'point particular interestinglarg', u'point particular interestingsinc', u'point precis', u'point precis 11mb', u'point thismak', u'point thismak easier', u'point thisparallel', u'point thisparallel road', u'point vari', u'point vari lot', u'point view', u'point view alsomak', u'point view alsotim', u'pointcorrespond', u'pointcorrespond epoch', u'pointcorrespond epoch test', u'pointer', u'pointer futur', u'pointer futur work', u'points1', u'points1 44the', u'points1 44the best', u'pointsgener', u'pointsgener points1', u'pointsgener points1 44the', u'pointsgener pointsgener', u'pointsgener pointsgener points1', u'pointsgener pointsgener pointsgener', u'pointsin', u'pointsin train', u'pointsin train phase', u'pointsin train phasein', u'pointstrain', u'pointstrain set', u'pointstrain set henc', u'pointw', u'pointw report', u'pointw report maximum', u'pole', u'pole column', u'pole column bicyclist', u'pole contrast', u'pole contrast effect', u'pole maintain', u'pole maintain competit', u'pole pedestrian', u'pole pedestrian highlight', u'pole peopl', u'pole peopl cyclist', u'pole side-walk', u'pole side-walk wea', u'pole side-walk weperform', u'pole sign-symbol', u'pole sign-symbol car', u'pool', u'pool follow', u'pool follow sub-sampl', u'pool indic', u'pool indic 17mb', u'pool indic calledmap', u'pool indic calledswitch', u'pool indic comput', u'pool indic convolv', u'pool indic encod', u'pool indic encoderencod', u'pool indic encoderit', u'pool indic insteadimag', u'pool indic insteadtransf', u'pool indic itconvolv', u'pool indic itpool', u'pool indic performloc', u'pool indic performnon-linear', u'pool indic storag', u'pool indic upsamplingar', u'pool indic upsamplingcr', u'pool indic usedfor', u'pool indic usednetwork', u'pool indicesfig', u'pool indicesfig illustr', u'pool indicesto', u'pool indicesto upsampl', u'pool layer', u'pool layer e', u'pool layer hasa', u'pool layer hasand', u'pool layer non-overlap', u'pool layer onli', u'pool layer order', u'pool process', u'pool process upsampl', u'pool store', u'pool store andpass', u'pool store andth', u'pool stride', u'pool stride toachiev', u'pool stride todeeplab-largefov', u'pool sub-sampl', u'pool sub-sampl reducefeatur', u'pool sub-sampl reducethi', u'pool upsampl', u'pool upsamplingdecod', u'pool upsamplingdecod pool', u'pool upsamplingff11i', u'pool upsamplingff11i ntroductioni', u'pool window', u'pool window andi', u'pool window andthi', u'pool window final', u'pool window of2', u'pool window ofsiz', u'pooling-subsampl', u'pooling-subsampl pipelin', u'pooling-subsampl pipelin decod', u'pooling-subsamplingcan', u'pooling-subsamplingcan introduc', u'pooling-subsamplingcan introduc increas', u'pooling-subsamplingdecod', u'pooling-subsamplingdecod learn', u'pooling-subsamplingdecod learn map', u'poolingi', u'poolingi locat', u'poolingi locat maximum', u'poolingwindow', u'poolingwindow memor', u'poolingwindow memor encod', u'poor', u'poor dens', u'poor dens depth', u'poor final', u'poor final pleas', u'poor light', u'poor light condit', u'poor particular', u'poor particular becaus', u'poor per-ar', u'poor per-ar train', u'poor per-train', u'poor per-train segnet', u'poor perform', u'poor perform architectur', u'poor perform couldli', u'poor perform couldtrain', u'poor perform larg', u'poor result', u'poor result obtain', u'poorer', u'poorer allobserv', u'poorer allobserv weight', u'poorer allth', u'poorer allth variant', u'poorer segment', u'poorer segment result', u'poorer share', u'poorer share otherarchitectur', u'poorer share otherth', u'poorer test', u'poorer test perform', u'poorer thansegnet-bas', u'poorer thansegnet-bas test', u'poorer thanth', u'poorer thanth model', u'poorlydens', u'poorlydens depth', u'poorlydens depth map', u'poorlyunari', u'poorlyunari structur', u'poorlyunari structur class', u'poornew', u'poornew deep', u'poornew deep architectur', u'poortheir', u'poortheir abil', u'poortheir abil delin', u'popular', u'popular dataset', u'popular factor', u'popular factor improv', u'popular hand', u'popular hand design', u'popular hand designedargu', u'popular hand designedfeatur', u'popular machinelearn', u'popular machinelearn algorithm', u'popular machineobject', u'popular machineobject autonom', u'popular machinevehicl', u'popular machinevehicl drive', u'popular segment', u'popular segment scenefigur', u'popular segment sceneunderstand', u'popular sinc', u'popular sinc releas', u'pose', u'pose appear', u'pose frequent', u'pose frequent partial', u'pose recognit', u'pose recognit singl', u'pose withcom', u'pose withcom various', u'pose withfrequ', u'pose withfrequ partial', u'posit', u'posit near', u'posit near alwaysfrom', u'posit near alwaysparallel', u'positivemetr', u'positivemetr class', u'positivemetr class averag', u'positivepredict', u'positivepredict howev', u'positivepredict howev miou', u'post', u'post process', u'post process tool', u'post-doctor', u'post-doctor research', u'post-doctor research associ', u'post-process', u'post-process alsodemonstr', u'post-process alsodemonstr use', u'post-process alsowithout', u'post-process alsowithout use', u'post-process class', u'post-process class method', u'post-process condit', u'post-process condit randomfield', u'post-process condit randomregion', u'post-process fact', u'post-process fact result', u'post-process fill-in', u'post-process fill-in missingcurr', u'post-process fill-in missingdepth', u'post-process fill-in missingmeasur', u'post-process fill-in missingmodif', u'post-process produc', u'post-process produc competit', u'post-process seen', u'post-process seen inth', u'post-process tabl', u'post-process tabl quantit', u'post-process techniqu', u'post-process techniqu alsobeen', u'post-process techniqu alsoperform', u'post-process use', u'post-process use crf', u'post-process use crfmodel', u'post-process use crfor', u'post-process withcrf', u'post-process withcrf model', u'post-process withcrf modelscrf', u'post-process withcu', u'post-process withcu depth', u'posterior', u'posterior areoften', u'posterior areoften use', u'posterior areperform', u'posterior areperform infer', u'posterior distribut', u'posterior distribut convolut', u'posterior distribut model', u'posterior distribut pixel', u'posterior distribut sampl', u'posterior distribut softmax', u'posterior distribut tractabl', u'posterior distribut weight', u'posterior kl', u'posterior kl q', u'posterior kullback-leibl', u'posterior kullback-leibl kl', u'postprocess', u'postprocess techniqu', u'postprocess techniqu perform', u'potenti', u'potenti deploy', u'potenti deploy forind', u'potenti deploy fortest', u'potenti destroy', u'potenti destroy structur', u'potenti destroy structurescontext', u'potenti destroy structuresth', u'potenti nip', u'potenti nip 6gaussian', u'potenti nip 6structur', u'power', u'power fcn', u'power fcn theyshow', u'power fcn theywhil', u'power gpus', u'power gpus initi', u'pp', u'pp 129\\u2013and', u'pp 129\\u2013and natur', u'pp 1915\\u20131929,201320132013201320132013n', u'pp 1915\\u20131929,201320132013201320132013n hft', u'pp 2004pp', u'pp 2004pp 2004pp', u'pp 2008no', u'pp 2008no pp', u'pp 2008u', u'pp 2008u frank', u'pp 2009surpass', u'pp 2009surpass human-level', u'pp 2009understand', u'pp 2009understand benchmark', u'pp 2010network', u'pp 2010network imag', u'pp 2010pp', u'pp 2010pp 2010pp', u'pp 2010recognit', u'pp 2010recognit nip', u'pp 2011s', u'pp 2011s zheng', u'pp 2014a', u'pp 2014a karpathi', u'pp 2014for', u'pp 2014for scene', u'pp 2014imag', u'pp 2014imag use', u'pp 2014network', u'pp 2014network train', u'pp 2015c', u'pp 2015c liang-chieh', u'pp 2015c szegedi', u'pp 2015comput', u'pp 2015comput vision', u'pp 2015confer', u'pp 2015confer comput', u'pp 2015cvpr', u'pp 2015cvpr pp', u'pp 2015edg', u'pp 2015edg comput', u'pp 2015iccv', u'pp 2015iccv pp', u'pp 2015intern', u'pp 2015intern confer', u'pp 2015k', u'pp 2015k simonyan', u'pp 2015label', u'pp 2015label common', u'pp 2015on', u'pp 2015on comput', u'pp 2015pp', u'pp 2015pp 2015pp', u'pp 2015s', u'pp 2015s guadarrama', u'pp 2015semant', u'pp 2015semant segment', u'pp 2015w', u'pp 2015w liu', u'pp 2146\\u2013best', u'pp 2146\\u2013best multi-stag', u'pp 3354\\u20133361,201220122012201220122012imag', u'pp 3354\\u20133361,201220122012201220122012imag categor', u'pp 3376\\u20133385,201520152015201520152015network', u'pp 3376\\u20133385,201520152015201520152015network cvpr', u'pp 447\\u2013object', u'pp 447\\u2013object segment', u'pp 88\\u2013video', u'pp 88\\u2013video high-definit', u'pp 98\\u2013136pp', u'pp 98\\u2013136pp 98\\u2013136pp', u'pp acm', u'pp acm 2014confer', u'pp acm 2014evalu', u'pp april', u'pp april 2015journal', u'pp april 2015p', u'pp confer', u'pp confer comput', u'pp drive', u'pp drive kitti', u'pp featur', u'pp featur scene', u'pp ieee', u'pp ieee 2009a', u'pp ieee 2009and', u'pp ieee 2010and', u'pp ieee 2010network', u'pp ieee 2011pp', u'pp ieee 2012algorithm', u'pp ieee 2012indoor', u'pp ieee 2013ieee', u'pp recognit', u'pp recognit indoor', u'pp springer', u'pp springer 2010scene', u'pp springer 2012pp', u'pp springer 2012springer', u'pp springer 2013algorithm', u'pp springer 2014and', u'pp springer 2014context', u'pp springer 2014deep', u'pp springer 2014edg', u'pp springer biomed', u'pp springer internationallectur', u'pp springer internationalpublish', u'pp springer network', u'pp springer,201420142014201420142014imag', u'pp springer,201420142014201420142014imag use', u'pp springer,201520152015201520152015201020102010201020102010learn', u'pp springer,201520152015201520152015201020102010201020102010learn invari', u'pp support', u'pp support infer', u'practic', u'practic abl', u'practic abl predict', u'practic advantag', u'practic advantag comput', u'practic applic', u'practic applic ar', u'practic applicationsi', u'practic applicationsi suitabl', u'practic applicationsth', u'practic applicationsth appropri', u'practic deep', u'practic deep fulli', u'practic factor', u'practic factor like', u'practic interestfor', u'practic interestfor various', u'practic interesti', u'practic interesti road', u'practic orient', u'practic orient withcurr', u'practic orient withindoor', u'practic strong', u'practic strong regularis', u'practic trade-off', u'practic trade-off involv', u'practic trade-offsinvolv', u'practic trade-offsinvolv design', u'practic trade-offswith', u'practic trade-offswith import', u'practicalappl', u'practicalappl henc', u'practicalappl henc propos', u'practicalfig', u'practicalfig segnet', u'practicalfig segnet predict', u'practicali', u'practicali constrain', u'practicali constrain encod', u'practicalmax-pool', u'practicalmax-pool indic', u'practicalmax-pool indic decod', u'pre-her', u'pre-her test', u'pre-her test kitti', u'pre-process', u'pre-process step', u'pre-process step input', u'pre-train', u'pre-train camvid', u'pre-train camvid dataset', u'pre-train classif', u'pre-train classif somewhat', u'pre-train convolut', u'pre-train convolut layeron', u'pre-train convolut layerweight', u'pre-train encod', u'pre-train encod network', u'pre-train encodertrain', u'pre-train encodertrain end-to-end', u'pre-train encoderweight', u'pre-train featur', u'pre-train featur hierarchi', u'pre-train larg', u'pre-train larg imagenet', u'pre-train layer', u'pre-train layer train', u'pre-train mscoco', u'pre-train mscoco train', u'pre-train segnet', u'pre-train segnet obtain', u'pre-train segnet use', u'pre-train train', u'pre-train train addit', u'pre-train use', u'pre-train use camvid', u'pre-train weight', u'pre-train weight trainingon', u'pre-train weight trainingpoor', u'pre-train weights31313131decod', u'pre-train weights31313131decod variantsdecod', u'pre-train weightsweight', u'pre-train weightsweight vgg', u'pre-trainedarchitectur', u'pre-trainedarchitectur fcn', u'pre-trainedarchitectur fcn use', u'pre-trainedto', u'pre-trainedto multi-stag', u'pre-trainedto multi-stag train', u'pre-trainingcan', u'pre-trainingcan produc', u'pre-trainingcan produc good', u'pre-trainingtrain', u'pre-trainingtrain epoch', u'pre-trainingtrain epoch kitti', u'preceed', u'preceed pair', u'preceed pair weightsand', u'preceed pair weightsfix', u'precis', u'precis 11mb', u'precis 11mb smaller', u'precis later', u'precis later work', u'precisionand', u'precisionand recal', u'precisionand recal valu', u'precisionth', u'precisionth key', u'precisionth key idea', u'predict', u'predict accuraci', u'predict accuraci class', u'predict appear', u'predict appear blocky2', u'predict areground', u'predict areground truth', u'predict arelarg', u'predict arelarg correct', u'predict aremad', u'predict aremad use', u'predict areoth', u'predict areoth applic', u'predict areth', u'predict areth qualit', u'predict class', u'predict class probabl', u'predict classforest', u'predict classforest boost', u'predict classprob', u'predict classprob center', u'predict creat', u'predict creat input', u'predict crf', u'predict crf result', u'predict delin', u'predict delin inter', u'predict effect', u'predict effect subset', u'predict encod', u'predict encod network', u'predict entir', u'predict entir static', u'predict fromdeep', u'predict fromdeep segment', u'predict frominterest', u'predict frominterest estim', u'predict fulli', u'predict fulli learnt', u'predict getbacktrack', u'predict getbacktrack input', u'predict getsmooth', u'predict getsmooth layer', u'predict ground', u'predict ground truth', u'predict high', u'predict high global', u'predict howev', u'predict howev foundthi', u'predict howev foundwhich', u'predict ina', u'predict ina crf', u'predict incombin', u'predict incombin object', u'predict incorrect', u'predict incorrect label', u'predict indoor', u'predict indoor scene', u'predict labelsfor', u'predict labelsfor pixel', u'predict labelsproduc', u'predict labelsproduc high', u'predict labelsto', u'predict labelsto produc', u'predict loos', u'predict loos small', u'predict madeoth', u'predict madeoth applic', u'predict madeus', u'predict madeus deep', u'predict model', u'predict model uncertainti', u'predict obtain', u'predict obtain atfigur', u'predict obtain atvari', u'predict obtaineddenot', u'predict obtaineddenot segnet', u'predict obtainedin', u'predict obtainedin scenario', u'predict oftencal', u'predict oftencal unari', u'predict oftenth', u'predict oftenth camvid', u'predict older', u'predict older method', u'predict otherdeep', u'predict otherdeep architectur', u'predict otherth', u'predict otherth qualit', u'predict overal', u'predict overal model', u'predict perform', u'predict perform fcn', u'predict perform networkw', u'predict perform networkwithout', u'predict pixel', u'predict pixel label', u'predict pixel unari', u'predict pixel-wis', u'predict pixel-wis label', u'predict pixel-wis labellingof', u'predict pixel-wis labellingthi', u'predict pixelwis', u'predict pixelwis class', u'predict problem', u'predict problem sucha', u'predict problem suchclassif', u'predict resolut', u'predict resolut restrict', u'predict restrict', u'predict restrict themap', u'predict restrict thenumb', u'predict retain', u'predict retain small', u'predict rgb', u'predict rgb indoor', u'predict rgbd', u'predict rgbd input', u'predict road', u'predict road scene', u'predict segment', u'predict segment correspond', u'predict sever', u'predict sever known', u'predict shown', u'predict shown note', u'predict singl', u'predict singl imag', u'predict size', u'predict size class', u'predict smoother', u'predict smoother depthi', u'predict smoother depthw', u'predict techniqu', u'predict techniqu arealreadi', u'predict techniqu areto', u'predict thinn', u'predict thinn network', u'predict unari', u'predict unari combin', u'predict unari term', u'predict unlikepatch', u'predict unlikepatch base', u'predict unlikepixel', u'predict unlikepixel label', u'predict use', u'predict use varianc', u'predictionsar', u'predictionsar better', u'predictionsar better multi-scal', u'predictionsdo', u'predictionsdo retain', u'predictionsdo retain small', u'predictionsher', u'predictionsher test', u'predictionsher test kitti', u'predictionsneur', u'predictionsneur network', u'predictionsneur network merg', u'predictionson', u'predictionson small', u'predictionson small set', u'predictionspart', u'predictionspart veri', u'predictionspart veri reason', u'predictionsshallow', u'predictionsshallow layer', u'predictionsshallow layer produc', u'predictionsth', u'predictionsth largest', u'predictionsth largest model', u'predictionsto', u'predictionsto creat', u'predictionsto creat input', u'predictionsto top-1', u'predictionsto top-1 layer', u'predictivesystem', u'predictivesystem output', u'predictiveuncertainti', u'predictiveuncertainti natur', u'predictiveuncertainti natur ani', u'predictlabel', u'predictlabel resolut', u'predictlabel resolut produc', u'predictsurpris', u'predictsurpris deeplab-largefov', u'predictsurpris deeplab-largefov train', u'predomin', u'predomin caus', u'predomin caus situat', u'preprint', u'preprint arxiv:1312', u'preprint arxiv:13126199', u'preprint arxiv:13126199 4network', u'preprint arxiv:13126199 6h', u'preprint arxiv:1408', u'preprint arxiv:1409', u'preprint arxiv:14091556', u'preprint arxiv:14091556 2014j', u'preprint arxiv:14091556 2014large-scal', u'preprint arxiv:1411', u'preprint arxiv:1412', u'preprint arxiv:1502', u'preprint arxiv:150202734', u'preprint arxiv:150202734 2015arxiv', u'preprint arxiv:150202734 2015for', u'preprint arxiv:1505', u'preprint arxiv:1509', u'preprint arxiv:1511', u'preprint arxiv:151102680', u'preprint arxiv:151102680 2015understand', u'preprint arxiv:151102680 2015vijay', u'preprint arxiv:1604', u'preprint arxiv:160401685', u'preprint arxiv:160401685 2016potenti', u'preprint arxiv:160401685 2016urban', u'preprintarxiv:1411', u'preprintarxiv:1502', u'preprintarxiv:1504', u'preprintarxiv:150401013', u'preprintarxiv:150401013 2015arxiv:150401013', u'preprintarxiv:150401013 2015arxiv:150401013 2015arxiv:150401013', u'preprintdeep', u'preprintdeep structur', u'preprintdeep structur model', u'preprintfor', u'preprintfor object', u'preprintfor object segment', u'preprintnetwork', u'preprintnetwork train', u'preprintnetwork train reduc', u'present', u'present bayesian', u'present bayesian segnet', u'present decod', u'present decod network', u'present deep', u'present deep learn', u'present encod', u'present encod featur', u'present ground', u'present ground truth', u'present improv', u'present improv hand', u'present novel', u'present novel practic', u'present real-timeonlin', u'present real-timeonlin demo', u'present real-timeto', u'present real-timeto demonstr', u'present scene', u'present scene spatialarrang', u'present scene spatialin', u'present segnet', u'present segnet deep', u'present segnet fulli', u'present testar', u'present testar typic', u'present testimag', u'present testimag factor', u'preserv', u'preserv structur', u'preserv structur scene', u'preval', u'preval inth', u'preval inth dataset', u'preval inthat', u'preval inthat bayesian', u'prevent', u'prevent neural', u'prevent neural network', u'prevent over-fit', u'prevent overfit', u'prevent overfit seeconvolut', u'prevent overfit seehttp', u'previous', u'previous approach', u'previous approach scene', u'previous benchmark', u'previous benchmark includ', u'previousbenchmark', u'previousbenchmark includ', u'previousbenchmark includ use', u'previousoth', u'previousoth method', u'previoust', u'previoust result', u'previoust result compar', u'primari', u'primari motiv', u'primari motiv propos', u'primarili', u'primarili becaus', u'primarili becaus max', u'primarili deepest', u'primarili deepest layer', u'primarili motiv', u'primarili motiv scene', u'primarilymotiv', u'primarilymotiv road', u'primarilymotiv road scene', u'primarilyour', u'primarilyour architectur', u'primarilyour architectur segnet', u'princip', u'princip engin', u'princip engin deepcurr', u'princip engin deeplearn', u'principl', u'principl use', u'principl use bit', u'principl window', u'principl window memor', u'prior', u'prior crf', u'prior crf lessenedalso', u'prior crf lessenedwhen', u'prl', u'prl vol', u'prl vol pp', u'probabilist', u'probabilist auto-encod', u'probabilist auto-encod use', u'probabilist deepconvolut', u'probabilist deepconvolut neural', u'probabilist deepsect', u'probabilist deepsect propos', u'probabilist encoderdecod', u'probabilist encoderdecod architectur', u'probabilist framework', u'probabilist framework semant', u'probabilist infer', u'probabilist infer segment', u'probabilist output', u'probabilist output measur', u'probabilist segment', u'probabilist segment output', u'probabilist segment witha', u'probabilist segment withlearn', u'probabilist variants4', u'probabilist variantsa', u'probabilist variantsa fulli', u'probabilisticbayesian', u'probabilisticbayesian neural', u'probabilisticbayesian neural network', u'probabilisticca', u'probabilisticca research', u'probabilisticca research probabilisticca', u'probabilisticca research probabilisticgraph', u'probabilisticgraph', u'probabilisticgraph model', u'probabilisticgraph model deep', u'probabilisticinterpret', u'probabilisticinterpret deep', u'probabilisticinterpret deep learn', u'probabilisticpixel-wis', u'probabilisticpixel-wis semant', u'probabilisticpixel-wis semant segment', u'probabilisticw', u'probabilisticw present', u'probabilisticw present deep', u'probabl', u'probabl center', u'probabl center pixel', u'probabl class', u'probabl classcarlo', u'probabl classcarlo sampl', u'probabl classlabel', u'probabl classlabel overal', u'probabl distribut', u'probabl distribut montecarlo', u'probabl distribut montew', u'probabl drop', u'probabl drop connect', u'probabl k', u'probabl k theclassifi', u'probabl k thenumb', u'probabl obtain', u'probabl obtain softmax', u'probabl pi', u'probabl pi optimis', u'probabl pixel', u'probabl pixelclass', u'probabl pixelclass maximum', u'probabl pixelindepend', u'probabl pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach', u'probabl pixelindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyindependentlyeach encod', u'probabl pixelsoft-max', u'probabl pixelsoft-max classifi', u'probabl pixelw', u'probabl pixelw add', u'problem', u'problem extrem', u'problem extrem larg', u'problem howev', u'problem howev recent', u'problem learn', u'problem learn map', u'problem scene', u'problem scene varyimag', u'problem scene varysignific', u'problem secondfor', u'problem secondfor various', u'problem secondtask', u'problem secondtask indoor', u'problem segnet', u'problem segnet outperform', u'problem sucha', u'problem sucha segment', u'problem suchclassif', u'problem suchclassif recent', u'problem use', u'problem use infer', u'problemattent', u'problemattent paid', u'problemattent paid import', u'problemr', u'problemr eferencesr', u'problemr eferencesr eferencesr', u'problemsalex', u'problemsalex kendal', u'problemsalex kendal graduat', u'problemsgraph', u'problemsgraph model', u'problemsgraph model deep', u'proceed', u'proceed 22nd', u'proceed 22nd acm', u'proceed ieee', u'proceed ieee confer', u'proceed ieee conferenceon', u'proceed ieee conferenceunderstand', u'proceed ieee intern', u'proceed ieeeintern', u'proceed ieeeintern confer', u'proceed ieeesegment', u'proceed ieeesegment deep', u'process', u'process demonstr', u'process demonstr efficaci', u'process expens', u'process expens given', u'process fromclassif', u'process fromclassif therefor', u'process fromweight', u'process fromweight train', u'process layer', u'process layer encod', u'process page', u'process page 2348\\u2013advanc', u'process sever', u'process sever practicalfig', u'process sever practicalmax-pool', u'process tool', u'process upsampl', u'process upsampl decod', u'process use', u'process use approach', u'produc', u'produc bayesian', u'produc bayesian segnet', u'produc best', u'produc best accuraci', u'produc binari', u'produc binari measur', u'produc class', u'produc class probabl', u'produc competit', u'produc competit performancegiven', u'produc competit performancelabel', u'produc competit result', u'produc competit resultsalthough', u'produc competit resultsand', u'produc decod', u'produc decod output', u'produc decod outputanoth', u'produc decod outputfeatur', u'produc dens', u'produc dens featur', u'produc estim', u'produc estim absolut', u'produc featur', u'produc featur map', u'produc featur recognit', u'produc featuresfor', u'produc featuresfor pixel-wis', u'produc featureswhich', u'produc featureswhich use', u'produc good', u'produc good result', u'produc high', u'produc high qualiti', u'produc imag', u'produc imag f1-measur', u'produc incorrect', u'produc incorrect class', u'produc multi-channel', u'produc multi-channel featur', u'produc overal', u'produc overal smooth', u'produc poorer', u'produc poorer segment', u'produc probabilist', u'produc probabilist segment', u'produc qualit', u'produc qualit better', u'produc random', u'produc random sampl', u'produc reliablemeasur', u'produc reliablemeasur model', u'produc reliablequantit', u'produc reliablequantit bayesian', u'produc result', u'produc result notclear', u'produc result notw', u'produc set', u'produc set featur', u'produc similar', u'produc similar look', u'produc smooth', u'produc smooth segment', u'produc smootha', u'produc smootha road', u'produc smoothsegment', u'produc smoothsegment engin', u'produc spars', u'produc spars featur', u'produc theoutput', u'produc theoutput decod', u'produc theth', u'produc theth correspond', u'producedbett', u'producedbett result', u'producedfound', u'producedfound comput', u'producedfound comput weight', u'producesthes', u'producesthes low', u'producesthes low resolut', u'producesto', u'producesto pixel-wis', u'producesto pixel-wis predict', u'producingarchitectur', u'producingarchitectur respons', u'producingarchitectur respons producingarchitectur', u'producingarchitectur respons producingmulti-dimension', u'producingmulti-dimension', u'producingmulti-dimension featur', u'producingmulti-dimension featur pixel', u'professor', u'professor 2000a', u'professor 2000a reader', u'professor 2000he', u'professor 2000he becam', u'progressivelyad', u'progressivelyad exist', u'progressivelyad exist train', u'progressivelyprocess', u'progressivelyprocess decod', u'progressivelyprocess decod decod', u'project', u'project webpage1', u'project webpage1 onlin', u'project webpageat', u'project webpageat object', u'project webpagemi', u'promin', u'promin deep', u'promin deep learn', u'promin scene', u'promin scene understand', u'properti', u'properti neurali', u'properti neurali goodfellow', u'properti neuralnetwork', u'properti neuralnetwork arxiv', u'properti onli', u'properti onli requir', u'proport', u'proport dropout', u'proport dropout percentag', u'proportionactiv', u'proportionactiv proportionactiv', u'proportionactiv proportionactiv proportionactiv', u'proportionactiv proportionactiv proportionof', u'proportionactiv proportionof', u'proportionactiv proportionof non-zero', u'proportionof', u'proportionof non-zero', u'proportionof non-zero featur', u'propos', u'propos architectur', u'propos architectur abil', u'propos architectur segment', u'propos architectur whichen', u'propos architectur whichus', u'propos architectur wide', u'propos base', u'propos base challeng', u'propos bayesian', u'propos bayesian segnet', u'propos bootstrap', u'propos bootstrap core', u'propos complement', u'propos complement miouauthor', u'propos complement mioumetr', u'propos deconvolut', u'propos deconvolut network', u'propos deep', u'propos deep architectur', u'propos effici', u'propos effici way', u'propos eigen', u'propos eigen andclass', u'propos eigen andfergus', u'propos enabl', u'propos enabl train', u'propos idea', u'propos idea decod', u'propos infer', u'propos infer believ', u'propos infer disjoint', u'propos medicala', u'propos medicala compar', u'propos medicalimag', u'propos medicalimag communiti', u'propos novel', u'propos novel deep', u'propos post-process', u'propos post-process use', u'propos ranzato', u'propos ranzato et', u'propos remov', u'propos remov dropout', u'propos segment', u'propos segment method', u'propos segnet', u'propos segnet architectur', u'propos segnet primari', u'propos segnet signific', u'propos therefor', u'propos therefor differ', u'propos train', u'propos train end-to-end', u'propos use', u'propos use increas', u'proposeda', u'proposeda similar', u'proposeda similar architectur', u'proposedhttp', u'proposedhttp //arxiv', u'proposedhttp //arxivorg/pdf/150504366pdf', u'proposedhttp //arxivorg/pdf/150504366pdf 2015http', u'pros', u'pros consand', u'pros consand reveal', u'pros consw', u'pros consw evalu', u'prototxt', u'prototxt road', u'prototxt road scene', u'provid', u'provid addit', u'provid addit degre', u'provid bothi', u'provid bothi use', u'provid bothloc', u'provid bothloc global', u'provid caff', u'provid caff implement', u'provid good', u'provid good perform', u'provid wide', u'provid wide context', u'pseudo', u'pseudo depth', u'pseudo depth edg', u'public', u'public avail', u'public avail roadscen', u'public avail roadth', u'public avail test', u'public soon', u'public soon withour', u'public soon withth', u'publish', u'publish 1note', u'publish 1note comput', u'publish 1what', u'publish 1what best', u'puriti', u'puriti tree', u'puriti tree optim', u'pursu', u'pursu multi-scal', u'pursu multi-scal deep', u'pursu scale', u'pursu scale correspond', u'q', u'q meanq', u'q meanq meanq', u'q w', u'q w minimisingth', u'q w minimisingweight', u'q w p', u'q wi', u'q wi foreveri', u'q wi forher', u'qualit', u'qualit allow', u'qualit allow tomont', u'qualit allow tounderstand', u'qualit analysi', u'qualit analysi quantit', u'qualit assess', u'qualit assess segnet', u'qualit better', u'qualit better predictionsshallow', u'qualit better predictionsto', u'qualit comparison', u'qualit comparison segnet', u'qualit fourcamvid', u'qualit fourcamvid dataset', u'qualit fourvari', u'qualit fourvari produc', u'qualit numer', u'qualit numer accuraci', u'qualit perform', u'qualit perform bayesian', u'qualit produc', u'qualit produc binari', u'qualit result', u'qualit result beunion', u'qualit result beview', u'qualit result fig', u'qualit result segnet', u'qualit result viewedevalu', u'qualit result viewedin', u'qualit resultsdeep', u'qualit resultsdeep architectur', u'qualit resultsshow', u'qualit resultsshow abil', u'qualitativejudg', u'qualitativejudg rank', u'qualitativejudg rank good', u'qualitativethat', u'qualitativethat metric', u'qualitativethat metric doe', u'qualiti', u'qualiti better', u'qualiti better object', u'qualiti csurka', u'qualiti csurka et', u'qualiti depth', u'qualiti depth imag', u'qualiti drop', u'qualiti drop signific', u'qualiti label', u'qualiti label improv', u'qualiti predict', u'qualiti predict obtaineddenot', u'qualiti predict obtainedin', u'qualiti segment', u'qualiti segment withexampl', u'qualiti segment withjudg', u'qualiti unari', u'qualiti unari tri', u'quality40k40k40k40k80k80k80k80kmax', u'quality40k40k40k40k80k80k80k80kmax itermax', u'quality40k40k40k40k80k80k80k80kmax itermax itermax', u'qualityacross', u'qualityacross class', u'qualityacross class row', u'qualityhowev', u'qualityhowev compar', u'qualityhowev compar outdoor', u'qualitysegment', u'qualitysegment especi', u'qualitysegment especi difficult', u'quantifi', u'quantifi perform', u'quantifi perform bayesian', u'quantifi perform metric', u'quantifi perform segnet', u'quantifi perform use', u'quantit', u'quantit analysi', u'quantit analysi shown', u'quantit assessmentsand', u'quantit assessmentsand architectur', u'quantit assessmentsshow', u'quantit assessmentsshow segnet', u'quantit comparison', u'quantit comparison sun', u'quantit differ', u'quantit differ sampl', u'quantit experi', u'quantit experi withit', u'quantit experi withsegnet', u'quantit observ', u'quantit perform', u'quantit perform differ', u'quantit performance2', u'quantit performance2 literatur', u'quantit performancemeasur', u'quantit performancemeasur quantit', u'quantit result', u'quantit result camvid', u'quantit result disentangl', u'quantit result kitti', u'quantit result nyu', u'quantit result tabl', u'quantit segment', u'quantit segment perform', u'question', u'question vari', u'question vari ob-input', u'question vari ob-ject', u'quit', u'quit satisfactori', u'quit satisfactori primarili', u'quitepoor', u'quitepoor comparison', u'quitepoor comparison abov', u'quitespars', u'quitespars array', u'quitespars array indic', u'r', u'r 897segnet', u'r 897segnet l4', u'r cipolla', u'r cipolla machin', u'r cipolla \\u201csegnet', u'r competit', u'r competit tempor', u'r eferencesr', u'r eferencesr eferencesr', u'r eviewl', u'r eviewl iteratur', u'r eviewsemant', u'r eviewsemant pixel-wis', u'r expect', u'r expect fig', u'r fergus', u'r fergus intrigu', u'r fergus \\u201cpredict', u'r ii', u'r ii initi', u'r segnet', u'r segnet r', u'r small', u'r small comput', u'rabinovich', u'rabinovich c', u'rabinovich c berg', u'rabinovich \\u201cgo', u'rabinovich \\u201cgo deeper', u'rabinovichd', u'rabinovichd anguelov', u'rabinovichd anguelov d', u'rabinovichgo', u'rabinovichgo deeper', u'rabinovichgo deeper convolut', u'rais', u'rais thea', u'rais thea complex', u'rais thequest', u'rais thequest perceiv', u'random', u'random chosen', u'random chosen imag', u'random drop', u'random drop unit', u'random field', u'random field recurr', u'random forest', u'random forest anoth', u'random forest available51', u'random forest available514', u'random forest availablestructur', u'random forest base', u'random forest basedpixel', u'random forest basedunari', u'random forest boost', u'random forest neural', u'random forest semant', u'random forest structur', u'random forest use', u'random forestbas', u'random forestbas classifi', u'random foresttextonboost', u'random foresttextonboost textonforest', u'random initi', u'random initi denot', u'random initi use', u'random initialis', u'random initialis remain', u'random sampl', u'random sampl road', u'random test', u'random test urban', u'random variablesand', u'random variablesand variat', u'random variableswith', u'random variableswith bi', u'randomalso', u'randomalso use', u'randomalso use input', u'randomfeatur', u'randomfeatur general', u'randomfeatur general use', u'randomfield', u'randomfield crfs', u'randomfield crfs crf-rnn', u'randomforest', u'randomforest anoth', u'randomforest anoth approach', u'randomforest boost', u'randomforest boost predict', u'randomlyremov', u'randomlyremov unit', u'randomlyremov unit network', u'randomlytrain', u'randomlytrain stochast', u'randomlytrain stochast gradient', u'randomr', u'randomr hand', u'randomr hand engin', u'randomregion', u'randomregion propos', u'randomregion propos bootstrap', u'rang', u'rang applic', u'rang applic robot', u'rang architectur', u'rang estim', u'rang estim scene', u'rang increas', u'rang increas contrast', u'rangingfrom', u'rangingfrom scene', u'rangingfrom scene understand', u'rangingsemant', u'rangingsemant segment', u'rangingsemant segment wide', u'rank', u'rank good', u'rank good qualiti', u'rank segment', u'rank segment output', u'rank segment outputsmor', u'rank segment outputsth', u'rank use', u'rank use multi-stagetoward', u'rank use multi-stagetrain', u'ranzato', u'ranzato et', u'ranzato et al', u'ranzato et almain', u'ranzato et alnetwork', u'ranzato main', u'ranzato main concentr', u'rare', u'rare challeng', u'rare challeng class', u'rare class', u'rare class signsymbol', u'rare class signth', u'rate', u'rate momentum', u'rate momentum paramet', u'rate momentumof', u'rate momentumof optim', u'rate momentumsgd', u'rate momentumsgd solver', u'rate smaller', u'rate smaller network', u'rate tune', u'rate tune use', u'rateof', u'rateof momentum', u'rateof momentum use', u'rateus', u'rateus stochast', u'rateus stochast gradient', u'ratio', u'ratio asa', u'ratio asa measur', u'ratio asvari', u'ratio asvari measur', u'ratio themedian', u'ratio themedian class', u'ratio theweight', u'ratio theweight assign', u'rc10001', u'rc10001 cam', u'rchitecturea', u'rchitecturea rchitecturea', u'rchitecturea rchitecturea rchitecturea', u'rchitecturea rchitecturea rchitecturesegnet', u'rchitecturea rchitecturesegnet', u'rchitecturea rchitecturesegnet encod', u'rchitecturesegnet', u'rchitecturesegnet encod', u'rchitecturesegnet encod network', u'reader', u'reader inform', u'reader inform engin', u'real', u'real time', u'real time gpu', u'real time performance5', u'real time performancet', u'real-tim', u'real-tim applic', u'real-tim applic alsointerest', u'real-tim applic alsomor', u'real-tim applic road', u'real-tim human', u'real-tim human pose', u'real-tim joint', u'real-tim joint reconstruct', u'real-timeonlin', u'real-timeonlin demo', u'real-timeonlin demo road', u'real-timeto', u'real-timeto demonstr', u'real-timeto demonstr efficaci', u'realiti', u'realiti ar', u'realiti ar applic', u'reason', u'reason avoid', u'reason avoid paramet', u'reason choos', u'reason choos camvida', u'reason choos camvidstil', u'reason context', u'reason context relatedbas', u'reason context relatedclass', u'reason indic', u'reason indic network', u'reason isedg', u'reason isedg error', u'reason isthat', u'reason isthat differ', u'reason overal', u'reason overal poor', u'reason poor', u'reason poor perform', u'reason predict', u'reason predict size', u'reason predictionsher', u'reason predictionsher test', u'reason predictionspart', u'reason predictionspart veri', u'reason shown', u'reason shown percentag', u'reason size', u'reason size veri', u'reason thatresult', u'reason thatresult overal', u'reason thatth', u'reason thatth contribut', u'reason time', u'reason time camviddataset', u'reason time camvidnet', u'reason whi', u'reason whi segnet-bas', u'reasonableaccuraci', u'reasonableaccuraci smaller', u'reasonableaccuraci smaller class', u'reasonablereport', u'reasonablereport tabl', u'reasonablereport tabl clear', u'recal', u'recal valu', u'recal valu predict', u'receiv', u'receiv fromappropri', u'receiv fromappropri decod', u'receiv fromth', u'receiv fromth correspond', u'receiv max-pool', u'receiv max-pool indic', u'recent', u'recent approach', u'recent approach aim', u'recent approach tri', u'recent compet', u'recent compet method', u'recent deep', u'recent deep architectur', u'recent deep learn', u'recent imag', u'recent imag dataset', u'recent independ', u'recent independ segment', u'recent led', u'recent led research', u'recent literatur', u'recent literatur describ', u'recent method', u'recent method showsset', u'recent method showsth', u'recent perform', u'recent perform techniqu', u'recent propos', u'recent propos deconvolut', u'recent propos deep', u'recent releas', u'recent releas sun', u'recent studi', u'recent studi shown', u'recent theauthor', u'recent theauthor fcn', u'recent theevalu', u'recent theevalu boundari', u'recent work', u'recent work bothaccuraci', u'recent work bothclass', u'recentarchitectur', u'recentarchitectur architectur', u'recentarchitectur architectur architectur', u'recentfavour', u'recentfavour techniqu', u'recentfavour techniqu use', u'recentresult', u'recentresult deconvolut', u'recentresult deconvolut network', u'recentstudi', u'recentstudi network', u'recentstudi network core', u'recentwhen', u'recentwhen joint', u'recentwhen joint train', u'recentwork', u'recentwork decoupl', u'recentwork decoupl classification-segment', u'recip', u'recip vari', u'recip vari input', u'recognit', u'recognit arxiv', u'recognit arxiv preprint', u'recognit corr', u'recognit corr vol', u'recognit cvpr', u'recognit cvpr algorithm', u'recognit cvpr ieee', u'recognit iccv', u'recognit iccv page', u'recognit iccv pp', u'recognit imagedeep', u'recognit imagedeep learn', u'recognit imagenetwork', u'recognit imagenetwork fcn', u'recognit indoor', u'recognit indoor scene', u'recognit nip', u'recognit nip page', u'recognit nip pp', u'recognit page', u'recognit page understand', u'recognit pp', u'recognit pp 2015edg', u'recognit pp 2015on', u'recognit pp 3376\\u20133385,201520152015201520152015network', u'recognit pp confer', u'recognit segment', u'recognit segment joint', u'recognit singl', u'recognit singl depth', u'recognit speech', u'recognit speech categoris', u'recognit speech categorisinglearn', u'recognit speech categorisingwhol', u'recognit speech huge', u'recognit success', u'recognit success add', u'recognit use', u'recognit use structur', u'recognition22label', u'recognitionand', u'recognitionand zisserman', u'recognitionand zisserman \\u201cthe', u'recognitionin', u'recognitionin video', u'recognitionin video sequenc', u'recognitionlett', u'recognitionsegment', u'recognitionsegment wild', u'recognitionsegment wild comput', u'recognitionvideo', u'recognitionvideo high-definit', u'recognitionvideo high-definit ground', u'reconstruct', u'reconstruct input', u'reconstruct input imag', u'reconstruct objectiveth', u'reconstruct objectiveth hand', u'reconstruct objectivewith', u'reconstruct objectivewith deeper', u'reconstruct semant', u'reconstruct semant segment', u'reconstruct semanticapproach', u'reconstruct semanticapproach focus', u'reconstruct semanticsegment', u'reconstruct semanticsegment random', u'reconstruct thecross-entropi', u'reconstruct thecross-entropi loss', u'reconstruct theinput', u'reconstruct theinput layer', u'reconstructswitch', u'reconstructswitch learn', u'reconstructswitch learn decod', u'reconstructth', u'reconstructth input', u'reconstructth input imag', u'rectifiedlinear', u'rectifiedlinear non-linear', u'rectifiedlinear non-linear relu', u'recurr', u'recurr neural', u'recurr neural network', u'recurr neuralc', u'recurr neuralc huang', u'recurr neuralnetwork', u'recurr neuralnetwork proceed', u'recurrentclassif', u'recurrentclassif blocki', u'recurrentclassif blocki anoth', u'recurrentneur', u'recurrentneur network', u'recurrentneur network merg', u'recurs', u'recurs neural', u'recurs neural network', u'reduc', u'reduc core', u'reduc core feed-forward', u'reduc dynamicnon-uniform', u'reduc dynamicnon-uniform scene', u'reduc dynamicrang', u'reduc dynamicrang increas', u'reduc forcomput', u'reduc forcomput parallel', u'reduc forpract', u'reduc forpract applic', u'reduc intern', u'reduc intern covari', u'reduc memori', u'reduc memori consumptionand', u'reduc memori consumptionwithout', u'reduc number', u'reduc number ofconvolut', u'reduc number offeatur', u'reduc number paramet', u'reduc number trainableparamet', u'reduc number trainabletheir', u'reduc size', u'reduc size fullyconnect', u'reduc size fullyreport', u'reduc spatial', u'reduc spatial context', u'reduc theadvantag', u'reduc theadvantag improv', u'reduc thenumb', u'reduc thenumb paramet', u'reduc total', u'reduc total number', u'reduc train', u'reduc train data', u'reduc width', u'reducefeatur', u'reducefeatur map', u'reducefeatur map resolut', u'reducethi', u'reducethi primarili', u'reducethi primarili becaus', u'reduct', u'reduct encodercorrespond', u'reduct encodercorrespond decod', u'reduct encoderfeatur', u'reduct encoderfeatur map', u'reduct fcn-basic', u'reduct fcn-basic model', u'reduct featur', u'reduct featur map', u'reduct fewer', u'reduct fewer fcn-basic', u'reduct fewer featur', u'reduct step', u'reduct step encod', u'reduct train', u'reduct train loss', u'redund', u'redund consum', u'redund consum memori', u'reed', u'reed d', u'reed d anguelov', u'refer', u'refer core', u'refer core segment', u'refer segnet', u'refer segnether', u'refer segnether note', u'refer segnetor', u'refer segnetor higher', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass video', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass video high-definit', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesin', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesin video', u'referencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesin video sequenc', u'referredtest', u'referredtest time', u'referredtest time standard', u'referredto', u'referredto weight', u'referredto weight averag', u'reflect', u'reflect ambigu', u'reflect ambigu surround', u'reflect semanticcontour', u'reflect semanticcontour delin', u'reflect semanticmap', u'reflect semanticmap store', u'regard', u'regard approach', u'regard approach withi', u'regard approach withpoint', u'region', u'region iccv', u'region iccv geometr', u'region iccv page', u'region iccv pp', u'region propos', u'region propos enabl', u'region propos infer', u'region segment', u'region segment obtain', u'region smooth', u'region smooth doe', u'regionmad', u'regionmad use', u'regionmad use richer', u'regionsegment', u'regionsegment obtain', u'regionsegment obtain higher', u'regress', u'regress c-e', u'regress c-e darker', u'regress onli', u'regress onli capabl', u'regular', u'regular convolut', u'regular convolut neural', u'regularis', u'regularis caus', u'regularis caus network', u'regularis model', u'regularis result', u'regularis result lower', u'regularityin', u'regularityin number', u'regularityin number class', u'regularitysinc', u'regularitysinc view', u'regularitysinc view point', u'relat', u'relat categori', u'relat categories4', u'relat categories4 experi', u'relat categoriesto', u'relat categoriesto top-1', u'relat differ', u'relat differ dataset', u'relat issu', u'relat issu need', u'relat probabl', u'relat probabl class', u'relat probabl classcarlo', u'relat probabl classlabel', u'relat problem', u'relat problem secondfor', u'relat problem secondtask', u'relat recent', u'relat recent literatur', u'relat work2', u'relat worksemant', u'relat worksemant pixel', u'relatedbas', u'relatedbas cue', u'relatedbas cue lack', u'relatedclass', u'relatedclass crf', u'relatedclass crf base', u'relationship', u'relationship class', u'relationship class accuraci', u'relationship effect', u'relationship effect model', u'relationship infer', u'relationship infer togeth', u'relationship infer togetherclass', u'relationship infer togetherus', u'relationship model', u'relationship model uncertainti', u'relationship uncertainti', u'relationship uncertainti classaccuraci', u'relationship uncertainti classvalu', u'relationshipbetween', u'relationshipbetween uncertainti', u'relationshipbetween uncertainti accuraci', u'relationshipth', u'relationshipth model', u'relationshipth model uncertain', u'releas', u'releas caff', u'releas caff implement', u'releas nyu', u'releas nyu dataset', u'releas nyudataset', u'releas nyudataset use', u'releas nyumeanwhil', u'releas nyumeanwhil indoor', u'releas sun', u'releas sun rgb-d', u'relev', u'relev task', u'relev task therefor', u'relev trainingset', u'relev trainingset use', u'relev trainingwhich', u'relev trainingwhich enabl', u'reli', u'reli hand', u'reli hand engineeredbest', u'reli hand engineeredfeatur', u'reli linear', u'reli linear discriminantfunct', u'reli linear discriminantfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionfunctionw', u'reli linear discriminantth', u'reli low-level', u'reli low-level vision', u'reli lowlevel', u'reli lowlevel vision', u'reliablemeasur', u'reliablemeasur model', u'reliablemeasur model uncertainti', u'reliablequantit', u'reliablequantit bayesian', u'reliablequantit bayesian segnet', u'reloc', u'relocalis', u'relu', u'relu max', u'relu max x', u'relu non-linear', u'relu non-linear follow', u'relu non-linear non-overlap', u'relu nonlinear', u'relu nonlinear present', u'reluconv', u'reluconv batch', u'reluconv batch normalis', u'reludecod', u'reludecod upsampl', u'reludecod upsampl input', u'reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur', u'reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur schemat', u'reludropoutdropoutdropoutdropoutdropoutdropoutdropoutdropoutpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingpooling/upsamplingsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxfigur schemat bayesian', u'relunon-linear', u'relunon-linear use', u'relunon-linear use decod', u'relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig', u'relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig illustr', u'relusoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxsoftmaxpoolingpoolingpoolingpoolingpoolingpoolingpoolingpoolingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingupsamplingsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationsegmentationfig illustr segnet', u'remain', u'remain case', u'remain case butsegnet', u'remain case butwith', u'remain class', u'remain class class', u'remain fix', u'remain fix experi', u'remain minim', u'remain minim labelcross-entropi', u'remain minim labelthat', u'remain plan', u'remain plan studi', u'remain set', u'remain set zero', u'remain zero', u'remain zero produc', u'remaind', u'remaind paper', u'remaind paper organ', u'remainsth', u'remainsth experi', u'remainsth experi slight', u'remainswith', u'remainswith connect', u'remainswith connect choic', u'remark', u'remark herethat', u'remark herethat use', u'remark hereto', u'remark hereto segment', u'remot', u'remot test', u'remot test server', u'remov', u'remov dropout', u'remov dropout test', u'remov fullyconnect', u'remov fullyconnect layer', u'remov fullyth', u'remov fullyth convolut', u'remov needfor', u'remov needfor sampl', u'remov needweight', u'remov needweight averag', u'ren', u'ren et', u'renn', u'renn franc', u'renn franc senior', u'replac', u'replac mini-batch', u'replac mini-batchavoid', u'replac mini-batchavoid gpu-cpu', u'replac mini-batchth', u'replac mini-batchth optim', u'replic', u'replic deepest', u'replic deepest layer', u'replic featuresmatch', u'replic featuresmatch input', u'replic featureswithin', u'replic featureswithin block', u'replic result', u'replic result noisi', u'replic use', u'replic use fix', u'report', u'report base', u'report base onli', u'report maximum', u'report maximum number', u'report metric', u'report metric stagesin', u'report metric stageswhen', u'report metric time', u'report numer', u'report numer result', u'report perform', u'report sever', u'report sever comparison', u'report thenumer', u'report thenumer perform', u'report theof', u'report theof import', u'reportal', u'reportal measur', u'reportal measur perform', u'reporti', u'reporti highest', u'reporti highest evalu', u'repres', u'repres model', u'repres model uncertainti', u'represent', u'represent architectur', u'represent architectur isth', u'represent architectur isthes', u'represent benefici', u'represent benefici segment', u'represent fed', u'represent fed soft-max', u'represent output', u'represent output finaldecod', u'represent output finalhigh', u'represent power', u'represent power fcn', u'represent requir', u'represent requir optimis', u'representations/featur', u'representations/featur map', u'representations/featur map small', u'representationslearn', u'representationslearn decod', u'representationslearn decod map', u'representationsto', u'representationsto pixel-wis', u'representationsto pixel-wis predict', u'reproduct', u'reproduct result', u'reproduct result releas', u'requir', u'requir 19mb', u'requir 19mb storagereduct', u'requir 19mb storagesegnet', u'requir addit', u'requir addit aid', u'requir addit infer', u'requir ani', u'requir ani addit', u'requir averag', u'requir averag iter', u'requir care', u'requir care post-process', u'requir forward', u'requir forward evaluationof', u'requir forward evaluationw', u'requir learn', u'requir learn class', u'requir map', u'requir map infer', u'requir neglig', u'requir neglig storag', u'requir nofix', u'requir nofix bilinear', u'requir nolearn', u'requir nolearn upsampl', u'requir onli', u'requir onli store', u'requir optim', u'requir optim determin', u'requir optimis', u'requir optimis step', u'requir report', u'requir report base', u'requir store', u'requir store encod', u'requir thehowev', u'requir thehowev model', u'requir theweight', u'requir theweight averag', u'requir understand', u'requir understand animag', u'requir understand ansemant', u'requir use', u'requir use fusion', u'requir various', u'requir various deep', u'requiremotiv', u'requiremotiv road', u'requiremotiv road scene', u'requireth', u'requireth abil', u'requireth abil model', u'research', u'research associ', u'research associ machin', u'research believ', u'research believ indoor', u'research comput', u'research comput vision', u'research develop', u'research develop centr', u'research direct', u'research direct compar', u'research exploit', u'research exploit featur', u'research fuell', u'research fuell challeng', u'research probabilisticca', u'research probabilisticca research', u'research probabilisticgraph', u'research probabilisticgraph model', u'research r', u'research salient', u'research salient object', u'research semant', u'research semant pixel-wis', u'research toengag', u'research toengag attent', u'research torobust', u'research torobust hope', u'research,15', u'resembl', u'resembl build', u'resembl build need', u'resiz', u'resiz imag', u'resiz imag 360x480', u'resiz input', u'resiz input imag', u'resiz theinput', u'resiz theinput imag', u'resiz thevari', u'resiz thevari background', u'resolut', u'resolut andsometim', u'resolut andsometim valid', u'resolut andtrain', u'resolut andtrain separ', u'resolut bit', u'resolut bit float', u'resolut challeng', u'resolut challeng segment', u'resolut compar', u'resolut compar input', u'resolut encod', u'resolut encod featur', u'resolut featur', u'resolut featur input', u'resolut featur map', u'resolut featuremap', u'resolut featuremap certain', u'resolut featuremap pixel-wis', u'resolut featurestop', u'resolut featurestop decod', u'resolut featurevgg16', u'resolut featurevgg16 network', u'resolut imag', u'resolut imag representationslearn', u'resolut imag representationsto', u'resolut inputfeatur', u'resolut inputfeatur map', u'resolut inputmap', u'resolut inputmap pixel-wis', u'resolut interpol', u'resolut interpol depth', u'resolut motiv', u'resolut motiv design', u'resolut predict', u'resolut predict creat', u'resolut predict techniqu', u'resolut predictionsneur', u'resolut predictionsneur network', u'resolut predictionsto', u'resolut predictionsto creat', u'resolut produc', u'resolut produc competit', u'resolut represent', u'resolut represent architectur', u'resolut restrict', u'resolut restrict theachiev', u'resolut restrict thefeatur', u'resolut task', u'resolut task segment', u'resolut use', u'resolut use nvidia-smi', u'resolutionclassif', u'resolutionclassif correspond', u'resolutionclassif correspond loss', u'resolutiondiscuss', u'resolutiondiscuss need', u'resolutiondiscuss need learn', u'resolutionfeatur', u'resolutionfeatur map', u'resolutionfeatur map central', u'resolutionfor', u'resolutionfor pixel-wis', u'resolutionfor pixel-wis classif', u'resolutionfrom', u'resolutionfrom need', u'resolutionfrom need map', u'resolutionlow', u'resolutionlow resolut', u'resolutionlow resolut predict', u'resolutionof', u'resolutionof featur', u'resolutionof featur map', u'resolutionpredict', u'resolutionpredict techniqu', u'resolutionpredict techniqu alreadi', u'resort', u'resort ad', u'resort ad hoc', u'resourc', u'resourc harder', u'resourc harder train', u'resourc requir', u'resourc requir various', u'respect', u'respect author', u'respect author use', u'respect otherclass', u'respect otherclass street', u'respect othervehicl', u'respect othervehicl segment', u'respons', u'respons producingarchitectur', u'respons producingarchitectur respons', u'respons producingmulti-dimension', u'respons producingmulti-dimension featur', u'rest', u'rest method', u'rest method ablefig', u'rest method ableto', u'restrict', u'restrict theachiev', u'restrict theachiev final', u'restrict thefeatur', u'restrict thefeatur size', u'restrict themap', u'restrict themap deep', u'restrict thenumb', u'restrict thenumb pool', u'result', u'result abil', u'result abil segnet', u'result analysi', u'result analysisin', u'result analysisin tabl', u'result analysisw', u'result analysisw size', u'result avail', u'result avail leaderboardhost', u'result avail leaderboardth', u'result averag', u'result averag techniqu', u'result averag trial', u'result bayesian', u'result bayesian segnet', u'result better', u'result better perform', u'result beunion', u'result beunion score', u'result beview', u'result beview fig', u'result camvid', u'result camvid consid', u'result camvid consist', u'result camvid day', u'result camvid road', u'result class', u'result class balanc', u'result class balancinganalys', u'result class balancingfrom', u'result class onli', u'result classif', u'result classif blocki', u'result clear', u'result clear illustr', u'result compar', u'result compar method', u'result compar previousbenchmark', u'result compar previoust', u'result correspond', u'result correspond model', u'result dataset', u'result dataset compar', u'result deconvolut', u'result deconvolut network', u'result disentangl', u'result disentangl key', u'result evalu', u'result evalu onlineevalu', u'result evalu onlinet', u'result far', u'result far satisfactori', u'result featur', u'result featur map', u'result fig', u'result fig predict', u'result improv', u'result improv accuraci', u'result improv withcrf', u'result improv withlarg', u'result increasedeach', u'result increasedeach deeper', u'result increasedspati', u'result increasedspati context', u'result kitti', u'result kitti dataset', u'result lower', u'result lower train', u'result lower trainingdecod', u'result lower trainingfit', u'result method', u'result method evalu', u'result noisi', u'result noisi predict', u'result notclear', u'result notclear interpret', u'result notw', u'result notw like', u'result nyu', u'result nyu v2', u'result nyuv2', u'result nyuv2 rgb-d', u'result obtain', u'result obtain start', u'result onth', u'result onth central', u'result onw', u'result onw therefor', u'result output', u'result output sub-sampl', u'result pascal', u'result pascal voc', u'result poor', u'result poor per-ar', u'result poor per-train', u'result poorer', u'result poorer allobserv', u'result poorer allth', u'result predict', u'result predict appear', u'result random', u'result random forest', u'result releas', u'result releas caff', u'result sampl', u'result sampl camvid', u'result sampl middl', u'result segnet', u'result segnet achievesstate-of-the-art', u'result segnet achievesth', u'result segnet sampl', u'result segnet seefig', u'result segnet seesegnet', u'result shown', u'result shown asaverag', u'result shown aspercentag', u'result slight', u'result slight loss', u'result small', u'result small extra', u'result smaller', u'result smaller class', u'result smooth', u'result smooth miss', u'result smooth predict', u'result smooth retainclass', u'result smooth retainsmal', u'result sun', u'result sun rgb-d', u'result tabl', u'result tabl deeparchitectur', u'result tabl deepth', u'result tabl segnet-bas', u'result tabul', u'result tabul class', u'result techniqu', u'result techniqu indic', u'result techniquesind', u'result techniquesind need', u'result techniqueslearn', u'result techniqueslearn object', u'result term', u'result term global', u'result theafter', u'result theafter deeper', u'result themodel', u'result themodel predict', u'result theobject', u'result theobject boundari', u'result thetop', u'result thetop n', u'result veri', u'result veri encourag', u'result viewedevalu', u'result viewedevalu subset', u'result viewedin', u'result viewedin fig', u'result visuallysimilar', u'result visuallysimilar class', u'result visuallysimilar pedestrian', u'result whenno', u'result whenno class', u'result whenth', u'result whenth column', u'resultand', u'resultand smooth', u'resultand smooth class', u'resulther', u'resulther larg', u'resulther larg perform', u'resultingclassif', u'resultingclassif blocki', u'resultingclassif blocki anoth', u'resultingimag', u'resultingimag dimens', u'resultingimag dimens howev', u'resultsalthough', u'resultsalthough smaller', u'resultsalthough smaller class', u'resultsand', u'resultsand crf', u'resultsand crf post-process', u'resultscan', u'resultscan view', u'resultscan view supplementari', u'resultsdeep', u'resultsdeep architectur', u'resultsdeep architectur seen', u'resultsfor', u'resultsfor test', u'resultsfor test train', u'resultsfrom', u'resultsfrom current', u'resultsfrom current avail', u'resultsin', u'resultsin larg', u'resultsin larg input', u'resultsnot', u'resultsnot optimis', u'resultsnot optimis use', u'resultsnyu', u'resultsnyu dataset', u'resultsnyu dataset futur', u'resultsof', u'resultsof segnet', u'resultsof segnet deconvnet', u'resultsov', u'resultsov small', u'resultsov small spatial', u'resultsshow', u'resultsshow abil', u'resultsshow abil propos', u'retain', u'retain boundari', u'retain boundari inform', u'retain class', u'retain class boundari', u'retain high', u'retain high frequenc', u'retain small', u'retain small categori', u'retain small class', u'retain small classesdo', u'retain small classesw', u'retain structur', u'retain structur smaller', u'retainclass', u'retainclass crf', u'retainclass crf base', u'retainingalso', u'retainingalso discard', u'retainingalso discard fulli', u'retaininghigh', u'retaininghigh resolut', u'retaininghigh resolut featur', u'retainsmal', u'retainsmal class', u'retainsmal class dens', u'retrospect', u'retrospect intern', u'retrospect intern journal', u'reus', u'reus encod', u'reus encod featurefrom', u'reus encod featuremap', u'reus pool', u'reus pool indic', u'reusingmax-pool', u'reusingmax-pool indic', u'reusingmax-pool indic decod', u'reusingtheir', u'reusingtheir input', u'reusingtheir input featur', u'reveal', u'reveal memori', u'reveal memori versusaccuraci', u'reveal memori versusand', u'reveal metric', u'reveal metric vari', u'reveal practic', u'reveal practic trade-offsinvolv', u'reveal practic trade-offswith', u'reveal pros', u'reveal pros consand', u'reveal pros consw', u'reveal true', u'reveal true perform', u'revealedtrain', u'revealedtrain fcn-8', u'revealedtrain fcn-8 main', u'revealedwhen', u'revealedwhen joint', u'revealedwhen joint train', u'review', u'review relat', u'review relat recent', u'review segnet', u'review segnet architectur', u'review2', u'review2 literatur', u'review2 literatur review2', u'review2 literatur reviewsemant', u'reviewsemant', u'reviewsemant pixel-wis', u'reviewsemant pixel-wis segment', u'rgb', u'rgb basedpredict', u'rgb basedpredict high', u'rgb basedtest', u'rgb basedtest imag', u'rgb contrast', u'rgb contrast normal', u'rgb dataset', u'rgb dataset object', u'rgb depth', u'rgb depth base', u'rgb fcn-32s', u'rgb fcn-32s rgb', u'rgb imag', u'rgb imag alsosinc', u'rgb imag alsous', u'rgb imag day', u'rgb indoor', u'rgb indoor test', u'rgb input', u'rgb inputperform', u'rgb inputperform local', u'rgb inputth', u'rgb inputth encod', u'rgb method', u'rgb modal', u'rgb modal train', u'rgb rgb', u'rgb rgb imag', u'rgb rgbd', u'rgb rgbd imag', u'rgb rgbd imageseith', u'rgb rgbd imagesfeatur', u'rgb rgbd imagesth', u'rgb rgbd mapof', u'rgb rgbd mapth', u'rgb road', u'rgb road scene', u'rgb unlik', u'rgb unlik otherdecod', u'rgb unlik otherit', u'rgb-d', u'rgb-d benchmark', u'rgb-d benchmark dataset', u'rgb-d dataset', u'rgb-d dataset consist', u'rgb-d dataset googl', u'rgb-d dataset hardchalleng', u'rgb-d dataset hardfig', u'rgb-d dataset shown', u'rgb-d dataset tabl', u'rgb-d datasetknown', u'rgb-d datasetknown deep', u'rgb-d datasetth', u'rgb-d datasetth qualit', u'rgb-d fcn-32s', u'rgb-d fcn-32s rgb-d', u'rgb-d imag', u'rgb-d imag cvpr', u'rgb-d imag icra', u'rgb-d imag icra,2014', u'rgb-d indoor', u'rgb-d indoor scene', u'rgb-d indoor scenessun', u'rgb-d indooroth', u'rgb-d indooroth deep', u'rgb-d indoorscen', u'rgb-d indoorscen understand', u'rgb-d veri', u'rgb-d veri challeng', u'rgb-dn', u'rgb-dn hft', u'rgb-dn hft h', u'rgb-drgb-drgb-dliu', u'rgb-drgb-drgb-dliu et', u'rgb-drgb-drgb-dliu et al', u'rgb-dscene', u'rgb-dscene gpu-acceler', u'rgb-dscene gpu-acceler deep', u'rgb-hha', u'rgb-hha fcn-16s', u'rgb-hha fcn-16s rgb-hha', u'rgb-sift', u'rgb-sift depth-sift', u'rgb-sift depth-sift locat', u'rgb-sift depth-sift pixel', u'rgb-sift segment', u'rgb-sift segment approach', u'rgbalthough', u'rgbalthough encod', u'rgbalthough encod input', u'rgbaverag', u'rgbaverag class', u'rgbaverag class row', u'rgbd', u'rgbd fig', u'rgbd fig high', u'rgbd imag', u'rgbd imag eccv', u'rgbd imag ineccv', u'rgbd imag insegment', u'rgbd imageseith', u'rgbd imageseith rgb', u'rgbd imagesfeatur', u'rgbd imagesfeatur classif', u'rgbd imagesth', u'rgbd imagesth applic', u'rgbd imagesth success', u'rgbd indoor', u'rgbd indoor scene', u'rgbd input', u'rgbd input extra', u'rgbd inputsmod', u'rgbd inputsmod rgb', u'rgbd inputsthi', u'rgbd inputsthi avoid', u'rgbd mapof', u'rgbd mapof normal', u'rgbd mapth', u'rgbd mapth input', u'rgbd pixel-wis', u'rgbd pixel-wis semant', u'rgbd scene', u'rgbd scene analysi', u'rgbd scene nyu', u'rgbd99', u'rgbdsun', u'rgbdsun rgbd99', u'rgbdsun rgbdsun', u'rgbdsun rgbdsun rgbd99', u'rgbdsun rgbdsun rgbdsun', u'rgbedg', u'rgbedg vice-versa', u'rgbedg vice-versaedg', u'rgbedg vice-versaedg vice-versaedg', u'rgbimag', u'rgbimag task', u'rgbimag task 480imag', u'rgbinput', u'rgbinput abl', u'rgbinput abl accur', u'rgbinputinputinputinputinputinputfigur', u'rgbinputinputinputinputinputinputfigur result', u'rgbinputinputinputinputinputinputfigur result sampl', u'rgbnormal', u'rgbnormal rgbinputinputinputinputinputinputfigur', u'rgbnormal rgbinputinputinputinputinputinputfigur result', u'rgbnormal rgbnormal', u'rgbnormal rgbnormal rgbinputinputinputinputinputinputfigur', u'rgbnormal rgbnormal rgbnormal', u'rgbor', u'rgbor rgbd', u'rgbor rgbd fig', u'rgbthis', u'rgbthis avoid', u'rgbthis avoid highlight', u'rgbto', u'rgbto sever', u'rgbto sever augment', u'rhechalleng', u'rhechalleng segnet', u'rhechalleng segnet predict', u'rhesegment', u'rhesegment qualiti', u'rhesegment qualiti better', u'richer', u'richer featur', u'richer featur set', u'richerfeatur', u'richerfeatur set', u'richerfeatur set includ', u'richersmooth', u'richersmooth use', u'richersmooth use crf', u'right', u'right appear', u'right appear textur', u'right fig', u'right fig fcn', u'right left', u'right left predict', u'rise', u'rise bayesian', u'rise bayesian segnet', u'rnn', u'rnn append', u'rnn append fcn', u'rnn layer', u'rnn layer mimic', u'road', u'road andbuild', u'road andbuild pixel', u'road andsinc', u'road andsinc major', u'road build', u'road build car', u'road build henc', u'road build littl', u'road build shape', u'road build side-walk', u'road class', u'road class segment', u'road confid', u'road indoorscen', u'road indoorscen understand', u'road indoorwa', u'road indoorwa need', u'road model', u'road model various', u'road scene', u'road scene analysi', u'road scene categori', u'road scene class', u'road scene dataset', u'road scene encod', u'road scene imag', u'road scene indoor', u'road scene perform', u'road scene produc', u'road scene segment', u'road scene sun', u'road scene understand', u'road scene understandingsegment', u'road scene understandingsuch', u'road scenesquantit', u'road scenesquantit comparison', u'road sceneswithout', u'road sceneswithout class', u'road side-walk', u'road side-walk typic', u'road sky', u'road sky build', u'road sky buildingpixel', u'road surfac', u'road surfac limit', u'roadpedestrian', u'roadpedestrian understand', u'roadpedestrian understand spatial-relationship', u'roadscen', u'roadscen dataset', u'roadscen dataset recent', u'roadscen major', u'roadscen major pixel', u'roadscen understand', u'roadscen understand end-to-end', u'roadsegnet', u'roadsegnet perform', u'roadsegnet perform competit', u'roadth', u'roadth kitti', u'roadth kitti dataset', u'roberto', u'roberto cipolla', u'roberto cipolla obtain', u'roberto cipolla senior', u'roberto cipollamachin', u'roberto cipollamachin intellig', u'roberto cipollavijay', u'roberto cipollavijay badrinarayanan', u'robot', u'robot ar', u'robot arcurr', u'robot arcurr applic', u'robot arth', u'robot arth metric', u'robot he2010', u'robot he2010 research', u'robot heha', u'robot heha author', u'robot interact', u'robot interact autonom', u'roboticsappl', u'roboticsappl deep', u'roboticsappl deep learn', u'roboticsha', u'roboticsha current', u'roboticsha current practic', u'roboticsroberto', u'roboticsroberto cipolla', u'roboticsroberto cipolla obtain', u'roboticsto', u'roboticsto encourag', u'roboticsto encourag research', u'robust', u'robust comparison', u'robust comparison imag', u'robust extract', u'robust extract featur', u'robust segment', u'robust segmentationobject', u'robust segmentationobject spatial-context', u'robust segmentationto', u'robust segmentationto demonstr', u'robust semant', u'robust semant pixel-wiselabel', u'robust semant pixel-wisev', u'robustclassif', u'robustclassif correspond', u'robustclassif correspond loss', u'robustsegnet', u'robustsegnet deep', u'robustsegnet deep convolut', u'robustsemant', u'robustsemant pixel-wis', u'robustsemant pixel-wis labellingsemant', u'robustsub-sampl', u'robustsub-sampl achiev', u'robustsub-sampl achiev translat', u'role', u'role decod', u'role decod network', u'romera-pared', u'romera-pared v', u'romera-pared v vineet', u'room', u'room bathroom', u'room bathroom shown', u'room laboratori', u'room laboratori differ', u'room laboratori meet', u'roth', u'roth b', u'roth b schiel', u'row', u'row bayesian', u'row bayesian segnet', u'row darker', u'row darker colour', u'row darker coloursbayesian', u'row darker coloursind', u'row indoor', u'row indoor scene', u'row input', u'row input imag', u'row poor', u'row poor result', u'row produc', u'row produc good', u'row right', u'row right appear', u'row segnet', u'row segnet fail', u'row segnet pre-train', u'row segnet predict', u'row showsbayesian', u'row showsbayesian segnet', u'row showsfigur', u'row showsfigur bayesian', u'royal', u'royal academi', u'royal academi engin', u'run', u'run anoth', u'run anoth 4epoch', u'run dataset', u'run dataset obtainbatch', u'run dataset obtainw', u'run iter', u'run iter mini-batch', u'run real', u'run real time', u'run segnet', u'run segnet 35ms', u's', u's activ', u's activ car', u's andarchitectur', u's andarchitectur learn', u's andcombin', u's andcombin correspond', u's behnk', u's behnk \\u201cfast', u's convolv', u's convolv trainabl', u's e', u's float', u's float precis', u's hong', u's hong b', u's jayasumana', u's jayasumana b', u's perform', u's perform convolut', u's pixel', u's pixel label', u's reed', u's reed d', u's rgb', u's rgb rgbd', u's roth', u's roth b', u's segnet', u's segnet decod', u's specif', u's specif decod', u's step', u's step produc', u's use', u's use memor', u's zheng', u's zheng s', u'sacrif', u'sacrif perform', u'sacrif perform reduc', u'salakhutdinov', u'salient', u'salient object', u'salient object class', u'salient object segment', u'sameencod', u'sameencod network', u'sameencod network onli', u'samein', u'samein order', u'samein order perform', u'samemani', u'samemani segment', u'samemani segment architectur', u'sames', u'sames encod', u'sames encod input', u'samesgd', u'samesgd solver', u'samesgd solver fix', u'sameth', u'sameth decod', u'sameth decod produc', u'sampl', u'sampl 90msand', u'sampl 90msand bayesian', u'sampl 90msper', u'sampl 90msper frame', u'sampl approxim', u'sampl approxim \\u201cinfluences\\u201d', u'sampl bernoulli', u'sampl bernoulli distribut', u'sampl camvid', u'sampl camvid day', u'sampl come', u'sampl come expens', u'sampl converg', u'sampl converg afteraround', u'sampl converg aftersampl', u'sampl dropout', u'sampl dropout performs4', u'sampl dropout performsbett', u'sampl dropout testachiev', u'sampl dropout testtim', u'sampl dropout usingfor', u'sampl dropout usingth', u'sampl fig', u'sampl ground', u'sampl ground truth', u'sampl histogram', u'sampl histogram mostactiv', u'sampl histogram mostvector', u'sampl indic', u'sampl indic max', u'sampl indic ofencod', u'sampl indic ofth', u'sampl indoor', u'sampl indoor scenesof', u'sampl indoor scenesth', u'sampl layer', u'sampl layer segnet', u'sampl middl', u'sampl middl column', u'sampl model', u'sampl model uncertainti', u'sampl network', u'sampl network random', u'sampl note', u'sampl note sinc', u'sampl obtain', u'sampl obtain posterior', u'sampl onli', u'sampl onli pre-her', u'sampl onli pre-train', u'sampl posterior', u'sampl posterior distribut', u'sampl qualit', u'sampl qualit allow', u'sampl requir', u'sampl requir addit', u'sampl road', u'sampl road scene', u'sampl segment', u'sampl segment predict', u'sampl segnet', u'sampl segnet segnet-bas', u'sampl segnet superior', u'sampl signific', u'sampl signific differ', u'sampl signific improv', u'sampl test', u'sampl test sampl', u'sampl therec', u'sampl therec sun', u'sampl thesiz', u'sampl thesiz object', u'sampl train', u'sampl train set', u'sample22ground', u'sample22ground truthground', u'sample22ground truthground truthground', u'samples505050606060figur', u'samples505050606060figur global', u'samples505050606060figur global segment', u'samples505050606060glob', u'samples505050606060glob accuraci', u'samples505050606060glob accuraci global', u'samplesa', u'samplesa measur', u'samplesa measur uncertainti', u'samplesfrom', u'samplesfrom number', u'samplesfrom number network', u'samplesnumb', u'samplesnumb samples505050606060figur', u'samplesnumb samples505050606060figur global', u'samplesnumb samples505050606060glob', u'samplesnumb samples505050606060glob accuraci', u'samplesnumb samplesnumb', u'samplesnumb samplesnumb samples505050606060figur', u'samplesnumb samplesnumb samples505050606060glob', u'samplesnumb samplesnumb samplesnumb', u'samplesremov', u'samplesremov unit', u'samplesremov unit network', u'sampleswhich', u'sampleswhich agre', u'sampleswhich agre class', u'sampletrain', u'sampletrain sample22ground', u'sampletrain sample22ground truthground', u'sampletrain sampletrain', u'sampletrain sampletrain sample22ground', u'sampletrain sampletrain sampletrain', u'samplingdropout', u'samplingdropout samplingdropout', u'samplingdropout samplingdropout samplingdropout', u'samplingdropout samplingdropout samplingmont', u'samplingdropout samplingmont', u'samplingdropout samplingmont carlo', u'samplingmont', u'samplingmont carlo', u'samplingmont carlo dropout', u'samplingweight', u'samplingweight averagingweight', u'samplingweight averagingweight averagingweight', u'satisfactori', u'satisfactori primarili', u'satisfactori primarili deepest', u'satisfactori thelack', u'satisfactori thelack cue', u'satisfactori thewith', u'satisfactori thewith scale', u'say', u'say channel', u'say channel perform', u'scale', u'scale chang', u'scale chang increas', u'scale correspond', u'scale correspond deep', u'scale provid', u'scale provid bothi', u'scale provid bothloc', u'scaleaverag', u'scaleaverag propos', u'scaleaverag propos remov', u'scaleth', u'scaleth weight', u'scaleth weight proport', u'scenario', u'scenario segnet', u'scenario segnet r', u'scenario sfm', u'scenario sfm cue', u'scenario test', u'scenario test adapt', u'scene', u'scene aconst', u'scene aconst kernel', u'scene analysi', u'scene analysi dataset', u'scene analysi indoor', u'scene asmal', u'scene asmal size', u'scene at360', u'scene at360 resolut', u'scene at367', u'scene at367 train', u'scene camvid', u'scene camvid kitti', u'scene categori', u'scene categoriesdeep', u'scene categoriesdeep layer', u'scene categoriesin', u'scene categoriesin agreement', u'scene class', u'scene class includ', u'scene class includingar', u'scene class includingwal', u'scene class sun', u'scene class wecaff', u'scene class weus', u'scene classesand', u'scene classesand class', u'scene classesand \\u201cfill', u'scene classesat', u'scene classesat depth', u'scene classeslay', u'scene classeslay featur', u'scene classesus', u'scene classesus mini-batch', u'scene classesw', u'scene classesw use', u'scene clutter', u'scene clutter note', u'scene complexmak', u'scene complexmak easier', u'scene complexsinc', u'scene complexsinc view', u'scene conjectur', u'scene conjectur base', u'scene dataset', u'scene dataset avail', u'scene dataset benchmark', u'scene dataset thisi', u'scene dataset thisperform', u'scene domin', u'scene domin sky', u'scene encod', u'scene encod decod', u'scene encod index', u'scene fromrgb', u'scene fromrgb scene', u'scene fromth', u'scene fromth nyu', u'scene geometri', u'scene geometri infer', u'scene geometryand', u'scene geometryand object', u'scene geometrysignific', u'scene geometrysignific pose', u'scene ground', u'scene ground truth', u'scene illumin', u'scene illumin reduc', u'scene imag', u'scene imag captur', u'scene imag fromgoogl', u'scene imag fromresult', u'scene imag limit', u'scene importantautonom', u'scene importantautonom drive', u'scene importantfor', u'scene importantfor domest', u'scene inde', u'scene inde control', u'scene indoor', u'scene indoor scene', u'scene label', u'scene label icml', u'scene label ieee', u'scene larg', u'scene larg class', u'scene need', u'scene need segmenta', u'scene need segmentdu', u'scene note', u'scene note class', u'scene note onli', u'scene nyu', u'scene nyu dataset', u'scene pars', u'scene pars benchmarkdeep', u'scene pars benchmarki', u'scene pars icml', u'scene perform', u'scene perform segnet', u'scene produc', u'scene produc smooth', u'scene recent', u'scene recent releas', u'scene rgb-d', u'scene rgb-d imag', u'scene road', u'scene road scene', u'scene segment', u'scene segment benchmark', u'scene segment challeng', u'scene segment challengingdu', u'scene segment challengingpres', u'scene segment class', u'scene segment current', u'scene segment immedi', u'scene segment includeth', u'scene segment includeweb', u'scene segment pascal', u'scene segment practic', u'scene segment quality40k40k40k40k80k80k80k80kmax', u'scene segment qualityhowev', u'scene segment sunrgb-d', u'scene segment sunw', u'scene segment task', u'scene segmentationa', u'scene segmentationa number', u'scene segmentationbayesian', u'scene segmentationbayesian segnet', u'scene segmentationha', u'scene segmentationha onli', u'scene segmentationroad', u'scene segmentationroad scene', u'scene segmentationtask', u'scene segmentationtask practic', u'scene segmentationth', u'scene segmentationth applic', u'scene spatialarrang', u'scene spatialarrang anoth', u'scene spatialin', u'scene spatialin number', u'scene sun', u'scene sun rgb-d', u'scene sun rgbd', u'scene test', u'scene test sampl', u'scene theother', u'scene theother method', u'scene thequalit', u'scene thequalit result', u'scene therefor', u'scene therefor believ', u'scene train', u'scene train test', u'scene tri', u'scene tri pleas', u'scene understand', u'scene understand applic', u'scene understand ar', u'scene understand arreal-tim', u'scene understand arthi', u'scene understand arxiv', u'scene understand benchmark', u'scene understand dataset', u'scene understand infer', u'scene understand meaning', u'scene understand perform', u'scene understand result', u'scene understand sun', u'scene understand test', u'scene understand use', u'scene understandingalex', u'scene understandingalex kendallalex', u'scene understandingarchitectur', u'scene understandingarchitectur scene', u'scene understandingsegment', u'scene understandingsegment challeng', u'scene understandingsuch', u'scene understandingsuch road', u'scene use', u'scene use dens', u'scene varyimag', u'scene varyimag pixel', u'scene varysignific', u'scene varysignific pose', u'scene veri', u'scene veri competit', u'scene vgg', u'scene vgg architectur', u'scene view-point', u'scene view-point overal', u'scene wide', u'scene wide array', u'sceneengag', u'sceneengag attent', u'sceneengag attent challeng', u'scenefigur', u'scenefigur bayesian', u'scenefigur bayesian segnet', u'sceneregion', u'sceneregion propos', u'sceneregion propos therefor', u'scenesand', u'scenesand natur', u'scenesand natur languag', u'scenesdataset', u'scenesof', u'scenesof differ', u'scenesof differ type', u'scenesquantit', u'scenesquantit comparison', u'scenesquantit comparison deep', u'scenesr', u'scenesr socher', u'scenesr socher c', u'scenesscen', u'scenesscen understand', u'scenesscen understand outdoor', u'scenessun', u'scenessun rgb-d', u'scenessun rgb-d indoor', u'scenessun rgb-d veri', u'scenesth', u'scenesth qualit', u'scenesth qualit result', u'sceneswithout', u'sceneswithout class', u'sceneswithout class balanc', u'scenetest', u'scenetest sampl', u'scenetest sampl test', u'sceneuncertainti', u'sceneuncertainti deep', u'sceneuncertainti deep convolut', u'sceneunderstand', u'sceneunderstand arxiv', u'sceneunderstand arxiv preprint', u'sceneunderstand benchmark', u'sceneunderstand benchmark sun', u'sceneunderstand idea', u'sceneunderstand idea exploit', u'schemat', u'schemat bayesian', u'schemat bayesian segnet', u'schemat segment', u'schemat segment predict', u'scheme', u'scheme3', u'scheme3 segnet', u'scheme3 segnet architectur', u'schemea', u'schemea layer', u'schemea layer segnet', u'schiel', u'schiel \\u201cthe', u'schiel \\u201cthe cityscap', u'scholarship', u'scholarship studi', u'scholarship studi ph', u'scholarship studi phd', u'schulz', u'schulz s', u'schulz s behnk', u'scienc', u'scienc page', u'scienc page springer', u'scienc pp', u'scienc pp springer', u'scope', u'scope paper', u'scope paper note', u'score', u'score achieveshigh', u'score achieveshigh metric', u'score achievesoppos', u'score achievesoppos fix', u'score common', u'score common use', u'score comput', u'score comput remot', u'score evalu', u'score evalu f1-measur', u'score higher', u'score higher otherarchitectur', u'score higher othernetwork', u'score indic', u'score indic need', u'score measur', u'score measur accuraci', u'score metric', u'score metric compar', u'score metric deeplab-largefovdensecrf', u'score note', u'score note densecrf', u'score note denseimprov', u'score note segnet', u'score roadscen', u'score roadscen understand', u'score roadsegnet', u'score roadsegnet perform', u'score signific', u'score signific margin', u'search', u'search base', u'search base optim', u'search process', u'search process expens', u'sec', u'sec 33analysi', u'sec 33analysi sec', u'sec 33surpris', u'sec 33surpris deeplab-largefov', u'sec 4as', u'sec 4as compar', u'sec 4deconvnet', u'sec 4deconvnet later', u'sec 622l', u'sec 622l iteratur', u'sec 6pointer', u'sec 6pointer futur', u'sec conclud', u'sec conclud sec', u'sec discuss', u'sec discuss advantag', u'sec evalu', u'sec evalu thearchitectur', u'sec evalu theperform', u'sec fact', u'sec fact share', u'sec mostconclud', u'sec mostconclud pointer', u'sec mostof', u'sec mostof experi', u'sec review', u'sec review relat', u'sec sec', u'sec sec evalu', u'sec sec review', u'sec usingand', u'sec usingand agre', u'sec usingth', u'sec usingth grid', u'sec withit', u'sec withit qualit', u'sec2', u'sec2 review', u'sec2 review relat', u'second', u'second ablat', u'second ablat studi', u'second object', u'second object visual', u'second row', u'second train', u'second train time', u'secondfor', u'secondfor various', u'secondfor various autonom', u'secondtask', u'secondtask indoor', u'secondtask indoor scene', u'secth', u'secth remaind', u'secth remaind paper', u'section', u'section demonstr', u'section demonstr bayesian', u'see11http', u'see11http //david', u'see11http //davidgrangierinfo/scen', u'see11http //davidgrangierinfo/scen parsing/http', u'see2', u'see2 see11http', u'see2 see11http //david', u'see2 see11http //davidgrangierinfo/scen', u'see2 see2', u'see2 see2 see11http', u'see2 see2 see2', u'seebett', u'seebett corr', u'seebett corr vol', u'seeconvolut', u'seeconvolut layer', u'seeconvolut layer model', u'seefig', u'seefig clear', u'seefig clear superior', u'seehttp', u'seehttp //mi', u'seehttp //miengcamacuk/projects/segnet/tutorialhtml', u'seehttp //miengcamacuk/projects/segnet/tutorialhtml examplehttp', u'seen', u'seen comput', u'seen comput statist', u'seen fig', u'seen fig qualit', u'seen grow', u'seen grow semant', u'seen huge', u'seen huge success', u'seen inth', u'seen inth impact', u'seen inth time', u'seen method', u'seen method improv', u'seen resultsfrom', u'seen resultsfrom current', u'seen resultsof', u'seen resultsof segnet', u'seen success', u'seen success ina', u'seen success inmodel', u'seenhug', u'seenhug success', u'seenhug success late', u'seenlearn', u'seenlearn algorithm', u'seenlearn algorithm particular', u'seesegnet', u'seesegnet correspond', u'seesegnet correspond qualit', u'seew', u'seew liu', u'seew liu rabinovich', u'seg-net', u'seg-net given', u'seg-net given standard', u'seg-train', u'seg-train set', u'seg-train set small', u'segmenationaccuraci', u'segmenationaccuraci appli', u'segmenationaccuraci appli segnet', u'segmenationbroad', u'segmenationbroad applic', u'segmenationbroad applic number', u'segment', u'segment accuraci', u'segment accuraci foraddit', u'segment accuraci forvari', u'segment accuraci number', u'segment activ', u'segment activ topic', u'segment advanc', u'segment advanc state-of-the-art', u'segment alsogain', u'segment alsogain popular', u'segment alsoindoor', u'segment alsoindoor rgbd', u'segment anoth', u'segment anoth reason', u'segment approach', u'segment approach use', u'segment architectur', u'segment architectur 66c', u'segment architectur deep', u'segment architectur includ', u'segment architectur methodsin', u'segment architectur methodsth', u'segment architectur recent', u'segment architectur share', u'segment architecturesmemori', u'segment architecturesmemori accuraci', u'segment architecturesth', u'segment architecturesth column', u'segment aroundobject', u'segment aroundobject boundari', u'segment aroundpredict', u'segment aroundpredict smooth', u'segment arxiv', u'segment arxiv preprintarxiv:1504', u'segment arxiv preprintarxiv:150401013', u'segment arxiv preprintdeep', u'segment asadopt', u'segment asadopt fulli', u'segment ascompar', u'segment ascompar experi', u'segment attempt', u'segment attempt appli', u'segment autonom', u'segment autonom drive', u'segment benchmark', u'segment benchmark use', u'segment benchmarknot', u'segment benchmarknot anoth', u'segment benchmarkon', u'segment benchmarkon road', u'segment bmvc', u'segment bmvc 2013evalu', u'segment bmvc 2013semant', u'segment camvid', u'segment camvid test', u'segment challeng', u'segment challeng andbut', u'segment challeng andha', u'segment challeng consistsof', u'segment challeng consiststh', u'segment challeng pascal', u'segment challengingdu', u'segment challengingdu high', u'segment challengingpres', u'segment challengingpres ani', u'segment class', u'segment class asroad', u'segment class asscen', u'segment class challeng', u'segment class interestfor', u'segment class interestonlin', u'segment class such360', u'segment class sucha', u'segment combin', u'segment combin form', u'segment commonattribut', u'segment commonattribut approach', u'segment commongroup', u'segment commongroup befor', u'segment corr', u'segment corr vol', u'segment correspond', u'segment correspond theclass', u'segment correspond thenumb', u'segment current', u'segment current practic', u'segment cvpr', u'segment cvpr 2008imag', u'segment cvpr 2008use', u'segment cvpr forest', u'segment cvpr pp', u'segment cvpr,2008', u'segment cvpr,2008 4segment', u'segment dataset', u'segment dataset balanc', u'segment deep', u'segment deep architectur', u'segment deep convolut', u'segment deep pars', u'segment engin', u'segment engin consist', u'segment engin ismad', u'segment engin iswould', u'segment fcn', u'segment fcn deeplablargfov', u'segment feed-forward', u'segment feed-forward infer', u'segment fine-grain', u'segment fine-grain local', u'segment follow', u'segment follow success', u'segment gain', u'segment gain popular', u'segment haveident', u'segment haveident encod', u'segment haveth', u'segment haveth practic', u'segment https', u'segment https //arxiv', u'segment https //arxivorg/pdf/160506211v1pdf', u'segment iccv', u'segment iccv pp', u'segment immedi', u'segment immedi interesttask', u'segment immedi interestto', u'segment import', u'segment import step', u'segment import tool', u'segment includeth', u'segment includeth camvid', u'segment includeweb', u'segment includeweb demo', u'segment indoor', u'segment indoor scene', u'segment joint', u'segment joint model', u'segment label', u'segment label compar', u'segment label resultand', u'segment label resulther', u'segment like', u'segment like typic', u'segment main', u'segment main motiv', u'segment measur', u'segment measur semanticcontour', u'segment measur semanticto', u'segment merit', u'segment merit separ', u'segment method', u'segment method generat', u'segment miccai', u'segment miccai pp', u'segment model', u'segment model rise', u'segment model run', u'segment motion', u'segment motion structur', u'segment network', u'segment network use', u'segment networkperform', u'segment networkperform improv', u'segment networkweak', u'segment networkweak label', u'segment object', u'segment object pedestrian', u'segment obtain', u'segment obtain higheraccuraci', u'segment obtain higherfeatur', u'segment occupi', u'segment occupi research', u'segment ofclass', u'segment ofclass road', u'segment ofth', u'segment ofth overal', u'segment ongo', u'segment ongo topic', u'segment output', u'segment output import', u'segment outputbayesian', u'segment outputbayesian segnet', u'segment outputsmor', u'segment outputsmor human', u'segment outputsth', u'segment outputsth key', u'segment overal', u'segment overal scene', u'segment particular', u'segment particular replic', u'segment particularlybi', u'segment particularlybi replic', u'segment particularlydesign', u'segment particularlydesign object', u'segment particularlyinvolv', u'segment particularlyinvolv design', u'segment particularlysegnet', u'segment particularlysegnet good', u'segment particularlytrain', u'segment particularlytrain time', u'segment particularlywhen', u'segment particularlywhen need', u'segment pascal', u'segment pascal voc12', u'segment perform', u'segment perform numberof', u'segment perform numbertim', u'segment performanceaccuraci', u'segment performanceaccuraci trade-off', u'segment performancecan', u'segment performancecan boost', u'segment performancemap', u'segment performancemap classif', u'segment performancesegnet', u'segment performancesegnet primarili', u'segment practic', u'segment practic orient', u'segment predict', u'segment predict model', u'segment predict overal', u'segment predict use', u'segment primarilymotiv', u'segment primarilymotiv road', u'segment primarilyour', u'segment primarilyour architectur', u'segment problem', u'segment problem segnet', u'segment quality40k40k40k40k80k80k80k80kmax', u'segment quality40k40k40k40k80k80k80k80kmax itermax', u'segment qualityhowev', u'segment qualityhowev compar', u'segment random', u'segment random forest', u'segment requir', u'segment requir understand', u'segment result', u'segment result averag', u'segment result term', u'segment rgb-dn', u'segment rgb-dn hft', u'segment rgb-dscene', u'segment rgb-dscene gpu-acceler', u'segment robust', u'segment robust comparison', u'segment salient', u'segment salient object', u'segment scene', u'segment scene understand', u'segment scenefigur', u'segment scenefigur bayesian', u'segment sceneunderstand', u'segment sceneunderstand benchmark', u'segment small', u'segment small car', u'segment small larg', u'segment smallerclass', u'segment smallerclass road', u'segment smallershow', u'segment smallershow abil', u'segment sunrgb-d', u'segment sunrgb-d indoor', u'segment sunw', u'segment sunw evalu', u'segment support', u'segment support experimentaldecod', u'segment support experimentalevid', u'segment support relationship', u'segment task', u'segment task camvid', u'segment task mani', u'segment task quantit', u'segment term', u'segment term bayesianpixel-wis', u'segment term bayesiansegnet', u'segment therefor', u'segment therefor believeto', u'segment therefor believeus', u'segment thinner', u'segment thinner structur', u'segment use', u'segment use deep', u'segment use motion', u'segment want', u'segment want understand', u'segment whereboundari', u'segment whereboundari delin', u'segment whereimag', u'segment whereimag represent', u'segment wide', u'segment wide array', u'segment wild', u'segment wild comput', u'segment witha', u'segment witha measur', u'segment withexampl', u'segment withexampl miou', u'segment withjudg', u'segment withjudg rank', u'segment withlearn', u'segment withlearn method', u'segment year', u'segment yearsbeen', u'segment yearsbeen benchmark', u'segment yearshowev', u'segment yearshowev major', u'segment \\u201darxiv', u'segment \\u201darxiv preprint', u'segment \\u201dsemi-supervis', u'segment \\u201dsemi-supervis learn', u'segment37', u'segment37 indoor', u'segment37 indoor scene', u'segmenta', u'segmenta larger', u'segmenta larger number', u'segmentationa', u'segmentationa number', u'segmentationa number road', u'segmentationabstract\\u2014w', u'segmentationabstract\\u2014w present', u'segmentationabstract\\u2014w present novel', u'segmentational', u'segmentational class', u'segmentational class row', u'segmentationand', u'segmentationand high', u'segmentationand high global', u'segmentationarchitectur', u'segmentationarchitectur harder', u'segmentationarchitectur harder challeng', u'segmentationarchitectur like', u'segmentationarchitectur like boundari', u'segmentationbayesian', u'segmentationbayesian segnet', u'segmentationbayesian segnet wide', u'segmentationchalleng', u'segmentationchalleng onli', u'segmentationchalleng onli use', u'segmentationdropout', u'segmentationdropout sampl', u'segmentationha', u'segmentationha onli', u'segmentationha onli just', u'segmentationimag', u'segmentationimag factor', u'segmentationimag factor make', u'segmentationobject', u'segmentationobject spatial-context', u'segmentationobject spatial-context perform', u'segmentationof', u'segmentationof import', u'segmentationof import class', u'segmentationperform', u'segmentationperform deep', u'segmentationperform deep learn', u'segmentationpredict', u'segmentationpredict smooth', u'segmentationpredict smooth sharp', u'segmentationrgb', u'segmentationrgb imag', u'segmentationrgb imag input', u'segmentationroad', u'segmentationroad scene', u'segmentationroad scene segmentationa', u'segmentationroad scene segmentationroad', u'segmentationsand', u'segmentationsand model', u'segmentationsand model uncertainti', u'segmentationsand visual', u'segmentationsand visual ambigu', u'segmentationscen', u'segmentationscen understand', u'segmentationscen understand end-to-end', u'segmentationsqualit', u'segmentationsqualit observ', u'segmentationsthat', u'segmentationsthat uncertain', u'segmentationsthat uncertain near', u'segmentationtask', u'segmentationtask practic', u'segmentationtask practic applic', u'segmentationterm', u'segmentationterm segnet', u'segmentationterm segnet core', u'segmentationth', u'segmentationth applic', u'segmentationth applic deep', u'segmentationth metric', u'segmentationth metric chose', u'segmentationto', u'segmentationto demonstr', u'segmentationto demonstr efficaci', u'segmentationvoc', u'segmentationvoc result', u'segmentdecor', u'segmentdecor object', u'segmentdecor object paint', u'segmentdu', u'segmentdu high', u'segmentdu high variabl', u'segmenth', u'segmenth come', u'segmenth come various', u'segmentof', u'segmentof segnet', u'segmentof segnet deconvnet', u'segnet', u'segnet 14mad', u'segnet 14mad hoc', u'segnet 14mparamet', u'segnet 14mparamet method', u'segnet 35k', u'segnet 35k dataset', u'segnet 35ms', u'segnet 35ms frameand', u'segnet 35ms framefor', u'segnet accuraci', u'segnet accuraci function', u'segnet achievesstate-of-the-art', u'segnet achievesstate-of-the-art perform', u'segnet achievesth', u'segnet achievesth nyu', u'segnet add', u'segnet add dropout', u'segnet addit', u'segnet addit benchmark', u'segnet addit overal', u'segnet ani', u'segnet ani arbitrari', u'segnet architectur', u'segnet architectur construct', u'segnet architectur differ', u'segnet architectur fulli', u'segnet architectur learn', u'segnet architectur propos', u'segnet architectur sec', u'segnet architectur thedecod', u'segnet architectur theexampl', u'segnet architectur use', u'segnet architectur wemodifi', u'segnet architectur wew', u'segnet architecture3', u'segnet architecturew', u'segnet architecturew briefli', u'segnet archiv', u'segnet archiv version', u'segnet arisesfeatur', u'segnet arisesfeatur map', u'segnet arisesfrom', u'segnet arisesfrom need', u'segnet aros', u'segnet aros need', u'segnet bayesian', u'segnet bayesian segnet', u'segnet bayesian segnetbayesian', u'segnet better', u'segnet better g', u'segnet camvid', u'segnet camvid dataset', u'segnet canabsorb', u'segnet canabsorb larg', u'segnet canimag', u'segnet canimag internet', u'segnet code', u'segnet code web2', u'segnet code webdemo', u'segnet code webdemodemodemodemodemodemoconverg', u'segnet column', u'segnet column right', u'segnet compar', u'segnet compar itand', u'segnet compar itwith', u'segnet compar perform', u'segnet compos', u'segnet compos stack', u'segnet confid', u'segnet confid preval', u'segnet consider', u'segnet consider smaller', u'segnet core', u'segnet core trainabl', u'segnet dealin', u'segnet dealin class', u'segnet dealwith', u'segnet dealwith scale', u'segnet decod', u'segnet decod techniqu', u'segnet decod tocreat', u'segnet decod toth', u'segnet decodingnetwork', u'segnet decodingnetwork choos', u'segnet decodingtechniqu', u'segnet decodingtechniqu wide', u'segnet deconvnet', u'segnet deconvnet compar', u'segnet deconvnet fig', u'segnet deconvnetachiev', u'segnet deconvnetachiev highest', u'segnet deconvnetfrom', u'segnet deconvnetfrom tabl', u'segnet deep', u'segnet deep convolut', u'segnet deepconvolut', u'segnet deepconvolut encod', u'segnet deeplab-largefov', u'segnet deeplab-largefov deeplab-largefov', u'segnet deepmodifi', u'segnet deepmodifi produc', u'segnet design', u'segnet design effici', u'segnet differ', u'segnet differ fromdecod', u'segnet differ fromthes', u'segnet effici', u'segnet effici compar', u'segnet encod', u'segnet encod isbas', u'segnet encod issegnet-bas', u'segnet encoderalso', u'segnet encoderalso reduc', u'segnet encoderconnect', u'segnet encoderconnect layer', u'segnet encodernetwork', u'segnet encodernetwork signific', u'segnet end-to-end', u'segnet end-to-end withoutoth', u'segnet end-to-end withoutweight', u'segnet fail', u'segnet fail label', u'segnet fcn', u'segnet fcn anddil', u'segnet fcn andof', u'segnet fcn decod', u'segnet fcn dilat', u'segnet fcn fcn', u'segnet featur', u'segnet featur ablat', u'segnet featur work', u'segnet fulli', u'segnet fulli trainabl', u'segnet given', u'segnet given aacross', u'segnet given asmal', u'segnet hand', u'segnet hand requir', u'segnet hand use', u'segnet higher', u'segnet higher model', u'segnet higher modelsymbol', u'segnet higher modeluncertainti', u'segnet indoor', u'segnet indoor sunscen', u'segnet indoor sunsmal', u'segnet just', u'segnet just epoch', u'segnet kernelsand', u'segnet kernelsand non-overlap', u'segnet kernelsspati', u'segnet kernelsspati context', u'segnet l4', u'segnet l4 830segnet', u'segnet l4 high', u'segnet l4 segnet', u'segnet larger', u'segnet larger comput', u'segnet largerboth', u'segnet largerboth learn', u'segnet largerterm', u'segnet largerterm decod', u'segnet layer', u'segnet layer comparison', u'segnet learn', u'segnet learn toperform', u'segnet learn towithout', u'segnet lie', u'segnet lie manner', u'segnet maintain', u'segnet maintain constant', u'segnet maintain far', u'segnet make', u'segnet make uncertain', u'segnet max-pool', u'segnet max-pool block', u'segnet median', u'segnet median frequencyclass', u'segnet median frequencyfollow', u'segnet median frequencystand', u'segnet memori', u'segnet memori effici', u'segnet miss', u'segnet miss label', u'segnet model', u'segnet model uncertainti', u'segnet model work', u'segnet model work:68', u'segnet mont', u'segnet mont carlo', u'segnet multi-channelconvolut', u'segnet multi-channelconvolut use', u'segnet multi-channeldeconvolut', u'segnet multi-channeldeconvolut note', u'segnet nowcomput', u'segnet nowcomput histogram', u'segnet nowfor', u'segnet nowfor train', u'segnet obtain', u'segnet obtain good', u'segnet obtaincompetit', u'segnet obtaincompetit result', u'segnet obtainsand', u'segnet obtainsand motion', u'segnet obtainsth', u'segnet obtainsth highest', u'segnet obtainth', u'segnet obtainth result', u'segnet onand', u'segnet onand model', u'segnet oncamvid', u'segnet oncamvid road', u'segnet onthre', u'segnet onthre differ', u'segnet onw', u'segnet onw quantifi', u'segnet othercompet', u'segnet othercompet architectur', u'segnet otheron', u'segnet otheron road', u'segnet outdoor', u'segnet outdoor indoor', u'segnet outdoorpixel', u'segnet outdoorpixel label', u'segnet outdoorrgb', u'segnet outdoorrgb scene', u'segnet outperform', u'segnet outperform method', u'segnet outperform previousbenchmark', u'segnet outperform previousoth', u'segnet outperform theother', u'segnet outperform thequantit', u'segnet outperformsmodel', u'segnet outperformsmodel smaller', u'segnet outperformsshallow', u'segnet outperformsshallow architectur', u'segnet overcomesnumb', u'segnet overcomesnumb pool', u'segnet overcomesthes', u'segnet overcomesthes problem', u'segnet perform', u'segnet perform best', u'segnet perform better', u'segnet perform compar', u'segnet perform widelyadopt', u'segnet perform widelyin', u'segnet popular', u'segnet popular segment', u'segnet posterior', u'segnet posterior distribut', u'segnet pre-train', u'segnet pre-train camvid', u'segnet predict', u'segnet predict delin', u'segnet predict getbacktrack', u'segnet predict getsmooth', u'segnet predict indoor', u'segnet predict otherdeep', u'segnet predict otherth', u'segnet predict retain', u'segnet predict rgb', u'segnet predict rgbd', u'segnet predict road', u'segnet predict sever', u'segnet predictionsar', u'segnet predictionsar better', u'segnet predictionson', u'segnet predictionson small', u'segnet present', u'segnet present real-timeonlin', u'segnet present real-timeto', u'segnet primari', u'segnet primari motiv', u'segnet primarili', u'segnet primarili motiv', u'segnet probabilist', u'segnet probabilist deepconvolut', u'segnet probabilist deepsect', u'segnet probabilist framework', u'segnet produc', u'segnet produc incorrect', u'segnet produc reliablemeasur', u'segnet produc reliablequantit', u'segnet provid', u'segnet provid good', u'segnet r', u'segnet r 897segnet', u'segnet r competit', u'segnet r expect', u'segnet r ii', u'segnet r segnet', u'segnet r small', u'segnet random', u'segnet random initi', u'segnet remain', u'segnet remain plan', u'segnet result', u'segnet result onth', u'segnet result onw', u'segnet result pascal', u'segnet result sun', u'segnet rgb', u'segnet rgb basedpredict', u'segnet rgb basedtest', u'segnet sampl', u'segnet sampl indoor', u'segnet scene', u'segnet scene segment', u'segnet seefig', u'segnet seefig clear', u'segnet seesegnet', u'segnet seesegnet correspond', u'segnet segment', u'segnet segment outputbayesian', u'segnet segment predict', u'segnet segment small', u'segnet segnet', u'segnet segnet bayesian', u'segnet segnet deeplab-largefov', u'segnet segnet fcn', u'segnet segnet segnet', u'segnet segnet-bas', u'segnet segnet-basicencoderaddit', u'segnet segnet-basicencoderaddit pool', u'segnet semant', u'segnet semant pixel', u'segnet setsin', u'segnet setsin section', u'segnet setsth', u'segnet setsth best', u'segnet sever', u'segnet sever adopteddeep', u'segnet sever adoptedw', u'segnet sever attract', u'segnet sever non', u'segnet signific', u'segnet signific smaller', u'segnet sm', u'segnet sm 587tabl', u'segnet sm iii', u'segnet sm segnet', u'segnet smaller', u'segnet smaller variant', u'segnet somediffer', u'segnet somediffer deconvnet', u'segnet submit', u'segnet submit toinputinputinputinputinputinputconvolut', u'segnet submit tothes', u'segnet superior', u'segnet superior perform', u'segnet term', u'segnet term segnet-bas', u'segnet theconsum', u'segnet theconsum memori', u'segnet theirmetr', u'segnet theirmetr increas', u'segnet theirthes', u'segnet theirthes larger', u'segnet theother', u'segnet theother hand', u'segnet topolog', u'segnet topolog ident', u'segnet topperform', u'segnet topperform rgb', u'segnet topwhich', u'segnet topwhich consist', u'segnet tradit', u'segnet tradit method', u'segnet train', u'segnet train median', u'segnet type', u'segnet type architectur', u'segnet type architecturein', u'segnet type architectureth', u'segnet type improveperform', u'segnet type improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg', u'segnet type improvewith', u'segnet u-net', u'segnet u-net propos', u'segnet use', u'segnet use caff', u'segnet use camvid', u'segnet use max', u'segnet use memori', u'segnet use minfunc', u'segnet use onli', u'segnet use \\u201cflat\\u201d', u'segnet variant', u'segnet variant arenot', u'segnet variant arew', u'segnet web', u'segnet web demo', u'segnet wide', u'segnet wide varieti', u'segnet work', u'segnet work bayesian', u'segnet work rgb-drgb-drgb-dliu', u'segnet-bas', u'segnet-bas adecod', u'segnet-bas adecod featur', u'segnet-bas ahand', u'segnet-bas ahand fcn-basic', u'segnet-bas allow', u'segnet-bas allow explor', u'segnet-bas competitiveit', u'segnet-bas competitiveit segnet-bas', u'segnet-bas competitivetrain', u'segnet-bas competitivetrain accuraci', u'segnet-bas earlier', u'segnet-bas earlier term', u'segnet-bas encod', u'segnet-bas encod decod', u'segnet-bas encod decodersal', u'segnet-bas encod decodersterm', u'segnet-bas fcn-basic', u'segnet-bas fcn-basic thatboth', u'segnet-bas fcn-basic thatwhen', u'segnet-bas layer-wis', u'segnet-bas layer-wis train', u'segnet-bas make', u'segnet-bas make overal', u'segnet-bas outperform', u'segnet-bas outperform fcn-basicnoaddit', u'segnet-bas outperform fcn-basicnoadditionth', u'segnet-bas perform', u'segnet-bas perform level', u'segnet-bas perform max-pool', u'segnet-bas segnet', u'segnet-bas segnet obtaincompetit', u'segnet-bas segnet obtainth', u'segnet-bas segnet segnet', u'segnet-bas segnet-bas', u'segnet-bas segnet-bas segnet', u'segnet-bas segnet-bas segnet-bas', u'segnet-bas segnet-basic-encoderaddit', u'segnet-bas segnet-basic-encoderaddit high', u'segnet-bas similar', u'segnet-bas similar fcn-basic-noaddit', u'segnet-bas sinc', u'segnet-bas sinc final', u'segnet-bas smaller', u'segnet-bas smaller model', u'segnet-bas superior', u'segnet-bas superior duefilt', u'segnet-bas superior dueto', u'segnet-bas thecamvid', u'segnet-bas thecamvid dataset', u'segnet-bas thefcn', u'segnet-bas thefcn decod', u'segnet-bas theshar', u'segnet-bas theshar encod', u'segnet-bas thetabl', u'segnet-bas thetabl architectur', u'segnet-bas train', u'segnet-bas train variant', u'segnet-bas variant', u'segnet-bas variant decod', u'segnet-bas variant perform', u'segnet-basic-encoderaddit', u'segnet-basic-encoderaddit high', u'segnet-basic-encoderaddit high bf', u'segnet-basic-singlechanneldecod', u'segnet-basic-singlechanneldecod thatanoth', u'segnet-basic-singlechanneldecod thatanoth comparison', u'segnet-basic-singlechanneldecod thatus', u'segnet-basic-singlechanneldecod thatus max-pool', u'segnet-basicarchitectur', u'segnet-basicarchitectur test', u'segnet-basicarchitectur test bayesian', u'segnet-basicbayesian', u'segnet-basicbayesian segnet-basicbayesian', u'segnet-basicbayesian segnet-basicbayesian segnet-basicbayesian', u'segnet-basicbayesian segnet-basicbayesian segnetbayesian', u'segnet-basicbayesian segnetbayesian', u'segnet-basicbayesian segnetbayesian segnetbayesian', u'segnet-basicencoderaddit', u'segnet-basicencoderaddit pool', u'segnet-basicencoderaddit pool indic', u'segnet-basicfor', u'segnet-basicfor analysi', u'segnet-basicfor analysi use', u'segnet-basicha', u'segnet-basicha advantag', u'segnet-basicha advantag fcn-basic', u'segnet-basicth', u'segnet-basicth number', u'segnet-basicth number iter', u'segnet-encoderaddit', u'segnet-encoderaddit area', u'segnet-encoderaddit area fcn-basic-nodimreduct', u'segnet-encoderaddit areboth', u'segnet-encoderaddit areboth accur', u'segnet-typ', u'segnet-typ decod', u'segnet-typ decod techniqu', u'segnet2', u'segnet2 review', u'segnet2 review relat', u'segnet3', u'segnet31', u'segnet31 train', u'segnet31 train segnet31', u'segnet31 train segnetmost', u'segnet32', u'segnet32 visual', u'segnet32 visual segnet32', u'segnet32 visual segnetw', u'segnet4', u'segnet80', u'segnetand', u'segnetand architectur', u'segnetand architectur road', u'segnetarchitectur', u'segnetarchitectur analysi', u'segnetarchitectur analysi sec', u'segnetarchitectur train', u'segnetarchitectur train end-to-end', u'segnetbas', u'segnetbas perform', u'segnetbas perform fcn-basic', u'segnetbas smaller', u'segnetbas smaller network', u'segnetbasic-singlechanneldecod', u'segnetbasic-singlechanneldecod reduc', u'segnetbasic-singlechanneldecod reduc number', u'segnetbayesian', u'segnetbayesian segnet80', u'segnetbayesian segnetbayesian', u'segnetbayesian segnetbayesian segnet80', u'segnetbayesian segnetbayesian segnetbayesian', u'segnetbayesian segnetbayesian segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'segnetbayesian segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'segnetbayesian segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'segnetboth', u'segnetboth qualit', u'segnetboth qualit numer', u'segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear', u'segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'segnetbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingmethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear sfm+appear', u'segnetencoderaddit', u'segnetencoderaddit perform', u'segnetencoderaddit perform better', u'segnetfor', u'segnetfor outdoor', u'segnetfor outdoor indoor', u'segnetfor semant', u'segnetfor semant segment', u'segnether', u'segnether note', u'segnether note over-fit', u'segnetmeet', u'segnetmeet room', u'segnetmeet room bathroom', u'segnetmost', u'segnetmost deep', u'segnetmost deep learn', u'segnetmulti-scal', u'segnetmulti-scal deep', u'segnetmulti-scal deep architectur', u'segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax', u'segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax itermax', u'segnetnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterationsnetwork/iterations80k80k80k80k140k140k140k140k140kmax itermax itermax', u'segnetobtain', u'segnetobtain reason', u'segnetobtain reason predict', u'segneton', u'segneton left', u'segneton left fig', u'segnetor', u'segnetor higher', u'segnetor higher forward-backward', u'segnetoth', u'segnetoth method', u'segnetoth method includ', u'segnetperform', u'segnetperform better', u'segnetperform better global', u'segnetpredict', u'segnetpredict accur', u'segnetpredict accur class', u'segnetse', u'segnetse tabl', u'segnetse tabl individu', u'segnetsegnetsegnetsegnetsegnetsegnetsegnet422', u'segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov', u'segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov deeplab-largefov', u'segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov deeplab-largefov deeplab-largefov', u'segnett', u'segnett quantit', u'segnett quantit result', u'segnetth', u'segnetth techniqu', u'segnetth techniqu use', u'segnetto', u'segnetto ani', u'segnetto ani deep', u'segnetupsampl', u'segnetupsampl step', u'segnetupsampl step howev', u'segnetw', u'segnetw perform', u'segnetw perform ablat', u'segnetwa', u'segnetwa need', u'segnetwa need design', u'select', u'select iter', u'select iter global', u'select modeleach', u'select modeleach imag', u'select modelwhich', u'select modelwhich perform', u'selectedfor', u'selectedfor test', u'selectedfor test train', u'selectediter', u'selectediter result', u'selectediter result tabul', u'self-train', u'self-train observ', u'self-train observ experiencemachin', u'seman', u'seman map', u'seman map 542segnet', u'seman map 863d', u'semant', u'semant consist', u'semant consist region', u'semant contour', u'semant contour score', u'semant cue', u'semant cue transferredacross', u'semant cue transferredperform', u'semant feedback', u'semant feedback convolut', u'semant imag', u'semant imag label', u'semant imag segment', u'semant imagelabel', u'semant imagelabel iccv', u'semant imagestructur', u'semant imagestructur class-label', u'semant label', u'semant labelsa', u'semant labelsa feed-forward', u'semant labelsa highlight', u'semant labelsboth', u'semant labelsboth qualit', u'semant labelslow', u'semant labelslow resolut', u'semant map', u'semant map note', u'semant parsinga', u'semant parsinga number', u'semant parsingus', u'semant parsingus camvid', u'semant pixel', u'semant pixel wise', u'semant pixel-wis', u'semant pixel-wis label', u'semant pixel-wis segment', u'semant pixel-wis segmentationabstract\\u2014w', u'semant pixel-wis segmentationterm', u'semant pixel-wiselabel', u'semant pixel-wiselabel corr', u'semant pixel-wisev', u'semant pixel-wisev badrinarayanan', u'semant pixelwis', u'semant pixelwis label', u'semant segment', u'semant segment alsogain', u'semant segment alsoindoor', u'semant segment arxiv', u'semant segment bmvc', u'semant segment camvid', u'semant segment corr', u'semant segment cvpr', u'semant segment gain', u'semant segment https', u'semant segment iccv', u'semant segment import', u'semant segment main', u'semant segment measur', u'semant segment output', u'semant segment primarilymotiv', u'semant segment primarilyour', u'semant segment random', u'semant segment rgb-dn', u'semant segment rgb-dscene', u'semant segment term', u'semant segment use', u'semant segmentational', u'semant segmentational class', u'semant segmentationrgb', u'semant segmentationrgb imag', u'semanticapproach', u'semanticapproach focus', u'semanticapproach focus real-tim', u'semanticcontour', u'semanticcontour accuraci', u'semanticcontour accuraci use', u'semanticcontour delin', u'semanticcontour delin metric', u'semanticd', u'semanticd eigen', u'semanticd eigen r', u'semantich', u'semantich jiang', u'semantich jiang local', u'semanticimag', u'semanticimag label', u'semanticimag label eccv', u'semanticlabel', u'semanticlabel common', u'semanticlabel common multi-scal', u'semanticmap', u'semanticmap store', u'semanticmap store reflect', u'semanticsegment', u'semanticsegment random', u'semanticsegment random forest', u'semanticto', u'semanticto semant', u'semanticto semant segment', u'semanticu', u'semanticu frank', u'semanticu frank s', u'semanticurban', u'semanticurban scene', u'semanticurban scene understand', u'semi-supervis', u'semi-supervis learn', u'semi-supervis learn dcnn', u'senior', u'senior member', u'senior member ieee', u'senior post-doctor', u'senior post-doctor research', u'sensor', u'sensor andhenc', u'sensor andhenc come', u'sensor andof', u'sensor andof indoor', u'sensor henc', u'sensor henc come', u'sensor seen', u'sensor seen resultsfrom', u'sensor seen resultsof', u'separ', u'separ bodi', u'separ bodi work', u'separ recip', u'separ recip vari', u'sequenc', u'sequenc evolut', u'sequenc evolut various', u'sequenc non-linear', u'sequenc non-linear process', u'sequenc thisen', u'sequenc thisen compar', u'sequenc thisus', u'sequenc thisus camvid', u'sequenc wear', u'sequenc wear abl', u'sequenc wecategori', u'sequenc wecategori dataset', u'sermanet', u'sermanet s', u'sermanet s reed', u'server', u'set', u'set adddataset', u'set adddataset analys', u'set addground', u'set addground truthground', u'set anyactiv', u'set anyactiv featur', u'set anyand', u'set anyand decod', u'set averag', u'set averag denot', u'set benchmark', u'set benchmark onin', u'set benchmark onmani', u'set class', u'set class citeraey', u'set comput', u'set comput thefor', u'set comput therootrootrootrootrootsquar', u'set decod', u'set decod follow', u'set decod kernel', u'set deeplab-largefov', u'set deeplab-largefov effici', u'set dimension', u'set dimension vectorfor', u'set dimension vectorth', u'set e', u'set featur', u'set featur map', u'set general', u'set general unseen', u'set henc', u'set henc onli', u'set includ', u'set includ lbp', u'set includ therefor', u'set larger', u'set larger dataset', u'set new', u'set new benchmark', u'set ofweak', u'set ofweak label', u'set ofwher', u'set ofwher classif', u'set overal', u'set overal scene', u'set perhap', u'set perhap thegrid', u'set perhap theworsen', u'set practic', u'set practic advantag', u'set remain', u'set remain zero', u'set report', u'set report metric', u'set reportal', u'set reportal measur', u'set reporti', u'set reporti highest', u'set road', u'set road sky', u'set segnet', u'set segnet superior', u'set select', u'set select iter', u'set shuffl', u'set shuffl eachconverg', u'set shuffl eachmini-batch', u'set sinc', u'set sinc valid', u'set size', u'set size approximatelycorrespond', u'set size approximatelygiven', u'set small', u'set small make', u'set supervis', u'set supervis pre-trainingcan', u'set supervis pre-trainingtrain', u'set surpris', u'set surpris percentag', u'set thea', u'set thea fix', u'set thekernel', u'set thekernel size', u'set thenon-zero', u'set thenon-zero bin', u'set theth', u'set theth entir', u'set train', u'set train corpus', u'set train lossconverg', u'set train lossoptim', u'set train set', u'set use', u'set use class', u'set use mini-batch', u'set wasavail', u'set wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun', u'set wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun rgb-d', u'set wasprocess', u'set wasprocess subset', u'set weight', u'set weight smaller', u'set zero', u'set zero note', u'setagainst', u'setagainst accuraci', u'setagainst accuraci increas', u'setar', u'setar train', u'setar train afresh', u'setdivid', u'setdivid class', u'setdivid class frequenc', u'setind', u'setind architectur', u'setind architectur potenti', u'setmedian', u'setmedian class', u'setmedian class frequenc', u'setobtain', u'setobtain use', u'setobtain use pre-train', u'setrow', u'setrow segnet', u'setrow segnet pre-train', u'setsin', u'setsin section', u'setsin section demonstr', u'setsth', u'setsth best', u'setsth best perform', u'setto', u'setto understand', u'setto understand addit', u'sever', u'sever adopteddeep', u'sever adopteddeep architectur', u'sever adoptedw', u'sever adoptedw benchmark', u'sever attract', u'sever attract properti', u'sever augment', u'sever augment realiti', u'sever challengingglob', u'sever challengingglob avg', u'sever challengingglob avgglob', u'sever challengingt', u'sever challengingt quantit', u'sever comparison', u'sever comparison convolut', u'sever comparison withdeconvnet', u'sever import', u'sever import categori', u'sever known', u'sever known algorithm', u'sever known benchmark', u'sever layer', u'sever layer max-pool', u'sever low', u'sever low resolut', u'sever non', u'sever non deep-learn', u'sever pool', u'sever pool layer', u'sever practicalfig', u'sever practicalfig segnet', u'sever practicalmax-pool', u'sever practicalmax-pool indic', u'sever recent', u'sever recent propos', u'severalin', u'severalin block', u'severalin block match', u'severallow', u'severallow resolut', u'severallow resolut predict', u'sfm', u'sfm appear', u'sfm appear explor', u'sfm cue', u'sfm cue particular', u'sfm+appear', u'sfm+appear 691boost', u'sfm+appear 691boost boost', u'sfm+appear boost', u'sfm+appear boost boost', u'sfm+appear sfm+appear', u'sfm+appear sfm+appear 691boost', u'sfm+appear sfm+appear boost', u'sfmbase', u'sfmbase cue', u'sfmbase cue use', u'sgd', u'sgd addit', u'sgd addit benefit', u'sgd fix', u'sgd fix learn', u'sgd howev', u'sgd howev enabl', u'sgd howev note', u'sgd need', u'sgd need suffici', u'sgd optim', u'sgd optim anoth', u'sgd train', u'sgd train sgd', u'sgd work', u'sgd work largebatch', u'sgd work largest', u'shadow', u'shadow ii', u'shadow ii highlight', u'shallow', u'shallow layer', u'shallow layer encoder-decod', u'shallow layer ii', u'shallow layer suggest', u'shallow method', u'shallow method utilis', u'shape', u'shape andcontextu', u'shape andcontextu relationship', u'shape andwith', u'shape andwith determinist', u'shape car', u'shape car abil', u'shape car v', u'shape clutter', u'shape clutter row', u'shape despit', u'shape despit small', u'shape rang', u'shape rang increas', u'shape size', u'shape size differ', u'shape size inbi', u'shape size indiffer', u'shape soft-max', u'shape soft-max weight', u'shape wide', u'shape wide vari', u'share', u'share low', u'share low miou', u'share otherarchitectur', u'share otherarchitectur deconvnet', u'share otherth', u'share otherth boundari', u'share sameencod', u'share sameencod network', u'share samemani', u'share samemani segment', u'share segnet', u'share segnet type', u'share similar', u'share similar architectur', u'sharp', u'sharp boundari', u'sharp boundari delin', u'sharp edg', u'sharp edg low', u'sharp main', u'sharp main becauselarg', u'sharp main becauseof', u'sharp segment', u'sharp segment aroundobject', u'sharp segment aroundpredict', u'shelf', u'shelf evalu', u'shelf evalu use', u'shelham', u'shelham t', u'shelham t darrel', u'shift', u'shift corr', u'shift corr network', u'shift corr vol', u'shift input', u'shift input imag', u'shortcom', u'shortcom hope', u'shortcom hope thatoptim', u'shortcom hope thatthi', u'shorter', u'shorter time', u'shorter time bf', u'shower', u'shower curtainboxboxboxboxwhiteboard', u'shower curtainboxboxboxboxwhiteboard person', u'shower curtaintowel', u'shower curtaintowel shower', u'shown', u'shown asaverag', u'shown asaverag mont', u'shown aspercentag', u'shown black', u'shown black colour', u'shown camvid', u'shown camvid dataset', u'shown effici', u'shown effici tasksarchitectur', u'shown effici taskssuch', u'shown experi', u'shown experi test', u'shown fig', u'shown fig 1are', u'shown fig 1the', u'shown fig 3top', u'shown fig 3we', u'shown fig observerec', u'shown fig observesom', u'shown fig segnetmeet', u'shown fig segnetobtain', u'shown fig thedusk', u'shown fig thequalit', u'shown fig use', u'shown layer', u'shown layer ofa', u'shown layer ofspac', u'shown minimis', u'shown minimis cross', u'shown note', u'shown note result', u'shown percentag', u'shown percentag activ', u'shown percentag natur', u'shown recentfavour', u'shown recentfavour techniqu', u'shown recentresult', u'shown recentresult deconvolut', u'shown recentwhen', u'shown recentwhen joint', u'shown recentwork', u'shown recentwork decoupl', u'shown second', u'shown second row', u'shown tabl', u'shown tabl segnet', u'showsbayesian', u'showsbayesian segnet', u'showsbayesian segnet segment', u'showsfigur', u'showsfigur bayesian', u'showsfigur bayesian segnet', u'showsset', u'showsset use', u'showsset use sgd', u'showsth', u'showsth benefit', u'showsth benefit reduc', u'shuffl', u'shuffl eachconverg', u'shuffl eachconverg befor', u'shuffl eachmini-batch', u'shuffl eachmini-batch imag', u'side-walk', u'side-walk main', u'side-walk main delin', u'side-walk sky', u'side-walk sky class', u'side-walk typic', u'side-walk typic roadpedestrian', u'side-walk typic roadscen', u'side-walk wea', u'side-walk wea road', u'side-walk weperform', u'side-walk weperform local', u'sidewalk', u'sidewalk column2', u'sidewalk column2 better', u'sidewalk columndetector', u'sidewalk columndetector crf', u'sidewalk given', u'sidewalk given theand', u'sidewalk given thefeatur', u'sidewalk reason', u'sidewalk reason shown', u'sidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalksidewalkpolepolepolepolepolefencefencefencefencefencefenceroadroadroadroadroadsignsignsignsignsigntreetreetreetreetreebuildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuild', u'sift-flow', u'sift-flow labelm', u'sift-flow labelm size', u'sign', u'sign cyclist', u'sign cyclist strong11th', u'sign cyclist strongclass', u'sign pole', u'sign pole pedestrian', u'sign pole side-walk', u'sign symbol', u'sign symbol bicyclist', u'sign-symbol', u'sign-symbol car', u'sign-symbol car bicyclistsin', u'sign-symbol car bicyclistsmor', u'signific', u'signific 134m', u'signific 134m 147m', u'signific benchmark', u'signific benchmark point', u'signific better', u'signific better emphas', u'signific better fcn', u'signific clutteri', u'signific clutteri clear', u'signific clutteri increas', u'signific differ', u'signific differ probabl', u'signific higher', u'signific higher segnet', u'signific improv', u'signific improv accuraci', u'signific improv fcn-8', u'signific improv perform', u'signific improv point', u'signific margin', u'signific parameter', u'signific parameter convolut', u'signific smaller', u'signific smaller easier', u'signific smaller faster', u'signific smaller number', u'significantlyon', u'significantlyon right', u'significantlyon right fig', u'significantlyparamet', u'significantlyparamet infer', u'significantlyparamet infer time', u'significantlyth', u'significantlyth benefit', u'significantlyth benefit reduc', u'significantlywithout', u'significantlywithout sacrif', u'significantlywithout sacrif perform', u'signsymbol', u'signsymbol bicyclist', u'signsymbol bicyclist bayesian', u'signth', u'signth dataset', u'similar', u'similar architectur', u'similar architectur proposeda', u'similar architectur proposedhttp', u'similar architectur segnet', u'similar decod', u'similar decod techniqu', u'similar fcn-basic-noaddit', u'similar fcn-basic-noaddit insegnet-bas', u'similar fcn-basic-noaddit interm', u'similar learn', u'similar learn spatial', u'similar look', u'similar look model', u'similar result', u'similar result visuallysimilar', u'similar tree', u'similar tree build', u'similardecod', u'similardecod techniqu', u'similardecod techniqu use', u'similarunsupervis', u'similarunsupervis pre-train', u'similarunsupervis pre-train classif', u'simonyan', u'simonyan zisserman', u'simonyan zisserman \\u201cveri', u'simpl', u'simpl way', u'simpl way prevent', u'simpli', u'simpli extend', u'simpli extend thissegment', u'simpli extend thisto', u'simultan', u'simultan task', u'simultan task outdoor', u'sinc', u'sinc compar', u'sinc compar iter', u'sinc conceptu', u'sinc conceptu mimic', u'sinc easilydesc', u'sinc easilydesc sgd', u'sinc easilyrepeat', u'sinc easilyrepeat design', u'sinc final', u'sinc final encoderfeatur', u'sinc final encodermodel', u'sinc onli', u'sinc onli store', u'sinc penal', u'sinc penal fals', u'sinc releas', u'sinc releas nyu', u'sinc releas nyudataset', u'sinc releas nyumeanwhil', u'sinc therear', u'sinc therear typic', u'sinc therediffer', u'sinc therediffer pose', u'sinc train', u'sinc train modular', u'sinc valid', u'sinc valid set', u'singl', u'singl channel', u'singl channel onli', u'singl channel rgbd', u'singl deep', u'singl deep architectur', u'singl depth', u'singl depth imag', u'singl imag', u'singl imag author', u'singl imag use', u'singl valu', u'singl valu camvid', u'singl valu e', u'singl valu given', u'situat', u'situat analysi', u'situat analysi self-train', u'situat caus', u'situat caus model', u'situationssegnet', u'situationssegnet deep', u'situationssegnet deep convolut', u'size', u'size 441414141road', u'size 441414141road scene', u'size 4we', u'size 4we use', u'size accuraci', u'size accuraci fcn-basic-noadditioni', u'size accuraci fcn-basic-noadditionto', u'size approxim', u'size approxim crop', u'size approximatelycorrespond', u'size approximatelycorrespond epoch', u'size approximatelygiven', u'size approximatelygiven mini-batch', u'size caff', u'size caff model', u'size channel', u'size channel encod', u'size class', u'size class arelarg', u'size class areobtain', u'size class indoor', u'size class skew', u'size context', u'size context window', u'size correspondsconverg', u'size correspondsconverg train', u'size correspondsto', u'size correspondsto test', u'size dataset', u'size dataset class', u'size differ', u'size differ pose', u'size encod', u'size encod decod', u'size fcn-basic-noaddition-nodimreductionmodel', u'size fcn-basic-noaddition-nodimreductionmodel slight', u'size fcn-basic-noaddition-nodimreductionth', u'size fcn-basic-noaddition-nodimreductionth size', u'size featur', u'size featur map', u'size fulli', u'size fulli connnect', u'size fullyconnect', u'size fullyconnect layer', u'size fullyconnect layersconnect', u'size fullyreport', u'size fullyreport littl', u'size henc', u'size henc isimport', u'size henc isobject', u'size imag', u'size imag resolut', u'size imag theinput', u'size imag thepatch', u'size images/featur', u'size images/featur map', u'size inbi', u'size inbi fact', u'size indiffer', u'size indiffer pose', u'size indoor', u'size indoor scene', u'size infer', u'size infer memori', u'size input', u'size input learn', u'size layer', u'size layer chosen', u'size layerencod', u'size layerencod featur', u'size layertherefor', u'size layertherefor memori', u'size manner', u'size manner upsampl', u'size mb', u'size mb forward', u'size mb segnetsegnetsegnetsegnetsegnetsegnetsegnet422', u'size mb segnetsegnetsegnetsegnetsegnetsegnetsegnet42250422504225042250422504225042250488714887148871488714887148871488716803680368036803680310521052105210521052117117117117deeplab-largefov', u'size model', u'size modelsher', u'size modelsher note', u'size modelsso', u'size modelsso enabl', u'size multi-stag', u'size multi-stag trainingprocess', u'size multi-stag trainingto', u'size network', u'size network make', u'size of64', u'size offor', u'size offor encod', u'size ofk', u'size ofk make', u'size ofth', u'size ofth model', u'size preserv', u'size preserv structur', u'size size', u'size size caff', u'size thea', u'size thea compar', u'size therefor', u'size therefor weadapt', u'size therefor weadopt', u'size thetrain', u'size thetrain set', u'size train', u'size train set', u'size trainabl', u'size trainabl paramet', u'size veri', u'size veri noisi', u'skew', u'skew class', u'skew class distribut', u'sky', u'sky build', u'sky build pixel', u'sky buildingpixel', u'sky buildingpixel class', u'sky buildingpixel domin', u'sky class', u'sky class domin', u'sky road', u'sky road andbuild', u'sky road andsinc', u'sky road build', u'sky road confid', u'sky road model', u'slight', u'slight decreas', u'slight decreas eachadditional/deep', u'slight decreas eachth', u'slight higher', u'slight higher miou', u'slight larger', u'slight larger segnet-bas', u'slight loss', u'slight loss accuraci', u'slight lower', u'slight lower miou', u'slowli', u'slowli comparabledeconvnet', u'slowli comparabledeconvnet fulli', u'slowli comparableor', u'slowli comparableor higher', u'sm', u'sm 587tabl', u'sm 587tabl quantit', u'sm iii', u'sm iii classifi', u'sm iii initi', u'sm segnet', u'sm segnet sm', u'small', u'small car', u'small car pedestrian', u'small categori', u'small categori pole', u'small class', u'small class note', u'small classesdo', u'small classesdo retain', u'small classesw', u'small classesw use', u'small comput', u'small comput budget', u'small consist', u'small consist of367', u'small consist ofw', u'small extra', u'small extra comput', u'small imag', u'small imag appear', u'small inputfor', u'small inputfor upsampl', u'small inputmain', u'small inputmain focus', u'small inputpatch', u'small inputpatch dure', u'small inputpatch extend', u'small larg', u'small larg class', u'small make', u'small make feasibl', u'small resolut', u'small resolut compar', u'small set', u'small set class', u'small size', u'small size henc', u'small spatial', u'small spatial shift', u'smalland', u'smalland class', u'smalland class averag', u'smalland handl', u'smalland handl miss', u'smallcontext', u'smallcontext window', u'smallcontext window input', u'smalldemonstr', u'smalldemonstr use', u'smalldemonstr use pre-train', u'smaller', u'smaller achiev', u'smaller achiev acompetit', u'smaller achiev aevalu', u'smaller amountcop', u'smaller amountcop addit', u'smaller amountof', u'smaller amountof data', u'smaller class', u'smaller class lost', u'smaller class lower', u'smaller dataset', u'smaller dataset sucha', u'smaller easier', u'smaller easier train', u'smaller faster', u'smaller faster competingarchitectur', u'smaller faster competingwhich', u'smaller kernel', u'smaller kernel decreasecontext', u'smaller kernel decreaseth', u'smaller layer', u'smaller layer segnet-basicarchitectur', u'smaller layer segnet-basicfor', u'smaller make', u'smaller make convolut', u'smaller memori', u'smaller memori time', u'smaller model', u'smaller model analysi', u'smaller network', u'smaller network like', u'smaller network onli', u'smaller number', u'smaller number trainabl', u'smaller nyudataset', u'smaller nyudataset differ', u'smaller nyuparamet', u'smaller nyuparamet method', u'smaller use', u'smaller use dimensionalityfcn-bas', u'smaller use dimensionalityreduct', u'smaller variant', u'smaller variant oneth', u'smaller variant onewher', u'smaller variant termedsegnet-bas', u'smaller variant termedw', u'smaller version', u'smaller version segnet', u'smaller weightsof', u'smaller weightsof smallest', u'smaller weightsth', u'smaller weightsth train', u'smaller/thinn', u'smaller/thinn class', u'smaller/thinn class note', u'smallercategori', u'smallercategori dataset', u'smallercategori dataset contain', u'smallerclass', u'smallerclass road', u'smallerclass road scene', u'smallerin', u'smallerin dataset', u'smallerin dataset make', u'smallershow', u'smallershow abil', u'smallershow abil propos', u'smallest', u'smallest class', u'smallest class highest', u'smallest effici', u'smallest effici model', u'smallest model', u'smallest model term', u'smallestmodel', u'smallestmodel deeplab-largefov', u'smallestmodel deeplab-largefov produc', u'smallestthi', u'smallestthi conjectur', u'smallestthi conjectur base', u'smallsegnet', u'smallsegnet outperform', u'smallsegnet outperform method', u'smallsiz', u'smallsiz segnet-bas', u'smallsiz segnet-bas allow', u'smooth', u'smooth class', u'smooth class segment', u'smooth doe', u'smooth doe notevalu', u'smooth doe notexampl', u'smooth label', u'smooth label aconst', u'smooth label apixel', u'smooth label pixelchosen', u'smooth label pixelin', u'smooth label predict', u'smooth miss', u'smooth miss sever', u'smooth predict', u'smooth predict crf', u'smooth predict unlikepatch', u'smooth predict unlikepixel', u'smooth retainclass', u'smooth retainclass crf', u'smooth retainsmal', u'smooth retainsmal class', u'smooth segment', u'smooth segment anoth', u'smooth segment label', u'smooth segment ofclass', u'smooth segment ofth', u'smooth segment overal', u'smooth sharp', u'smooth sharp segment', u'smooth use', u'smooth use crf', u'smooth use pair-wis', u'smootha', u'smootha road', u'smootha road build', u'smoothedbi', u'smoothedbi use', u'smoothedbi use pair-wis', u'smoothedcal', u'smoothedcal unari', u'smoothedcal unari term', u'smoother', u'smoother depthi', u'smoother depthi increas', u'smoother depthw', u'smoother depthw observ', u'smoothingfield', u'smoothingfield crfs', u'smoothingfield crfs crf-rnn', u'smoothingth', u'smoothingth output', u'smoothingth output ensur', u'smoothqual', u'smoothqual segment', u'smoothqual segment like', u'smoothsegment', u'smoothsegment engin', u'smoothsegment engin abil', u'smoothsegnet-bas', u'smoothsegnet-bas segnet', u'smoothsegnet-bas segnet addit', u'socher', u'socher c', u'socher c c', u'sofa', u'sofa orbench', u'sofa orbench tabl', u'sofa orsimilar', u'sofa orsimilar class', u'sofa task', u'sofa task hardbi', u'sofa task hardwal', u'soft-max', u'soft-max classifi', u'soft-max classifi hidden', u'soft-max classifi pixel-wis', u'soft-max classifi soft-maxclassifi', u'soft-max classifi soft-maxdecod', u'soft-max classifi unlikeor', u'soft-max classifi unliketh', u'soft-max classifi withno', u'soft-max classifi withth', u'soft-max k', u'soft-max k channel', u'soft-max layer', u'soft-max layer classifi', u'soft-max layer onli', u'soft-max layer train', u'soft-max weight', u'soft-max weight fix', u'soft-max weight zero', u'soft-maxclassif', u'soft-maxclassif layer', u'soft-maxclassif layer decod', u'soft-maxclassifi', u'soft-maxclassifi hidden', u'soft-maxclassifi hidden layer', u'soft-maxclassifi k', u'soft-maxclassifi k channel', u'soft-maxclassifi pixel', u'soft-maxclassifi pixel independ', u'soft-maxcorrespond', u'soft-maxcorrespond decod', u'soft-maxcorrespond decod stack', u'soft-maxdecod', u'soft-maxdecod fed', u'soft-maxdecod fed trainabl', u'soft-maxwith', u'soft-maxwith camvid', u'soft-maxwith camvid train', u'softmax', u'softmax class', u'softmax class probabl', u'softmax classifi', u'softmax function', u'softmax function approxim', u'softmax regress', u'softmax regress c-e', u'softmax regress onli', u'softmax sampl', u'softmax sampl model', u'solver', u'solver fix', u'solver fix learn', u'solver optim', u'solver optim achiev', u'solver sgd', u'solver sgd howev', u'somediffer', u'somediffer deconvnet', u'somediffer deconvnet larger', u'somewhat', u'somewhat similardecod', u'somewhat similardecod techniqu', u'somewhat similarunsupervis', u'somewhat similarunsupervis pre-train', u'soon', u'soon withour', u'soon withour light-weight', u'soon withth', u'soon withth current', u'sourc', u'sourc code', u'sourc code project', u'sourc model', u'sourc model shelf', u'space', u'space ani', u'space ani depth', u'space ani depthsegnet', u'space ani depthto', u'space top-1', u'space top-1 4this', u'space top-1 4thlayer', u'space use', u'space use deconvolut', u'spars', u'spars array', u'spars array indic', u'spars encod', u'spars encod thea', u'spars encod theinputinputinputinputinputinputstochast', u'spars featur', u'spars featur map', u'spars input', u'spars inputar', u'spars inputar use', u'spars inputthi', u'spars inputthi ad', u'spars thenconvolv', u'spars thenconvolv trainabl', u'spars thenperform', u'spars thenperform non-linear', u'sparseinput', u'sparseinput decod', u'sparseinput decod filter', u'sparsewith', u'sparsewith trainabl', u'sparsewith trainabl multi-channel', u'spatial', u'spatial arrang', u'spatial arrang capturedclass', u'spatial arrang capturedfrom', u'spatial context', u'spatial context forcan', u'spatial context forpixel', u'spatial context input', u'spatial context pixel', u'spatial context segnet', u'spatial context/class', u'spatial context/class locat', u'spatial contextfor', u'spatial contextfor pixel-wis', u'spatial contextof', u'spatial contextof featur', u'spatial resolutionclassif', u'spatial resolutionclassif correspond', u'spatial resolutionof', u'spatial resolutionof featur', u'spatial shift', u'spatial shift input', u'spatial window', u'spatial window pixelin', u'spatial-context', u'spatial-context perform', u'spatial-context perform robust', u'spatial-relationship', u'spatial-relationship context', u'spatial-relationship context differ', u'spatialarrang', u'spatialarrang anoth', u'spatialarrang anoth difficulti', u'spatialin', u'spatialin number', u'spatialin number class', u'spatio-tempor', u'spatio-tempor super-pixel', u'spatio-tempor super-pixel obtain', u'spatiocombin', u'spatiocombin popular', u'spatiocombin popular hand', u'spatiotempor', u'spatiotempor super-pixel', u'spatiotempor super-pixel obtain', u'special', u'special layer-wis', u'special layer-wis weight', u'specialis', u'specialis embed', u'specialis embed devic', u'specif', u'specif decod', u'specif decod use', u'speech', u'speech categoris', u'speech categoris imag', u'speech categorisinglearn', u'speech categorisinglearn algorithm', u'speech categorisingwhol', u'speech categorisingwhol imag', u'speech huge', u'speech huge success', u'speedup', u'speedup gain', u'speedup gain https', u'spent', u'spent perform', u'spent perform tensor', u'springer', u'springer 2010scene', u'springer 2010scene use', u'springer 2012pp', u'springer 2012pp springer', u'springer 2012segment', u'springer 2012segment deep', u'springer 2012springer', u'springer 2012springer 2012springer', u'springer 2013algorithm', u'springer 2013algorithm cvpr', u'springer 2014and', u'springer 2014and support', u'springer 2014context', u'springer 2014context comput', u'springer 2014deep', u'springer 2014deep structur', u'springer 2014edg', u'springer 2014edg comput', u'springer 3from', u'springer 3from singl', u'springer 3page', u'springer 3page springer', u'springer 611segnet', u'springer 611segnet deep', u'springer 6convolut', u'springer 6convolut network', u'springer 6imag', u'springer 6imag label', u'springer 6segnet', u'springer 6segnet deep', u'springer 8abs/14091556', u'springer 8abs/14091556 1abs/14091556', u'springer 8eccv', u'springer 8eccv page', u'springer biomed', u'springer biomed imag', u'springer context', u'springer intern', u'springer intern publish', u'springer internationallectur', u'springer internationallectur note', u'springer internationalpublish', u'springer internationalpublish 2014publish', u'springer network', u'springer network imag', u'springer springer', u'springer springer 611segnet', u'springer springer 6segnet', u'springer springer springer', u'springer,2014', u'springer,201420142014201420142014imag', u'springer,201420142014201420142014imag use', u'springer,201420142014201420142014imag use multi-scal', u'springer,2015', u'springer,201520152015201520152015201020102010201020102010learn', u'springer,201520152015201520152015201020102010201020102010learn invari', u'springer,201520152015201520152015201020102010201020102010learn invari featur', u'squar', u'squar valu', u'squar valu map', u'squash', u'squash function', u'squash function max', u'stack', u'stack encod', u'stack encod follow', u'stack feed', u'stack feed soft-maxclassif', u'stack feed soft-maxcorrespond', u'stack fullclassif', u'stack fullclassif layer', u'stack fullinput', u'stack fullinput imag', u'stack train', u'stack train modular', u'stackunderstand', u'stackunderstand effect', u'stackunderstand effect featur', u'stackw', u'stackw draw', u'stackw draw inspir', u'stage-wis', u'stage-wis train', u'stage-wis train scheme', u'stage-wis traininga', u'stage-wis traininga relev', u'stage-wis trainingprocess', u'stage-wis trainingprocess decod', u'stagesin', u'stagesin train', u'stagesin train phase', u'stageswhen', u'stageswhen over-fit', u'stageswhen over-fit set', u'standard', u'standard deviat', u'standard deviat error', u'standard dropout', u'standard dropout approxim', u'standard gpu', u'standard gpu reason', u'standard probabl', u'standard probabl drop', u'standnight', u'standnight standnight', u'standnight standnight standnight', u'standnight standnight standtvtvtvpaperpaperpaperpaperpaperpaper86', u'standnight standtvtvtvpaperpaperpaperpaperpaperpaper86', u'standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag19', u'standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t', u'standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t 5tabl', u'standtoilettoilettoilettoilettoilettoilettoiletsinksinksinksinksinklamplamplamplamplampbathtubbathtubbathtubbathtubbathtubbathtubbathtubbathtubbagbagbagbag198319831983198319831983003003003003003231423142314231423142314602560256025602560256025272727272727272727272727298829882988298829882988760076007600760076007600581058105810581058105810352735273527352735273527488648864886488648864886167616761676167616761676t 5tabl 5tabl', u'standtvtvtvpaperpaperpaperpaperpaperpaper86', u'standwhiteboard', u'standwhiteboard person', u'standwhiteboard person night', u'start', u'start pre-train', u'start pre-train weight', u'state', u'state art', u'state art architectur', u'state code', u'state code optimis', u'state-of-the-art', u'state-of-the-art bydesign', u'state-of-the-art bydesign segment', u'state-of-the-art bylearn', u'state-of-the-art bylearn decod', u'state-of-the-art method', u'state-of-the-art method alreadyselect', u'state-of-the-art method alreadytrain', u'static', u'static scene', u'static scene classesand', u'static scene classesat', u'static scene classeslay', u'statist', u'statist evalu', u'statist evalu test', u'statist tabl', u'statist tabl fcn', u'statist tabl fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010', u'statist train', u'statist train dataset', u'statisticstest', u'statisticstest time', u'statisticswhil', u'statisticswhil use', u'statisticswhil use dropout', u'step', u'step andmodel', u'step andmodel discard', u'step andon', u'step andon learn', u'step appli', u'step appli map', u'step appli mapsa', u'step appli mapsnot', u'step correspond', u'step correspond encod', u'step densifi', u'step densifi spars', u'step dure', u'step dure test', u'step encod', u'step encod featur', u'step howev', u'step howev upsampl', u'step input', u'step input advantag', u'step input normal', u'step lower', u'step lower parameteris', u'step mani', u'step mani correct', u'step produc', u'step produc spars', u'step size', u'step size therefor', u'step stage-wis', u'step stage-wis train', u'step stochast', u'step stochast gradient', u'step understand', u'step understand infer', u'stochast', u'stochast gradient', u'stochast gradient descent', u'stochast gradientan', u'stochast gradientan effici', u'stochast gradientdesc', u'stochast gradientdesc sgd', u'storag', u'storag costfor', u'storag costfor pool', u'storag costsegnet', u'storag costsegnet hand', u'storag memori', u'storag memori ofresolut', u'storag memori ofth', u'storag result', u'storag result slight', u'storagecost', u'storagecost accuraci', u'storagecost accuraci versus', u'storagereduct', u'storagereduct featur', u'storagereduct featur map', u'storagesegnet', u'storagesegnet hand', u'storagesegnet hand requir', u'storagewhen', u'storagewhen need', u'storagewhen need compromis', u'store', u'store andpass', u'store andpass decod', u'store andth', u'store andth max', u'store boundari', u'store boundari inform', u'store compar', u'store compar memorizingfeatur', u'store compar memorizingi', u'store encod', u'store encod featur', u'store encod network', u'store featur', u'store featur map', u'store max-pool', u'store max-pool indic', u'store max-poolingindic', u'store max-poolingindic featur', u'store max-poolingoth', u'store max-poolingoth hand', u'store onli', u'store onli max-pool', u'store pass', u'store pass decod', u'store pool', u'store pool indic', u'store reflect', u'store reflect semanticcontour', u'store reflect semanticmap', u'store use', u'store use bit', u'store usedreduct', u'store usedreduct max-pool', u'store usedwith', u'store usedwith appropri', u'store usual', u'store usual case', u'storeappl', u'storeappl henc', u'storeappl henc propos', u'storethi', u'storethi inform', u'storethi inform involv', u'street', u'street sign', u'street sign cyclist', u'stride', u'stride non-overlap', u'stride non-overlap pixel', u'stride non-overlappingmax-pool', u'stride non-overlappingmax-pool window', u'stride non-overlappingwindow', u'stride non-overlappingwindow perform', u'stride toachiev', u'stride toachiev final', u'stride todeeplab-largefov', u'stride todeeplab-largefov chang', u'strikinglyat', u'strikinglyat depth', u'strikinglyat depth onli', u'strikinglyvari', u'strikinglyvari depth', u'strikinglyvari depth onli', u'stringentintersect', u'stringentintersect union', u'stringentintersect union miou', u'stringentmetr', u'stringentmetr class', u'stringentmetr class averag', u'strong', u'strong correl', u'strong correl miou', u'strong invers', u'strong invers relationship', u'strong regularis', u'strong regularis caus', u'strong regularis model', u'strong regularis result', u'strong11th', u'strong11th main', u'strong11th main contribut', u'strongclass', u'strongclass street', u'strongclass street sign', u'structur', u'structur class', u'structur class classfi', u'structur class classifi', u'structur leg', u'structur leg chairsand', u'structur leg chairsus', u'structur model', u'structur model semant', u'structur motion', u'structur motion crf', u'structur motion point', u'structur motionbas', u'structur motionbas cue', u'structur motionoth', u'structur motionoth method', u'structur predict', u'structur predict problem', u'structur random', u'structur random forest', u'structur scene', u'structur scene aconst', u'structur scene asmal', u'structur smaller', u'structur smaller kernel', u'structur video', u'structur video segment', u'structuredbuild', u'structuredbuild littl', u'structuredbuild littl effect', u'structuredbut', u'structuredbut equal', u'structuredbut equal import', u'structurescontext', u'structurescontext larger', u'structurescontext larger potenti', u'structuresth', u'structuresth input', u'structuresth input segnet', u'studi', u'studi byadopt', u'studi byadopt l-bfgs', u'studi byngiam', u'studi byngiam et', u'studi choos', u'studi choos featur', u'studi effect', u'studi effect featur', u'studi gain', u'studi gain insight', u'studi layer', u'studi layer use', u'studi ph', u'studi phd', u'studi phd university2014', u'studi phd universityof', u'studi predict', u'studi predict effect', u'studi shown', u'studi shown layer', u'studi thenyu', u'studi thenyu dataset', u'studi thethat', u'studi thethat differ', u'studi topatch', u'studi topatch base', u'studi tounderstand', u'studi tounderstand effect', u'studi upsampl', u'studi upsampl usingfix', u'studi upsampl usingin', u'studyactiv', u'studyactiv studyactiv', u'studyactiv studyactiv studyactiv', u'studyactiv studyactiv studysampl', u'studyactiv studyactiv studysamplesamplesamplesamplesamplesamplesamplesamplenot', u'studyactiv studysampl', u'studyactiv studysamplesamplesamplesamplesamplesamplesamplesamplenot', u'studyactiv studysamplesamplesamplesamplesamplesamplesamplesamplenot doe', u'studyeach', u'studyeach layer', u'studyeach layer dure', u'studyfigur', u'studyfigur segnet', u'studyfigur segnet featur', u'studysampl', u'studysamplesamplesamplesamplesamplesamplesamplesamplenot', u'studysamplesamplesamplesamplesamplesamplesamplesamplenot doe', u'studysamplesamplesamplesamplesamplesamplesamplesamplenot doe meannot', u'su', u'su d', u'su d du', u'su-encoder-decod', u'su-encoder-decod stack', u'su-encoder-decod stack train', u'su-w', u'su-w propos', u'su-w propos novel', u'sub-sampl', u'sub-sampl bya', u'sub-sampl bya factor', u'sub-sampl bywindow', u'sub-sampl bywindow perform', u'sub-sampl correspond', u'sub-sampl correspond encod', u'sub-sampl encod', u'sub-sampl encod network', u'sub-sampl obtain', u'sub-sampl obtain featur', u'sub-sampl perform', u'sub-sampl perform memori', u'sub-sampl reducefeatur', u'sub-sampl reducefeatur map', u'sub-sampl reducethi', u'sub-sampl reducethi primarili', u'sub-sampl resultsin', u'sub-sampl resultsin larg', u'sub-sampl resultsov', u'sub-sampl resultsov small', u'sub-samplingth', u'sub-samplingth layer', u'sub-samplingth layer featur', u'sub-samplingw', u'sub-samplingw averag', u'sub-samplingw averag time', u'submit', u'submit cvpr', u'submit cvpr novemb', u'submit toinputinputinputinputinputinputconvolut', u'submit toinputinputinputinputinputinputconvolut encoder-decoderconvolut', u'submit tothes', u'submit tothes architectur', u'subsampl', u'subsampl correspond', u'subsampl correspond decod', u'subsampl store', u'subsampl store usual', u'subsequ', u'subsequ ident', u'subsequ ident situationssegnet', u'subsequ train', u'subsequ train note', u'subset', u'subset featur', u'subset featur thedeep', u'subset featur thefor', u'subset offeatur', u'subset offeatur activ', u'subset ofrath', u'subset ofrath individu', u'subset train', u'subset train set', u'success', u'success add', u'success add deeper', u'success decreasesfor', u'success decreasesfor additional/deep', u'success decreasesp', u'success decreasesp layer', u'success deep', u'success deep convolut', u'success duedeep', u'success duedeep learn', u'success dueto', u'success dueto avail', u'success ina', u'success ina mont', u'success inmodel', u'success inmodel uncertainti', u'success late', u'success late handwritten', u'success object', u'success object recognit', u'such360', u'such360 resolut', u'such360 resolut challeng', u'sucha', u'sucha camvid', u'sucha camvid bayesian', u'sucha fcn-basic-nodimreduct', u'sucha fcn-basic-nodimreduct segnet-encoderaddit', u'sucha larger', u'sucha larger perform', u'sucha road', u'sucha road build', u'sucha segment', u'sucha segment attempt', u'sucha use', u'sucha use region', u'suchclassif', u'suchclassif recent', u'suchclassif recent led', u'suchcomput', u'suchcomput histogram', u'suchcomput histogram n', u'suchmemori', u'suchmemori infer', u'suchmemori infer time', u'suchof', u'suchof network', u'suchof network veri', u'suchscen', u'suchscen major', u'suchscen major pixel', u'suchvector', u'suchvector sampl', u'suchvector sampl histogram', u'suffici', u'suffici expertis', u'suffici expertis initi', u'suffici train', u'suffici train data', u'suggest', u'suggest segnet', u'suggest segnet dealin', u'suggest segnet dealwith', u'suggest subset', u'suggest subset featur', u'suit', u'suit cvpr', u'suit cvpr pp', u'suit proceed', u'suit proceed ieee', u'suitabl', u'suitabl practic', u'suitabl practic applic', u'suitabl practic applicationsi', u'suitabl practic applicationsth', u'sum', u'sum pixelsin', u'sum pixelsin mini-batch', u'sum pixelstrain', u'sum pixelstrain network', u'summar', u'summar abov', u'summar abov analysi', u'sun', u'sun fig', u'sun indoor', u'sun indoor scene', u'sun left', u'sun left camvid', u'sun rgb-d', u'sun rgb-d benchmark', u'sun rgb-d dataset', u'sun rgb-d datasetknown', u'sun rgb-d datasetth', u'sun rgb-d indoor', u'sun rgb-d indooroth', u'sun rgb-d indoorscen', u'sun rgb-d veri', u'sun rgbd', u'sun rgbd indoor', u'sun sun', u'sun sun rgb-d', u'sunrgb-d', u'sunrgb-d dataset', u'sunrgb-d dataset train', u'sunrgb-d indoor', u'sunrgb-d indoor scene', u'sunscen', u'sunscen understand', u'sunscen understand outdoor', u'sunsmal', u'sunsmal dataset', u'sunsmal dataset model', u'sunw', u'sunw evalu', u'sunw evalu perform', u'super', u'super pars', u'super pars 833segnet', u'super pars boosting+detectors+crf', u'super pars segnet', u'super pars super', u'super-pixel', u'super-pixel obtain', u'super-pixel obtain higher', u'super-pixel obtain higheraccuraci', u'super-pixel obtain higherfeatur', u'super-resolut', u'super-resolut depth', u'super-resolut depth map', u'super-resolut depthmap', u'super-resolut depthmap predict', u'super-resolut depthus', u'super-resolut depthus deep', u'super-resolut eccv', u'super-resolut eccv convolut', u'super-resolut eccv page', u'super-resolut eccv pp', u'super-resolut use', u'super-resolut use deep', u'superior', u'superior duefilt', u'superior duefilt perform', u'superior dueto', u'superior dueto larger', u'superior overrec', u'superior overrec compet', u'superior overwith', u'superior overwith addit', u'superior perform', u'superior perform compar', u'superior perform particular', u'superior rest', u'superior rest method', u'supersed', u'supersed popular', u'supersed popular machinelearn', u'supersed popular machineobject', u'supersed popular machinevehicl', u'supervis', u'supervis learn', u'supervis learn task', u'supervis pre-train', u'supervis pre-train use', u'supervis pre-trainingcan', u'supervis pre-trainingcan produc', u'supervis pre-trainingtrain', u'supervis pre-trainingtrain epoch', u'supplementari', u'supplementari materi', u'supplementari material5', u'supplementari material5 conclusion5', u'supplementari materialcan', u'supplementari materialcan view', u'support', u'support aid', u'support aid asarchitectur', u'support aid asregion', u'support experimentaldecod', u'support experimentaldecod segment', u'support experimentalevid', u'support experimentalevid gather', u'support infer', u'support infer rgbd', u'support relationship', u'support relationship infer', u'support techniqu', u'support techniqu multi-stag', u'support-relationship', u'support-relationship amongfrom', u'support-relationship amongfrom scene', u'support-relationship amongobject', u'support-relationship amongobject autonom', u'support-relationship object', u'support-relationship object autonomousappl', u'support-relationship object autonomousvehicl', u'surfac', u'surfac limit', u'surfac limit variabl', u'surfac normal', u'surfac normal semanticd', u'surfac normal semanticlabel', u'surpass', u'surpass human-level', u'surpass human-level perform', u'surpris', u'surpris deeplab-largefov', u'surpris deeplab-largefov train', u'surpris percentag', u'surpris percentag improvementlarg', u'surpris percentag improvementobtain', u'surround', u'surround definit', u'surround definit defin', u'surround high', u'surround high vari', u'suscept', u'suscept over-fit', u'suscept over-fit larg', u'symbol', u'symbol bicyclist', u'symbol bicyclist bayesian', u'symbol bicyclist difficult', u'szegedi', u'szegedi w', u'szegedi w liu', u't', u't darrel', u't darrel \\u201ccaff', u't darrel \\u201cfulli', u'tabl', u'tabl 3practic', u'tabl 3practic applic', u'tabl 3to', u'tabl 3to highest', u'tabl 4model', u'tabl 4model predict', u'tabl 4segment', u'tabl 4segment tasksegment', u'tabl 5show', u'tabl 5show mean', u'tabl 5show result', u'tabl 5their', u'tabl 5their train', u'tabl 5with', u'tabl 5with score', u'tabl agre', u'tabl agre analysi', u'tabl bilinear', u'tabl bilinear interpol', u'tabl chair', u'tabl chair sofa', u'tabl class', u'tabl class accuraci', u'tabl class balanc', u'tabl clear', u'tabl clear larger', u'tabl compar', u'tabl compar algorithm', u'tabl compar segnet', u'tabl deeparchitectur', u'tabl deeparchitectur share', u'tabl deepth', u'tabl deepth quantit', u'tabl did', u'tabl did use', u'tabl differ', u'tabl differ inpedestrian', u'tabl differ inquantit', u'tabl encod', u'tabl encod layerha', u'tabl encod layerrec', u'tabl fcn', u'tabl fcn seen', u'tabl fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010', u'tabl fcn,7267267267267267667667667667669479479479479479759759759759759629629629629626056056056056057787787787787783813813813813812252252252252252472472472472472872872872872871091091091091091471471471471476226226226226220050050050050051791791791791795345534553455345534553454134134134134131717171732132132132132112412412412412470070070070070093393393393393345745745745745734234234234234243043043043043037237237237237245745745745745747647647647647613013013013013081818181143143143143143793793793793793776776776776776815815815815815007007007007007194194194194194365365365365365530530530530530598598598598598554554554554554514514514514514561561561561561363363363363363512512512512512712071207120712071207120691691691691691764764764764764821821821821821725725725725725821821821821821736736736736736833833833833833904090409040904090409040n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u2217n/a\\u22176010 4684231231231231231285285285285285339339339339339599599599599599592592592592592625625625625625798798798798798838838838838838838838838838838n/a\\u2217n/a\\u2217n/a\\u2217bfbfbf70770770770770784584584584584581581581581581507070707258258258258258220220220220220mioumioumioumioumiou888888888888888969969969969969961961961961961466466466466466376376376376376443443443443443glob', u'tabl howev', u'tabl howev boundari', u'tabl howev fastest', u'tabl immedi', u'tabl immedi segnet', u'tabl individu', u'tabl individu class', u'tabl lamp', u'tabl lamp difficult', u'tabl nyu', u'tabl nyu v2', u'tabl ourevalu', u'tabl ourevalu subset', u'tabl ouri', u'tabl ouri includ', u'tabl quantit', u'tabl quantit result', u'tabl report', u'tabl report numer', u'tabl result', u'tabl result compar', u'tabl result dataset', u'tabl result whenno', u'tabl result whenth', u'tabl segment', u'tabl segment accuraci', u'tabl segnet', u'tabl segnet bayesian', u'tabl segnet predictionsar', u'tabl segnet predictionson', u'tabl segnet r', u'tabl segnet-bas', u'tabl segnet-bas segnet', u'tabl sun', u'tabl sun indoor', u'table,37', u'table,37 indoor', u'table,37 indoor scene', u'tabul', u'tabul class', u'tabul class balancinganalys', u'tabul class balancingiter', u'taketheir', u'taketheir train', u'taketheir train open', u'taketrain', u'taketrain respect', u'taketrain respect author', u'tanh', u'tanh non-linear', u'tanh non-linear convolut', u'tanh non-linear max-pool', u'tanh squash', u'tanh squash function', u'task', u'task 480imag', u'task 480imag task', u'task 480we', u'task 480we benchmark', u'task approxim', u'task approxim model', u'task camvid', u'task camvid road', u'task class', u'task class architectur', u'task difficult', u'task difficult becaus', u'task foregroundclass', u'task foregroundclass surround', u'task foregroundhowev', u'task foregroundhowev major', u'task hardbi', u'task hardbi fact', u'task hardwal', u'task hardwal floor', u'task henc', u'task henc decod', u'task mani', u'task mani occupya', u'task mani occupyon', u'task outdoor', u'task outdoor anda', u'task outdoor andindoor', u'task pre-train', u'task pre-train encodertrain', u'task pre-train encoderweight', u'task quantit', u'task quantit assessmentsand', u'task quantit assessmentsshow', u'task segment', u'task segment indoor', u'task segment37', u'task segment37 indoor', u'task segmenth', u'task segmenth come', u'task therefor', u'task therefor author', u'taskan', u'taskan import', u'taskan import choic', u'taski', u'taski road', u'taski road scene', u'tasksarchitectur', u'tasksarchitectur shown', u'tasksarchitectur shown effici', u'tasksdecor', u'tasksdecor object', u'tasksdecor object paint', u'tasksegment', u'tasksegment taskan', u'tasksegment taskan import', u'tasksegment tasksegment', u'tasksegment tasksegment taskan', u'tasksegment tasksegment tasksegment', u'taskshowev', u'taskshowev compar', u'taskshowev compar outdoor', u'taskssuch', u'taskssuch road', u'taskssuch road scene', u'taskw', u'taskw quantifi', u'taskw quantifi perform', u'techniqu', u'techniqu allow', u'techniqu allow learn', u'techniqu alreadi', u'techniqu alreadi present', u'techniqu alsobeen', u'techniqu alsobeen popular', u'techniqu alsoperform', u'techniqu alsoperform boost', u'techniqu anoth', u'techniqu anoth reason', u'techniqu approxim', u'techniqu approxim sampl', u'techniqu arealreadi', u'techniqu arealreadi improv', u'techniqu areto', u'techniqu areto creat', u'techniqu camvid', u'techniqu camvid test', u'techniqu camvidaccuraci', u'techniqu camvidaccuraci best', u'techniqu camvidtest', u'techniqu camvidtest address', u'techniqu compar', u'techniqu compar segnet-bas', u'techniqu core', u'techniqu core feed-forwardsegment', u'techniqu core feed-forwardto', u'techniqu fig', u'techniqu fig use', u'techniqu indic', u'techniqu indic thea', u'techniqu indic thene', u'techniqu isbroad', u'techniqu isbroad applic', u'techniqu isfrom', u'techniqu isfrom correspond', u'techniqu isillustr', u'techniqu isillustr fig', u'techniqu ismoreov', u'techniqu ismoreov section', u'techniqu known', u'techniqu known dropout', u'techniqu multi-stag', u'techniqu multi-stag trainingrecip', u'techniqu multi-stag trainingus', u'techniqu perform', u'techniqu perform segment', u'techniqu problem', u'techniqu produc', u'techniqu produc poorer', u'techniqu propos', u'techniqu propos base', u'techniqu seen', u'techniqu seen success', u'techniqu segnet-typ', u'techniqu segnet-typ decod', u'techniqu stochast', u'techniqu stochast gradientan', u'techniqu stochast gradientdesc', u'techniqu use', u'techniqu use detect', u'techniqu use form', u'techniqu use remov', u'techniqu use segneton', u'techniqu use segnetupsampl', u'techniqu use upsampl', u'techniqu use visual', u'techniqu variat', u'techniqu variat inferenceghahramani', u'techniqu variat inferencein', u'techniqu wide', u'techniqu wide use', u'techniquesind', u'techniquesind need', u'techniquesind need improv', u'techniqueslearn', u'techniqueslearn object', u'techniqueslearn object detector', u'techniquesth', u'techniquesth result', u'techniquesth result tabl', u'techniquesto', u'techniquesto classic', u'techniquesto classic featur', u'technolog', u'technolog develop', u'technolog develop human', u'tempor', u'tempor cue', u'tempor cue compar', u'tempor cue methodmethodmethodmethodmethodmethodmethodmulti-scal', u'tempor cue use', u'tempor cue usedfor', u'tempor cue usedi', u'tempor inform', u'tempor inform use', u'tempor super-pixel', u'tempor super-pixel obtain', u'tensor', u'tensor convolut', u'tensor convolut feedforwardi', u'tensor convolut feedforwardpath', u'term', u'term asdeconvolut', u'term asdeconvolut note', u'term askernel', u'term askernel size', u'term bayesianpixel-wis', u'term bayesianpixel-wis semant', u'term bayesiansegnet', u'term classbalanc', u'term classbalanc use', u'term classifi', u'term classifi pixel', u'term classifi smoothedbi', u'term classifi smoothedcal', u'term classifiersar', u'term classifiersar smooth', u'term classifiersnoisi', u'term classifiersnoisi predict', u'term classth', u'term classth loss', u'term decod', u'term decod decod', u'term g', u'term g c', u'term global', u'term global accuraci', u'term infer', u'term infer time', u'term memori', u'term memori andcomput', u'term memori andfor', u'term memori andsegnet', u'term memoryand', u'term memoryand comput', u'term memoryscen', u'term memoryscen understand', u'term ofmiou', u'term ofmiou comparison', u'term ofmodel', u'term ofmodel deeplab-largefov', u'term parameterizationand', u'term parameterizationand fastest', u'term parameterizationgiven', u'term parameterizationgiven smallest', u'term segnet', u'term segnet archiv', u'term segnet-bas', u'term segnet-bas encod', u'term size', u'term size ofk', u'term size ofth', u'term theclass', u'term theclass spatial', u'term theroad', u'term theroad scene', u'termedsegnet-bas', u'termedsegnet-bas base', u'termedsegnet-bas base model', u'termedw', u'termedw segnet', u'termedw segnet smaller', u'terms\\u2014deep', u'terms\\u2014deep convolut', u'terms\\u2014deep convolut neural', u'test', u'test 224x224', u'test 224x224 pixel', u'test 224x224pixel', u'test 224x224the', u'test 224x224the hardest', u'test adapt', u'test adapt employ', u'test address', u'test address imbal', u'test approxim', u'test approxim everi', u'test architectur', u'test architectur variant', u'test bayesian', u'test bayesian variant', u'test dataset', u'test imag', u'test imag class', u'test imag day', u'test imag imagesar', u'test imag imagesscen', u'test imag scene', u'test imag score', u'test imag train', u'test image0', u'test image075', u'test image075 imag', u'test imagei', u'test imagei averag', u'test importantand', u'test importantand comput', u'test importantfactor', u'test importantfactor consid', u'test ioumethodmethodmethodmethodmethodmethodmethoddil', u'test ioumethodmethodmethodmethodmethodmethodmethoddil network', u'test iouparamet', u'test iouparamet pascal', u'test kitti', u'test kitti sampl', u'test measur', u'test measur ofaccuraci', u'test measur ofboth', u'test model', u'test model thisbatch', u'test model thisstatist', u'test paramet', u'test paramet segnet', u'test per-pixel', u'test per-pixel noisi', u'test per-pixelnoisi', u'test per-pixelnoisi predict', u'test per-pixelth', u'test per-pixelth camvid', u'test perform', u'test perform segnet', u'test perform strong', u'test pointcorrespond', u'test pointcorrespond epoch', u'test pointw', u'test pointw report', u'test recent', u'test recent perform', u'test result', u'test result evalu', u'test rgb', u'test rgb imag', u'test sampl', u'test sampl ground', u'test sampl segnet', u'test sampl test', u'test sampl therec', u'test sampl thesiz', u'test scene', u'test scene recent', u'test scene sun', u'test sequenc', u'test sequenc evolut', u'test server', u'test set', u'test set adddataset', u'test set addground', u'test set averag', u'test set larger', u'test set train', u'test set use', u'test size', u'test size images/featur', u'test time', u'test time imposea', u'test time imposeshow', u'test time produc', u'test time scaleaverag', u'test time scaleth', u'test time size', u'test time use', u'test time wemap', u'test time westudi', u'test time whichallow', u'test time whichconvolut', u'test time360', u'test time360 week', u'test timean', u'test timean integr', u'test timeand', u'test timeand handl', u'test timei', u'test timei order', u'test timeincreas', u'test timeincreas train', u'test timememori', u'test timememori comput', u'test timeoth', u'test timeoth applic', u'test timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass', u'test timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass video', u'test train', u'test train accuraci', u'test train variant', u'test urban', u'test urban highwayimag', u'test urban highwaypract', u'testachiev', u'testachiev mont', u'testachiev mont carlo', u'testand', u'testand joint', u'testand joint train', u'testar', u'testar typic', u'testar typic mani', u'testdataset', u'testdataset differ', u'testdataset differ perform', u'testfor', u'testfor autonom', u'testfor autonom drive', u'testimag', u'testimag factor', u'testimag factor make', u'testingof', u'testingw', u'testingw resiz', u'testingw resiz imag', u'teston', u'teston small', u'teston small set', u'testresult', u'testresult produc', u'testresult produc random', u'testtim', u'testtim generat', u'testtim generat posterior', u'testtim requir', u'testtim requir optim', u'textonforest', u'textonforest random', u'textonforest random forestbas', u'textonforest random foresttextonboost', u'textur', u'textur cue', u'textur cue ieeeimag', u'textur cue ieeetransact', u'textur layout', u'textur layout context', u'textur shape', u'textur shape clutter', u'textur shape wide', u'than300', u'than300 paper', u'than300 papers300', u'than300 papers300 papers300', u'thanha', u'thanha author', u'thanha author book', u'thansegnet-bas', u'thansegnet-bas test', u'thansegnet-bas test train', u'thanth', u'thanth model', u'thanth model perform', u'thatan', u'thatan encod', u'thatan encod unit', u'thatanoth', u'thatanoth comparison', u'thatanoth comparison fcn-basicnoaddit', u'thatboth', u'thatboth perform', u'thatboth perform equal', u'thateach', u'thateach imag', u'thateach imag use', u'thatmini-batch', u'thatmini-batch imag', u'thatmini-batch imag pick', u'thatoptim', u'thatoptim non-convex', u'thatoptim non-convex problem', u'thator', u'thator determinist', u'thator determinist encod', u'thatresult', u'thatresult overal', u'thatresult overal smooth', u'thatshow', u'thatshow signific', u'thatshow signific improv', u'thatth', u'thatth contribut', u'thatth contribut segment', u'thatthi', u'thatthi control', u'thatthi control analysi', u'thatthi differ', u'thatthi differ reduc', u'thatus', u'thatus max-pool', u'thatus max-pool indic', u'thatwhen', u'thatwhen compar', u'thatwhen compar segnet-bas', u'the0th', u'the0th percentil', u'the0th percentil pixel', u'thea', u'thea compar', u'thea compar sift-flow', u'thea complex', u'thea complex train', u'thea crf', u'thea crf framework', u'thea fix', u'thea fix trainabl', u'thea relu', u'thea relu non-linear', u'theachiev', u'theachiev final', u'theachiev final predict', u'theacm', u'theadvantag', u'theadvantag improv', u'theadvantag improv boundari', u'theafter', u'theafter deeper', u'theafter deeper layer', u'theaid', u'theaid region', u'theaid region propos', u'theand', u'theand \\u201cfill', u'theand \\u201cfill in\\u201d', u'theappropri', u'theappropri decod', u'theappropri decod use', u'thearchitectur', u'thearchitectur analysi', u'thearchitectur analysi sec', u'thearchitectur test', u'thearchitectur test bayesian', u'theauthor', u'theauthor fcn', u'theauthor fcn henc', u'thebalanc', u'thebalanc includ', u'thebalanc includ trend', u'thebalanc use', u'thebalanc use median', u'thebenchmark', u'thebenchmark control', u'thebenchmark control mean', u'thebest', u'thebest perform', u'thebest perform fcn-basic', u'thebf', u'thebf measur', u'thebf measur variant', u'thebi', u'thebi pixel-wis', u'thebi pixel-wis classif', u'thecamvid', u'thecamvid dataset', u'theclass', u'theclass maximum', u'theclass maximum probabl', u'theclass spatial', u'theclass spatial arrang', u'theclassifi', u'theclassifi k', u'theclassifi k channel', u'thecompet', u'thecompet architectur', u'thecompet architectur use', u'thecompress', u'thecompress encod', u'thecompress encod featur', u'theconsum', u'theconsum memori', u'theconsum memori dure', u'thecorrespond', u'thecorrespond decod', u'thecorrespond decod dimension', u'thecross-entropi', u'thecross-entropi loss', u'thecross-entropi loss mini-batch', u'thedata', u'thedata prevent', u'thedata prevent over-fit', u'thedecod', u'thedecod encod', u'thedecod encod train', u'thedecod learn', u'thedecod learn map', u'thedecod network', u'thedecod network produc', u'thedeep', u'thedeep layer', u'thedeep layer \\u201ctuned\\u201d', u'thediffer', u'thediffer deep', u'thediffer deep architectur', u'thedimension', u'thedimension reduct', u'thedimension reduct fcn-basic', u'thedusk', u'thedusk poor', u'thedusk poor light', u'theear', u'theear encod', u'theear encod layer', u'theeffect', u'theeffect featur', u'theeffect featur activ', u'theencod', u'theencod consist', u'theencod consist filter', u'theevalu', u'theevalu boundari', u'theevalu boundari accuraci', u'theexampl', u'theexampl featur', u'theexampl featur result', u'thefcn', u'thefcn decod', u'thefcn decod techniqu', u'thefeatur', u'thefeatur s', u'thefeatur s activ', u'thefeatur size', u'thefeatur size fulli', u'thefilt', u'thefilt pair', u'thefilt pair encod', u'thefor', u'thefor 90th', u'thefor 90th percentil', u'thefor better', u'thefor better perform', u'thefor sampl', u'thefor sampl train', u'thefor shallow', u'thefor shallow layer', u'thegrid', u'thegrid search', u'thegrid search process', u'thehigh', u'thehigh dimension', u'thehigh dimension featur', u'thehowev', u'thehowev model', u'thehowev model uncertainti', u'theinput', u'theinput discrep', u'theinput discrep correct', u'theinput imag', u'theinput imag train', u'theinput layer', u'theinput layer question', u'theinputinputinputinputinputinputstochast', u'theinputinputinputinputinputinputstochast dropoutstochast', u'theinputinputinputinputinputinputstochast dropoutstochast dropoutstochast', u'theinvolv', u'theinvolv gradient', u'theinvolv gradient back-propag', u'theireffort', u'theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth', u'theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth qualit', u'theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth qualit comparison', u'theirfigur', u'theirfigur row', u'theirfigur row indoor', u'theirground', u'theirground truth', u'theirground truth row', u'theirmetr', u'theirmetr increas', u'theirmetr increas trend', u'theirmetr increas trendmetr', u'theirour', u'theirour control', u'theirour control benchmark', u'theirthes', u'theirthes larger', u'theirthes larger model', u'thekernel', u'thekernel size', u'thekernel size manner', u'thekullback-leibl', u'thekullback-leibl diverg', u'thekullback-leibl diverg term', u'thelack', u'thelack cue', u'thelack cue height', u'thelarg', u'thelarg fcn-basic-noaddition-nodimreduct', u'thelarg fcn-basic-noaddition-nodimreduct bigger', u'thelarg model', u'thelarg model deeplab-largefov', u'thelargest', u'thelargest model', u'thelargest model longest', u'thelearn', u'thelearn modul', u'thelearn modul encoder-decod', u'theloc', u'theloc global', u'theloc global context', u'theloss', u'theloss object', u'theloss object function', u'themann', u'themann train', u'themann train mani', u'themap', u'themap deep', u'themap deep layer', u'themax-pool', u'themax-pool layer', u'themax-pool layer includ', u'themedian', u'themedian class', u'themedian class frequenc', u'themfeatur', u'themfeatur map', u'themfeatur map say', u'themodel', u'themodel gaussian', u'themodel gaussian process', u'themodel learn', u'themodel learn distribut', u'themodel predict', u'themodel predict incorrect', u'themodel uncertainti', u'themodel uncertainti effect', u'themwith', u'themwith k', u'themwith k trainabl', u'thenclassifi', u'thenclassifi predict', u'thenclassifi predict pixel', u'thenconvolv', u'thenconvolv trainabl', u'thenconvolv trainabl filter', u'thene', u'thene improv', u'thene improv featur', u'thenetwork', u'thenetwork stochast', u'thenetwork stochast gradient', u'thenetwork unsupervis', u'thenetwork unsupervis featur', u'theno', u'theno bias', u'theno bias term', u'thenon-linear', u'thenon-linear use', u'thenon-linear use decod', u'thenon-zero', u'thenon-zero bin', u'thenon-zero bin featur', u'thenperform', u'thenperform non-linear', u'thenperform non-linear upsampl', u'thensmooth', u'thensmooth use', u'thensmooth use crf', u'thenumb', u'thenumb class', u'thenumb class predict', u'thenumb classesnumb', u'thenumb classesnumb classesnumb', u'thenumb paramet', u'thenumb paramet enabl', u'thenumb pool', u'thenumb pool layer', u'thenumer', u'thenumer perform', u'thenumer perform class', u'thenyu', u'thenyu dataset', u'thenyu dataset futur', u'theobject', u'theobject boundari', u'theof', u'theof decod', u'theof decod correspond', u'theof import', u'theof import class', u'theoptim', u'theoptim non-convex', u'theoptim non-convex problem', u'theoret', u'theoret memori', u'theoret memori requir', u'theother', u'theother hand', u'theother hand effici', u'theother method', u'theother method includ', u'theother method shown', u'theoutput', u'theoutput decod', u'theoutput decod featur', u'theoutput soft-max', u'theoutput soft-max k', u'thepatch', u'thepatch dure', u'thepatch dure test', u'theperceiv', u'theperceiv perform', u'theperceiv perform increas', u'thepercentil', u'thepercentil dataset', u'theperform', u'theperform segnet', u'theperform segnet outdoor', u'thepool', u'thepool process', u'thepool process upsampl', u'thepost-process', u'thepost-process produc', u'thepost-process produc competit', u'thequalit', u'thequalit result', u'thequalit result abil', u'thequantit', u'thequantit comparison', u'thequantit comparison deep', u'thequantit comparison segnet', u'thequest', u'thequest perceiv', u'thequest perceiv advantag', u'therear', u'therear typic', u'therear typic mani', u'therec', u'therec sun', u'therec sun rgb-d', u'therediffer', u'therediffer pose', u'therediffer pose frequent', u'therefor', u'therefor ad', u'therefor ad hoc', u'therefor analysednecessari', u'therefor analysednecessari achiev', u'therefor analysedth', u'therefor analysedth decod', u'therefor author', u'therefor author use', u'therefor believ', u'therefor believ iscan', u'therefor believ isth', u'therefor believeour', u'therefor believeour control', u'therefor believesometim', u'therefor believesometim valid', u'therefor believeto', u'therefor believeto robust', u'therefor believeus', u'therefor believeus depth', u'therefor benchmark', u'therefor benchmark bayesian', u'therefor consid', u'therefor consid use', u'therefor differ', u'therefor differ sceneregion', u'therefor differ sceneunderstand', u'therefor encourag', u'therefor encourag control', u'therefor experimentedform', u'therefor experimentedform becaus', u'therefor experimentedwith', u'therefor experimentedwith train', u'therefor explor', u'therefor explor numberaft', u'therefor explor numberof', u'therefor focus', u'therefor focus studi', u'therefor initi', u'therefor initi train', u'therefor necessari', u'therefor necessari captureand', u'therefor necessari captureboundari', u'therefor need', u'therefor need approxim', u'therefor number', u'therefor number channel', u'therefor requir', u'therefor requir nofix', u'therefor requir nolearn', u'therefor train', u'therefor train thekullback-leibl', u'therefor train thenetwork', u'therefor use', u'therefor use compar', u'therefor weadapt', u'therefor weadapt appropri', u'therefor weadopt', u'therefor weadopt l-bfgs', u'therefor weightaverag', u'therefor weightaverag techniqu', u'therefor weightbeyond', u'therefor weightbeyond approxim', u'therei', u'therei activ', u'therei activ semant', u'therewhol', u'therewhol imag', u'therewhol imag detect', u'thergb', u'thergb modal', u'thergb modal use', u'theroad', u'theroad scene', u'theroad scene imag', u'therootrootrootrootrootsquar', u'therootrootrootrootrootsquar valu', u'therootrootrootrootrootsquar valu map', u'thesam', u'thesam number', u'thesam number size', u'thesam number train', u'thesea', u'thesea mont', u'thesea mont carlo', u'theseapproach', u'theseapproach howev', u'theseapproach howev did', u'thesear', u'thesear typic', u'thesear typic pre-train', u'thesearchitectur', u'thesearchitectur respons', u'thesearchitectur respons producingarchitectur', u'thesecriteria', u'thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath', u'thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath encod', u'thesecriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriacriteriath encod network', u'theseful', u'theseful imag', u'theseful imag size', u'theseg', u'theseg imag', u'theseg imag reduc', u'thesegnet', u'thesegnet superior', u'thesegnet superior perform', u'thesegnet-bas', u'thesegnet-bas test', u'thesegnet-bas test train', u'thesein', u'thesein general', u'thesein general posterior', u'thesein lower', u'thesein lower layer', u'theserepeat', u'theserepeat design', u'theserepeat design segnet', u'theseresult', u'theseresult appli', u'theseresult appli bayesian', u'theseweight', u'theseweight requir', u'theseweight requir ani', u'theshar', u'theshar encod', u'theshar encod network', u'thesiz', u'thesiz object', u'thesiz object class', u'thesmal', u'thesmal size', u'thesmal size class', u'thestandard', u'thestandard probabl', u'thestandard probabl drop', u'thetabl', u'thetabl architectur', u'thetabl architectur variant', u'thetechniqu', u'thetechniqu describ', u'thetechniqu describ et', u'theth', u'theth correspond', u'theth correspond resolut', u'theth encod', u'theth encod decod', u'theth entir', u'theth entir train', u'theth input', u'theth input featur', u'theth segnet', u'theth segnet architectur', u'thethat', u'thethat differ', u'thethat differ dataset', u'theto', u'theto test', u'theto test approxim', u'thetop', u'thetop n', u'thetop n featur', u'thetrain', u'thetrain set', u'thetrain set select', u'thetrain set small', u'thevari', u'thevari background', u'thevari background class', u'thevgg16', u'thevgg16 network', u'thevgg16 network role', u'theweight', u'theweight assign', u'theweight assign class', u'theweight averag', u'theweight averag techniqu', u'thewith', u'thewith scale', u'thewith scale chang', u'theworsen', u'theworsen bf', u'theworsen bf score', u'theyshow', u'theyshow signific', u'theyshow signific improv', u'theywhil', u'theywhil exploit', u'theywhil exploit featur', u'thielscher', u'thielscher ed', u'thielscher ed vol', u'thinn', u'thinn network', u'thinn network use', u'thinner', u'thinner structur', u'thinner structur leg', u'this2', u'this2 stride', u'this2 stride non-overlap', u'thisalso', u'thisalso reduc', u'thisalso reduc number', u'thisarchitectur', u'thisarchitectur illustr', u'thisarchitectur illustr fig', u'thisbas', u'thisbas cue', u'thisbas cue use', u'thisbatch', u'thisbatch norm', u'thisbatch norm statist', u'thiscompress', u'thiscompress encod', u'thiscompress encod featur', u'thisdataset', u'thisdataset analys', u'thisdataset analys effect', u'thisdataset use', u'thisdataset use depth', u'thisdimension', u'thisdimension reduct', u'thisdimension reduct step', u'thisdistribut', u'thisdistribut network', u'thisdistribut network weight', u'thisen', u'thisen compar', u'thisen compar propos', u'thisfeatur', u'thisfeatur s', u'thisfeatur s activ', u'thisform', u'thisform upsampl', u'thisform upsampl incorpor', u'thisgain', u'thisgain popular', u'thisgain popular sinc', u'thishigh', u'thishigh resolut', u'thishigh resolut featur', u'thisi', u'thisi follow', u'thisi follow general', u'thislow', u'thislow resolut', u'thislow resolut featur', u'thismak', u'thismak easier', u'thismak easier deep', u'thismap', u'thismap input', u'thismap input decod', u'thismethod', u'thismethod perform', u'thismethod perform probabilist', u'thisnetwork', u'thisnetwork follow', u'thisnetwork follow final', u'thisnetwork upsampl', u'thisnetwork upsampl perform', u'thisnumb', u'thisnumb paramet', u'thisnumb paramet enabl', u'thispap', u'thispaperpaperpaperpaperpaperpaperpaper3', u'thispaperpaperpaperpaperpaperpaperpaper3 segnet', u'thispaperpaperpaperpaperpaperpaperpaper3 segnet architectur', u'thisparallel', u'thisparallel road', u'thisparallel road surfac', u'thispart', u'thispart veri', u'thispart veri reason', u'thisperform', u'thisperform segnet', u'thisperform segnet outdoor', u'thispredict', u'thispredict reason', u'thispredict reason indic', u'thissegment', u'thissegment qualiti', u'thissegment qualiti csurka', u'thissmal', u'thissmal size', u'thissmal size preserv', u'thisstatist', u'thisstatist http', u'thisstatist http //mi', u'thisstatist http //miengcamacuk/projects/segnet/tutorialhtmlstatist', u'thisto', u'thisto make', u'thisto make compat', u'thisto semant', u'thisto semant segment', u'thisus', u'thisus camvid', u'thisus camvid dataset', u'throughput', u'throughput power', u'throughput power gpus', u'time', u'time analys', u'time analys segnet', u'time becom', u'time becom import', u'time best', u'time best case', u'time bf', u'time bf score', u'time camviddataset', u'time camviddataset contain', u'time camvidnet', u'time camvidnet given', u'time command', u'time command use', u'time compromis', u'time compromis toi', u'time compromis tosom', u'time constrain', u'time constrain larger', u'time dense-crf', u'time depend', u'time depend implement', u'time dure', u'time dure infer', u'time dure train', u'time effici', u'time effici infer', u'time effici model', u'time fact', u'time fact agre', u'time forward', u'time forward pass', u'time given', u'time given analysisin', u'time given analysisnetwork', u'time gpu', u'time hardwar', u'time hardwar resourc', u'time howev', u'time howev model', u'time imposea', u'time imposea bernoulli', u'time imposeshow', u'time imposeshow dropout', u'time justifi', u'time justifi setagainst', u'time justifi setto', u'time memori', u'time memori versus', u'time memorybest', u'time memorybest effici', u'time memoryha', u'time memoryha advantag', u'time memoryi', u'time memoryi constrain', u'time memoryspars', u'time memoryspars array', u'time mont', u'time mont carlo', u'time ms', u'time ms g', u'time particular', u'time particular larger', u'time performance5', u'time performancet', u'time performancet segnet', u'time point', u'time point deeplab-largefov-densecrf', u'time pointsin', u'time pointsin train', u'time pointstrain', u'time pointstrain set', u'time predict', u'time predict loos', u'time produc', u'time produc featur', u'time refer', u'time refer segnet', u'time refer segnether', u'time refer segnetor', u'time remainsth', u'time remainsth experi', u'time remainswith', u'time remainswith connect', u'time requir', u'time requir averag', u'time requir map', u'time requir optim', u'time result', u'time result featur', u'time scaleaverag', u'time scaleaverag propos', u'time scaleth', u'time scaleth weight', u'time segnet', u'time segnet theconsum', u'time segnet theother', u'time segnet-bas', u'time segnet-bas adecod', u'time segnet-bas ahand', u'time sever', u'time sever recent', u'time shown', u'time shown experi', u'time signific', u'time significantlyon', u'time significantlyon right', u'time significantlyparamet', u'time significantlyparamet infer', u'time size', u'time size imag', u'time standard', u'time standard dropout', u'time tabl', u'time tabl howev', u'time use', u'time use dropoutto', u'time use dropoutw', u'time weconclud', u'time weconclud pointer', u'time wemap', u'time wemap decod', u'time wesegnet', u'time wesegnet sever', u'time westudi', u'time westudi network', u'time whenfollow', u'time whenfollow train', u'time whenprovid', u'time whenprovid measur', u'time whichallow', u'time whichallow approxim', u'time whichconvolut', u'time whichconvolut neural', u'time360', u'time360 week', u'time360 week unoptim', u'timean', u'timean integr', u'timean integr network', u'timeand', u'timeand handl', u'timeand handl miss', u'timeand improv', u'timeand improv infer', u'timei', u'timei order', u'timei order 2secs/fram', u'timei spent', u'timei spent perform', u'timeincreas', u'timeincreas train', u'timeincreas train time', u'timememori', u'timememori comput', u'timememori comput load', u'timeoth', u'timeoth applic', u'timeoth applic pixel', u'timeour', u'timeour work', u'timeour work inspir', u'timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass', u'timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass video', u'timereferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesreferencesclass video high-definit', u'timesmor', u'timesmor pedestrian', u'timesmor pedestrian pole', u'timesroad', u'timesroad sky', u'timesroad sky build', u'timessampl', u'timessampl approxim', u'timessampl approxim \\u201cinfluences\\u201d', u'timesw', u'timesw train', u'timesw train encoder-decod', u'titan', u'titan gpu', u'titan gpu cudnn', u'titan x', u'titan x gpu', u'toa', u'toa camvid', u'toa camvid bayesian', u'toa comparison', u'toa comparison comput', u'toa context', u'toa context window', u'toa highlight', u'toa highlight propos', u'toachiev', u'toachiev final', u'toachiev final predict', u'toaddit', u'toaddit train', u'toaddit train data', u'toarchitectur', u'toarchitectur like', u'toarchitectur like boundari', u'tobayesian', u'tobayesian segnet', u'tobayesian segnet make', u'tobi', u'tobi use', u'tobi use pair-wis', u'tocombin', u'tocombin correspond', u'tocombin correspond encod', u'tocompl', u'tocompl exist', u'tocompl exist metric', u'tocomput', u'tocomput time', u'tocomput time requir', u'tocontrol', u'tocontrol benchmark', u'tocontrol benchmark use', u'tocop', u'tocop addit', u'tocop addit uncertainti', u'tocreat', u'tocreat memori', u'tocreat memori intens', u'todecod', u'todecod lead', u'todecod lead better', u'todeeplab-largefov', u'todeeplab-largefov chang', u'todeeplab-largefov chang max', u'toear', u'toear encod', u'toear encod layer', u'toenabl', u'toenabl end-to-end', u'toenabl end-to-end train', u'toengag', u'toengag attent', u'toengag attent challeng', u'toextrem', u'toextrem add', u'toextrem add encod', u'tofeatur', u'tofeatur map', u'tofeatur map s', u'tofor', u'tofor pixel', u'tofor pixel wise', u'togeth', u'togeth use', u'togeth use combin', u'togetherclass', u'togetherclass segment', u'togetherclass segment support', u'togetherus', u'togetherus combin', u'togetherus combin rgb', u'toi', u'toi constrain', u'toi constrain infer', u'toin', u'toin term', u'toin term global', u'toindic', u'toindic larg', u'toindic larg deep', u'toinputinputinputinputinputinputconvolut', u'toinputinputinputinputinputinputconvolut encoder-decoderconvolut', u'toinputinputinputinputinputinputconvolut encoder-decoderconvolut encoder-decoderconvolut', u'tolearn', u'tolearn object', u'tolearn object detector', u'tolearn spatial', u'tolearn spatial context/class', u'toler', u'toler distanc', u'toler distanc f1measur', u'toler distanc use', u'tomap', u'tomap deep', u'tomap deep layer', u'tomap fcn', u'tomap fcn k', u'tomatch', u'tomatch input', u'tomatch input imag', u'tomeasur', u'tomeasur quantit', u'tomeasur quantit perform', u'tomeasur quantit performancemeasur', u'tomont', u'tomont carlo', u'tomont carlo dropout', u'tonot', u'tonot anoth', u'tonot anoth recent', u'tonot decod', u'tonot decod correspond', u'toobtain', u'toobtain featur', u'toobtain featur accur', u'toof', u'toof experi', u'toof experi use', u'toof model', u'toof model uncertainti', u'tool', u'tool forsegnet', u'tool forvisu', u'tool forvisu scene', u'tool imag', u'tool imag annot', u'tool scene', u'tool scene understand', u'toother', u'toother method', u'top-1', u'top-1 4this', u'top-1 4this increas', u'top-1 4thlayer', u'top-1 4thlayer featur', u'top-1 featur', u'top-1 featur activ', u'top-1 layer', u'top-1 layer indic', u'top-down', u'top-down semant', u'top-down semant feedback', u'topatch', u'topatch base', u'topatch base classifi', u'toperform', u'toperform better', u'toperform better shorter', u'toperform non-linear', u'toperform non-linear upsampl', u'topic', u'topic ofresearch', u'topic ofresearch fuell', u'topic ofsemant', u'topic ofsemant pixel-wis', u'topic paper', u'topic paper33a', u'topic paper33a rchitecturea', u'topic paperfeatur', u'topic paperfeatur map', u'topic research', u'topic research fuell', u'topic research semant', u'topic thislow', u'topic thislow resolut', u'topic thispap', u'topic thispaperpaperpaperpaperpaperpaperpaper3', u'topic thispaperpaperpaperpaperpaperpaperpaper3 segnet', u'topixel', u'topixel deepest', u'topixel deepest layer', u'topolog', u'topolog ident', u'topolog ident convolut', u'topolog ident toth', u'topperform', u'topperform rgb', u'topperform rgb method', u'topredict', u'topredict reason', u'topredict reason indic', u'toprev', u'toprev overfit', u'toprev overfit co-adapt', u'toproduc', u'toproduc high', u'toproduc high qualiti', u'toproduc input', u'toproduc input decod', u'toproduc smooth', u'toproduc smooth segment', u'toprovid', u'toprovid measur', u'toprovid measur model', u'topwhich', u'topwhich consist', u'topwhich consist test', u'toresult', u'toresult overal', u'toresult overal smooth', u'torobust', u'torobust hope', u'torobust hope experi', u'torr', u'torr \\u201ccondit', u'torr \\u201ccondit random', u'tosegment', u'tosegment engin', u'tosegment engin segnet', u'tosegnet', u'tosegnet good', u'tosegnet good architectur', u'tosharp', u'tosharp class', u'tosharp class boundari', u'toshiba', u'toshiba corporationfellow', u'toshiba corporationfellow engin', u'toshiba corporationresearch', u'toshiba corporationresearch develop', u'toshibafellow', u'toshibafellow engin', u'toshibafellow engin toshiba', u'toshibaoxford', u'toshibaoxford toshibafellow', u'toshibaoxford toshibafellow engin', u'toshibaoxford toshibaoxford', u'toshibaoxford toshibaoxford toshibafellow', u'toshibaoxford toshibaoxford toshibaoxford', u'tosom', u'tosom extent', u'tosom extentsom', u'tosom extentsom extentsom', u'totabl', u'totabl result', u'totabl result dataset', u'total', u'total number', u'total number ofmodel', u'total number ofseg', u'total use', u'total use layer', u'toth', u'toth camvid', u'toth camvid test', u'toth convolut', u'toth convolut layer', u'toth correspond', u'toth correspond decod', u'toth correspond output', u'toth correspond resolut', u'toth encod', u'toth encod network', u'toth input', u'toth input imag', u'toth variant', u'toth variant import', u'tothes', u'tothes architectur', u'tothes architectur independ', u'tothi', u'tothi differ', u'tothi differ reduc', u'totrain', u'totrain end-to-end', u'totrain end-to-end task', u'totrain fcn-8', u'totrain fcn-8 main', u'totransf', u'totransf entir', u'totransf entir featur', u'tounderstand', u'tounderstand confid', u'tounderstand confid trust', u'tounderstand effect', u'tounderstand effect featur', u'tounderstand model', u'tounderstand model uncertainti', u'tous', u'tous regular', u'tous regular convolut', u'towardscompl', u'towardscompl exist', u'towardscompl exist metric', u'towardsregion', u'towardsregion accuraci', u'towardsregion accuraci clear', u'towithout', u'towithout class', u'towithout class balanc', u'trace', u'trace acontext', u'trace acontext window', u'trace ain', u'trace ain deepest', u'trace toa', u'trace toa context', u'trace topixel', u'trace topixel deepest', u'tractabl', u'tractabl therefor', u'tractabl therefor need', u'trade-off', u'trade-off involv', u'trade-off involv achiev', u'trade-off involv betweenmemori', u'trade-off involv betweenscor', u'trade-off involv design', u'trade-off involv differ', u'trade-off size', u'trade-off size context', u'trade-offsinvolv', u'trade-offsinvolv design', u'trade-offsinvolv design architectur', u'trade-offswith', u'trade-offswith import', u'trade-offswith import variant', u'tradit', u'tradit method', u'tradit method camvid', u'train', u'train 140k', u'train 140k buildingbuildingbuildingbuildingbuildingbuildingbuildingbuildingbuilding101010t', u'train 140k segnet', u'train accuraci', u'train accuraci compar', u'train accuraci fcn-basic', u'train accuraci lower', u'train accuraci shown', u'train addedbatch', u'train addedbatch normal', u'train addedon', u'train addedon dataset', u'train addit', u'train addit perform', u'train addit pre-train', u'train advantag', u'train advantag trainingstack', u'train advantag trainingth', u'train afresh', u'train afresh random', u'train alarg', u'train alarg dataset', u'train and654', u'train and654 test', u'train andchalleng', u'train andchalleng onli', u'train andi', u'train andi largest', u'train andtest', u'train andtest use', u'train ani', u'train ani deep', u'train append', u'train append network', u'train apredict', u'train apredict accur', u'train architectur', u'train architectur fcn8', u'train batch', u'train batch size', u'train bayesian', u'train bayesian segnet', u'train bus', u'train bus class', u'train classif', u'train classif larg', u'train classificationand', u'train classificationand segment', u'train classificationregion', u'train classificationregion propos', u'train control', u'train control set', u'train convolutionaldecod', u'train convolutionaldecod techniqu', u'train convolutionalnetwork', u'train convolutionalnetwork classif', u'train convolutionalnetwork object', u'train convolutionalth', u'train convolutionalth input', u'train corpus', u'train corpus indoor', u'train corpus road', u'train data', u'train data avail', u'train data availablein', u'train data availablewhen', u'train data pascal', u'train data use', u'train data x', u'train dataand', u'train dataand segment', u'train datafor', u'train datafor pre-train', u'train dataset', u'train dataset miou', u'train dataset obtain', u'train dataset use', u'train decod', u'train decod encod', u'train decoderfilt', u'train decoderfilt perform', u'train decoderor', u'train decoderor upsampl', u'train deepest', u'train deepest layer', u'train differ', u'train differ variant', u'train difficulti', u'train difficulti train', u'train discard', u'train discard decod', u'train discard thedecod', u'train discard thenetwork', u'train dropouta', u'train dropouta fulli', u'train dropoutaft', u'train dropoutaft everi', u'train encoder-decod', u'train encoder-decod pair', u'train end', u'train end end', u'train end-to-end', u'train end-to-end ona', u'train end-to-end onlarg', u'train end-to-end step', u'train end-to-end use', u'train end-to-endcomput', u'train end-to-endcomput time', u'train end-to-endin', u'train end-to-endin convolut', u'train end-to-endin order', u'train end-to-endmor', u'train end-to-endmor comput', u'train end-to-endon', u'train end-to-endon dataset', u'train end-to-endth', u'train end-to-endth perform', u'train epoch', u'train epoch use', u'train fit', u'train fit poorer', u'train help', u'train help shown', u'train hold', u'train hold preceed', u'train howev', u'train howev feed-forward', u'train iii', u'train iii thisform', u'train iii thisnumb', u'train imag', u'train imag of360', u'train imag ofdeep', u'train imag test', u'train infer', u'train infer aid', u'train infer anoth', u'train infer howev', u'train inference4', u'train inference86868685', u'train larg', u'train larg set', u'train largermodel', u'train largermodel deconvnet', u'train largersegnet', u'train largersegnet becaus', u'train layer', u'train layer segnet', u'train layerdeep', u'train layerdeep segnet', u'train layerth', u'train layerth current', u'train loss', u'train loss function', u'train loss2', u'train loss2 http', u'train lossconverg', u'train lossconverg train', u'train lossof', u'train lossof segnet-bas', u'train lossoptim', u'train lossoptim camvid', u'train mani', u'train mani architectur', u'train mani othernetwork', u'train mani otherrec', u'train median', u'train median frequenc', u'train memori', u'train memori comput', u'train memori mb', u'train mini-batch', u'train mini-batch size', u'train model', u'train model dropout', u'train modular', u'train modular doneaft', u'train modular doneand', u'train modular fulli', u'train moreov', u'train moreov duringa', u'train moreov duringinfer', u'train network', u'train network ledof', u'train network ledto', u'train network network', u'train network use', u'train networksinvolv', u'train networksinvolv gradient', u'train networksresult', u'train networksresult main', u'train note', u'train note encod', u'train onli', u'train onli 4th', u'train onli soft-maxclassifi', u'train onli soft-maxwith', u'train open', u'train open sourc', u'train paramet', u'train paramet size', u'train perform', u'train perform fix', u'train phase', u'train phase reveal', u'train phasefrom', u'train phasefrom tabl', u'train phasein', u'train phasein train', u'train predictionsdo', u'train predictionsdo retain', u'train predictionsth', u'train predictionsth largest', u'train predictlabel', u'train predictlabel resolut', u'train predictsurpris', u'train predictsurpris deeplab-largefov', u'train process', u'train process fromclassif', u'train process fromweight', u'train random', u'train random initialis', u'train reduc', u'train reduc intern', u'train relat', u'train relat issu', u'train sampl', u'train sampl layer', u'train scheme', u'train seg-net', u'train seg-net given', u'train seg-train', u'train seg-train set', u'train segnet', u'train segnet addit', u'train segnet architectur', u'train segnet differ', u'train segnet median', u'train segnet-bas', u'train segnet-bas layer-wis', u'train segnet-bas segnet-bas', u'train segnet3', u'train segnet31', u'train segnet31 train', u'train segnetmost', u'train segnetmost deep', u'train set', u'train set anyactiv', u'train set anyand', u'train set comput', u'train set dimension', u'train set e', u'train set general', u'train set road', u'train set shuffl', u'train set sinc', u'train set size', u'train set supervis', u'train set surpris', u'train set thenon-zero', u'train set theth', u'train set train', u'train set use', u'train set weight', u'train setar', u'train setar train', u'train setdivid', u'train setdivid class', u'train setind', u'train setind architectur', u'train setmedian', u'train setmedian class', u'train setobtain', u'train setobtain use', u'train setrow', u'train setrow segnet', u'train sgd', u'train sgd need', u'train slowli', u'train slowli comparabledeconvnet', u'train slowli comparableor', u'train solver', u'train solver sgd', u'train test', u'train test 224x224', u'train test 224x224pixel', u'train test 224x224the', u'train test imag', u'train test importantand', u'train test importantfactor', u'train test rgb', u'train testingof', u'train testingw', u'train testingw resiz', u'train thekullback-leibl', u'train thekullback-leibl diverg', u'train thenetwork', u'train thenetwork stochast', u'train time', u'train time becom', u'train time justifi', u'train time predict', u'train time remainsth', u'train time remainswith', u'train time shown', u'train time tabl', u'train train', u'train train imag', u'train use', u'train use semant', u'train use stochast', u'train valu', u'train valu andiniti', u'train valu andtrain', u'train valu train', u'train variant', u'train variant kitti', u'train variant selectedfor', u'train variant selectediter', u'train variant train', u'train variant wetechniqu', u'train variant weus', u'train veri', u'train veri long', u'train weight', u'train weight holdingth', u'train weight holdingw', u'train0', u'trainabl', u'trainabl decod', u'trainabl decod filter', u'trainabl decod filterbank', u'trainabl decod filterconvolv', u'trainabl decod filters000000000000000000000000max-poolingmax-poolingmax-poolingindicesindicesindicesindicesindicesindicesindicesindicesdeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutiondeconvolutionfor', u'trainabl decod filtersconvolut', u'trainabl deep', u'trainabl deep architecturefor', u'trainabl deep architecturew', u'trainabl filter', u'trainabl filter bank', u'trainabl filter bankinput', u'trainabl filter bankit', u'trainabl filter bankpervis', u'trainabl filter bankto', u'trainabl filter k', u'trainabl filter produc', u'trainabl multi-channel', u'trainabl multi-channel decod', u'trainabl multi-channel upsampl', u'trainabl paramet', u'trainabl paramet competingarchitectur', u'trainabl paramet competingcomput', u'trainabl paramet encod', u'trainabl paramet highestresolut', u'trainabl paramet highestw', u'trainabl paramet order', u'trainabl segment', u'trainabl segment engin', u'trainabl soft-max', u'trainabl soft-max classifi', u'trainableparamet', u'trainableparamet infer', u'trainableparamet infer time', u'trainabletheir', u'trainabletheir correspond', u'trainabletheir correspond upsampl', u'traineddetector', u'traineddetector crf', u'traineddetector crf model', u'trainedend-to-end', u'trainedend-to-end step', u'trainedend-to-end step stochast', u'trainedfigur', u'trainedfigur result', u'trainedfigur result sampl', u'trainedfigur schemat', u'trainedfigur schemat bayesian', u'trainedjoint', u'trainedjoint supervis', u'trainedjoint supervis learn', u'trainedthes', u'trainedthes architectur', u'trainedthes architectur deep', u'trainedw', u'trainedw appli', u'trainedw appli deep', u'trainedwith', u'trainedwith dropout', u'trainedwith dropout fcn', u'training90', u'training90 paramet', u'training90 paramet entir', u'traininga', u'traininga relev', u'traininga relev task', u'trainingal', u'trainingal encoder-decod', u'trainingal encoder-decod pair', u'trainingcamvid', u'trainingcamvid test', u'trainingcamvid test set', u'trainingdecod', u'trainingdecod strong', u'trainingdecod strong regularis', u'trainingfcn', u'trainingfcn did', u'trainingfcn did improv', u'trainingfit', u'trainingfor', u'trainingfor poor', u'trainingfor poor perform', u'trainingher', u'trainingher note', u'trainingher note over-fit', u'trainingnot', u'trainingnot attempt', u'trainingnot attempt use', u'trainingof', u'trainingof network', u'trainingof network veri', u'trainingon', u'trainingon soft-max', u'trainingon soft-max classifi', u'trainingpoor', u'trainingpoor result', u'trainingpoor result obtain', u'trainingprocess', u'trainingprocess decod', u'trainingprocess decod decod', u'trainingprocess employ', u'trainingprocess employ data', u'trainingrecip', u'trainingrecip arriv', u'trainingrecip arriv high', u'trainingsegnet-bas', u'trainingsegnet-bas segnet', u'trainingsegnet-bas segnet addit', u'trainingset', u'trainingset use', u'trainingset use sgd', u'trainingstack', u'trainingstack train', u'trainingstack train advantag', u'trainingth', u'trainingth soft-max', u'trainingth soft-max layer', u'trainingth variant', u'trainingth variant import', u'trainingthat', u'trainingthat use', u'trainingthat use median', u'trainingthes', u'trainingthes larger', u'trainingthes larger model', u'trainingto', u'trainingto train', u'trainingto train paramet', u'trainingus', u'trainingus host', u'trainingus host support', u'trainingwhich', u'trainingwhich enabl', u'trainingwhich enabl train', u'trainobtain', u'trainobtain combin', u'trainobtain combin use', u'trainsegnet', u'trainsegnet correspond', u'trainsegnet correspond qualit', u'trainth', u'trainth network', u'trainth network converg', u'transact', u'transact pattern', u'transact pattern analysi', u'transfer', u'transfer pool', u'transfer pool indic', u'transfer typic', u'transfer typic random', u'transferredacross', u'transferredacross dataset', u'transferredacross dataset use', u'transferredperform', u'transferredperform camvid', u'transferredperform camvid pre-train', u'transit', u'translat', u'translat invari', u'translat invari robustclassif', u'translat invari robustsub-sampl', u'translat invariancea', u'translat invariancea factor', u'translat invarianceov', u'translat invarianceov small', u'transpos', u'transpos encod', u'transpos encod kernel', u'tree', u'tree build', u'tree build bollard', u'tree optim', u'tree optim cover', u'treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear', u'treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear', u'treetreetreetreetreemethodmethodmethodmethodmethodmethodmethodsfm+appear sfm+appear sfm+appear', u'trend', u'trend bf', u'trend bf measur', u'trend detect', u'trend detect improv', u'trendfor', u'trendfor fcn', u'trendfor fcn model', u'trendmetr', u'trendmetr increas', u'trendmetr increas trendfor', u'trendmetr increas trendmetr', u'tri', u'tri direct', u'tri direct adopt', u'tri generic', u'tri generic variant', u'tri pleas', u'tri pleas onlin', u'tri predict', u'tri predict labelsfor', u'tri predict labelsproduc', u'tri predict labelsto', u'trial', u'trial standard', u'trial standard deviat', u'true', u'true class', u'true class term', u'true natur', u'true natur frequencybalanc', u'true natur frequencybuild', u'true perform', u'true perform deep', u'true perform underit', u'true perform undertim', u'trust', u'trust imag', u'trust imag segment', u'trust semant', u'trust semant segment', u'truth', u'truth classand', u'truth classand recal', u'truth classboundari', u'truth classboundari given', u'truth classedg', u'truth classedg error', u'truth classresolut', u'truth classresolut lack', u'truth databas', u'truth databas prl', u'truth databaseclass', u'truth databaseclass video', u'truth databaseprl', u'truth databaseprl 6prl', u'truth ground', u'truth ground truth', u'truth label', u'truth label shown', u'truth public', u'truth public avail', u'truth row', u'truth row segnet', u'truth segnet', u'truth segnet segnet', u'truth shown', u'truth shown second', u'truth test', u'truth test image0', u'truth test image075', u'truth test imagei', u'truth33activ', u'truth33activ proportionactiv', u'truth33activ proportionactiv proportionactiv', u'truthground', u'truthground truth33activ', u'truthground truth33activ proportionactiv', u'truthground truthground', u'truthground truthground truth33activ', u'truthground truthground truthground', u'truthground truthground truthrandom', u'truthground truthrandom', u'truthground truthrandom forest', u'truthinput', u'truthinput abl', u'truthinput abl accur', u'truthlabel', u'truthlabel shown', u'truthlabel shown black', u'truthrandom', u'truthrandom forest', u'truthrandom forest withrandom', u'tune', u'tune activ', u'tune activationsfin', u'tune activationsfin tune', u'tune activationsfor', u'tune activationsfor given', u'tune group', u'tune group relat', u'tune larg', u'tune larg static', u'tune use', u'tune use invers', u'turn', u'turn convolut', u'turn convolut layer', u'turn set', u'turn set remain', u'tvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass', u'tvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass car', u'tvtvtvbooksbooksbooksbooksbooksbookswindowwindowwindowwindowwindowwindowwindowwallwallwallwallwalltabletabletabletabletabletablesofasofasofasofasofadecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationdecorationfloorfloorfloorfloorfloorfloorceilingceilingceilingceilingceilingceilingceilingceilingfurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturefurniturechairchairchairchairchairchairobjectsobjectsobjectsobjectsobjectsobjectsobjectsobjectsbedbedbedbedclass car pedestrian', u'type', u'type architectur', u'type architectur probabilist', u'type architecturein', u'type architecturein sec', u'type architectureth', u'type architectureth impact', u'type bedroom', u'type bedroom live', u'type improveperform', u'type improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg', u'type improveperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformanceperformancelarg decod', u'type improvewith', u'type improvewith appropri', u'typic', u'typic encod', u'typic encod consist', u'typic mani', u'typic mani differ', u'typic obtain', u'typic obtain withcrf', u'typic obtain withqual', u'typic patch', u'typic patch fed', u'typic pre-train', u'typic pre-train larg', u'typic random', u'typic random chosen', u'typic roadpedestrian', u'typic roadpedestrian understand', u'typic roadscen', u'typic roadscen major', u'typic set', u'typic set practic', u'u', u'u-net', u'u-net propos', u'u-net propos medicala', u'u-net propos medicalimag', u'u-net vgg', u'u-net vgg net', u'uk', u'uk hecurr', u'uk hecurr work', u'uk heinria', u'uk heinria renn', u'uk member', u'uk member machin', u'uk/projects/segnet/', u'uk/projects/segnet/ segnet', u'uk/projects/segnet/ segnet code', u'uk/projects/segnet/can', u'uk/projects/segnet/can trust', u'uk/projects/segnet/can trust semant', u'uk/projects/segnet/convolut', u'uk/projects/segnet/convolut layer', u'uk/projects/segnet/convolut layer model', u'uk/projects/segnet/ggcci/un/a68', u'uk/projects/segnet/http', u'uk/projects/segnet/http //mi', u'uk/projects/segnet/mi', u'uk/projects/segnet/tutori', u'uk:2', u'uk:2 leader', u'uk:2 leader board', u'uk:8080/leaderboard8080/leaderboard8080/leaderboard8080/leaderboardfigur', u'uk:8080/leaderboard8080/leaderboard8080/leaderboard8080/leaderboardfigur bayesian', u'uk:8080/leaderboard8080/leaderboard8080/leaderboard8080/leaderboardfigur bayesian segnet', u'uk:8080/leaderboardhost', u'uk:8080/leaderboardus', u'uk:8080/leaderboardus depth', u'uk:8080/leaderboardus depth modal', u'ukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl', u'ukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl rang', u'ukabstractabstractabstractabstractabstractabstractabstractabstractabstractappl rang estim', u'ukagk34', u'ukagk34 vb292', u'ukagk34 vb292 rc10001', u'uke-mail', u'uke-mail vb292', u'uke-mail vb292 agk34', u'ukinput', u'ukinput imagesinput', u'ukinput imagesinput imagesinput', u'ukpedestrian', u'ukpedestrian understand', u'ukpedestrian understand spatial-relationship', u'ukunivers', u'ukunivers cambridg', u'ukunivers cambridg ukunivers', u'ukunivers cambridg ukvb292', u'ukv', u'ukv badrinarayanan', u'ukv badrinarayanan kendal', u'ukvb292', u'ukvb292 ah781', u'ukvb292 ah781 cipolla', u'unabl', u'unabl toin', u'unabl toin term', u'unabl toprovid', u'unabl toprovid measur', u'unari', u'unari combin', u'unari combin extern', u'unari improv', u'unari improv result', u'unari noisi', u'unari noisi unari', u'unari noisysuch', u'unari noisysuch rgb-sift', u'unari noisyunari', u'unari noisyunari smooth', u'unari predict', u'unari predict unari', u'unari structur', u'unari structur class', u'unari term', u'unari term classifi', u'unari term classifiersar', u'unari term classifiersnoisi', u'unari thenclassifi', u'unari thenclassifi predict', u'unari thensmooth', u'unari thensmooth use', u'unari tri', u'unari tri predict', u'unari unaries+crf', u'unari unaries+crf shown', u'unaries+crf', u'unaries+crf shown', u'unaries+crf shown fig', u'uncertain', u'uncertain model', u'uncertain near', u'uncertain near border', u'uncertain object', u'uncertain object boundari', u'uncertain plot', u'uncertain plot relationshipbetween', u'uncertain plot relationshipth', u'uncertain predict', u'uncertainti', u'uncertainti abov', u'uncertainti abov 90thof', u'uncertainti abov 90thpercentil', u'uncertainti accuraci', u'uncertainti accuraci fig', u'uncertainti averag', u'uncertainti averag class', u'uncertainti averagedacross', u'uncertainti averagedacross class', u'uncertainti averagedtruth', u'uncertainti averagedtruth shown', u'uncertainti calcul', u'uncertainti calcul mean', u'uncertainti camera', u'uncertainti camera relocalis', u'uncertainti class', u'uncertainti class camvid', u'uncertainti classaccuraci', u'uncertainti classaccuraci class', u'uncertainti classvalu', u'uncertainti classvalu pixel', u'uncertainti deep', u'uncertainti deep convolut', u'uncertainti deep learn', u'uncertainti eachclass', u'uncertainti eachw', u'uncertainti eachw present', u'uncertainti effect', u'uncertainti effect measur', u'uncertainti effective0th', u'uncertainti effective0th percentil', u'uncertainti effectivemeasur', u'uncertainti effectivemeasur predict', u'uncertainti estim', u'uncertainti estim process', u'uncertainti frequenc', u'uncertainti frequenc atmodel', u'uncertainti frequenc atwhich', u'uncertainti ground', u'uncertainti ground truth', u'uncertainti improv', u'uncertainti improv segment', u'uncertainti isgener', u'uncertainti isgener veri', u'uncertainti ismodel', u'uncertainti ismodel predict', u'uncertainti known', u'uncertainti known asbayesian', u'uncertainti known asneur', u'uncertainti mont', u'uncertainti mont carlo', u'uncertainti natur', u'uncertainti natur ani', u'uncertainti output', u'uncertainti output1', u'uncertainti outputbayesian', u'uncertainti outputbayesian segnet', u'uncertainti predict', u'uncertainti predict fromdeep', u'uncertainti predict frominterest', u'uncertainti predomin', u'uncertainti predomin caus', u'uncertainti produc', u'uncertainti produc estim', u'uncertainti requir', u'uncertainti requir thehowev', u'uncertainti requir theweight', u'uncertainti respect', u'uncertainti respect otherclass', u'uncertainti respect othervehicl', u'uncertainti result', u'uncertainti result bayesian', u'uncertainti smaller', u'uncertainti smaller amountcop', u'uncertainti smaller amountof', u'uncertainti softmax', u'uncertainti softmax regress', u'uncertainti veri', u'uncertainti veri effect', u'uncertainti whenth', u'uncertainti whenth object', u'uncertainti whenth situat', u'uncertainty3', u'uncertainty5', u'uncertaintyal', u'uncertaintyal class', u'uncertaintyal class row', u'uncertaintyat', u'uncertaintyat object', u'uncertaintyat object boundari', u'uncertaintyfig', u'uncertaintylabel', u'uncertaintylabel overal', u'uncertaintylabel overal measur', u'uncertaintymodel', u'uncertaintymodel uncertaintymodel', u'uncertaintymodel uncertaintymodel uncertaintymodel', u'uncertaintymodel uncertaintymodel uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb', u'uncertaintymodel uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb', u'uncertaintymodel uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb imagergb', u'uncertaintyqualit', u'uncertaintyqualit observ', u'uncertaintyvalu', u'uncertaintyvalu pixel', u'uncertaintyvalu pixel class', u'uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb', u'uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb imagergb', u'uncertaintyvariancevariancevariancevariancevariancevariancevariancevariancevariancergb imagergb imagergb', u'underit', u'underit difficult', u'underit difficult gather', u'understand', u'understand addit', u'understand addit train', u'understand animag', u'understand animag pixel', u'understand ansemant', u'understand ansemant segment', u'understand applic', u'understand applic henc', u'understand applic requiremotiv', u'understand applic requireth', u'understand ar', u'understand arreal-tim', u'understand arreal-tim applic', u'understand arthi', u'understand arthi primari', u'understand arxiv', u'understand arxiv preprint', u'understand benchmark', u'understand benchmark describ', u'understand benchmark suit', u'understand bmvc', u'understand bmvc 7d', u'understand bmvc 7scene', u'understand causesquantit', u'understand causesquantit observ', u'understand causesth', u'understand causesth model', u'understand dataset', u'understand dataset 367camvid', u'understand dataset 367train', u'understand dataset applic', u'understand dataset camvid', u'understand effect', u'understand effect featur', u'understand effici', u'understand effici term', u'understand end-to-end', u'understand end-to-end learn', u'understand infer', u'understand infer differ', u'understand infer support-relationship', u'understand meaning', u'understand meaning measur', u'understand model', u'understand model uncertainti', u'understand model uncertainty5', u'understand model uncertaintyqualit', u'understand multi-class', u'understand multi-class object', u'understand offor', u'understand offor futur', u'understand ofsegment', u'understand ofsegment architectur', u'understand outdoor', u'understand outdoor camvid', u'understand perform', u'understand quantit', u'understand quantit differ', u'understand result', u'understand result fig', u'understand spatial-relationship', u'understand spatial-relationship context', u'understand sun', u'understand sun sun', u'understand test', u'understand test per-pixelnoisi', u'understand test per-pixelth', u'understand use', u'understand use lowlevel', u'understand use lowprevi', u'understanddeep', u'understanddeep architectur', u'understanddeep architectur segment', u'understandingalex', u'understandingalex kendallalex', u'understandingalex kendallalex kendallalex', u'understandingarchitectur', u'understandingarchitectur scene', u'understandingarchitectur scene understandingalex', u'understandingarchitectur scene understandingarchitectur', u'understandingsegment', u'understandingsegment challeng', u'understandingsegment challeng pascal', u'understandingsuch', u'understandingsuch road', u'understandingsuch road scene', u'understandth', u'understandth perform', u'understandth perform architectur', u'undertim', u'undertim memori', u'undertim memori constraint', u'unfortun', u'unfortun difficult', u'unfortun difficult fromchalleng', u'unfortun difficult fromtheir', u'unfortunatelydo', u'unfortunatelydo reveal', u'unfortunatelydo reveal true', u'unfortunatelyvalu', u'unfortunatelyvalu increas', u'unfortunatelyvalu increas perform', u'union', u'union i/u', u'union miou', u'union miou acomparison', u'union miou asemant', u'union miou class', u'unit', u'unit befor', u'unit befor classifi', u'unit contain', u'unit contain convolut', u'unit containsfollow', u'unit containsfollow max', u'unit containson', u'unit containson convolut', u'unit featur', u'unit featur activ', u'unit l2', u'unit l2 norm', u'unit l2 normth', u'unit l2 normw', u'unit network', u'unit result', u'unit result lower', u'unit test', u'unit test time', u'unit varianc', u'unit varianc gaussian', u'unitseveri', u'unitseveri k', u'unitseveri k k', u'unitsfind', u'unitsfind drop', u'unitsfind drop half', u'unitsi', u'unitsi optim', u'unitsi optim configur', u'unitsj', u'unitsj defin', u'unitsj defin j', u'univers', u'univers auckland', u'univers auckland new', u'univers cambridg', u'univers cambridg lectur', u'univers cambridg u', u'univers cambridg uk', u'univers cambridg uke-mail', u'univers cambridg ukunivers', u'univers cambridg ukv', u'univers cambridgein', u'univers cambridgein m', u'univers cambridgein mse', u'univers cambridgeroberto', u'univers cambridgeroberto cipolla', u'univers ofd', u'univers ofdphil', u'univers ofdphil comput', u'univers ofoxford', u'univers ofoxford toshibaoxford', u'univers pennsylvania', u'univers pennsylvania ad', u'univers pennsylvania adphil', u'univers pennsylvania ath', u'university2014', u'university2014 award', u'university2014 award woolf', u'universityof', u'universityof cambridg', u'universityof cambridg u', u'universityof cambridg uk', u'unixcommand', u'unixcommand comput', u'unixcommand comput memori', u'unixcomput', u'unixcomput time', u'unixcomput time requir', u'unknown', u'unknown class', u'unknown class blacken', u'unknown class blackenedfigur', u'unknown class blackenedon', u'unlik', u'unlik deconvolut', u'unlik deconvolut network', u'unlik expand', u'unlik expand deep', u'unlik fcn-basic', u'unlik fcn-basic final', u'unlik otherdecod', u'unlik otherdecod network', u'unlik otherit', u'unlik otherit encod', u'unlik segment', u'unlik segment scene', u'unlik unsupervis', u'unlik unsupervis featur', u'unlikeor', u'unlikeor rgbd', u'unlikeor rgbd fig', u'unlikepatch', u'unlikepatch base', u'unlikepatch base classifi', u'unlikepixel', u'unlikepixel label', u'unlikepixel label result', u'unliketh', u'unliketh decod', u'unliketh decod produc', u'unoptim', u'unoptim test', u'unoptim test time360', u'unoptim test timei', u'unseen', u'unseen imag', u'unseen imag itabsorb', u'unseen imag italso', u'unsupervis', u'unsupervis featur', u'unsupervis featur learn', u'unsupervis featur learningarchitectur', u'unsupervis featur learningour', u'unsupervis featur train', u'unsupervis imagematch', u'unsupervis imagematch score', u'unsupervis imagesegment', u'unsupervis imagesegment qualiti', u'unsupervis learn', u'unsupervis learn featur', u'unsupervis pre-train', u'unsupervis pre-train featur', u'unthin', u'unthin network', u'unti', u'untiedmod', u'untiedmod rgb', u'untiedmod rgb contrast', u'untiedsoft-max', u'untiedsoft-max weight', u'untiedsoft-max weight fix', u'untilad', u'untilad exist', u'untilad exist train', u'untilno', u'untilno increas', u'untilno increas perform', u'updat', u'updat techniqu', u'updat techniqu stochast', u'upsampl', u'upsampl architectur', u'upsampl architectur ranzato', u'upsampl base', u'upsampl base approach', u'upsampl bilinear', u'upsampl bilinear initialis', u'upsampl bilinear-interpol', u'upsampl bilinear-interpol otherextrem', u'upsampl bilinear-interpol otherlearn', u'upsampl convolv', u'upsampl convolv train', u'upsampl decod', u'upsampl decod network', u'upsampl decod use', u'upsampl deconvnet', u'upsampl deconvnet isi', u'upsampl deconvnet isth', u'upsampl deepest', u'upsampl deepest layer', u'upsampl elimin', u'upsampl elimin need', u'upsampl fcn-basic', u'upsampl fcn-basic variant', u'upsampl featur', u'upsampl featur e', u'upsampl featur map', u'upsampl featur replic', u'upsampl featuremap', u'upsampl featuremap fcn', u'upsampl featuremap use', u'upsampl featurepass', u'upsampl featurepass decod', u'upsampl featureupsampl', u'upsampl featureupsampl densifi', u'upsampl fromand', u'upsampl fromand depth', u'upsampl fromlow', u'upsampl fromlow resolut', u'upsampl incorpor', u'upsampl incorpor ani', u'upsampl input', u'upsampl input featur', u'upsampl input use', u'upsampl input usingal', u'upsampl input usingth', u'upsampl itsfig', u'upsampl itsfig illustr', u'upsampl itsinput', u'upsampl itsinput use', u'upsampl kernel', u'upsampl kernel fcn-basic-noaddit', u'upsampl kernel initializedoutput', u'upsampl kernel initializedus', u'upsampl kernel set', u'upsampl layer', u'upsampl layer segnet', u'upsampl learn', u'upsampl learn deconvolveth', u'upsampl learn deconvolveto', u'upsampl learn featur', u'upsampl learn upsampl', u'upsampl low', u'upsampl low resolutiondiscuss', u'upsampl low resolutionfeatur', u'upsampl lower', u'upsampl lower resolut', u'upsampl map', u'upsampl map convolvedupsampl', u'upsampl map convolvedwith', u'upsampl map spars', u'upsampl map use', u'upsampl ofth', u'upsampl ofth correspond', u'upsampl oftheir', u'upsampl oftheir input', u'upsampl overal', u'upsampl overal largerdecod', u'upsampl overal largerus', u'upsampl perform', u'upsampl perform invers', u'upsampl perform quitepoor', u'upsampl perform quitespars', u'upsampl reduc', u'upsampl reduc spatial', u'upsampl replic', u'upsampl replic use', u'upsampl segnet-bas', u'upsampl segnet-bas variant', u'upsampl term', u'upsampl term asdeconvolut', u'upsampl term askernel', u'upsampl upsampl', u'upsampl upsampl map', u'upsampl usingfix', u'upsampl usingfix bilinear', u'upsampl usingin', u'upsampl usingin addit', u'upsampledmax-pool', u'upsampledmax-pool block', u'upsampledmax-pool block u-net', u'upsampledth', u'upsampledth correspond', u'upsampledth correspond decod', u'upsamplesit', u'upsamplesit input', u'upsamplesit input featur', u'upsamplesth', u'upsamplesth appropri', u'upsamplesth appropri decod', u'upsamplingar', u'upsamplingar use', u'upsamplingar use follow', u'upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation0', u'upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242', u'upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242 599upsampl', u'upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242 599upsampl use', u'upsamplingcr', u'upsamplingcr memori', u'upsamplingcr memori intens', u'upsamplingdecod', u'upsamplingdecod pool', u'upsamplingdecod pool upsamplingdecod', u'upsamplingdecod pool upsamplingff11i', u'upsamplingencod', u'upsamplingencod featur', u'upsamplingencod featur mapencod', u'upsamplingff11i', u'upsamplingff11i ntroductioni', u'upsamplingff11i ntroductioni ntroductioni', u'upsamplingfix', u'upsamplingfix upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation0', u'upsamplingfix upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242', u'upsamplingfix upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242 599upsampl', u'upsamplingfix upsamplingfix', u'upsamplingfix upsamplingfix upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation0', u'upsamplingfix upsamplingfix upsamplingbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolationbilinear-interpolation06250625062506250625062500242', u'upsamplingfix upsamplingfix upsamplingfix', u'upsamplingfor', u'upsamplingfor upsamplingencod', u'upsamplingfor upsamplingencod featur', u'upsamplingfor upsamplingfor', u'upsamplingfor upsamplingfor upsamplingencod', u'upsamplingfor upsamplingfor upsamplingfor', u'urban', u'urban highwayimag', u'urban highwayimag internet', u'urban highwaypract', u'urban highwaypract applic', u'urban scene', u'urban scene understand', u'urban scene use', u'usag', u'usag andavoid', u'usag andavoid gpu-cpu', u'usag andw', u'usag andw use', u'use', u'use accur', u'use accur boundari', u'use achiev', u'use achiev translat', u'use acombin', u'use acombin popular', u'use addit', u'use addit cue', u'use addit infer', u'use addit train', u'use additionalcu', u'use additionalcu depth', u'use additionalstate-of-the-art', u'use additionalstate-of-the-art perform', u'use aforest', u'use aforest anoth', u'use alreadi', u'use alreadi store', u'use ani', u'use ani crf', u'use anyclass', u'use anyclass blanc', u'use anycompar', u'use anycompar experi', u'use approach', u'use approach decod', u'use approach reveal', u'use approxim', u'use approxim infer', u'use atfergus', u'use attest', u'use attest time', u'use batch', u'use batch normal', u'use batch normalis', u'use benchmark', u'use benchmark compar', u'use benchmark farabet', u'use benchmark howev', u'use better', u'use better accuraci', u'use better accuracyclass', u'use better accuracyth', u'use bilinear', u'use bilinear interpol', u'use bit', u'use bit 2for', u'use bit 2pool', u'use bit pool', u'use buildgen', u'use buildgen model', u'use buildw', u'use buildw draw', u'use caff', u'use caff implement', u'use caff implementationof', u'use caff library0', u'use caff libraryw', u'use camvid', u'use camvid data', u'use camvid road', u'use class', u'use class balanc', u'use class informationfeatur', u'use class informationrath', u'use classifierfocuss', u'use classifierfocuss real-tim', u'use classifiergroup', u'use classifiergroup befor', u'use classifiersegment', u'use classifiersegment random', u'use classifierth', u'use classifierth common', u'use combin', u'use combin popular', u'use combin rgb', u'use common', u'use common use', u'use compar', u'use compar method', u'use complement', u'use complement theireffort', u'use complement theireffortseffortseffortseffortseffortseffortseffortseffortseffortsth', u'use complement theirour', u'use conjunct', u'use conjunct miou', u'use convolut', u'use convolut relu', u'use convolution-relu-max', u'use convolution-relu-max pooling-subsampl', u'use crf', u'use crf base', u'use crf dueperceiv', u'use crf dueto', u'use crf improv', u'use crfmodel', u'use crfmodel various', u'use crfor', u'use crfor modal', u'use cross-entropi', u'use cross-entropi loss', u'use cudnn', u'use cudnn acceler', u'use decod', u'use decod networkindic', u'use decod networkto', u'use decod stack', u'use decod stackunderstand', u'use decod stackw', u'use decod toobtain', u'use decod tosegment', u'use decod unlik', u'use decodersfcn', u'use decodersfcn decod', u'use decoderson', u'use decoderson left', u'use deconvolut', u'use deconvolut network', u'use deconvolut networkback', u'use deconvolut networkth', u'use deep', u'use deep encoder-decod', u'use deep encoder-decoderapproach', u'use deep encoder-decodernetwork', u'use deep learn', u'use deep network', u'use deeper', u'use deeper layer', u'use dens', u'use dens depth', u'use depth', u'use depth channel', u'use depth imagesand', u'use depth imagesfrom', u'use depth modal', u'use depth video', u'use detect', u'use detect shown', u'use dimension', u'use dimension reduct', u'use dimensionalityfcn-bas', u'use dimensionalityfcn-bas resolut', u'use dimensionalityreduct', u'use dimensionalityreduct featur', u'use dropout', u'use dropout encod', u'use dropout sampl', u'use dropout test', u'use dropout way', u'use dropoutto', u'use dropoutto obtain', u'use dropoutw', u'use dropoutw train', u'use dusk', u'use dusk scenario', u'use encod', u'use encod featur', u'use evalu', u'use evalu unsupervis', u'use experi', u'use experi complex', u'use experimentsa', u'use experimentsa layer', u'use experimentsi', u'use experimentsi illustr', u'use featur', u'use featur extract', u'use featur input', u'use featur map', u'use featur rgb-sift', u'use featur segnet', u'use featuremap', u'use featuremap classif', u'use featureperform', u'use featureperform improv', u'use featuresdataset', u'use featuresdataset use', u'use featuressuch', u'use featuressuch rgb-sift', u'use fix', u'use fix andconvolut', u'use fix andsimpli', u'use follow', u'use follow convolut', u'use forbank', u'use forbank reconstruct', u'use form', u'use form probabilist', u'use formula', u'use formula propos', u'use forunsupervis', u'use forunsupervis pre-train', u'use fulli', u'use fulli convolut', u'use fullyconvolut', u'use fullyconvolut network', u'use fullyof', u'use fullyof segnet', u'use fusion', u'use fusion mani', u'use global', u'use global g', u'use hand', u'use hand engineeredattribut', u'use hand engineeredfeatur', u'use increas', u'use increas inferenceinfer', u'use increas inferencetim', u'use infer', u'use infer scene', u'use inform', u'use inform inencod', u'use input', u'use input classif', u'use input nvidia', u'use input post-process', u'use inputcomput', u'use inputcomput camvid', u'use inputfor', u'use inputfor classif', u'use invers', u'use invers frequencyor', u'use invers frequencyweight', u'use kitti', u'use kitti train', u'use l-bfgs', u'use l-bfgs particular', u'use largerdecod', u'use largerdecod import', u'use largersam', u'use largersam number', u'use layer', u'use layer network', u'use local', u'use local bright', u'use lowlevel', u'use lowlevel visual', u'use lowprevi', u'use lowprevi approach', u'use max', u'use max pool', u'use max-pool', u'use max-pool indic', u'use max-pool indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic1', u'use max-pool indicessegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basicsegnet-basic14251425142514251425142511526', u'use max-pool indicesupsampl', u'use maxim', u'use maxim throughput', u'use maxloc', u'use maxloc encod', u'use maxpool', u'use maxpool indic', u'use maxsemi-supervis', u'use maxsemi-supervis variant', u'use median', u'use median frequenc', u'use memor', u'use memor max-pool', u'use memor pool', u'use memori', u'use memori duringaccuraci', u'use memori duringinfer', u'use minfunc', u'use minfunc optim', u'use mini-batch', u'use mini-batch maxim', u'use mini-batch size', u'use mont', u'use mont carlo', u'use motion', u'use motion depth', u'use motion structur', u'use multi-scal', u'use multi-scal deep', u'use multi-stagetoward', u'use multi-stagetoward attain', u'use multi-stagetrain', u'use multi-stagetrain dataset', u'use natur', u'use natur frequenc', u'use need', u'use need achiev', u'use nvidia-smi', u'use nvidia-smi unixcommand', u'use nvidia-smi unixcomput', u'use onli', u'use onli onc', u'use onli rgbaverag', u'use onli rgbinput', u'use outdoor', u'use outdoor rgb', u'use pair-wis', u'use pair-wis higher', u'use paper', u'use paper howev', u'use pascal', u'use pascal voc12', u'use per-pixel', u'use per-pixel independ', u'use perform', u'use perform measur', u'use pool', u'use pool indic', u'use pre-train', u'use pre-train convolut', u'use pre-train encod', u'use pre-train segnet', u'use predict', u'use predict areground', u'use predict arelarg', u'use propos', u'use propos segnet', u'use random', u'use random forest', u'use randomalso', u'use randomalso use', u'use randomforest', u'use randomforest anoth', u'use recurr', u'use recurr neural', u'use recurrentclassif', u'use recurrentclassif blocki', u'use recurrentneur', u'use recurrentneur network', u'use region', u'use region propos', u'use relev', u'use relev trainingset', u'use relev trainingwhich', u'use remain', u'use remain set', u'use remov', u'use remov needfor', u'use remov needweight', u'use rgb', u'use rgb input', u'use rgb modal', u'use richer', u'use richer featur', u'use richerfeatur', u'use richerfeatur set', u'use richersmooth', u'use richersmooth use', u'use samein', u'use samein order', u'use samesgd', u'use samesgd solver', u'use segmentdecor', u'use segmentdecor object', u'use segmentof', u'use segmentof segnet', u'use segnet-bas', u'use segnet-bas smaller', u'use segneton', u'use segneton left', u'use segnetupsampl', u'use segnetupsampl step', u'use semant', u'use semant cue', u'use sgd', u'use sgd optim', u'use shallow', u'use shallow layer', u'use small', u'use small inputfor', u'use small inputmain', u'use small inputpatch', u'use smaller', u'use smaller layer', u'use smaller nyudataset', u'use smaller nyuparamet', u'use smaller version', u'use stage-wis', u'use stage-wis traininga', u'use stage-wis trainingprocess', u'use stochast', u'use stochast gradient', u'use store', u'use store pool', u'use structur', u'use structur motion', u'use structur motionbas', u'use structur motionoth', u'use support', u'use support aid', u'use test', u'use test size', u'use test time', u'use thecompress', u'use thecompress encod', u'use thecorrespond', u'use thecorrespond decod', u'use thetechniqu', u'use thetechniqu describ', u'use theth', u'use theth encod', u'use this2', u'use this2 stride', u'use thisdataset', u'use thisdataset analys', u'use thissmal', u'use thissmal size', u'use thisto', u'use thisto make', u'use time', u'use time result', u'use toa', u'use toa comparison', u'use tocomput', u'use tocomput time', u'use toof', u'use toof model', u'use tothi', u'use tothi differ', u'use totrain', u'use totrain fcn-8', u'use tounderstand', u'use tounderstand confid', u'use trainabl', u'use trainabl decod', u'use trainingal', u'use trainingal encoder-decod', u'use trainingnot', u'use trainingnot attempt', u'use trainobtain', u'use trainobtain combin', u'use trainsegnet', u'use trainsegnet correspond', u'use transfer', u'use transfer pool', u'use unsupervis', u'use unsupervis pre-train', u'use upsampl', u'use upsampl deepest', u'use valu', u'use valu of0', u'use valu of075', u'use valu ofboundari', u'use varianc', u'use varianc output', u'use variat', u'use variat infer', u'use variat ratio', u'use visual', u'use visual theeffect', u'use visual theth', u'use visual train', u'use weight', u'use weight unthin', u'use \\xd7implement', u'use \\xd7implement averag', u'use \\u201cflat\\u201d', u'use \\u201cflat\\u201d architectur', u'usear', u'usear abl', u'usear abl benchmark', u'usecompetit', u'usecompetit result', u'usecompetit result compar', u'usecrf', u'usecrf abil', u'usecrf abil deep', u'usecrf segnet', u'usecrf segnet maintain', u'usedaft', u'usedaft convolut', u'usedaft convolut layer', u'usedfor', u'usedfor indoor', u'usedfor indoor rgbd', u'usedfor upsampl', u'usedfor upsampl architectur', u'usedi', u'usedi competit', u'usedi competit tempor', u'usednetwork', u'usednetwork object', u'usednetwork object classif', u'usedreduct', u'usedreduct max-pool', u'usedreduct max-pool indic', u'usedth', u'usedth receiv', u'usedth receiv max-pool', u'usedwith', u'usedwith appropri', u'usedwith appropri decod', u'usemot', u'usemot structur', u'usemot structur video', u'useof', u'useof hand', u'useof hand engin', u'user', u'user perspect', u'user perspect improvementsin', u'user perspect improvementsthi', u'useregion', u'useregion propos', u'useregion propos bootstrap', u'usesad', u'usesad hoc', u'usesad hoc featur', u'usesegment', u'usesegment engin', u'usesegment engin architectur', u'usesi', u'usesi therefor', u'usesi therefor use', u'usesmooth', u'usesmooth layer', u'usesmooth layer ad', u'useth', u'useth common', u'useth common attribut', u'usinga', u'usinga fix', u'usinga fix trainabl', u'usingaddit', u'usingaddit train', u'usingaddit train data', u'usingaddress', u'usingaddress imbal', u'usingaddress imbal label', u'usingal', u'usingal encod', u'usingal encod segnet-bas', u'usingan', u'usingan effici', u'usingan effici weight', u'usingand', u'usingand agre', u'usingand agre analysi', u'usingcomput', u'usingcomput layer', u'usingcomput layer usingcomput', u'usingcomput layer usingth', u'usingfix', u'usingfix bilinear', u'usingfix bilinear interpol', u'usingfor', u'usingfor segment', u'usingfor segment want', u'usingin', u'usingin addit', u'usingin addit abov', u'usingin order', u'usingin order joint', u'usingmodel', u'usingmodel paramet', u'usingnetwork', u'usingnetwork upsampl', u'usingnetwork upsampl perform', u'usingperform', u'usingperform deep', u'usingperform deep learn', u'usingstochast', u'usingstochast gradient', u'usingstochast gradient descent', u'usingth', u'usingth bayesian', u'usingth bayesian approach', u'usingth entir', u'usingth entir train', u'usingth grid', u'usingth grid search', u'usingth receiv', u'usingth receiv max-pool', u'usingth weight', u'usingth weight averag', u'usual', u'usual case', u'usual case practicalappl', u'usual case practicali', u'utilis', u'utilis depth', u'utilis depth video', u'utilis depthand', u'utilis depthand motion', u'utilis depthbenchmark', u'v', u'v badrinarayanan', u'v badrinarayanan kendal', u'v vanhouck', u'v vanhouck rabinovich', u'v vanhouck rabinovichd', u'v vanhouck rabinovichgo', u'v vineet', u'v vineet z', u'v2', u'v2 segnet', u'v2 segnet perform', u'v3', u'v3 acceler', u'v3 acceleration480', u'v3 acceleration480 input', u'v3 accelerationw', u'v3 accelerationw note', u'valid', u'valid dataset', u'valid datasetw', u'valid datasetw use', u'valid datasetwhich', u'valid datasetwhich perform', u'valid set', u'valid set includ', u'valid set reportal', u'valid set reporti', u'valid set train', u'valid set wasavail', u'valid set wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun', u'valid set wasprocess', u'valu', u'valu andiniti', u'valu andiniti paramet', u'valu andtrain', u'valu andtrain onli', u'valu camvid', u'valu camvid train', u'valu close', u'valu close class', u'valu e', u'valu featur', u'valu featur map', u'valu given', u'valu given layer', u'valu map', u'valu map \\u2200j', u'valu model', u'valu model uncertainti', u'valu of0', u'valu of075', u'valu of075 imag', u'valu ofboundari', u'valu ofboundari given', u'valu pixelfeatur', u'valu pixelfeatur map', u'valu pixeli\\u2208i', u'valu pixeli\\u2208i j', u'valu poolingi', u'valu poolingi locat', u'valu poolingwindow', u'valu poolingwindow memor', u'valu predict', u'valu predict ground', u'valu train', u'valu train onli', u'valuabl', u'valuabl row', u'valuabl row segnet', u'vanhouck', u'vanhouck rabinovich', u'vanhouck rabinovich \\u201cgo', u'vanhouck rabinovichd', u'vanhouck rabinovichd anguelov', u'vanhouck rabinovichgo', u'vanhouck rabinovichgo deeper', u'vari', u'vari background', u'vari background implicitlyclass', u'vari background implicitlyfavour', u'vari form', u'vari form decoderencod', u'vari form decodernetwork', u'vari indoor', u'vari indoor scene', u'vari input', u'vari input resolut', u'vari lot', u'vari lot regularityin', u'vari lot regularitysinc', u'vari ob-input', u'vari ob-input layer', u'vari ob-ject', u'vari ob-ject layer', u'vari parameter', u'vari parameter thediffer', u'vari parameter themann', u'vari thesear', u'vari thesear typic', u'vari thesearchitectur', u'vari thesearchitectur respons', u'vari train', u'vari train phase', u'vari withtrain', u'vari withtrain time', u'variabl', u'variabl indoor', u'variabl indoor scene', u'variabl view', u'variabl view point', u'variablesand', u'variablesand variat', u'variablesand variat paramet', u'variableswith', u'variableswith bi', u'variableswith bi vector', u'varianc', u'varianc gaussian', u'varianc gaussian n', u'varianc output', u'varianc output modelto', u'varianc output modeluncertainti', u'varianc softmax', u'varianc softmax sampl', u'variant', u'variant 32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw', u'variant 32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw use', u'variant arenot', u'variant arenot optimis', u'variant arew', u'variant arew note', u'variant class', u'variant class balanc', u'variant dataset', u'variant dataset small', u'variant decod', u'variant decod filter', u'variant decoupl', u'variant decoupl network', u'variant differ', u'variant differ configur', u'variant explainbf', u'variant explainbf measur', u'variant explainth', u'variant explainth reason', u'variant fcn-basicmodel', u'variant fcn-basicmodel discard', u'variant fcn-basicpool', u'variant fcn-basicpool window', u'variant featur', u'variant featur map', u'variant follow', u'variant follow convolut', u'variant follow encod', u'variant high', u'variant high bfbest', u'variant high bfscore', u'variant hold', u'variant hold true', u'variant import', u'variant import achiev', u'variant insert', u'variant insert dropout', u'variant iter', u'variant iter ofoptim', u'variant iter ofw', u'variant kitti', u'variant kitti dataset', u'variant learningdecod', u'variant learningdecod filter', u'variant learningus', u'variant learningus learn', u'variant oneth', u'variant oneth number', u'variant onewher', u'variant onewher decod', u'variant particular', u'variant particular class', u'variant particular discardingboth', u'variant particular discardingdimension', u'variant perform', u'variant perform signific', u'variant poorer', u'variant poorer thansegnet-bas', u'variant poorer thanth', u'variant produc', u'variant produc similar', u'variant quantifi', u'variant quantifi perform', u'variant reveal', u'variant reveal practic', u'variant segnet', u'variant segnet segnet-basicencoderaddit', u'variant segnet-bas', u'variant segnet-bas thecamvid', u'variant segnet-bas thetabl', u'variant segnetbasic-singlechanneldecod', u'variant segnetbasic-singlechanneldecod reduc', u'variant selectedfor', u'variant selectedfor test', u'variant selectediter', u'variant selectediter result', u'variant studi', u'variant studi upsampl', u'variant termedsegnet-bas', u'variant termedsegnet-bas base', u'variant termedw', u'variant termedw segnet', u'variant thearchitectur', u'variant thearchitectur test', u'variant thecamvid', u'variant thecamvid dataset', u'variant train', u'variant train loss2', u'variant train lossof', u'variant use', u'variant use common', u'variant use smaller', u'variant variant', u'variant variant 32323232trainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingtrainingw', u'variant variant variant', u'variant variant withoutmax-pool', u'variant variant withoutpoor', u'variant wetechniqu', u'variant wetechniqu describ', u'variant weus', u'variant weus stochast', u'variant withoutmax-pool', u'variant withoutmax-pool sub-sampl', u'variant withoutpoor', u'variant withoutpoor comparison', u'variantanoth', u'variantanoth memori', u'variantanoth memori intens', u'variantimpli', u'variantimpli unlik', u'variantimpli unlik fcn-basic', u'variants4', u'variantsa', u'variantsa fulli', u'variantsa fulli bayesian', u'variantsdecod', u'variantsdecod variantsdecod', u'variantsdecod variantsdecod variantsdecod', u'variantsdecod variantsdecod variantsmani', u'variantsdecod variantsmani', u'variantsdecod variantsmani segment', u'variantsfcn-bas', u'variantsfcn-bas compar', u'variantsfcn-bas compar version', u'variantsggc', u'variantsggc i/uc', u'variantsggc i/uc i/uc', u'variantsless', u'variantsless effici', u'variantsless effici model', u'variantsmani', u'variantsmani segment', u'variantsmani segment architectur', u'variantsprobabilist', u'variantsprobabilist variantsggc', u'variantsprobabilist variantsggc i/uc', u'variantsprobabilist variantsprobabilist', u'variantsprobabilist variantsprobabilist variantsggc', u'variantsprobabilist variantsprobabilist variantsprobabilist', u'variantss', u'variantss segnet-bas', u'variantss segnet-bas allow', u'variantsw', u'variantsw summar', u'variantsw summar abov', u'variat', u'variat distribut', u'variat distribut q', u'variat infer', u'variat infer approxim', u'variat inferenceghahramani', u'variat inferenceghahramani link', u'variat inferencein', u'variat inferencein bayesian', u'variat number', u'variat number ofin', u'variat number ofpixel', u'variat paramet', u'variat paramet mi', u'variat ratio', u'variat ratio asa', u'variat ratio asvari', u'variat term', u'variat term theclass', u'variat term theroad', u'varieti', u'varieti scene', u'varieti scene segmentationbayesian', u'varieti scene segmentationtask', u'varieti scene view-point', u'various', u'various autonom', u'various autonom drive', u'various deep', u'various deep architectur', u'various deep segmentationarchitectur', u'various deep segmentationth', u'various order', u'various order main', u'various resolut', u'various resolut task', u'various shape', u'various shape size', u'various unari', u'various unari predict', u'varyimag', u'varyimag pixel', u'varyimag pixel level', u'varyingarrang', u'varyingarrang anoth', u'varyingarrang anoth difficulti', u'varyings', u'varyings object', u'varyings object class', u'varysignific', u'varysignific pose', u'varysignific pose appear', u'vb292', u'vb292 agk34', u'vb292 agk34 cipolla', u'vb292 rc10001', u'vb292 rc10001 cam', u'vector', u'vector bernoulli', u'vector bernoulli distribut', u'vectorfor', u'vectorfor train', u'vectorfor train sampl', u'vectorth', u'vectorth camvid', u'vectorth camvid train', u'vehicl', u'vehicl camera', u'vehicl camera posit', u'veri', u'veri challeng', u'veri challeng label', u'veri challeng larg', u'veri competit', u'veri competit evenfor', u'veri competit evenwithout', u'veri difficult', u'veri difficult requir', u'veri effect', u'veri effect whenmeasur', u'veri effect whenmodel', u'veri encourag', u'veri encourag notbeen', u'veri encourag notcategoris', u'veri expens', u'veri expens increas', u'veri high', u'veri high levelsof', u'veri high levelsvari', u'veri long', u'veri long time', u'veri noisi', u'veri noisi scene', u'veri reason', u'veri reason predict', u'veri reason predictionsher', u'veri reason predictionspart', u'veri slowli', u'verifi', u'verifi hypothesi', u'verifi hypothesis55d', u'verifi hypothesis55d iscuss', u'verifi hypothesisdataset', u'verifi hypothesisdataset need', u'version', u'version fcn', u'version fcn analysi', u'version indoor', u'version indoor rgbd', u'version largest', u'version largest benchmark', u'version paper1', u'version paper1 segnet-bas', u'version papershar', u'version papershar encod', u'version segnet', u'version segnet fcn', u'version segnet term', u'version submit', u'version submit cvpr', u'version theirfigur', u'version theirfigur row', u'version theirground', u'version theirground truth', u'versus', u'versus accuraci', u'versus accuraci architectur', u'versus infer', u'versus infer time', u'versus solver', u'versus solver optim', u'versusaccuraci', u'versusaccuraci trade-off', u'versusaccuraci trade-off involv', u'versusand', u'versusand known', u'versusand known deeplab-largefov', u'vgg', u'vgg architectur', u'vgg architectur larg', u'vgg net', u'vgg net architectur', u'vgg net pre-train', u'vgg-16', u'vgg-16 network', u'vgg-16 network consist', u'vgg-16 network follow', u'vgg-16 networkat', u'vgg-16 networkat test', u'vgg-16 networkend-to-end', u'vgg-16 networkend-to-end step', u'vgg16', u'vgg16 classif', u'vgg16 classif network', u'vgg16 differ', u'vgg16 differ formident', u'vgg16 differ formof', u'vgg16 encod', u'vgg16 encod networkdiscard', u'vgg16 encod networkwhich', u'vgg16 make', u'vgg16 make segnet', u'vgg16 network', u'vgg16 network design', u'vgg16 remov', u'vgg16 remov fullyconnect', u'vgg16 remov fullyth', u'vice-versa', u'vice-versa31', u'vice-versa31 train', u'vice-versa31 train segnet31', u'vice-versaedg', u'vice-versaedg vice-versa31', u'vice-versaedg vice-versa31 train', u'vice-versaedg vice-versaedg', u'vice-versaedg vice-versaedg vice-versa31', u'vice-versaedg vice-versaedg vice-versaedg', u'video', u'video and/or', u'video and/or crf', u'video base', u'video base percept', u'video data', u'video data improv', u'video frame', u'video frame post-process', u'video havealso', u'video havealso use', u'video havedens', u'video havedens depth', u'video high-definit', u'video high-definit ground', u'video segment', u'video segment combin', u'video segment dataset', u'video segment motion', u'video segment use', u'video sequenc', u'video sequenc thisen', u'video sequenc thisus', u'video sequenc wear', u'video sequenc wecategori', u'video use', u'video use inputcomput', u'video use inputfor', u'view', u'view alsomak', u'view alsomak difficult', u'view alsotim', u'view alsotim signific', u'view ca', u'view ca research', u'view fig', u'view learn', u'view learn magic', u'view point', u'view point particular', u'view point thismak', u'view point thisparallel', u'view point vari', u'view supplementari', u'view supplementari materi', u'view supplementari material5', u'view supplementari materialcan', u'view-point', u'view-point overal', u'view-point overal rhechalleng', u'view-point overal rhesegment', u'viewedevalu', u'viewedevalu subset', u'viewedin', u'viewedin fig', u'viewpoint', u'viewpoint feel', u'viewpoint feel attent', u'vijay', u'vijay badrinarayanan', u'vijay badrinarayanan alex', u'vijay badrinarayanan obtain', u'vineet', u'vineet z', u'vineet z su', u'vision', u'vision 2014for', u'vision 2014for scene', u'vision 2014on', u'vision 2014on deep', u'vision 3cvpr', u'vision 3cvpr page', u'vision 3in', u'vision 3in cvpr', u'vision benchmark', u'vision benchmark suit', u'vision challeng', u'vision challeng pascal', u'vision cue', u'vision cue fast', u'vision iccv', u'vision iccv ieee', u'vision ijcv', u'vision ijcv pp', u'vision pattern', u'vision pattern recognit', u'vision pattern recognition22label', u'vision pattern recognitionand', u'vision pattern recognitionin', u'vision pattern recognitionsegment', u'vision pp', u'vision pp 2015comput', u'vision pp 2015intern', u'vision pp 2015label', u'vision pp 2015w', u'vision robot', u'vision robot he2010', u'vision robot heha', u'vision univers', u'vision univers ofd', u'vision univers ofdphil', u'vision univers ofoxford', u'vision vol', u'vision vol pp', u'vision vol zisserman', u'vision-bas', u'vision-bas offline-onlin', u'vision-bas offline-onlin perceptionvision-bas', u'vision\\u2013dens', u'vision\\u2013dens correspond', u'vision\\u2013dens correspond differ', u'vision\\u2013eccv', u'vision\\u2013eccv page', u'vision\\u2013eccv pp', u'vision\\u2013eccv pp springer', u'visual', u'visual ambigu', u'visual ambigu model', u'visual ambigu object', u'visual difficult', u'visual difficult identifyoften', u'visual difficult identifysecond', u'visual difficult object', u'visual featur', u'visual object', u'visual object class', u'visual recognit', u'visual recognit nip', u'visual segnet3', u'visual segnet32', u'visual segnet32 visual', u'visual segnetw', u'visual segnetw perform', u'visual theeffect', u'visual theeffect featur', u'visual theth', u'visual theth segnet', u'visual train', u'visual train convolutionaldecod', u'visual train convolutionalnetwork', u'visual train convolutionalth', u'visualand', u'visualand y', u'visualand y lecun', u'visualis', u'visualis effect', u'visualis effect featur', u'visuallyexampl', u'visuallyexampl cyclist', u'visuallyexampl cyclist camvid', u'visuallysimilar', u'visuallysimilar class', u'visuallysimilar class sun', u'visuallysimilar pedestrian', u'visuallysimilar pedestrian model', u'visualrecognit', u'visualrecognit nip', u'visualrecognit nip pp', u'vital', u'vital therefor', u'vital therefor necessari', u'vitali', u'vitali lower', u'vitali lower compar', u'vitalto', u'vitalto captur', u'vitalto captur inform', u'voc', u'voc afor', u'voc afor domest', u'voc argb', u'voc argb dataset', u'voc dataset', u'voc dataset toaddit', u'voc dataset tolearn', u'voc datasetpasc', u'voc datasetpasc voc', u'voc datasetsegnet', u'voc datasetsegnet layerssegnet', u'voc right', u'voc test', u'voc test ioumethodmethodmethodmethodmethodmethodmethoddil', u'voc test iouparamet', u'voc12', u'voc12 challeng', u'voc12 challeng miou', u'voc12 comput', u'voc12 comput vision', u'voc12 hasbeen', u'voc12 hasbeen benchmark', u'voc12 hasrgb-d', u'voc12 hasrgb-d indoor', u'voc12 salient', u'voc12 salient object', u'voc12 segment', u'voc12 segment challeng', u'voc12 test', u'voc12 test result', u'voc5', u'vocth', u'vocth pascal', u'vocth pascal voc12', u'vol', u'vol abs/14091556', u'vol abs/14091556 2014c', u'vol abs/14091556 2014large-scal', u'vol abs/150203167', u'vol abs/150203167 2015vol', u'vol abs/150504366', u'vol abs/150504366 2015best', u'vol abs/150504366 2015semant', u'vol abs/150507293', u'vol abs/150507293 2015d', u'vol abs/150507293 2015label', u'vol abs/150604579', u'vol abs/150604579 2015better', u'vol abs/150604579 2015v', u'vol databas', u'vol databas web-bas', u'vol ofin', u'vol ofin artifici', u'vol oflectur', u'vol oflectur note', u'vol pp', u'vol pp 1915\\u20131929,201320132013201320132013n', u'vol pp 2004pp', u'vol pp 2008no', u'vol pp 2009understand', u'vol pp 88\\u2013video', u'vol pp 98\\u2013136pp', u'vol pp featur', u'vol transact', u'vol transact pattern', u'vol zisserman', u'vol zisserman \\u201cthe', u'volum', u'volum co-author', u'volum co-author than300', u'volum co-author thanha', u'volum lectureadv', u'volum lectureadv artifici', u'volum lecturenot', u'volum lecturenot comput', u'w', u'w givenfor', u'w givenfor bayesian', u'w givenour', u'w givenour observ', u'w liu', u'w liu y', u'w minimisingth', u'w minimisingth kullback-leibl', u'w minimisingweight', u'w p', u'w p w', u'w x', u'w x y', u'wacv', u'wacv 8labelm', u'wacv 8labelm databas', u'wacv 8paradigm', u'wacv 8paradigm autonom', u'wall', u'wall ar', u'wall ar task', u'wall ar tasksdecor', u'wall ar taskshowev', u'wall ceil', u'wall ceil label', u'wall floor', u'wall floor ceil', u'wall,654', u'wall,654 test', u'wall,654 test imag', u'want', u'want understand', u'want understand quantit', u'wasavail', u'wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun', u'wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun rgb-d', u'wasavailableavailableavailableavailableavailableavailableavailableavailableavailableavailableavailable42424242sun rgb-d indoor', u'wasbenchmark', u'wasbenchmark control', u'wasbenchmark control mean', u'wasprocess', u'wasprocess subset', u'wasprocess subset train', u'wastrain', u'wastrain separ', u'wastrain separ recip', u'way', u'way gettingcan', u'way gettingcan therefor', u'way gettingsampl', u'way gettingsampl posterior', u'way prevent', u'way prevent neural', u'way storeappl', u'way storeappl henc', u'way storethi', u'way storethi inform', u'wea', u'wea road', u'wea road build', u'weachiev', u'weachiev mont', u'weachiev mont carlo', u'weadapt', u'weadapt appropri', u'weadapt appropri learn', u'weadopt', u'weadopt l-bfgs', u'weadopt l-bfgs base', u'wealso', u'wealso note', u'wealso note earlier', u'wealso observ', u'wealso observ signific', u'wear', u'wear abl', u'wear abl benchmark', u'web', u'web demo', u'web demo caff', u'web demo http', u'web-bas', u'web-bas tool', u'web-bas tool imag', u'web2', u'web2 http', u'web2 http //miengcamacuk/projects/segnet/', u'webdemo', u'webdemodemodemodemodemodemoconverg', u'webdemodemodemodemodemodemoconverg befor', u'webdemodemodemodemodemodemoconverg befor epoch', u'webenchmark', u'webenchmark includ', u'webenchmark includ use', u'webenchmark perform', u'webenchmark perform 40k', u'webpage1', u'webpage1 onlin', u'webpage1 onlin demo', u'webpageat', u'webpageat object', u'webpageat object boundari', u'webpagemi', u'wecaff', u'wecaff prototxt', u'wecaff prototxt road', u'wecan', u'wecan therefor', u'wecan therefor consid', u'wecategori', u'wecategori dataset', u'wecategori dataset contain', u'weclass', u'weconclud', u'weconclud pointer', u'weconclud pointer futur', u'wecould', u'wecould access', u'wecould access predict', u'wedil', u'wedil network', u'wedil network addit', u'week', u'week unoptim', u'week unoptim test', u'wefigur', u'wefigur bayesian', u'wefigur bayesian segnet', u'wefind', u'wefind drop', u'wefind drop half', u'weight', u'weight appropri', u'weight appropri magnitud', u'weight averag', u'weight averag approxim', u'weight averag mont', u'weight averag producedbett', u'weight averag producedfound', u'weight averag techniqu', u'weight closest', u'weight closest input', u'weight decay', u'weight decay paramet', u'weight explain', u'weight explain thedata', u'weight explain themodel', u'weight fcn', u'weight fcn decod', u'weight fix', u'weight fix deeper', u'weight fix noteth', u'weight fix notethat', u'weight holdingth', u'weight holdingth shallow', u'weight holdingw', u'weight holdingw train', u'weight improv', u'weight improv perform', u'weight initi', u'weight initi use', u'weight initializationor', u'weight initializationor ani', u'weight initializationwithout', u'weight initializationwithout need', u'weight layer', u'weight layer andbatch', u'weight layer andth', u'weight layer doe', u'weight network', u'weight network usingan', u'weight network usingin', u'weight proport', u'weight proport dropout', u'weight q', u'weight q w', u'weight result', u'weight result poorer', u'weight smaller', u'weight smaller weightsof', u'weight smaller weightsth', u'weight test', u'weight test time', u'weight therefor', u'weight therefor requir', u'weight trainingon', u'weight trainingon soft-max', u'weight trainingpoor', u'weight trainingpoor result', u'weight unthin', u'weight unthin network', u'weight unti', u'weight untiedmod', u'weight untiedmod rgb', u'weight untiedsoft-max', u'weight untiedsoft-max weight', u'weight updat', u'weight updat techniqu', u'weight use', u'weight use bilinear', u'weight vgg', u'weight vgg net', u'weight w', u'weight w givenfor', u'weight w givenour', u'weight zero', u'weight zero mean', u'weight77', u'weightaverag', u'weightaverag mont', u'weightaverag mont carlo', u'weightaverag techniqu', u'weightaverag techniqu produc', u'weightbeyond', u'weightbeyond approxim', u'weightbeyond approxim sampl', u'weightcamvid', u'weightcamvid dataset', u'weightingmetr', u'weightingmetr global', u'weightingmetr global accuraci', u'weightingsinc', u'weightingsinc major', u'weightingsinc major scene', u'weightpixel', u'weightpixel domin', u'weightpixel domin camvid', u'weights31313131decod', u'weights31313131decod variantsdecod', u'weights31313131decod variantsdecod variantsdecod', u'weightsand', u'weightsand train', u'weightsand train hold', u'weightsar', u'weightsar typic', u'weightsar typic pre-train', u'weightsfix', u'weightsfix total', u'weightsfix total use', u'weightslay', u'weightslay fulli', u'weightslay fulli connect', u'weightsof', u'weightsof smallest', u'weightsof smallest class', u'weightsth', u'weightsth train', u'weightsth train set', u'weightsweight', u'weightsweight vgg', u'weightsweight vgg net', u'weightth', u'weightth loss', u'weightth loss differ', u'weightth weight', u'weightth weight averag', u'weightweightweightweightweightweightweightaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingprobabilist', u'weightweightweightweightweightweightweightaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingprobabilist variantsprobabilist', u'weightweightweightweightweightweightweightaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingaveragingprobabilist variantsprobabilist variantsprobabilist', u'weinput', u'weinput imag', u'weinput imag train', u'welarg', u'welarg dataset', u'welarg dataset 35k', u'wellknown', u'wellknown deep', u'wellknown deep architectur', u'wellto', u'wellto encourag', u'wellto encourag research', u'wemap', u'wemap decod', u'wemap decod make', u'wemodel', u'wemodel deconvnet', u'wemodel deconvnet median', u'wemodifi', u'wemodifi produc', u'wemodifi produc bayesian', u'weoften', u'weoften observ', u'weoften observ high', u'weperform', u'weperform local', u'weperform local contrast', u'wequantit', u'wequantit bayesian', u'wequantit bayesian segnet', u'wereactiv', u'wereactiv studyactiv', u'wereactiv studyactiv studyactiv', u'weremad', u'weremad use', u'weremad use richer', u'werenon-zero', u'werenon-zero bin', u'werenon-zero bin featur', u'wereunari', u'wereunari smooth', u'wereunari smooth use', u'wesegment', u'wesegment especi', u'wesegment especi difficult', u'wesegnet', u'wesegnet sever', u'wesegnet sever known', u'weselect', u'weselect state-of-the-art', u'weselect state-of-the-art method', u'westudi', u'westudi network', u'westudi network core', u'wesystem', u'wesystem output', u'wetechniqu', u'wetechniqu describ', u'wetechniqu describ et', u'weth', u'weth techniqu', u'weth techniqu use', u'wetrain', u'wetrain train', u'wetrain train imag', u'weuncertainti', u'weuncertainti essenti', u'weuncertainti essenti decis', u'weus', u'weus mini-batch', u'weus mini-batch size', u'weus stochast', u'weus stochast gradient', u'wew', u'wew briefli', u'wew briefli review', u'wew observ', u'wew observ use', u'wewith', u'wewith dropout', u'wewith dropout fcn', u'whenfollow', u'whenfollow train', u'whenfollow train segnet', u'whenmeasur', u'whenmeasur model', u'whenmeasur model uncertainti', u'whenmodel', u'whenmodel smaller', u'whenmodel smaller dataset', u'whenno', u'whenno class', u'whenno class balanc', u'whenprovid', u'whenprovid measur', u'whenprovid measur model', u'whenth', u'whenth column', u'whenth column tabl', u'whenth object', u'whenth object appear', u'whenth situat', u'whenth situat caus', u'whereboundari', u'whereboundari delin', u'whereboundari delin vital', u'whereimag', u'whereimag represent', u'whereimag represent benefici', u'whi', u'whi segnet-bas', u'whi segnet-bas outperform', u'which1', u'which1 segnet-bas', u'which1 segnet-bas earlier', u'whichallow', u'whichallow approxim', u'whichallow approxim posterior', u'whichar', u'whichar increas', u'whichar increas accur', u'whichbenchmark', u'whichbenchmark perform', u'whichbenchmark perform 40k', u'whichcan', u'whichcan produc', u'whichcan produc probabilist', u'whichconvolut', u'whichconvolut encoder-decod', u'whichconvolut encoder-decod neural', u'whichconvolut neural', u'whichconvolut neural network', u'whichen', u'whichen compar', u'whichen compar propos', u'whichfcn-bas', u'whichfcn-bas compar', u'whichfcn-bas compar version', u'whichgiven', u'whichgiven mini-batch', u'whichgiven mini-batch size', u'whichha', u'whichha larg', u'whichha larg number', u'whichhav', u'whichhav adopt', u'whichhav adopt network', u'whichi', u'whichi scope', u'whichi scope paper', u'whichinput', u'whichinput imag', u'whichinput imag size', u'whichproduc', u'whichproduc input', u'whichproduc input decod', u'whichthi', u'whichthi dataset', u'whichthi dataset unlik', u'whichtrain', u'whichtrain time', u'whichtrain time memori', u'whichus', u'whichus depth', u'whichus depth segment', u'whichus motion', u'whichus motion structur', u'whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor', u'whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor window', u'whichwallwallwallwallwallfloorfloorfloorfloorfloorfloorcabinetcabinetcabinetcabinetcabinetcabinetcabinetcabinetbedbedbedbedchairchairchairchairchairchairsofasofasofasofasofatabletabletabletabletabletabledoor window bookshelf', u'wi', u'wi foreveri', u'wi foreveri k', u'wi forher', u'wi forher approxim', u'wi mi', u'wi mi diag', u'wide', u'wide adopt', u'wide adopt fcn', u'wide array', u'wide array applic', u'wide array of1', u'wide array ofsemant', u'wide context', u'wide context smooth', u'wide rang', u'wide rang applic', u'wide use', u'wide use fulli', u'wide use fullyconvolut', u'wide use fullyof', u'wide vari', u'wide vari indoor', u'wide varieti', u'wide varieti scene', u'wide varyingarrang', u'wide varyingarrang anoth', u'wide varyings', u'wide varyings object', u'widelyadopt', u'widelyadopt fulli', u'widelyadopt fulli convolut', u'widelyin', u'widelyin tabl', u'widelyin tabl compar', u'widelyof', u'widelyof segment', u'widelyof segment salient', u'widelyvari', u'widelyvari background', u'widelyvari background class', u'wider', u'wider seebett', u'wider seebett corr', u'wider seew', u'wider seew liu', u'width', u'wild', u'wild comput', u'wild comput vision', u'window', u'window andi', u'window andi effici', u'window andthi', u'window andthi use', u'window bookshelf', u'window bookshelf pictur', u'window creat', u'window creat variant', u'window final', u'window final down-sampl', u'window input', u'window input imag', u'window memor', u'window memor encod', u'window of2', u'window of2 stride', u'window ofsiz', u'window ofsiz encod', u'window pixelin', u'window pixelin featur', u'window pixelin larg', u'window retain', u'window retain structur', u'window stride', u'window stride non-overlappingmax-pool', u'window stride non-overlappingwindow', u'wise', u'wise featur', u'wise featur learn', u'wise imag', u'wise imag label', u'wise label', u'wise label method', u'wise pixel', u'wise pixel depth', u'wise predict', u'wise predict aremad', u'wise predict areoth', u'wise predict madeoth', u'wise predict madeus', u'wise segment', u'wise segment follow', u'witha', u'witha measur', u'witha measur model', u'witha stage-wis', u'witha stage-wis train', u'witha trainabl', u'witha trainabl decod', u'withbayesian', u'withbayesian weight', u'withboost', u'withboost d', u'withboost d abov', u'withboost withboost', u'withboost withboost d', u'withboost withboost withboost', u'withcom', u'withcom various', u'withcom various shape', u'withcontextu', u'withcontextu relationship', u'withcontextu relationship effect', u'withcrf', u'withcrf model', u'withcrf modelscrf', u'withcrf modelscrf modelscrf', u'withcrf post-process', u'withcrf post-process fact', u'withcu', u'withcu depth', u'withcu depth video', u'withcurr', u'withcurr applic', u'withcurr applic autonom', u'withdeconvnet', u'withdeconvnet later', u'withdeconvnet later paper', u'withevid', u'withevid gather', u'withevid gather author', u'withexampl', u'withexampl miou', u'withexampl miou favour', u'withfcn', u'withfcn decod', u'withfcn decod variant', u'withfigur', u'withfigur bayesian', u'withfigur bayesian segnet', u'withfrequ', u'withfrequ partial', u'withfrequ partial occlus', u'withi', u'withi follow', u'withi follow general', u'withillustr', u'withillustr fig', u'withillustr fig featur', u'withincreas', u'withincreas train', u'withincreas train time', u'withindoor', u'withindoor scene', u'withindoor scene segment', u'withit', u'withit qualit', u'withit qualit analysi', u'withjudg', u'withjudg rank', u'withjudg rank good', u'withlarg', u'withlarg train', u'withlarg train set', u'withlearn', u'withlearn method', u'withlearn method produc', u'withloc', u'withloc patch', u'withloc patch base', u'withno', u'withno bias', u'withno bias term', u'withour', u'withour light-weight', u'withour light-weight matlab', u'withoutmax-pool', u'withoutmax-pool sub-sampl', u'withoutmax-pool sub-sampl encod', u'withoutoth', u'withoutoth aid', u'withoutoth aid report', u'withoutpoor', u'withoutpoor comparison', u'withoutpoor comparison abov', u'withoutweight', u'withparticular', u'withparticular perform', u'withparticular perform gain', u'withpoint', u'withpoint futur', u'withpoint futur work', u'withproduc', u'withproduc smooth', u'withproduc smooth segment', u'withpropos', u'withpropos refer', u'withpropos refer core', u'withqual', u'withqual segment', u'withqual segment like', u'withrandom', u'withrandom forest', u'withrandom forest withrandom', u'withrandom forest withsfmsfmsfmsfmtexton', u'withsegnet', u'withsegnet sever', u'withsegnet sever known', u'withsegnet-typ', u'withsegnet-typ decod', u'withsegnet-typ decod techniqu', u'withsemant', u'withsemant pixel', u'withsemant pixel label', u'withsfmsfmsfmsfmtexton', u'withsfmsfmsfmsfmtexton featurestexton', u'withsfmsfmsfmsfmtexton featurestexton featurestexton', u'withtextonboost', u'withtextonboost textonforest', u'withtextonboost textonforest random', u'withth', u'withth current', u'withth current state', u'withth ground', u'withth ground truth', u'withth object', u'withth object final', u'withtrain', u'withtrain time', u'withtrain time particular', u'woolf', u'woolf fisher', u'woolf fisher scholarship', u'work', u'work agreement', u'work agreement earlier', u'work bayesian', u'work bayesian segnet', u'work bothaccuraci', u'work bothaccuraci follow', u'work bothclass', u'work bothclass segment', u'work decoupl', u'work decoupl classification-segment', u'work featur', u'work featur map', u'work inspir', u'work inspir unsupervis', u'work largebatch', u'work largebatch use', u'work largest', u'work largest converg', u'work like', u'work like add', u'work lower', u'work lower memori', u'work princip', u'work princip engin', u'work rgb-drgb-drgb-dliu', u'work rgb-drgb-drgb-dliu et', u'work sec', u'work sec conclud', u'work sec mostconclud', u'work sec mostof', u'work whichi', u'work whichi scope', u'work whichus', u'work whichus depth', u'work zeiler', u'work zeiler et', u'work2', u'work:68', u'workd', u'workd iscuss', u'workd iscuss futur', u'workdeep', u'workdeep learn', u'workdeep learn model', u'worksemant', u'worksemant pixel', u'worksemant pixel label', u'workshop', u'workshop deep', u'workshop deep learn', u'workshop deep vision', u'workshop deeplearn', u'workshop deeplearn 3learn', u'workshop deepnetwork', u'workshop deepnetwork scene', u'workshop icml', u'workshop icml 2015insight', u'workshop icml 2015uncertainti', u'workshopon', u'workshopon deep', u'workshopon deep vision', u'workshopsemant', u'workshopsemant feedback', u'workshopsemant feedback convolut', u'worsefor', u'worsefor shallow', u'worsefor shallow layer', u'worseto', u'worseto pole', u'worseto pole contrast', u'worst', u'worst base', u'worst base onal', u'worst base onupsampl', u'wrote', u'wrote matlab', u'wrote matlab gpu', u'x', u'x appli', u'x appli follow', u'x gpu', u'x label', u'x label y', u'x y', u'x y general', u'y', u'y general', u'y general posterior', u'y jia', u'y jia p', u'y lecun', u'y lecun learn', u'y lecun \\u201clearn', u'y ng', u'y ng optim', u'y ng \\u201cpars', u'year', u'yearsbeen', u'yearsbeen benchmark', u'yearsbeen benchmark challeng', u'yearshowev', u'yearshowev major', u'yearshowev major task', u'york', u'york 2nd', u'york 2nd edit', u'yuill', u'yuill c', u'yuill c liang-chieh', u'yuill connect', u'yuill connect crfs', u'z', u'z su', u'z su d', u'zealand', u'zealand in2014', u'zealand in2014 award', u'zealand inth', u'zealand inth univers', u'zeiler', u'zeiler et', u'zeiler et al', u'zero', u'zero mean', u'zero mean unit', u'zero note', u'zero note qualiti', u'zero produc', u'zero produc result', u'zero thisfeatur', u'zero thisfeatur s', u'zero thispredict', u'zero thispredict reason', u'zheng', u'zheng s', u'zheng s jayasumana', u'zisserman', u'zisserman \\u201cthe', u'zisserman \\u201cthe pascal', u'zisserman \\u201cveri', u'zisserman \\u201cveri deep', u'zitnick', u'zitnick \\u201cmicrosoft', u'zitnick \\u201cmicrosoft coco', u'\\xd7implement', u'\\xd7implement averag', u'\\xd7implement averag measur', u'\\u201ccaff', u'\\u201ccaff convolut', u'\\u201ccaff convolut architectur', u'\\u201ccondit', u'\\u201ccondit random', u'\\u201ccondit random field', u'\\u201cdirection\\u201d', u'\\u201cdirection\\u201d \\u201cspace\\u201d', u'\\u201cdirection\\u201d \\u201cspace\\u201d ensembl', u'\\u201cfast', u'\\u201cfast semant', u'\\u201cfast semant segment', u'\\u201cfill', u'\\u201cfill in\\u201d', u'\\u201cfill in\\u201d miss', u'\\u201cflat\\u201d', u'\\u201cflat\\u201d architectur', u'\\u201cflat\\u201d architectur number', u'\\u201cfulli', u'\\u201cfulli convolut', u'\\u201cfulli convolut network', u'\\u201cgo', u'\\u201cgo deeper', u'\\u201cgo deeper convolut', u'\\u201cinfluences\\u201d', u'\\u201cinfluences\\u201d optim', u'\\u201cinfluences\\u201d optim time', u'\\u201cinfluences\\u201d optim timessampl', u'\\u201cinfluences\\u201d optim timesw', u'\\u201clearn', u'\\u201clearn convolut', u'\\u201clearn convolut featur', u'\\u201clearn deconvolut', u'\\u201clearn deconvolut network', u'\\u201clearn hierarchicalc', u'\\u201clearn hierarchicalc farabet', u'\\u201clearn hierarchicalfeatur', u'\\u201clearn hierarchicalfeatur scene', u'\\u201cmicrosoft', u'\\u201cmicrosoft coco', u'\\u201cmicrosoft coco common', u'\\u201cpars', u'\\u201cpars natur', u'\\u201cpars natur scenesand', u'\\u201cpars natur scenesr', u'\\u201cparsenet', u'\\u201cparsenet look', u'\\u201cparsenet look wider', u'\\u201cpredict', u'\\u201cpredict depth', u'\\u201cpredict depth surfac', u'\\u201csegnet', u'\\u201csegnet deep', u'\\u201csegnet deep convolut', u'\\u201cspace\\u201d', u'\\u201cspace\\u201d ensembl', u'\\u201cspace\\u201d ensembl ofa', u'\\u201cspace\\u201d ensembl offeatur', u'\\u201cthe', u'\\u201cthe cityscap', u'\\u201cthe cityscap dataset', u'\\u201cthe pascal', u'\\u201cthe pascal visual', u'\\u201ctuned\\u201d', u'\\u201ctuned\\u201d certain', u'\\u201ctuned\\u201d certain scene', u'\\u201cveri', u'\\u201cveri deep', u'\\u201cveri deep convolut', u'\\u201darxiv', u'\\u201darxiv preprint', u'\\u201darxiv preprint arxiv:1502', u'\\u201darxiv preprint arxiv:150202734', u'\\u201dsemi-supervis', u'\\u201dsemi-supervis learn', u'\\u201dsemi-supervis learn dcnn', u'\\u2200j', u'\\u2200j q', u'\\u2200j q meanq', u'\\u2200j squar', u'\\u2200j squar valu']\n"
     ]
    }
   ],
   "source": [
    "#for tfidf, there are two important things, max_df & min_df;\n",
    "#max_df - When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "#min_idf - When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature.\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfVectorizer = TfidfVectorizer(stop_words='english', use_idf=True, tokenizer=tokenizeAndStem, ngram_range=(1,3))\n",
    "#Now fit the vectorizer to synopses\n",
    "%time tfidf_matrix = tfidfVectorizer.fit_transform(paragraphs)\n",
    "print tfidf_matrix\n",
    "print tfidfVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-169f681f039b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fateh/.local/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fateh/.local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtocoo\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmajor_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mminor_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         \u001b[0mmajor_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m         \u001b[0m_sparsetools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Now we calculate the cosine similarity as follows. This will gives us the distance which wil help us in clustering in the later stage.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "print dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.55003055e-02   6.89017630e-02   6.14515575e-02   5.94127048e-02\n",
      "   5.72184442e-02   5.43801958e-02   5.20751341e-02   5.17230086e-02\n",
      "   5.05201827e-02   4.86059785e-02   4.78122717e-02   4.64631198e-02\n",
      "   4.51457458e-02   4.45865845e-02   4.43397555e-02   4.07385296e-02\n",
      "   3.98080264e-02   3.83333042e-02   3.61129769e-02   1.68704108e-02\n",
      "   9.44401537e-35]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=21)\n",
    "pca.fit(dist)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 ms, sys: 0 ns, total: 48 ms\n",
      "Wall time: 47.2 ms\n",
      "[1, 2, 2, 2, 2, 0, 0, 3, 1, 4, 4, 3, 3, 3, 0, 4, 2, 0, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "numClusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=numClusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 0, 0, 3, 1, 4, 4, 3, 3, 3, 0, 4, 2, 0, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()\n",
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              topics  cluster\n",
      "1  book:0 sentence:0        1\n",
      "2  book:0 sentence:1        2\n",
      "2  book:0 sentence:2        2\n",
      "2  book:0 sentence:3        2\n",
      "2  book:0 sentence:4        2\n",
      "0  book:0 sentence:5        0\n",
      "0  book:0 sentence:6        0\n",
      "3  book:0 sentence:7        3\n",
      "1  book:1 sentence:0        1\n",
      "4  book:1 sentence:1        4\n",
      "4  book:1 sentence:2        4\n",
      "3  book:1 sentence:3        3\n",
      "3  book:1 sentence:4        3\n",
      "3  book:1 sentence:5        3\n",
      "0  book:2 sentence:0        0\n",
      "4  book:2 sentence:1        4\n",
      "2  book:2 sentence:2        2\n",
      "0  book:2 sentence:3        0\n",
      "1  book:3 sentence:0        1\n",
      "1  book:3 sentence:1        1\n",
      "2  book:3 sentence:2        2\n"
     ]
    }
   ],
   "source": [
    "#Converting to a pandas da frame.\n",
    "\n",
    "texts = { 'topics': topics, 'paragraphs': paragraphs, 'cluster': clusters}\n",
    "\n",
    "frame = pd.DataFrame(texts, index = [clusters] , columns = ['topics', 'cluster'])\n",
    "\n",
    "print frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
    "\n",
    "#set up cluster names using a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim.summarization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9459258e9982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclusterNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtempClusterStatements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclusterStatements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumClusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim.summarization"
     ]
    }
   ],
   "source": [
    "clusterNames = []\n",
    "tempClusterStatements = []\n",
    "for i in range(0,numClusters,1) :\n",
    "    clusterNames.append(\"\")\n",
    "    tempClusterStatements.append(\"\")\n",
    "from gensim.summarization import keywords, summarize\n",
    "clusterStatements = []\n",
    "for i in range(0,numClusters,1) :\n",
    "    clusterStatements.append([])\n",
    "# for i in range(0,numClusters,1) :\n",
    "#     clusterStatements.append(\"\")\n",
    "#print clusterStatements\n",
    "for i in range(0, len(paragraphs), 1) :\n",
    "    clusterStatements[clusters[i]].append(paragraphs[i])\n",
    "    tempClusterStatements[clusters[i]] += paragraphs[i]\n",
    "for i in range(0, numClusters, 1) :\n",
    "    temp = keywords(tempClusterStatements[i])\n",
    "    # while len(temp)>60 :\n",
    "    #     temp = keywords(temp)\n",
    "    temp=temp.replace('\\n',' ').split(' ')\n",
    "    #print temp\n",
    "    #print len(temp)\n",
    "    for j in range(0, len(temp), 1) :\n",
    "        clusterNames[i] += \" \" + temp[j]\n",
    "print clusterNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os  # for os.path.basename\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()\n",
    "\n",
    "# convert two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkIAAASeCAYAAACaUjLsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG+r0DqpgxosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc84babc590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc849a4cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#some ipython magic to show the matplotlib plots inline\n",
    "%matplotlib inline \n",
    "\n",
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, topics=topics)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(20, 15)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=clusterNames[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "#add label in x,y position with the label as the film title\n",
    "for i in range(len(df)):\n",
    "    ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['topics'], size=8)  \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "plt.savefig('clusters_small_noaxes.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           8.           0.87470092   2.        ]\n",
      " [  9.          14.           1.24356626   2.        ]\n",
      " [  1.           6.           1.28326702   2.        ]\n",
      " [  5.          12.           1.29103793   2.        ]\n",
      " [  3.           4.           1.30003278   2.        ]\n",
      " [ 19.          20.           1.33493314   2.        ]\n",
      " [ 13.          25.           1.34041681   3.        ]\n",
      " [ 11.          24.           1.35172697   3.        ]\n",
      " [  2.          17.           1.36053418   2.        ]\n",
      " [ 10.          15.           1.36242952   2.        ]\n",
      " [ 16.          29.           1.37789255   3.        ]\n",
      " [  7.          28.           1.39371783   4.        ]\n",
      " [ 18.          30.           1.39849233   3.        ]\n",
      " [ 23.          26.           1.42054644   4.        ]\n",
      " [ 22.          33.           1.42435429   5.        ]\n",
      " [ 31.          34.           1.42824468   7.        ]\n",
      " [ 27.          36.           1.48378876  10.        ]\n",
      " [ 32.          35.           1.51303931   9.        ]\n",
      " [ 37.          38.           1.55520955  19.        ]\n",
      " [ 21.          39.           1.82808262  21.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAfGCAYAAAATLkwDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc84babf290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "print linkage_matrix\n",
    "fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
    "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=topics)\n",
    "\n",
    "plt.tick_params(\\\n",
    "    axis= 'x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off')\n",
    "\n",
    "plt.tight_layout() #show plot with tight layout\n",
    "\n",
    "#uncomment below to save figure\n",
    "plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusterStatements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c5dff186f193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumClusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtfidfVectorizerCluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizeAndStem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtfidfMatrixCluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidfVectorizerCluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterStatements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdistCluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfMatrixCluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmaxClusterDistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clusterStatements' is not defined"
     ]
    }
   ],
   "source": [
    "for k in range(0, numClusters, 1) :\n",
    "    tfidfVectorizerCluster = TfidfVectorizer(stop_words='english', use_idf=True, tokenizer=tokenizeAndStem, ngram_range=(1,3))\n",
    "    tfidfMatrixCluster = tfidfVectorizerCluster.fit_transform(clusterStatements[k])\n",
    "    distCluster = 1 - cosine_similarity(tfidfMatrixCluster)\n",
    "    maxClusterDistance=0\n",
    "    farthestSentence=0\n",
    "    for i in range(0, len(distCluster), 1) :\n",
    "        temp=0\n",
    "        for j in range(0, len(distCluster[i]), 1) :\n",
    "            temp+=distCluster[i][j]\n",
    "        farthestSentence = farthestSentence if maxClusterDistance<temp else i\n",
    "        maxClusterDistance = maxClusterDistance if maxClusterDistance<temp else temp\n",
    "    print clusterStatements[k][farthestSentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.22044605e-16,   9.41912666e-01,   9.61054289e-01,\n",
       "          1.00000000e+00,   9.71604554e-01,   9.65635793e-01,\n",
       "          9.89021019e-01,   1.00000000e+00,   6.06426770e-01,\n",
       "          9.27036432e-01,   9.66382044e-01,   9.78664744e-01,\n",
       "          9.81471435e-01,   9.83629818e-01,   9.39132344e-01,\n",
       "          9.68149648e-01,   9.92395918e-01,   9.67287436e-01,\n",
       "          8.11236937e-01,   9.65008303e-01,   9.75344955e-01],\n",
       "       [  9.41912666e-01,  -2.22044605e-16,   9.43420593e-01,\n",
       "          9.76037609e-01,   9.36201358e-01,   9.69965140e-01,\n",
       "          9.02790675e-01,   1.00000000e+00,   9.21470073e-01,\n",
       "          9.54749857e-01,   9.75425615e-01,   9.83739915e-01,\n",
       "          9.90109342e-01,   9.78199516e-01,   9.47389784e-01,\n",
       "          9.95233042e-01,   9.83806102e-01,   9.74370693e-01,\n",
       "          9.46634908e-01,   9.44485749e-01,   9.60884824e-01],\n",
       "       [  9.61054289e-01,   9.43420593e-01,  -2.22044605e-16,\n",
       "          9.62386321e-01,   9.20991346e-01,   9.52854389e-01,\n",
       "          9.63298627e-01,   1.00000000e+00,   9.57247577e-01,\n",
       "          9.55383657e-01,   9.61425676e-01,   9.89769208e-01,\n",
       "          9.84474669e-01,   9.65779858e-01,   9.46448571e-01,\n",
       "          9.92517324e-01,   9.74580497e-01,   9.59769769e-01,\n",
       "          9.68429111e-01,   9.68869560e-01,   9.78065585e-01],\n",
       "       [  1.00000000e+00,   9.76037609e-01,   9.62386321e-01,\n",
       "          0.00000000e+00,   9.16556885e-01,   1.00000000e+00,\n",
       "          9.70762859e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.60571369e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.46073454e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.79750251e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   9.77239294e-01],\n",
       "       [  9.71604554e-01,   9.36201358e-01,   9.20991346e-01,\n",
       "          9.16556885e-01,  -4.44089210e-16,   9.80893628e-01,\n",
       "          9.51689738e-01,   1.00000000e+00,   9.68829068e-01,\n",
       "          9.43204279e-01,   9.84367254e-01,   9.95853838e-01,\n",
       "          9.93708158e-01,   9.28210005e-01,   9.78297587e-01,\n",
       "          9.96967548e-01,   9.47266814e-01,   9.83696176e-01,\n",
       "          9.66052338e-01,   9.87383985e-01,   9.67737651e-01],\n",
       "       [  9.65635793e-01,   9.69965140e-01,   9.52854389e-01,\n",
       "          1.00000000e+00,   9.80893628e-01,  -2.22044605e-16,\n",
       "          9.11250330e-01,   9.64267528e-01,   9.62276896e-01,\n",
       "          9.55300223e-01,   9.65963490e-01,   9.63449131e-01,\n",
       "          9.08904371e-01,   9.87896825e-01,   9.19883162e-01,\n",
       "          9.93397572e-01,   9.94377978e-01,   9.64502381e-01,\n",
       "          9.72143054e-01,   9.72531689e-01,   9.80645910e-01],\n",
       "       [  9.89021019e-01,   9.02790675e-01,   9.63298627e-01,\n",
       "          9.70762859e-01,   9.51689738e-01,   9.11250330e-01,\n",
       "         -2.22044605e-16,   9.68522122e-01,   9.87947889e-01,\n",
       "          9.53781740e-01,   9.86192385e-01,   9.67801169e-01,\n",
       "          9.64788391e-01,   9.73400658e-01,   9.55951676e-01,\n",
       "          9.94183710e-01,   9.80241401e-01,   9.46333734e-01,\n",
       "          9.94564326e-01,   9.67126858e-01,   9.76837682e-01],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   9.64267528e-01,\n",
       "          9.68522122e-01,   2.22044605e-16,   1.00000000e+00,\n",
       "          9.75561318e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.31210325e-01,   9.62691103e-01,   9.66772420e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00],\n",
       "       [  6.06426770e-01,   9.21470073e-01,   9.57247577e-01,\n",
       "          1.00000000e+00,   9.68829068e-01,   9.62276896e-01,\n",
       "          9.87947889e-01,   1.00000000e+00,   7.77156117e-16,\n",
       "          9.53448221e-01,   9.63096088e-01,   9.66561986e-01,\n",
       "          9.79660378e-01,   9.82029730e-01,   9.14166481e-01,\n",
       "          9.90197001e-01,   9.91652664e-01,   9.64089977e-01,\n",
       "          9.74738859e-01,   9.48084866e-01,   9.63420752e-01],\n",
       "       [  9.27036432e-01,   9.54749857e-01,   9.55383657e-01,\n",
       "          9.60571369e-01,   9.43204279e-01,   9.55300223e-01,\n",
       "          9.53781740e-01,   9.75561318e-01,   9.53448221e-01,\n",
       "         -4.44089210e-16,   9.77640716e-01,   9.67300183e-01,\n",
       "          9.53694865e-01,   9.66090641e-01,   8.75272056e-01,\n",
       "          9.14226997e-01,   9.68387368e-01,   9.79056013e-01,\n",
       "          9.49688383e-01,   9.80225394e-01,   9.68664374e-01],\n",
       "       [  9.66382044e-01,   9.75425615e-01,   9.61425676e-01,\n",
       "          1.00000000e+00,   9.84367254e-01,   9.65963490e-01,\n",
       "          9.86192385e-01,   1.00000000e+00,   9.63096088e-01,\n",
       "          9.77640716e-01,   1.11022302e-15,   9.84644399e-01,\n",
       "          9.76697721e-01,   9.79412191e-01,   9.53774381e-01,\n",
       "          9.60826487e-01,   9.90436796e-01,   9.65273245e-01,\n",
       "          9.77207573e-01,   9.77525553e-01,   9.84164572e-01],\n",
       "       [  9.78664744e-01,   9.83739915e-01,   9.89769208e-01,\n",
       "          1.00000000e+00,   9.95853838e-01,   9.63449131e-01,\n",
       "          9.67801169e-01,   1.00000000e+00,   9.66561986e-01,\n",
       "          9.67300183e-01,   9.84644399e-01,  -4.44089210e-16,\n",
       "          9.20616654e-01,   9.66016552e-01,   9.70663434e-01,\n",
       "          9.93531640e-01,   9.73936691e-01,   9.63852299e-01,\n",
       "          9.93954927e-01,   9.85129377e-01,   9.89522203e-01],\n",
       "       [  9.81471435e-01,   9.90109342e-01,   9.84474669e-01,\n",
       "          1.00000000e+00,   9.93708158e-01,   9.08904371e-01,\n",
       "          9.64788391e-01,   9.31210325e-01,   9.79660378e-01,\n",
       "          9.53694865e-01,   9.76697721e-01,   9.20616654e-01,\n",
       "         -2.22044605e-16,   9.20998825e-01,   9.50092505e-01,\n",
       "          9.90184198e-01,   9.91641763e-01,   9.80860320e-01,\n",
       "          9.90826541e-01,   9.90954521e-01,   9.93626583e-01],\n",
       "       [  9.83629818e-01,   9.78199516e-01,   9.65779858e-01,\n",
       "          9.46073454e-01,   9.28210005e-01,   9.87896825e-01,\n",
       "          9.73400658e-01,   9.62691103e-01,   9.82029730e-01,\n",
       "          9.66090641e-01,   9.79412191e-01,   9.66016552e-01,\n",
       "          9.20998825e-01,  -2.22044605e-16,   9.77490547e-01,\n",
       "          9.91327635e-01,   9.81577200e-01,   9.83089891e-01,\n",
       "          9.91895153e-01,   9.92008224e-01,   9.81962078e-01],\n",
       "       [  9.39132344e-01,   9.47389784e-01,   9.46448571e-01,\n",
       "          1.00000000e+00,   9.78297587e-01,   9.19883162e-01,\n",
       "          9.55951676e-01,   9.66772420e-01,   9.14166481e-01,\n",
       "          8.75272056e-01,   9.53774381e-01,   9.70663434e-01,\n",
       "          9.50092505e-01,   9.77490547e-01,  -4.44089210e-16,\n",
       "          9.87720822e-01,   9.89544177e-01,   9.55019320e-01,\n",
       "          9.68358045e-01,   9.51885450e-01,   9.66098631e-01],\n",
       "       [  9.68149648e-01,   9.95233042e-01,   9.92517324e-01,\n",
       "          1.00000000e+00,   9.96967548e-01,   9.93397572e-01,\n",
       "          9.94183710e-01,   1.00000000e+00,   9.90197001e-01,\n",
       "          9.14226997e-01,   9.60826487e-01,   9.93531640e-01,\n",
       "          9.90184198e-01,   9.91327635e-01,   9.87720822e-01,\n",
       "          5.55111512e-16,   9.95971617e-01,   9.90775331e-01,\n",
       "          9.72883189e-01,   9.95640390e-01,   9.96928232e-01],\n",
       "       [  9.92395918e-01,   9.83806102e-01,   9.74580497e-01,\n",
       "          9.79750251e-01,   9.47266814e-01,   9.94377978e-01,\n",
       "          9.80241401e-01,   1.00000000e+00,   9.91652664e-01,\n",
       "          9.68387368e-01,   9.90436796e-01,   9.73936691e-01,\n",
       "          9.91641763e-01,   9.81577200e-01,   9.89544177e-01,\n",
       "          9.95971617e-01,   4.44089210e-16,   9.62830551e-01,\n",
       "          9.96235233e-01,   9.68579425e-01,   9.97384364e-01],\n",
       "       [  9.67287436e-01,   9.74370693e-01,   9.59769769e-01,\n",
       "          1.00000000e+00,   9.83696176e-01,   9.64502381e-01,\n",
       "          9.46333734e-01,   1.00000000e+00,   9.64089977e-01,\n",
       "          9.79056013e-01,   9.65273245e-01,   9.63852299e-01,\n",
       "          9.80860320e-01,   9.83089891e-01,   9.55019320e-01,\n",
       "          9.90775331e-01,   9.62830551e-01,   2.22044605e-16,\n",
       "          9.76229147e-01,   9.76560777e-01,   9.83484793e-01],\n",
       "       [  8.11236937e-01,   9.46634908e-01,   9.68429111e-01,\n",
       "          1.00000000e+00,   9.66052338e-01,   9.72143054e-01,\n",
       "          9.94564326e-01,   1.00000000e+00,   9.74738859e-01,\n",
       "          9.49688383e-01,   9.77207573e-01,   9.93954927e-01,\n",
       "          9.90826541e-01,   9.91895153e-01,   9.68358045e-01,\n",
       "          9.72883189e-01,   9.96235233e-01,   9.76229147e-01,\n",
       "         -2.22044605e-16,   9.81605944e-01,   9.87039603e-01],\n",
       "       [  9.65008303e-01,   9.44485749e-01,   9.68869560e-01,\n",
       "          1.00000000e+00,   9.87383985e-01,   9.72531689e-01,\n",
       "          9.67126858e-01,   1.00000000e+00,   9.48084866e-01,\n",
       "          9.80225394e-01,   9.77525553e-01,   9.85129377e-01,\n",
       "          9.90954521e-01,   9.92008224e-01,   9.51885450e-01,\n",
       "          9.95640390e-01,   9.68579425e-01,   9.76560777e-01,\n",
       "          9.81605944e-01,  -2.22044605e-16,   9.43098838e-01],\n",
       "       [  9.75344955e-01,   9.60884824e-01,   9.78065585e-01,\n",
       "          9.77239294e-01,   9.67737651e-01,   9.80645910e-01,\n",
       "          9.76837682e-01,   1.00000000e+00,   9.63420752e-01,\n",
       "          9.68664374e-01,   9.84164572e-01,   9.89522203e-01,\n",
       "          9.93626583e-01,   9.81962078e-01,   9.66098631e-01,\n",
       "          9.96928232e-01,   9.97384364e-01,   9.83484793e-01,\n",
       "          9.87039603e-01,   9.43098838e-01,   0.00000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh=np.average(dist)\n",
    "clusters = hcluster.fclusterdata(dist, thresh, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 11  7  5  6 13 12 17  3  8 20 15 14 16  9 10 19 18  4  1  2]\n"
     ]
    }
   ],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
