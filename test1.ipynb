{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topics = [\"ml1\", \"ml2\", \"ml3\", \"ml4\", \"ml5\", \"ml6\", \"ml7\", \"ml8\", \"ml9\", \"ml10\", \"ml11\", \"ml12\", \"ml13\", \"ml14\", \"ml15\", \"ml16\", \"ml17\", \"ml18\", \"ml19\"]\n",
    "print \"The titles are \", topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paragraphs are  ['Machine learning is a type of artificial intelligence (AI) that provides computers with the ability to learn without being explicitly programmed.', 'Machine learning focuses on the development of computer programs that can change when exposed to new data.', ' The process of machine learning is similar to that of data mining. Both systems search through data to look for patterns.', ' However, instead of extracting data for human comprehension -- as is the case in data mining applications -- machine learning uses that data to detect patterns in data and adjust program actions accordingly.', '  Machine learning algorithms are often categorized as being supervised or unsupervized. Supervised algorithms can apply what has been learned in the past to new data.', 'Unsupervised algorithms can draw inferences from datasets.', 'Machine learning is the subfield of computer science that gives computers the ability to learn without being explicitly programmed. ', 'Evolved from the study of pattern recognition and computational learning theory in artificial intelligence,[1] machine learning explores the study and construction of algorithms that can learn from and make predictions on data[2] \\xe2\\x80\\x93 such algorithms overcome following strictly static program instructions by making data driven predictions or decisions,[3]:2 through building a model from sample inputs.', 'Machine learning tasks are typically classified into three broad categories, depending on the nature of the learning signal or feedback available to a learning system.', ' These are[13]Supervised learning: The computer is presented with example inputs and their desired outputs, given by a teacher, and the goal is to learn a general rule that maps inputs to outputs.', 'Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input.', ' Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).', 'Machine learning studies computer algorithms for learning to do stuff. ', 'We might, forinstance, be interested in learning to complete a task, or to make accurate predictions,or to behave intelligently.', ' The learning that is being done is always based on some sortof observations or data, such as examples (the most common case in this course), directexperience, or instruction.', ' So in general, machine learning is about learning to do better inthe future based on what was experienced in the past.', 'Machine learning is an artificial intelligence (AI) discipline geared toward the technological development of human knowledge. ', 'Machine learning allows computers to handle new situations via analysis, self-training, observation and experience.', 'Machine learning facilitates the continuous advancement of computing through exposure to new scenarios, testing and adaptation, while employing pattern and trend detection for improved decisions in subsequent (though not identical) situations.']\n"
     ]
    }
   ],
   "source": [
    "paragraphs=[]\n",
    "paragraphs.append(\"Machine learning is a type of artificial intelligence (AI) that provides computers with the ability to learn without being explicitly programmed.\")\n",
    "paragraphs.append(\"Machine learning focuses on the development of computer programs that can change when exposed to new data.\")\n",
    "paragraphs.append(\" The process of machine learning is similar to that of data mining. Both systems search through data to look for patterns.\")\n",
    "paragraphs.append(\" However, instead of extracting data for human comprehension -- as is the case in data mining applications -- machine learning uses that data to detect patterns in data and adjust program actions accordingly.\")\n",
    "paragraphs.append(\"  Machine learning algorithms are often categorized as being supervised or unsupervized. Supervised algorithms can apply what has been learned in the past to new data.\")\n",
    "paragraphs.append(\"Unsupervised algorithms can draw inferences from datasets.\")\n",
    "\n",
    "paragraphs.append(\"Machine learning is the subfield of computer science that gives computers the ability to learn without being explicitly programmed. \")\n",
    "paragraphs.append(\"Evolved from the study of pattern recognition and computational learning theory in artificial intelligence,[1] machine learning explores the study and construction of algorithms that can learn from and make predictions on data[2] â€“ such algorithms overcome following strictly static program instructions by making data driven predictions or decisions,[3]:2 through building a model from sample inputs.\")\n",
    "paragraphs.append(\"Machine learning tasks are typically classified into three broad categories, depending on the nature of the learning signal or feedback available to a learning system.\")\n",
    "paragraphs.append(\" These are[13]Supervised learning: The computer is presented with example inputs and their desired outputs, given by a teacher, and the goal is to learn a general rule that maps inputs to outputs.\")\n",
    "paragraphs.append(\"Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input.\")\n",
    "paragraphs.append(\" Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\")\n",
    "\n",
    "paragraphs.append(\"Machine learning studies computer algorithms for learning to do stuff. \")\n",
    "paragraphs.append(\"We might, forinstance, be interested in learning to complete a task, or to make accurate predictions,or to behave intelligently.\")\n",
    "paragraphs.append(\" The learning that is being done is always based on some sortof observations or data, such as examples (the most common case in this course), directexperience, or instruction.\")\n",
    "paragraphs.append(\" So in general, machine learning is about learning to do better inthe future based on what was experienced in the past.\")\n",
    "\n",
    "paragraphs.append(\"Machine learning is an artificial intelligence (AI) discipline geared toward the technological development of human knowledge. \")\n",
    "paragraphs.append(\"Machine learning allows computers to handle new situations via analysis, self-training, observation and experience.\") \n",
    "paragraphs.append(\"Machine learning facilitates the continuous advancement of computing through exposure to new scenarios, testing and adaptation, while employing pattern and trend detection for improved decisions in subsequent (though not identical) situations.\")\n",
    "\n",
    "print \"The paragraphs are \", paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now we want to break a word into its root using a stemmer.\n",
    "#We use the snowball.\n",
    "#snowball is better than porter stemmer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#First the parageraph is tokenized by sentence then by word\n",
    "def tokenize(paragraph) :\n",
    "    tokenList = [word for sentence in nltk.sent_tokenize(paragraph) for word in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    filteredTokens = []\n",
    "    \n",
    "    for token in tokenList:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filteredTokens.append(token)\n",
    "    return filteredTokens\n",
    "\n",
    "#Next step would be to remove the useless tokens. Useless tokens are raw puntuation, numeric tokens, etc.\n",
    "def stem(filteredTokens) :\n",
    "    stemList = [stemmer.stem(tok) for tok in filteredTokens]\n",
    "    return stemList\n",
    "\n",
    "def tokenizeAndStem(paragraph) :\n",
    "    tokens = [word for sentence in nltk.sent_tokenize(paragraph) for word in nltk.word_tokenize(sentence)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):  #normal regex search\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', 'is', 'a', 'type', 'of', 'artificial', 'intelligence', 'AI', 'that', 'provides', 'computers', 'with', 'the', 'ability', 'to', 'learn', 'without', 'being', 'explicitly', 'programmed', 'Machine', 'learning', 'focuses', 'on', 'the', 'development', 'of', 'computer', 'programs', 'that', 'can', 'change', 'when', 'exposed', 'to', 'new', 'data', 'The', 'process', 'of', 'machine', 'learning', 'is', 'similar', 'to', 'that', 'of', 'data', 'mining', 'Both', 'systems', 'search', 'through', 'data', 'to', 'look', 'for', 'patterns', 'However', 'instead', 'of', 'extracting', 'data', 'for', 'human', 'comprehension', 'as', 'is', 'the', 'case', 'in', 'data', 'mining', 'applications', 'machine', 'learning', 'uses', 'that', 'data', 'to', 'detect', 'patterns', 'in', 'data', 'and', 'adjust', 'program', 'actions', 'accordingly', 'Machine', 'learning', 'algorithms', 'are', 'often', 'categorized', 'as', 'being', 'supervised', 'or', 'unsupervized', 'Supervised', 'algorithms', 'can', 'apply', 'what', 'has', 'been', 'learned', 'in', 'the', 'past', 'to', 'new', 'data', 'Unsupervised', 'algorithms', 'can', 'draw', 'inferences', 'from', 'datasets', 'Machine', 'learning', 'is', 'the', 'subfield', 'of', 'computer', 'science', 'that', 'gives', 'computers', 'the', 'ability', 'to', 'learn', 'without', 'being', 'explicitly', 'programmed', 'Evolved', 'from', 'the', 'study', 'of', 'pattern', 'recognition', 'and', 'computational', 'learning', 'theory', 'in', 'artificial', 'intelligence', 'machine', 'learning', 'explores', 'the', 'study', 'and', 'construction', 'of', 'algorithms', 'that', 'can', 'learn', 'from', 'and', 'make', 'predictions', 'on', 'data', 'such', 'algorithms', 'overcome', 'following', 'strictly', 'static', 'program', 'instructions', 'by', 'making', 'data', 'driven', 'predictions', 'or', 'decisions', 'through', 'building', 'a', 'model', 'from', 'sample', 'inputs', 'Machine', 'learning', 'tasks', 'are', 'typically', 'classified', 'into', 'three', 'broad', 'categories', 'depending', 'on', 'the', 'nature', 'of', 'the', 'learning', 'signal', 'or', 'feedback', 'available', 'to', 'a', 'learning', 'system', 'These', 'are', 'Supervised', 'learning', 'The', 'computer', 'is', 'presented', 'with', 'example', 'inputs', 'and', 'their', 'desired', 'outputs', 'given', 'by', 'a', 'teacher', 'and', 'the', 'goal', 'is', 'to', 'learn', 'a', 'general', 'rule', 'that', 'maps', 'inputs', 'to', 'outputs', 'Unsupervised', 'learning', 'No', 'labels', 'are', 'given', 'to', 'the', 'learning', 'algorithm', 'leaving', 'it', 'on', 'its', 'own', 'to', 'find', 'structure', 'in', 'its', 'input', 'Unsupervised', 'learning', 'can', 'be', 'a', 'goal', 'in', 'itself', 'discovering', 'hidden', 'patterns', 'in', 'data', 'or', 'a', 'means', 'towards', 'an', 'end', 'feature', 'learning', 'Machine', 'learning', 'studies', 'computer', 'algorithms', 'for', 'learning', 'to', 'do', 'stuff', 'We', 'might', 'forinstance', 'be', 'interested', 'in', 'learning', 'to', 'complete', 'a', 'task', 'or', 'to', 'make', 'accurate', 'predictions', 'or', 'to', 'behave', 'intelligently', 'The', 'learning', 'that', 'is', 'being', 'done', 'is', 'always', 'based', 'on', 'some', 'sortof', 'observations', 'or', 'data', 'such', 'as', 'examples', 'the', 'most', 'common', 'case', 'in', 'this', 'course', 'directexperience', 'or', 'instruction', 'So', 'in', 'general', 'machine', 'learning', 'is', 'about', 'learning', 'to', 'do', 'better', 'inthe', 'future', 'based', 'on', 'what', 'was', 'experienced', 'in', 'the', 'past', 'Machine', 'learning', 'is', 'an', 'artificial', 'intelligence', 'AI', 'discipline', 'geared', 'toward', 'the', 'technological', 'development', 'of', 'human', 'knowledge', 'Machine', 'learning', 'allows', 'computers', 'to', 'handle', 'new', 'situations', 'via', 'analysis', 'self-training', 'observation', 'and', 'experience', 'Machine', 'learning', 'facilitates', 'the', 'continuous', 'advancement', 'of', 'computing', 'through', 'exposure', 'to', 'new', 'scenarios', 'testing', 'and', 'adaptation', 'while', 'employing', 'pattern', 'and', 'trend', 'detection', 'for', 'improved', 'decisions', 'in', 'subsequent', 'though', 'not', 'identical', 'situations']\n[u'machin', u'learn', 'is', 'a', u'type', 'of', u'artifici', u'intellig', 'ai', u'that', u'provid', u'comput', u'with', u'the', u'abil', 'to', u'learn', u'without', u'be', u'explicit', u'program', u'machin', u'learn', u'focus', 'on', u'the', u'develop', 'of', u'comput', u'program', u'that', u'can', u'chang', u'when', u'expos', 'to', u'new', u'data', u'the', u'process', 'of', u'machin', u'learn', 'is', u'similar', 'to', u'that', 'of', u'data', u'mine', u'both', u'system', u'search', u'through', u'data', 'to', u'look', u'for', u'pattern', u'howev', u'instead', 'of', u'extract', u'data', u'for', u'human', u'comprehens', 'as', 'is', u'the', u'case', 'in', u'data', u'mine', u'applic', u'machin', u'learn', u'use', u'that', u'data', 'to', u'detect', u'pattern', 'in', u'data', u'and', u'adjust', u'program', u'action', u'accord', u'machin', u'learn', u'algorithm', u'are', u'often', u'categor', 'as', u'be', u'supervis', 'or', u'unsuperv', u'supervis', u'algorithm', u'can', u'appli', u'what', u'has', u'been', u'learn', 'in', u'the', u'past', 'to', u'new', u'data', u'unsupervis', u'algorithm', u'can', u'draw', u'infer', u'from', u'dataset', u'machin', u'learn', 'is', u'the', u'subfield', 'of', u'comput', u'scienc', u'that', u'give', u'comput', u'the', u'abil', 'to', u'learn', u'without', u'be', u'explicit', u'program', u'evolv', u'from', u'the', u'studi', 'of', u'pattern', u'recognit', u'and', u'comput', u'learn', u'theori', 'in', u'artifici', u'intellig', u'machin', u'learn', u'explor', u'the', u'studi', u'and', u'construct', 'of', u'algorithm', u'that', u'can', u'learn', u'from', u'and', u'make', u'predict', 'on', u'data', u'such', u'algorithm', u'overcom', u'follow', u'strict', u'static', u'program', u'instruct', 'by', u'make', u'data', u'driven', u'predict', 'or', u'decis', u'through', u'build', 'a', u'model', u'from', u'sampl', u'input', u'machin', u'learn', u'task', u'are', u'typic', u'classifi', u'into', u'three', u'broad', u'categori', u'depend', 'on', u'the', u'natur', 'of', u'the', u'learn', u'signal', 'or', u'feedback', u'avail', 'to', 'a', u'learn', u'system', u'these', u'are', u'supervis', u'learn', u'the', u'comput', 'is', u'present', u'with', u'exampl', u'input', u'and', u'their', u'desir', u'output', u'given', 'by', 'a', u'teacher', u'and', u'the', u'goal', 'is', 'to', u'learn', 'a', u'general', u'rule', u'that', u'map', u'input', 'to', u'output', u'unsupervis', u'learn', 'no', u'label', u'are', u'given', 'to', u'the', u'learn', u'algorithm', u'leav', 'it', 'on', u'it', u'own', 'to', u'find', u'structur', 'in', u'it', u'input', u'unsupervis', u'learn', u'can', 'be', 'a', u'goal', 'in', u'itself', u'discov', u'hidden', u'pattern', 'in', u'data', 'or', 'a', u'mean', u'toward', 'an', u'end', u'featur', u'learn', u'machin', u'learn', u'studi', u'comput', u'algorithm', u'for', u'learn', 'to', 'do', u'stuff', 'we', u'might', u'forinst', 'be', u'interest', 'in', u'learn', 'to', u'complet', 'a', u'task', 'or', 'to', u'make', u'accur', u'predict', 'or', 'to', u'behav', u'intellig', u'the', u'learn', u'that', 'is', u'be', u'done', 'is', u'alway', u'base', 'on', u'some', u'sortof', u'observ', 'or', u'data', u'such', 'as', u'exampl', u'the', u'most', u'common', u'case', 'in', u'this', u'cours', u'directexperi', 'or', u'instruct', 'so', 'in', u'general', u'machin', u'learn', 'is', u'about', u'learn', 'to', 'do', u'better', u'inth', u'futur', u'base', 'on', u'what', u'was', u'experienc', 'in', u'the', u'past', u'machin', u'learn', 'is', 'an', u'artifici', u'intellig', 'ai', u'disciplin', u'gear', u'toward', u'the', u'technolog', u'develop', 'of', u'human', u'knowledg', u'machin', u'learn', u'allow', u'comput', 'to', u'handl', u'new', u'situat', u'via', u'analysi', u'self-train', u'observ', u'and', u'experi', u'machin', u'learn', u'facilit', u'the', u'continu', u'advanc', 'of', u'comput', u'through', u'exposur', 'to', u'new', u'scenario', u'test', u'and', u'adapt', u'while', u'employ', u'pattern', u'and', u'trend', u'detect', u'for', u'improv', u'decis', 'in', u'subsequ', u'though', u'not', u'ident', u'situat']\n"
     ]
    }
   ],
   "source": [
    "tokenizedParagraphList = []\n",
    "stemmedParagraphList = []\n",
    "for i in paragraphs :\n",
    "    tokenizedParagraph = tokenize(i)\n",
    "    tokenizedParagraphList.extend(tokenizedParagraph)\n",
    "    stemmedParagraphList.extend(stem(tokenizedParagraph))\n",
    "print tokenizedParagraphList\n",
    "print stemmedParagraphList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 435 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "#create a pandas DataFrame with the stemmed vocabulary as the index and the tokenized words as the column.\n",
    "#The benefit of this is it provides an efficient way to look up a stem and return a full token. \n",
    "#The downside here is that stems to tokens are one to many: the stem 'run' could be associated with 'ran', 'runs', 'running', etc.\n",
    "\n",
    "\n",
    "vocabFrame = pd.DataFrame({'words': tokenizedParagraphList}, index = stemmedParagraphList)\n",
    "print 'there are ' + str(vocabFrame.shape[0]) + ' items in vocab_frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\nWall time: 27 ms\n  (0, 353)\t0.0830098533262\n  (0, 295)\t0.128649390276\n  (0, 518)\t0.202072799672\n  (0, 52)\t0.159661722465\n  (0, 282)\t0.146008405178\n  (0, 18)\t0.177263909891\n  (0, 434)\t0.202072799672\n  (0, 100)\t0.110043942903\n  (0, 0)\t0.177263909891\n  (0, 200)\t0.177263909891\n  (0, 427)\t0.134852832684\n  (0, 354)\t0.0830098533262\n  (0, 344)\t0.202072799672\n  (0, 519)\t0.202072799672\n  (0, 53)\t0.159661722465\n  (0, 283)\t0.177263909891\n  (0, 21)\t0.202072799672\n  (0, 435)\t0.202072799672\n  (0, 101)\t0.177263909891\n  (0, 1)\t0.177263909891\n  (0, 311)\t0.177263909891\n  (0, 201)\t0.177263909891\n  (0, 366)\t0.202072799672\n  (0, 345)\t0.202072799672\n  (0, 520)\t0.202072799672\n  :\t:\n  (18, 412)\t0.138659828994\n  (18, 516)\t0.138659828994\n  (18, 160)\t0.138659828994\n  (18, 268)\t0.138659828994\n  (18, 151)\t0.138659828994\n  (18, 489)\t0.138659828994\n  (18, 266)\t0.138659828994\n  (18, 359)\t0.138659828994\n  (18, 316)\t0.138659828994\n  (18, 216)\t0.138659828994\n  (18, 122)\t0.138659828994\n  (18, 17)\t0.138659828994\n  (18, 106)\t0.138659828994\n  (18, 210)\t0.138659828994\n  (18, 390)\t0.138659828994\n  (18, 447)\t0.138659828994\n  (18, 511)\t0.138659828994\n  (18, 11)\t0.138659828994\n  (18, 185)\t0.138659828994\n  (18, 413)\t0.138659828994\n  (18, 517)\t0.138659828994\n  (18, 161)\t0.138659828994\n  (18, 269)\t0.138659828994\n  (18, 152)\t0.138659828994\n  (18, 490)\t0.138659828994\n[u'abil', u'abil learn', u'abil learn explicit', u'accord', u'accur', u'accur predict', u'accur predict behav', u'action', u'action accord', u'adapt', u'adapt employ', u'adapt employ pattern', u'adjust', u'adjust program', u'adjust program action', u'advanc', u'advanc comput', u'advanc comput exposur', u'ai', u'ai disciplin', u'ai disciplin gear', u'ai provid', u'ai provid comput', u'algorithm', u'algorithm appli', u'algorithm appli learn', u'algorithm categor', u'algorithm categor supervis', u'algorithm draw', u'algorithm draw infer', u'algorithm learn', u'algorithm learn make', u'algorithm learn stuff', u'algorithm leav', u'algorithm leav structur', u'algorithm overcom', u'algorithm overcom follow', u'allow', u'allow comput', u'allow comput handl', u'alway', u'alway base', u'alway base sortof', u'analysi', u'analysi self-train', u'analysi self-train observ', u'appli', u'appli learn', u'appli learn past', u'applic', u'applic machin', u'applic machin learn', u'artifici', u'artifici intellig', u'artifici intellig ai', u'artifici intellig machin', u'avail', u'avail learn', u'base', u'base experienc', u'base experienc past', u'base sortof', u'base sortof observ', u'behav', u'behav intellig', u'better', u'better inth', u'better inth futur', u'broad', u'broad categori', u'broad categori depend', u'build', u'build model', u'build model sampl', u'case', u'case cours', u'case cours directexperi', u'case data', u'case data applic', u'categor', u'categor supervis', u'categor supervis unsuperv', u'categori', u'categori depend', u'categori depend natur', u'chang', u'chang expos', u'chang expos new', u'classifi', u'classifi broad', u'classifi broad categori', u'common', u'common case', u'common case cours', u'complet', u'complet task', u'complet task make', u'comprehens', u'comprehens case', u'comprehens case data', u'comput', u'comput abil', u'comput abil learn', u'comput algorithm', u'comput algorithm learn', u'comput exposur', u'comput exposur new', u'comput handl', u'comput handl new', u'comput learn', u'comput learn theori', u'comput present', u'comput present exampl', u'comput program', u'comput program chang', u'comput scienc', u'comput scienc comput', u'construct', u'construct algorithm', u'construct algorithm learn', u'continu', u'continu advanc', u'continu advanc comput', u'cours', u'cours directexperi', u'cours directexperi instruct', u'data', u'data adjust', u'data adjust program', u'data algorithm', u'data algorithm overcom', u'data applic', u'data applic machin', u'data detect', u'data detect pattern', u'data driven', u'data driven predict', u'data exampl', u'data exampl common', u'data human', u'data human comprehens', u'data look', u'data look pattern', u'data mean', u'data mean end', u'data search', u'data search data', u'dataset', u'decis', u'decis build', u'decis build model', u'decis subsequ', u'decis subsequ ident', u'depend', u'depend natur', u'depend natur learn', u'desir', u'desir output', u'desir output given', u'detect', u'detect improv', u'detect improv decis', u'detect pattern', u'detect pattern data', u'develop', u'develop comput', u'develop comput program', u'develop human', u'develop human knowledg', u'directexperi', u'directexperi instruct', u'disciplin', u'disciplin gear', u'disciplin gear technolog', u'discov', u'discov hidden', u'discov hidden pattern', u'draw', u'draw infer', u'draw infer dataset', u'driven', u'driven predict', u'driven predict decis', u'employ', u'employ pattern', u'employ pattern trend', u'end', u'end featur', u'end featur learn', u'evolv', u'evolv studi', u'evolv studi pattern', u'exampl', u'exampl common', u'exampl common case', u'exampl input', u'exampl input desir', u'experi', u'experienc', u'experienc past', u'explicit', u'explicit program', u'explor', u'explor studi', u'explor studi construct', u'expos', u'expos new', u'expos new data', u'exposur', u'exposur new', u'exposur new scenario', u'extract', u'extract data', u'extract data human', u'facilit', u'facilit continu', u'facilit continu advanc', u'featur', u'featur learn', u'feedback', u'feedback avail', u'feedback avail learn', u'focus', u'focus develop', u'focus develop comput', u'follow', u'follow strict', u'follow strict static', u'forinst', u'forinst learn', u'forinst learn complet', u'futur', u'futur base', u'futur base experienc', u'gear', u'gear technolog', u'gear technolog develop', u'general', u'general machin', u'general machin learn', u'general rule', u'general rule map', u'given', u'given learn', u'given learn algorithm', u'given teacher', u'given teacher goal', u'goal', u'goal discov', u'goal discov hidden', u'goal learn', u'goal learn general', u'handl', u'handl new', u'handl new situat', u'hidden', u'hidden pattern', u'hidden pattern data', u'howev', u'howev instead', u'howev instead extract', u'human', u'human comprehens', u'human comprehens case', u'human knowledg', u'ident', u'ident situat', u'improv', u'improv decis', u'improv decis subsequ', u'infer', u'infer dataset', u'input', u'input desir', u'input desir output', u'input output', u'instead', u'instead extract', u'instead extract data', u'instruct', u'instruct make', u'instruct make data', u'intellig', u'intellig ai', u'intellig ai disciplin', u'intellig ai provid', u'intellig machin', u'intellig machin learn', u'inth', u'inth futur', u'inth futur base', u'knowledg', u'label', u'label given', u'label given learn', u'learn', u'learn algorithm', u'learn algorithm categor', u'learn algorithm leav', u'learn allow', u'learn allow comput', u'learn alway', u'learn alway base', u'learn artifici', u'learn artifici intellig', u'learn better', u'learn better inth', u'learn complet', u'learn complet task', u'learn comput', u'learn comput present', u'learn explicit', u'learn explicit program', u'learn explor', u'learn explor studi', u'learn facilit', u'learn facilit continu', u'learn focus', u'learn focus develop', u'learn general', u'learn general rule', u'learn goal', u'learn goal discov', u'learn label', u'learn label given', u'learn learn', u'learn learn better', u'learn make', u'learn make predict', u'learn past', u'learn past new', u'learn signal', u'learn signal feedback', u'learn similar', u'learn similar data', u'learn studi', u'learn studi comput', u'learn stuff', u'learn subfield', u'learn subfield comput', u'learn task', u'learn task typic', u'learn theori', u'learn theori artifici', u'learn type', u'learn type artifici', u'learn use', u'learn use data', u'leav', u'leav structur', u'leav structur input', u'look', u'look pattern', u'machin', u'machin learn', u'machin learn algorithm', u'machin learn allow', u'machin learn artifici', u'machin learn explor', u'machin learn facilit', u'machin learn focus', u'machin learn learn', u'machin learn similar', u'machin learn studi', u'machin learn subfield', u'machin learn task', u'machin learn type', u'machin learn use', u'make', u'make accur', u'make accur predict', u'make data', u'make data driven', u'make predict', u'make predict data', u'map', u'map input', u'map input output', u'mean', u'mean end', u'mean end featur', u'model', u'model sampl', u'model sampl input', u'natur', u'natur learn', u'natur learn signal', u'new', u'new data', u'new scenario', u'new scenario test', u'new situat', u'new situat analysi', u'observ', u'observ data', u'observ data exampl', u'observ experi', u'output', u'output given', u'output given teacher', u'overcom', u'overcom follow', u'overcom follow strict', u'past', u'past new', u'past new data', u'pattern', u'pattern data', u'pattern data adjust', u'pattern data mean', u'pattern recognit', u'pattern recognit comput', u'pattern trend', u'pattern trend detect', u'predict', u'predict behav', u'predict behav intellig', u'predict data', u'predict data algorithm', u'predict decis', u'predict decis build', u'present', u'present exampl', u'present exampl input', u'process', u'process machin', u'process machin learn', u'program', u'program action', u'program action accord', u'program chang', u'program chang expos', u'program instruct', u'program instruct make', u'provid', u'provid comput', u'provid comput abil', u'recognit', u'recognit comput', u'recognit comput learn', u'rule', u'rule map', u'rule map input', u'sampl', u'sampl input', u'scenario', u'scenario test', u'scenario test adapt', u'scienc', u'scienc comput', u'scienc comput abil', u'search', u'search data', u'search data look', u'self-train', u'self-train observ', u'self-train observ experi', u'signal', u'signal feedback', u'signal feedback avail', u'similar', u'similar data', u'similar data search', u'situat', u'situat analysi', u'situat analysi self-train', u'sortof', u'sortof observ', u'sortof observ data', u'static', u'static program', u'static program instruct', u'strict', u'strict static', u'strict static program', u'structur', u'structur input', u'studi', u'studi comput', u'studi comput algorithm', u'studi construct', u'studi construct algorithm', u'studi pattern', u'studi pattern recognit', u'stuff', u'subfield', u'subfield comput', u'subfield comput scienc', u'subsequ', u'subsequ ident', u'subsequ ident situat', u'supervis', u'supervis algorithm', u'supervis algorithm appli', u'supervis learn', u'supervis learn comput', u'supervis unsuperv', u'supervis unsuperv supervis', u'task', u'task make', u'task make accur', u'task typic', u'task typic classifi', u'teacher', u'teacher goal', u'teacher goal learn', u'technolog', u'technolog develop', u'technolog develop human', u'test', u'test adapt', u'test adapt employ', u'theori', u'theori artifici', u'theori artifici intellig', u'trend', u'trend detect', u'trend detect improv', u'type', u'type artifici', u'type artifici intellig', u'typic', u'typic classifi', u'typic classifi broad', u'unsuperv', u'unsuperv supervis', u'unsuperv supervis algorithm', u'unsupervis', u'unsupervis algorithm', u'unsupervis algorithm draw', u'unsupervis learn', u'unsupervis learn goal', u'unsupervis learn label', u'use', u'use data', u'use data detect']\n"
     ]
    }
   ],
   "source": [
    "#for tfidf, there are two important things, max_df & min_df;\n",
    "#max_df - When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "#min_idf - When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature.\n",
    "\n",
    "#it is very important to tune the parameters for best results - follow the link given below\n",
    "\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfVectorizer = TfidfVectorizer(stop_words='english', use_idf=True, tokenizer=tokenizeAndStem, ngram_range=(1,3))\n",
    "#Now fit the vectorizer to synopses\n",
    "%time tfidf_matrix = tfidfVectorizer.fit_transform(paragraphs)\n",
    "print tfidf_matrix\n",
    "print tfidfVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.22044605e-16   9.44228736e-01   9.75732600e-01   9.72848015e-01\n    9.73369106e-01   1.00000000e+00   6.09492488e-01   9.28867093e-01\n    9.67714364e-01   9.79321983e-01   9.81869529e-01   9.83974222e-01\n    9.41801046e-01   9.68728151e-01   9.92558523e-01   9.68736071e-01\n    8.13521572e-01   9.66710362e-01   9.76555530e-01]\n [  9.44228736e-01  -2.22044605e-16   9.46769726e-01   9.34521461e-01\n    9.17180652e-01   1.00000000e+00   9.24573912e-01   9.54928388e-01\n    9.76663946e-01   9.84331795e-01   9.90342606e-01   9.77282428e-01\n    9.50088360e-01   9.95342109e-01   9.82866239e-01   9.75780626e-01\n    9.48034032e-01   9.46702368e-01   9.62464755e-01]\n [  9.75732600e-01   9.46769726e-01   7.77156117e-16   8.91553336e-01\n    9.52133502e-01   1.00000000e+00   9.73345817e-01   9.44923799e-01\n    9.75899217e-01   9.93431024e-01   9.90026131e-01   9.42518464e-01\n    9.66722813e-01   9.95189468e-01   9.68703200e-01   9.74986950e-01\n    9.80509487e-01   9.80790843e-01   9.72742538e-01]\n [  9.72848015e-01   9.34521461e-01   8.91553336e-01  -2.22044605e-16\n    9.54357741e-01   1.00000000e+00   9.70177522e-01   9.41352192e-01\n    9.85220159e-01   9.95971566e-01   9.93883510e-01   9.26257026e-01\n    9.79592715e-01   9.97049934e-01   9.45059805e-01   9.84660710e-01\n    9.67087462e-01   9.88219956e-01   9.68736208e-01]\n [  9.73369106e-01   9.17180652e-01   9.52133502e-01   9.54357741e-01\n   -2.22044605e-16   9.52503557e-01   9.70749864e-01   9.38590647e-01\n    9.71653793e-01   9.49706721e-01   9.18879235e-01   9.74242207e-01\n    9.19693417e-01   9.92322425e-01   9.82612519e-01   9.44114758e-01\n    9.80855207e-01   9.62894598e-01   9.73868251e-01]\n [  1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00\n    9.52503557e-01  -2.22044605e-16   1.00000000e+00   9.72748037e-01\n    1.00000000e+00   1.00000000e+00   9.28833881e-01   9.63286092e-01\n    9.62908973e-01   1.00000000e+00   1.00000000e+00   1.00000000e+00\n    1.00000000e+00   1.00000000e+00   1.00000000e+00]\n [  6.09492488e-01   9.24573912e-01   9.73345817e-01   9.70177522e-01\n    9.70749864e-01   1.00000000e+00  -1.11022302e-15   9.55175730e-01\n    9.64538958e-01   9.67691967e-01   9.80086334e-01   9.82398031e-01\n    9.17838111e-01   9.90395370e-01   9.91826628e-01   9.65661154e-01\n    9.76049907e-01   9.50476780e-01   9.65122912e-01]\n [  9.28867093e-01   9.54928388e-01   9.44923799e-01   9.41352192e-01\n    9.38590647e-01   9.72748037e-01   9.55175730e-01   1.11022302e-15\n    9.78506591e-01   9.68045309e-01   9.52161551e-01   9.65608081e-01\n    8.74721895e-01   9.15136291e-01   9.67687259e-01   9.79953674e-01\n    9.50946577e-01   9.81199162e-01   9.69611317e-01]\n [  9.67714364e-01   9.76663946e-01   9.75899217e-01   9.85220159e-01\n    9.71653793e-01   1.00000000e+00   9.64538958e-01   9.78506591e-01\n   -1.33226763e-15   9.85021283e-01   9.77257374e-01   9.79897474e-01\n    9.55727636e-01   9.61263608e-01   9.90665509e-01   9.66722342e-01\n    9.78344262e-01   9.78656874e-01   9.84968948e-01]\n [  9.79321983e-01   9.84331795e-01   9.93431024e-01   9.95971566e-01\n    9.49706721e-01   1.00000000e+00   9.67691967e-01   9.68045309e-01\n    9.85021283e-01  -1.99840144e-15   9.21789100e-01   9.66485743e-01\n    9.71644830e-01   9.93690919e-01   9.74244616e-01   9.64324559e-01\n    9.94097452e-01   9.85669879e-01   9.89907908e-01]\n [  9.81869529e-01   9.90342606e-01   9.90026131e-01   9.93883510e-01\n    9.18879235e-01   9.28833881e-01   9.80086334e-01   9.52161551e-01\n    9.77257374e-01   9.21789100e-01  -8.88178420e-16   9.22074803e-01\n    9.47820947e-01   9.90420737e-01   9.91848214e-01   9.81312444e-01\n    9.91037988e-01   9.91167360e-01   9.93779549e-01]\n [  9.83974222e-01   9.77282428e-01   9.42518464e-01   9.26257026e-01\n    9.74242207e-01   9.63286092e-01   9.82398031e-01   9.65608081e-01\n    9.79897474e-01   9.66485743e-01   9.22074803e-01   0.00000000e+00\n    9.78024312e-01   9.91532755e-01   9.80824146e-01   9.83481807e-01\n    9.92078352e-01   9.92192705e-01   9.82418883e-01]\n [  9.41801046e-01   9.50088360e-01   9.66722813e-01   9.79592715e-01\n    9.19693417e-01   9.62908973e-01   9.17838111e-01   8.74721895e-01\n    9.55727636e-01   9.71644830e-01   9.47820947e-01   9.78024312e-01\n    0.00000000e+00   9.88008822e-01   9.89795717e-01   9.57128673e-01\n    9.70098812e-01   9.54350877e-01   9.67851273e-01]\n [  9.68728151e-01   9.95342109e-01   9.95189468e-01   9.97049934e-01\n    9.92322425e-01   1.00000000e+00   9.90395370e-01   9.15136291e-01\n    9.61263608e-01   9.93690919e-01   9.90420737e-01   9.91532755e-01\n    9.88008822e-01   0.00000000e+00   9.96068284e-01   9.90986740e-01\n    9.73406735e-01   9.95739898e-01   9.96999793e-01]\n [  9.92558523e-01   9.82866239e-01   9.68703200e-01   9.45059805e-01\n    9.82612519e-01   1.00000000e+00   9.91826628e-01   9.67687259e-01\n    9.90665509e-01   9.74244616e-01   9.91848214e-01   9.80824146e-01\n    9.89795717e-01   9.96068284e-01   0.00000000e+00   9.63205423e-01\n    9.96321629e-01   9.68843487e-01   9.97446876e-01]\n [  9.68736071e-01   9.75780626e-01   9.74986950e-01   9.84660710e-01\n    9.44114758e-01   1.00000000e+00   9.65661154e-01   9.79953674e-01\n    9.66722342e-01   9.64324559e-01   9.81312444e-01   9.83481807e-01\n    9.57128673e-01   9.90986740e-01   9.63205423e-01   1.11022302e-16\n    9.77524546e-01   9.77848991e-01   9.84399990e-01]\n [  8.13521572e-01   9.48034032e-01   9.80509487e-01   9.67087462e-01\n    9.80855207e-01   1.00000000e+00   9.76049907e-01   9.50946577e-01\n    9.78344262e-01   9.94097452e-01   9.91037988e-01   9.92078352e-01\n    9.70098812e-01   9.73406735e-01   9.96321629e-01   9.77524546e-01\n   -2.22044605e-16   9.82739628e-01   9.87844258e-01]\n [  9.66710362e-01   9.46702368e-01   9.80790843e-01   9.88219956e-01\n    9.62894598e-01   1.00000000e+00   9.50476780e-01   9.81199162e-01\n    9.78656874e-01   9.85669879e-01   9.91167360e-01   9.92192705e-01\n    9.54350877e-01   9.95739898e-01   9.68843487e-01   9.77848991e-01\n    9.82739628e-01   7.77156117e-16   9.44661818e-01]\n [  9.76555530e-01   9.62464755e-01   9.72742538e-01   9.68736208e-01\n    9.73868251e-01   1.00000000e+00   9.65122912e-01   9.69611317e-01\n    9.84968948e-01   9.89907908e-01   9.93779549e-01   9.82418883e-01\n    9.67851273e-01   9.96999793e-01   9.97446876e-01   9.84399990e-01\n    9.87844258e-01   9.44661818e-01   2.10942375e-15]]\n"
     ]
    }
   ],
   "source": [
    "#Now we calculate the cosine similarity as follows. This will gives us the distance which wil help us in clustering in the later stage.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "print dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 0 ns, total: 84 ms\nWall time: 88.6 ms\n[1, 4, 4, 4, 4, 2, 1, 0, 0, 2, 2, 2, 0, 1, 3, 0, 1, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 4, 4, 2, 1, 0, 0, 2, 2, 2, 0, 1, 3, 0, 1, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()\n",
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  topics  cluster\n1    ml1        1\n4    ml2        4\n4    ml3        4\n4    ml4        4\n4    ml5        4\n2    ml6        2\n1    ml7        1\n0    ml8        0\n0    ml9        0\n2   ml10        2\n2   ml11        2\n2   ml12        2\n0   ml13        0\n1   ml14        1\n3   ml15        3\n0   ml16        0\n1   ml17        1\n4   ml18        4\n4   ml19        4\n"
     ]
    }
   ],
   "source": [
    "#Converting to a pandas da frame.\n",
    "\n",
    "texts = { 'topics': topics, 'paragraphs': paragraphs, 'cluster': clusters}\n",
    "\n",
    "frame = pd.DataFrame(texts, index = [clusters] , columns = ['topics', 'cluster'])\n",
    "\n",
    "print frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}